--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/collect_indoor3d_data.py	2024-06-30 23:19:41.944057+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/collect_indoor3d_data.py	2024-07-08 11:53:39.207181+00:00
@@ -1,28 +1,33 @@
 import os
 import sys
+
 BASE_DIR = os.path.dirname(os.path.abspath(__file__))
 ROOT_DIR = os.path.dirname(BASE_DIR)
-DATA_PATH = os.path.join(ROOT_DIR, 'data/Stanford3dDataset_v1.2_Aligned_Version')
+DATA_PATH = os.path.join(ROOT_DIR, "data/Stanford3dDataset_v1.2_Aligned_Version")
 import indoor3d_util
 
-anno_paths = [line.rstrip() for line in open(os.path.join(BASE_DIR, 'meta/anno_paths.txt'))]
+anno_paths = [
+    line.rstrip() for line in open(os.path.join(BASE_DIR, "meta/anno_paths.txt"))
+]
 anno_paths = [os.path.join(DATA_PATH, p) for p in anno_paths]
 
-output_folder = os.path.join(ROOT_DIR, 'data/stanford_indoor3d') 
+output_folder = os.path.join(ROOT_DIR, "data/stanford_indoor3d")
 if not os.path.exists(output_folder):
     os.mkdir(output_folder)
 
 revise_file = os.path.join(DATA_PATH, "Area_5/hallway_6/Annotations/ceiling_1.txt")
 with open(revise_file, "r") as f:
     data = f.read()
-    data = data[:5545347] + ' ' + data[5545348:]
+    data = data[:5545347] + " " + data[5545348:]
     f.close()
 with open(revise_file, "w") as f:
     f.write(data)
     f.close()
 
 for anno_path in anno_paths:
-	print(anno_path)
-	elements = anno_path.split('/')
-	out_filename = elements[-3]+'_'+elements[-2]+'.npy' # Area_1_hallway_1.npy
-	indoor3d_util.collect_point_label(anno_path, os.path.join(output_folder, out_filename), 'numpy')
\ No newline at end of file
+    print(anno_path)
+    elements = anno_path.split("/")
+    out_filename = elements[-3] + "_" + elements[-2] + ".npy"  # Area_1_hallway_1.npy
+    indoor3d_util.collect_point_label(
+        anno_path, os.path.join(output_folder, out_filename), "numpy"
+    )
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/data_prep_util.py	2024-06-30 23:19:41.949493+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/data_prep_util.py	2024-07-08 11:53:39.638011+00:00
@@ -1,145 +1,168 @@
 import os
 import sys
+
 BASE_DIR = os.path.dirname(os.path.abspath(__file__))
 sys.path.append(BASE_DIR)
-from plyfile import (PlyData, PlyElement, make2d, PlyParseError, PlyProperty)
+from plyfile import PlyData, PlyElement, make2d, PlyParseError, PlyProperty
 import numpy as np
 import h5py
 
-SAMPLING_BIN = os.path.join(BASE_DIR, 'third_party/mesh_sampling/build/pcsample')
+SAMPLING_BIN = os.path.join(BASE_DIR, "third_party/mesh_sampling/build/pcsample")
 
 SAMPLING_POINT_NUM = 2048
 SAMPLING_LEAF_SIZE = 0.005
 
-MODELNET40_PATH = '../datasets/modelnet40'
+MODELNET40_PATH = "../datasets/modelnet40"
+
+
 def export_ply(pc, filename):
-	vertex = np.zeros(pc.shape[0], dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4')])
-	for i in range(pc.shape[0]):
-		vertex[i] = (pc[i][0], pc[i][1], pc[i][2])
-	ply_out = PlyData([PlyElement.describe(vertex, 'vertex', comments=['vertices'])])
-	ply_out.write(filename)
+    vertex = np.zeros(pc.shape[0], dtype=[("x", "f4"), ("y", "f4"), ("z", "f4")])
+    for i in range(pc.shape[0]):
+        vertex[i] = (pc[i][0], pc[i][1], pc[i][2])
+    ply_out = PlyData([PlyElement.describe(vertex, "vertex", comments=["vertices"])])
+    ply_out.write(filename)
+
 
 # Sample points on the obj shape
 def get_sampling_command(obj_filename, ply_filename):
-    cmd = SAMPLING_BIN + ' ' + obj_filename
-    cmd += ' ' + ply_filename
-    cmd += ' -n_samples %d ' % SAMPLING_POINT_NUM
-    cmd += ' -leaf_size %f ' % SAMPLING_LEAF_SIZE
+    cmd = SAMPLING_BIN + " " + obj_filename
+    cmd += " " + ply_filename
+    cmd += " -n_samples %d " % SAMPLING_POINT_NUM
+    cmd += " -leaf_size %f " % SAMPLING_LEAF_SIZE
     return cmd
+
 
 # --------------------------------------------------------------
 # Following are the helper functions to load MODELNET40 shapes
 # --------------------------------------------------------------
 
+
 # Read in the list of categories in MODELNET40
 def get_category_names():
-    shape_names_file = os.path.join(MODELNET40_PATH, 'shape_names.txt')
+    shape_names_file = os.path.join(MODELNET40_PATH, "shape_names.txt")
     shape_names = [line.rstrip() for line in open(shape_names_file)]
     return shape_names
 
-# Return all the filepaths for the shapes in MODELNET40 
+
+# Return all the filepaths for the shapes in MODELNET40
 def get_obj_filenames():
-    obj_filelist_file = os.path.join(MODELNET40_PATH, 'filelist.txt')
-    obj_filenames = [os.path.join(MODELNET40_PATH, line.rstrip()) for line in open(obj_filelist_file)]
-    print('Got %d obj files in modelnet40.' % len(obj_filenames))
+    obj_filelist_file = os.path.join(MODELNET40_PATH, "filelist.txt")
+    obj_filenames = [
+        os.path.join(MODELNET40_PATH, line.rstrip()) for line in open(obj_filelist_file)
+    ]
+    print("Got %d obj files in modelnet40." % len(obj_filenames))
     return obj_filenames
+
 
 # Helper function to create the father folder and all subdir folders if not exist
 def batch_mkdir(output_folder, subdir_list):
     if not os.path.exists(output_folder):
         os.mkdir(output_folder)
     for subdir in subdir_list:
         if not os.path.exists(os.path.join(output_folder, subdir)):
             os.mkdir(os.path.join(output_folder, subdir))
 
+
 # ----------------------------------------------------------------
 # Following are the helper functions to load save/load HDF5 files
 # ----------------------------------------------------------------
 
+
 # Write numpy array data and label to h5_filename
-def save_h5_data_label_normal(h5_filename, data, label, normal, 
-		data_dtype='float32', label_dtype='uint8', normal_dtype='float32'):
+def save_h5_data_label_normal(
+    h5_filename,
+    data,
+    label,
+    normal,
+    data_dtype="float32",
+    label_dtype="uint8",
+    normal_dtype="float32",
+):
     h5_fout = h5py.File(h5_filename)
     h5_fout.create_dataset(
-            'data', data=data,
-            compression='gzip', compression_opts=4,
-            dtype=data_dtype)
+        "data", data=data, compression="gzip", compression_opts=4, dtype=data_dtype
+    )
     h5_fout.create_dataset(
-            'normal', data=normal,
-            compression='gzip', compression_opts=4,
-            dtype=normal_dtype)
+        "normal",
+        data=normal,
+        compression="gzip",
+        compression_opts=4,
+        dtype=normal_dtype,
+    )
     h5_fout.create_dataset(
-            'label', data=label,
-            compression='gzip', compression_opts=1,
-            dtype=label_dtype)
+        "label", data=label, compression="gzip", compression_opts=1, dtype=label_dtype
+    )
     h5_fout.close()
 
 
 # Write numpy array data and label to h5_filename
-def save_h5(h5_filename, data, label, data_dtype='uint8', label_dtype='uint8'):
+def save_h5(h5_filename, data, label, data_dtype="uint8", label_dtype="uint8"):
     h5_fout = h5py.File(h5_filename, "w")
     h5_fout.create_dataset(
-            'data', data=data,
-            compression='gzip', compression_opts=4,
-            dtype=data_dtype)
+        "data", data=data, compression="gzip", compression_opts=4, dtype=data_dtype
+    )
     h5_fout.create_dataset(
-            'label', data=label,
-            compression='gzip', compression_opts=1,
-            dtype=label_dtype)
+        "label", data=label, compression="gzip", compression_opts=1, dtype=label_dtype
+    )
     h5_fout.close()
+
 
 # Read numpy array data and label from h5_filename
 def load_h5_data_label_normal(h5_filename):
     f = h5py.File(h5_filename)
-    data = f['data'][:]
-    label = f['label'][:]
-    normal = f['normal'][:]
+    data = f["data"][:]
+    label = f["label"][:]
+    normal = f["normal"][:]
     return (data, label, normal)
+
 
 # Read numpy array data and label from h5_filename
 def load_h5_data_label_seg(h5_filename):
     f = h5py.File(h5_filename)
-    data = f['data'][:]
-    label = f['label'][:]
-    seg = f['pid'][:]
+    data = f["data"][:]
+    label = f["label"][:]
+    seg = f["pid"][:]
     return (data, label, seg)
+
 
 # Read numpy array data and label from h5_filename
 def load_h5(h5_filename):
     f = h5py.File(h5_filename)
-    data = f['data'][:]
-    label = f['label'][:]
+    data = f["data"][:]
+    label = f["label"][:]
     return (data, label)
+
 
 # ----------------------------------------------------------------
 # Following are the helper functions to load save/load PLY files
 # ----------------------------------------------------------------
 
+
 # Load PLY file
 def load_ply_data(filename, point_num):
     plydata = PlyData.read(filename)
-    pc = plydata['vertex'].data[:point_num]
-    pc_array = np.array([[x, y, z] for x,y,z in pc])
+    pc = plydata["vertex"].data[:point_num]
+    pc_array = np.array([[x, y, z] for x, y, z in pc])
     return pc_array
+
 
 # Load PLY file
 def load_ply_normal(filename, point_num):
     plydata = PlyData.read(filename)
-    pc = plydata['normal'].data[:point_num]
-    pc_array = np.array([[x, y, z] for x,y,z in pc])
+    pc = plydata["normal"].data[:point_num]
+    pc_array = np.array([[x, y, z] for x, y, z in pc])
     return pc_array
+
 
 # Make up rows for Nxk array
 # Input Pad is 'edge' or 'constant'
-def pad_arr_rows(arr, row, pad='edge'):
-    assert(len(arr.shape) == 2)
-    assert(arr.shape[0] <= row)
-    assert(pad == 'edge' or pad == 'constant')
+def pad_arr_rows(arr, row, pad="edge"):
+    assert len(arr.shape) == 2
+    assert arr.shape[0] <= row
+    assert pad == "edge" or pad == "constant"
     if arr.shape[0] == row:
         return arr
-    if pad == 'edge':
-        return np.lib.pad(arr, ((0, row-arr.shape[0]), (0, 0)), 'edge')
-    if pad == 'constant':
-        return np.lib.pad(arr, ((0, row-arr.shape[0]), (0, 0)), 'constant', (0, 0))
-
-
+    if pad == "edge":
+        return np.lib.pad(arr, ((0, row - arr.shape[0]), (0, 0)), "edge")
+    if pad == "constant":
+        return np.lib.pad(arr, ((0, row - arr.shape[0]), (0, 0)), "constant", (0, 0))
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/main_cls.py	2024-06-30 23:19:41.923325+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/main_cls.py	2024-07-08 11:53:39.911342+00:00
@@ -28,33 +28,46 @@
 from util import cal_loss, IOStream
 import sklearn.metrics as metrics
 
 
 def _init_():
-    if not os.path.exists('outputs'):
-        os.makedirs('outputs')
-    if not os.path.exists('outputs/'+args.exp_name):
-        os.makedirs('outputs/'+args.exp_name)
-    if not os.path.exists('outputs/'+args.exp_name+'/'+'models'):
-        os.makedirs('outputs/'+args.exp_name+'/'+'models')
-    os.system('cp main_cls.py outputs'+'/'+args.exp_name+'/'+'main_cls.py.backup')
-    os.system('cp model.py outputs' + '/' + args.exp_name + '/' + 'model.py.backup')
-    os.system('cp util.py outputs' + '/' + args.exp_name + '/' + 'util.py.backup')
-    os.system('cp data.py outputs' + '/' + args.exp_name + '/' + 'data.py.backup')
+    if not os.path.exists("outputs"):
+        os.makedirs("outputs")
+    if not os.path.exists("outputs/" + args.exp_name):
+        os.makedirs("outputs/" + args.exp_name)
+    if not os.path.exists("outputs/" + args.exp_name + "/" + "models"):
+        os.makedirs("outputs/" + args.exp_name + "/" + "models")
+    os.system(
+        "cp main_cls.py outputs" + "/" + args.exp_name + "/" + "main_cls.py.backup"
+    )
+    os.system("cp model.py outputs" + "/" + args.exp_name + "/" + "model.py.backup")
+    os.system("cp util.py outputs" + "/" + args.exp_name + "/" + "util.py.backup")
+    os.system("cp data.py outputs" + "/" + args.exp_name + "/" + "data.py.backup")
+
 
 def train(args, io):
-    train_loader = DataLoader(ModelNet40(partition='train', num_points=args.num_points), num_workers=8,
-                              batch_size=args.batch_size, shuffle=True, drop_last=True)
-    test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=8,
-                             batch_size=args.test_batch_size, shuffle=True, drop_last=False)
+    train_loader = DataLoader(
+        ModelNet40(partition="train", num_points=args.num_points),
+        num_workers=8,
+        batch_size=args.batch_size,
+        shuffle=True,
+        drop_last=True,
+    )
+    test_loader = DataLoader(
+        ModelNet40(partition="test", num_points=args.num_points),
+        num_workers=8,
+        batch_size=args.test_batch_size,
+        shuffle=True,
+        drop_last=False,
+    )
 
     device = torch.device("cuda" if args.cuda else "cpu")
 
-    #Try to load models
-    if args.model == 'pointnet':
+    # Try to load models
+    if args.model == "pointnet":
         model = PointNet(args).to(device)
-    elif args.model == 'dgcnn':
+    elif args.model == "dgcnn":
         model = DGCNN_cls(args).to(device)
     else:
         raise Exception("Not implemented")
 
     print(str(model))
@@ -62,20 +75,25 @@
     model = nn.DataParallel(model)
     print("Let's use", torch.cuda.device_count(), "GPUs!")
 
     if args.use_sgd:
         print("Use SGD")
-        opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)
+        opt = optim.SGD(
+            model.parameters(),
+            lr=args.lr * 100,
+            momentum=args.momentum,
+            weight_decay=1e-4,
+        )
     else:
         print("Use Adam")
         opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)
 
-    if args.scheduler == 'cos':
+    if args.scheduler == "cos":
         scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=1e-3)
-    elif args.scheduler == 'step':
+    elif args.scheduler == "step":
         scheduler = StepLR(opt, step_size=20, gamma=0.7)
-    
+
     criterion = cal_loss
 
     best_test_acc = 0
     for epoch in range(args.epochs):
         ####################
@@ -98,27 +116,27 @@
             preds = logits.max(dim=1)[1]
             count += batch_size
             train_loss += loss.item() * batch_size
             train_true.append(label.cpu().numpy())
             train_pred.append(preds.detach().cpu().numpy())
-        if args.scheduler == 'cos':
+        if args.scheduler == "cos":
             scheduler.step()
-        elif args.scheduler == 'step':
-            if opt.param_groups[0]['lr'] > 1e-5:
+        elif args.scheduler == "step":
+            if opt.param_groups[0]["lr"] > 1e-5:
                 scheduler.step()
-            if opt.param_groups[0]['lr'] < 1e-5:
+            if opt.param_groups[0]["lr"] < 1e-5:
                 for param_group in opt.param_groups:
-                    param_group['lr'] = 1e-5
+                    param_group["lr"] = 1e-5
 
         train_true = np.concatenate(train_true)
         train_pred = np.concatenate(train_pred)
-        outstr = 'Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f' % (epoch,
-                                                                                 train_loss*1.0/count,
-                                                                                 metrics.accuracy_score(
-                                                                                     train_true, train_pred),
-                                                                                 metrics.balanced_accuracy_score(
-                                                                                     train_true, train_pred))
+        outstr = "Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f" % (
+            epoch,
+            train_loss * 1.0 / count,
+            metrics.accuracy_score(train_true, train_pred),
+            metrics.balanced_accuracy_score(train_true, train_pred),
+        )
         io.cprint(outstr)
 
         ####################
         # Test
         ####################
@@ -140,30 +158,36 @@
             test_pred.append(preds.detach().cpu().numpy())
         test_true = np.concatenate(test_true)
         test_pred = np.concatenate(test_pred)
         test_acc = metrics.accuracy_score(test_true, test_pred)
         avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)
-        outstr = 'Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f' % (epoch,
-                                                                              test_loss*1.0/count,
-                                                                              test_acc,
-                                                                              avg_per_class_acc)
+        outstr = "Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f" % (
+            epoch,
+            test_loss * 1.0 / count,
+            test_acc,
+            avg_per_class_acc,
+        )
         io.cprint(outstr)
         if test_acc >= best_test_acc:
             best_test_acc = test_acc
-            torch.save(model.state_dict(), 'outputs/%s/models/model.t7' % args.exp_name)
+            torch.save(model.state_dict(), "outputs/%s/models/model.t7" % args.exp_name)
 
 
 def test(args, io):
-    test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points),
-                             batch_size=args.test_batch_size, shuffle=True, drop_last=False)
+    test_loader = DataLoader(
+        ModelNet40(partition="test", num_points=args.num_points),
+        batch_size=args.test_batch_size,
+        shuffle=True,
+        drop_last=False,
+    )
 
     device = torch.device("cuda" if args.cuda else "cpu")
 
-    #Try to load models
-    if args.model == 'pointnet':
+    # Try to load models
+    if args.model == "pointnet":
         model = PointNet(args).to(device)
-    elif args.model == 'dgcnn':
+    elif args.model == "dgcnn":
         model = DGCNN_cls(args).to(device)
     else:
         raise Exception("Not implemented")
 
     model = nn.DataParallel(model)
@@ -184,70 +208,128 @@
         test_pred.append(preds.detach().cpu().numpy())
     test_true = np.concatenate(test_true)
     test_pred = np.concatenate(test_pred)
     test_acc = metrics.accuracy_score(test_true, test_pred)
     avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)
-    outstr = 'Test :: test acc: %.6f, test avg acc: %.6f'%(test_acc, avg_per_class_acc)
+    outstr = "Test :: test acc: %.6f, test avg acc: %.6f" % (
+        test_acc,
+        avg_per_class_acc,
+    )
     io.cprint(outstr)
 
 
 if __name__ == "__main__":
     # Training settings
-    parser = argparse.ArgumentParser(description='Point Cloud Recognition')
-    parser.add_argument('--exp_name', type=str, default='exp', metavar='N',
-                        help='Name of the experiment')
-    parser.add_argument('--model', type=str, default='dgcnn', metavar='N',
-                        choices=['pointnet', 'dgcnn'],
-                        help='Model to use, [pointnet, dgcnn]')
-    parser.add_argument('--dataset', type=str, default='modelnet40', metavar='N',
-                        choices=['modelnet40'])
-    parser.add_argument('--batch_size', type=int, default=32, metavar='batch_size',
-                        help='Size of batch)')
-    parser.add_argument('--test_batch_size', type=int, default=16, metavar='batch_size',
-                        help='Size of batch)')
-    parser.add_argument('--epochs', type=int, default=250, metavar='N',
-                        help='number of episode to train ')
-    parser.add_argument('--use_sgd', type=bool, default=True,
-                        help='Use SGD')
-    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',
-                        help='learning rate (default: 0.001, 0.1 if using sgd)')
-    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',
-                        help='SGD momentum (default: 0.9)')
-    parser.add_argument('--scheduler', type=str, default='cos', metavar='N',
-                        choices=['cos', 'step'],
-                        help='Scheduler to use, [cos, step]')
-    parser.add_argument('--no_cuda', type=bool, default=False,
-                        help='enables CUDA training')
-    parser.add_argument('--seed', type=int, default=1, metavar='S',
-                        help='random seed (default: 1)')
-    parser.add_argument('--eval', type=bool,  default=False,
-                        help='evaluate the model')
-    parser.add_argument('--num_points', type=int, default=1024,
-                        help='num of points to use')
-    parser.add_argument('--dropout', type=float, default=0.5,
-                        help='initial dropout rate')
-    parser.add_argument('--emb_dims', type=int, default=1024, metavar='N',
-                        help='Dimension of embeddings')
-    parser.add_argument('--k', type=int, default=20, metavar='N',
-                        help='Num of nearest neighbors to use')
-    parser.add_argument('--model_path', type=str, default='', metavar='N',
-                        help='Pretrained model path')
+    parser = argparse.ArgumentParser(description="Point Cloud Recognition")
+    parser.add_argument(
+        "--exp_name",
+        type=str,
+        default="exp",
+        metavar="N",
+        help="Name of the experiment",
+    )
+    parser.add_argument(
+        "--model",
+        type=str,
+        default="dgcnn",
+        metavar="N",
+        choices=["pointnet", "dgcnn"],
+        help="Model to use, [pointnet, dgcnn]",
+    )
+    parser.add_argument(
+        "--dataset", type=str, default="modelnet40", metavar="N", choices=["modelnet40"]
+    )
+    parser.add_argument(
+        "--batch_size",
+        type=int,
+        default=32,
+        metavar="batch_size",
+        help="Size of batch)",
+    )
+    parser.add_argument(
+        "--test_batch_size",
+        type=int,
+        default=16,
+        metavar="batch_size",
+        help="Size of batch)",
+    )
+    parser.add_argument(
+        "--epochs",
+        type=int,
+        default=250,
+        metavar="N",
+        help="number of episode to train ",
+    )
+    parser.add_argument("--use_sgd", type=bool, default=True, help="Use SGD")
+    parser.add_argument(
+        "--lr",
+        type=float,
+        default=0.001,
+        metavar="LR",
+        help="learning rate (default: 0.001, 0.1 if using sgd)",
+    )
+    parser.add_argument(
+        "--momentum",
+        type=float,
+        default=0.9,
+        metavar="M",
+        help="SGD momentum (default: 0.9)",
+    )
+    parser.add_argument(
+        "--scheduler",
+        type=str,
+        default="cos",
+        metavar="N",
+        choices=["cos", "step"],
+        help="Scheduler to use, [cos, step]",
+    )
+    parser.add_argument(
+        "--no_cuda", type=bool, default=False, help="enables CUDA training"
+    )
+    parser.add_argument(
+        "--seed", type=int, default=1, metavar="S", help="random seed (default: 1)"
+    )
+    parser.add_argument("--eval", type=bool, default=False, help="evaluate the model")
+    parser.add_argument(
+        "--num_points", type=int, default=1024, help="num of points to use"
+    )
+    parser.add_argument(
+        "--dropout", type=float, default=0.5, help="initial dropout rate"
+    )
+    parser.add_argument(
+        "--emb_dims",
+        type=int,
+        default=1024,
+        metavar="N",
+        help="Dimension of embeddings",
+    )
+    parser.add_argument(
+        "--k", type=int, default=20, metavar="N", help="Num of nearest neighbors to use"
+    )
+    parser.add_argument(
+        "--model_path", type=str, default="", metavar="N", help="Pretrained model path"
+    )
     args = parser.parse_args()
 
     _init_()
 
-    io = IOStream('outputs/' + args.exp_name + '/run.log')
+    io = IOStream("outputs/" + args.exp_name + "/run.log")
     io.cprint(str(args))
 
     args.cuda = not args.no_cuda and torch.cuda.is_available()
     torch.manual_seed(args.seed)
     if args.cuda:
         io.cprint(
-            'Using GPU : ' + str(torch.cuda.current_device()) + ' from ' + str(torch.cuda.device_count()) + ' devices')
+            "Using GPU : "
+            + str(torch.cuda.current_device())
+            + " from "
+            + str(torch.cuda.device_count())
+            + " devices"
+        )
         torch.cuda.manual_seed(args.seed)
     else:
-        io.cprint('Using CPU')
+        io.cprint("Using CPU")
 
     if not args.eval:
         train(args, io)
     else:
         test(args, io)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/gen_indoor3d_h5.py	2024-06-30 23:19:41.949493+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/gen_indoor3d_h5.py	2024-07-08 11:53:40.011365+00:00
@@ -1,92 +1,118 @@
 import os
 import numpy as np
 import sys
 import json
+
 BASE_DIR = os.path.dirname(os.path.abspath(__file__))
 ROOT_DIR = os.path.dirname(BASE_DIR)
 sys.path.append(BASE_DIR)
 import data_prep_util
 import indoor3d_util
 
 # Constants
-data_dir = os.path.join(ROOT_DIR, 'data')
-indoor3d_data_dir = os.path.join(data_dir, 'stanford_indoor3d')
+data_dir = os.path.join(ROOT_DIR, "data")
+indoor3d_data_dir = os.path.join(data_dir, "stanford_indoor3d")
 NUM_POINT = 4096
 H5_BATCH_SIZE = 1000
 data_dim = [NUM_POINT, 9]
 label_dim = [NUM_POINT]
-data_dtype = 'float32'
-label_dtype = 'uint8'
+data_dtype = "float32"
+label_dtype = "uint8"
 
 # Set paths
-filelist = os.path.join(BASE_DIR, 'meta/all_data_label.txt')
-data_label_files = [os.path.join(indoor3d_data_dir, line.rstrip()) for line in open(filelist)]
-output_dir = os.path.join(data_dir, 'indoor3d_sem_seg_hdf5_data_test')
+filelist = os.path.join(BASE_DIR, "meta/all_data_label.txt")
+data_label_files = [
+    os.path.join(indoor3d_data_dir, line.rstrip()) for line in open(filelist)
+]
+output_dir = os.path.join(data_dir, "indoor3d_sem_seg_hdf5_data_test")
 if not os.path.exists(output_dir):
     os.mkdir(output_dir)
-output_filename_prefix = os.path.join(output_dir, 'ply_data_all')
-output_room_filelist = os.path.join(output_dir, 'room_filelist.txt')
-output_all_file = os.path.join(output_dir, 'all_files.txt')
-fout_room = open(output_room_filelist, 'w')
-all_file = open(output_all_file, 'w')
+output_filename_prefix = os.path.join(output_dir, "ply_data_all")
+output_room_filelist = os.path.join(output_dir, "room_filelist.txt")
+output_all_file = os.path.join(output_dir, "all_files.txt")
+fout_room = open(output_room_filelist, "w")
+all_file = open(output_all_file, "w")
 
 # --------------------------------------
 # ----- BATCH WRITE TO HDF5 -----
 # --------------------------------------
 batch_data_dim = [H5_BATCH_SIZE] + data_dim
 batch_label_dim = [H5_BATCH_SIZE] + label_dim
-h5_batch_data = np.zeros(batch_data_dim, dtype = np.float32)
-h5_batch_label = np.zeros(batch_label_dim, dtype = np.uint8)
+h5_batch_data = np.zeros(batch_data_dim, dtype=np.float32)
+h5_batch_label = np.zeros(batch_label_dim, dtype=np.uint8)
 buffer_size = 0  # state: record how many samples are currently in buffer
-h5_index = 0 # state: the next h5 file to save
+h5_index = 0  # state: the next h5 file to save
+
 
 def insert_batch(data, label, last_batch=False):
     global h5_batch_data, h5_batch_label
     global buffer_size, h5_index
     data_size = data.shape[0]
     # If there is enough space, just insert
     if buffer_size + data_size <= h5_batch_data.shape[0]:
-        h5_batch_data[buffer_size:buffer_size+data_size, ...] = data
-        h5_batch_label[buffer_size:buffer_size+data_size] = label
+        h5_batch_data[buffer_size : buffer_size + data_size, ...] = data
+        h5_batch_label[buffer_size : buffer_size + data_size] = label
         buffer_size += data_size
-    else: # not enough space
+    else:  # not enough space
         capacity = h5_batch_data.shape[0] - buffer_size
-        assert(capacity>=0)
+        assert capacity >= 0
         if capacity > 0:
-           h5_batch_data[buffer_size:buffer_size+capacity, ...] = data[0:capacity, ...] 
-           h5_batch_label[buffer_size:buffer_size+capacity, ...] = label[0:capacity, ...] 
+            h5_batch_data[buffer_size : buffer_size + capacity, ...] = data[
+                0:capacity, ...
+            ]
+            h5_batch_label[buffer_size : buffer_size + capacity, ...] = label[
+                0:capacity, ...
+            ]
         # Save batch data and label to h5 file, reset buffer_size
-        h5_filename =  output_filename_prefix + '_' + str(h5_index) + '.h5'
-        data_prep_util.save_h5(h5_filename, h5_batch_data, h5_batch_label, data_dtype, label_dtype) 
-        print('Stored {0} with size {1}'.format(h5_filename, h5_batch_data.shape[0]))
+        h5_filename = output_filename_prefix + "_" + str(h5_index) + ".h5"
+        data_prep_util.save_h5(
+            h5_filename, h5_batch_data, h5_batch_label, data_dtype, label_dtype
+        )
+        print("Stored {0} with size {1}".format(h5_filename, h5_batch_data.shape[0]))
         h5_index += 1
         buffer_size = 0
         # recursive call
         insert_batch(data[capacity:, ...], label[capacity:, ...], last_batch)
     if last_batch and buffer_size > 0:
-        h5_filename =  output_filename_prefix + '_' + str(h5_index) + '.h5'
-        data_prep_util.save_h5(h5_filename, h5_batch_data[0:buffer_size, ...], h5_batch_label[0:buffer_size, ...], data_dtype, label_dtype)
-        print('Stored {0} with size {1}'.format(h5_filename, buffer_size))
+        h5_filename = output_filename_prefix + "_" + str(h5_index) + ".h5"
+        data_prep_util.save_h5(
+            h5_filename,
+            h5_batch_data[0:buffer_size, ...],
+            h5_batch_label[0:buffer_size, ...],
+            data_dtype,
+            label_dtype,
+        )
+        print("Stored {0} with size {1}".format(h5_filename, buffer_size))
         h5_index += 1
         buffer_size = 0
     return
 
 
 sample_cnt = 0
 for i, data_label_filename in enumerate(data_label_files):
     print(data_label_filename)
-    data, label = indoor3d_util.room2blocks_wrapper_normalized(data_label_filename, NUM_POINT, block_size=1.0, stride=1,
-                                                 random_sample=False, sample_num=None)
-    print('{0}, {1}'.format(data.shape, label.shape))
+    data, label = indoor3d_util.room2blocks_wrapper_normalized(
+        data_label_filename,
+        NUM_POINT,
+        block_size=1.0,
+        stride=1,
+        random_sample=False,
+        sample_num=None,
+    )
+    print("{0}, {1}".format(data.shape, label.shape))
     for _ in range(data.shape[0]):
-        fout_room.write(os.path.basename(data_label_filename)[0:-4]+'\n')
+        fout_room.write(os.path.basename(data_label_filename)[0:-4] + "\n")
 
     sample_cnt += data.shape[0]
-    insert_batch(data, label, i == len(data_label_files)-1)
+    insert_batch(data, label, i == len(data_label_files) - 1)
 
 fout_room.close()
 print("Total samples: {0}".format(sample_cnt))
 
 for i in range(h5_index):
-    all_file.write(os.path.join('indoor3d_sem_seg_hdf5_data_test', 'ply_data_all_') + str(i) +'.h5\n')
+    all_file.write(
+        os.path.join("indoor3d_sem_seg_hdf5_data_test", "ply_data_all_")
+        + str(i)
+        + ".h5\n"
+    )
 all_file.close()
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/RandLANet.py	2024-06-30 22:34:18.826910+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/RandLANet.py	2024-07-08 11:53:40.109105+00:00
@@ -10,11 +10,11 @@
 class Network(nn.Module):
 
     def __init__(self, config):
         super().__init__()
         self.config = config
-        self.class_weights = DP.get_class_weights('SemanticKITTI')
+        self.class_weights = DP.get_class_weights("SemanticKITTI")
 
         self.fc0 = pt_utils.Conv1d(3, 8, kernel_size=1, bn=True)
 
         self.dilated_res_blocks = nn.ModuleList()
         d_in = 8
@@ -22,56 +22,62 @@
             d_out = self.config.d_out[i]
             self.dilated_res_blocks.append(Dilated_res_block(d_in, d_out))
             d_in = 2 * d_out
 
         d_out = d_in
-        self.decoder_0 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
+        self.decoder_0 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
 
         self.decoder_blocks = nn.ModuleList()
         for j in range(self.config.num_layers):
             if j < 3:
-                d_in = d_out + 2 * self.config.d_out[-j-2]
-                d_out = 2 * self.config.d_out[-j-2]
+                d_in = d_out + 2 * self.config.d_out[-j - 2]
+                d_out = 2 * self.config.d_out[-j - 2]
             else:
                 d_in = 4 * self.config.d_out[-4]
                 d_out = 2 * self.config.d_out[-4]
-            self.decoder_blocks.append(pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True))
-
-        self.fc1 = pt_utils.Conv2d(d_out, 64, kernel_size=(1,1), bn=True)
-        self.fc2 = pt_utils.Conv2d(64, 32, kernel_size=(1,1), bn=True)
+            self.decoder_blocks.append(
+                pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+            )
+
+        self.fc1 = pt_utils.Conv2d(d_out, 64, kernel_size=(1, 1), bn=True)
+        self.fc2 = pt_utils.Conv2d(64, 32, kernel_size=(1, 1), bn=True)
         self.dropout = nn.Dropout(0.5)
-        self.fc3 = pt_utils.Conv2d(32, self.config.num_classes, kernel_size=(1,1), bn=False, activation=None)
-        
+        self.fc3 = pt_utils.Conv2d(
+            32, self.config.num_classes, kernel_size=(1, 1), bn=False, activation=None
+        )
+
     def activations_hook(self, grad):
         self.gradients = grad
-        
+
     def logits_hook(self, grad):
         self.logits_gradients = grad
 
     def forward(self, end_points):
         self.activation_maps = []
-        features = end_points['features']  # Batch*channel*npoints
+        features = end_points["features"]  # Batch*channel*npoints
         features = self.fc0(features)
 
         features = features.unsqueeze(dim=3)  # Batch*channel*npoints*1
 
         # ###########################Encoder############################
         f_encoder_list = []
         for i in range(self.config.num_layers):
-            f_encoder_i = self.dilated_res_blocks[i](features, end_points['xyz'][i], end_points['neigh_idx'][i])
-            f_sampled_i = self.random_sample(f_encoder_i, end_points['sub_idx'][i])
+            f_encoder_i = self.dilated_res_blocks[i](
+                features, end_points["xyz"][i], end_points["neigh_idx"][i]
+            )
+            f_sampled_i = self.random_sample(f_encoder_i, end_points["sub_idx"][i])
             features = f_sampled_i
             if i == 0:
-#                 activations = f_encoder_i
-#                 act_hook = f_encoder_i.register_hook(self.activations_hook)
-#                 f_encoder_i.retain_grad()
-#                 print("Activations grad shape: ", self.activations.grad.shape)
+                #                 activations = f_encoder_i
+                #                 act_hook = f_encoder_i.register_hook(self.activations_hook)
+                #                 f_encoder_i.retain_grad()
+                #                 print("Activations grad shape: ", self.activations.grad.shape)
                 act_hook = f_encoder_i.register_hook(self.activations_hook)
                 f_encoder_i.retain_grad()
                 self.activation_maps.append(f_encoder_i)
                 f_encoder_list.append(f_encoder_i)
-            
+
             if i != self.config.num_layers - 1:
                 act_hook = f_sampled_i.register_hook(self.activations_hook)
                 f_sampled_i.retain_grad()
                 self.activation_maps.append(f_sampled_i)
             f_encoder_list.append(f_sampled_i)
@@ -80,47 +86,47 @@
         features = self.decoder_0(f_encoder_list[-1])
 
         # ###########################Decoder############################
         f_decoder_list = []
         for j in range(self.config.num_layers):
-            f_interp_i = self.nearest_interpolation(features, end_points['interp_idx'][-j - 1])
-            f_decoder_i = self.decoder_blocks[j](torch.cat([f_encoder_list[-j - 2], f_interp_i], dim=1))
+            f_interp_i = self.nearest_interpolation(
+                features, end_points["interp_idx"][-j - 1]
+            )
+            f_decoder_i = self.decoder_blocks[j](
+                torch.cat([f_encoder_list[-j - 2], f_interp_i], dim=1)
+            )
 
             features = f_decoder_i
             act_hook = f_decoder_i.register_hook(self.activations_hook)
             f_decoder_i.retain_grad()
             self.activation_maps.append(f_decoder_i)
             f_decoder_list.append(f_decoder_i)
         # ###########################Decoder############################
-        
-
 
         features = self.fc1(features)
         act_hook = features.register_hook(self.activations_hook)
         features.retain_grad()
         self.activation_maps.append(features)
-        
+
         features = self.fc2(features)
         act_hook = features.register_hook(self.activations_hook)
         features.retain_grad()
         self.activation_maps.append(features)
-        
+
         features = self.dropout(features)
 
         features = self.fc3(features)
         act_hook = features.register_hook(self.activations_hook)
         features.retain_grad()
         self.activation_maps.append(features)
 
-
         f_out = features.squeeze(3)
-        
-        
-#         self.logits = f_out
-#         self.activations = activations
-        end_points['activations'] = self.activation_maps
-        end_points['logits'] = f_out
+
+        #         self.logits = f_out
+        #         self.activations = activations
+        end_points["activations"] = self.activation_maps
+        end_points["logits"] = f_out
 
         return end_points
 
     @staticmethod
     def random_sample(feature, pool_idx):
@@ -132,13 +138,17 @@
         feature = feature.squeeze(dim=3)  # batch*channel*npoints
         num_neigh = pool_idx.shape[-1]
         d = feature.shape[1]
         batch_size = pool_idx.shape[0]
         pool_idx = pool_idx.reshape(batch_size, -1)  # batch*(npoints,nsamples)
-        pool_features = torch.gather(feature, 2, pool_idx.unsqueeze(1).repeat(1, feature.shape[1], 1))
+        pool_features = torch.gather(
+            feature, 2, pool_idx.unsqueeze(1).repeat(1, feature.shape[1], 1)
+        )
         pool_features = pool_features.reshape(batch_size, d, -1, num_neigh)
-        pool_features = pool_features.max(dim=3, keepdim=True)[0]  # batch*channel*npoints*1
+        pool_features = pool_features.max(dim=3, keepdim=True)[
+            0
+        ]  # batch*channel*npoints*1
         return pool_features
 
     @staticmethod
     def nearest_interpolation(feature, interp_idx):
         """
@@ -148,23 +158,26 @@
         """
         feature = feature.squeeze(dim=3)  # batch*channel*npoints
         batch_size = interp_idx.shape[0]
         up_num_points = interp_idx.shape[1]
         interp_idx = interp_idx.reshape(batch_size, up_num_points)
-        interpolated_features = torch.gather(feature, 2, interp_idx.unsqueeze(1).repeat(1,feature.shape[1],1))
-        interpolated_features = interpolated_features.unsqueeze(3)  # batch*channel*npoints*1
+        interpolated_features = torch.gather(
+            feature, 2, interp_idx.unsqueeze(1).repeat(1, feature.shape[1], 1)
+        )
+        interpolated_features = interpolated_features.unsqueeze(
+            3
+        )  # batch*channel*npoints*1
         return interpolated_features
 
 
-
 def compute_acc(end_points):
 
-    logits = end_points['valid_logits']
-    labels = end_points['valid_labels']
+    logits = end_points["valid_logits"]
+    labels = end_points["valid_labels"]
     logits = logits.max(dim=1)[1]
     acc = (logits == labels).sum().float() / float(labels.shape[0])
-    end_points['acc'] = acc
+    end_points["acc"] = acc
     return acc, end_points
 
 
 class IoUCalculator:
     def __init__(self, cfg):
@@ -172,12 +185,12 @@
         self.positive_classes = [0 for _ in range(cfg.num_classes)]
         self.true_positive_classes = [0 for _ in range(cfg.num_classes)]
         self.cfg = cfg
 
     def add_data(self, end_points):
-        logits = end_points['valid_logits']
-        labels = end_points['valid_labels']
+        logits = end_points["valid_logits"]
+        labels = end_points["valid_labels"]
         pred = logits.max(dim=1)[1]
         pred_valid = pred.detach().cpu().numpy()
         labels_valid = labels.detach().cpu().numpy()
 
         val_total_correct = 0
@@ -185,96 +198,130 @@
 
         correct = np.sum(pred_valid == labels_valid)
         val_total_correct += correct
         val_total_seen += len(labels_valid)
 
-        conf_matrix = confusion_matrix(labels_valid, pred_valid, labels=np.arange(0, self.cfg.num_classes, 1))
+        conf_matrix = confusion_matrix(
+            labels_valid, pred_valid, labels=np.arange(0, self.cfg.num_classes, 1)
+        )
         self.gt_classes += np.sum(conf_matrix, axis=1)
         self.positive_classes += np.sum(conf_matrix, axis=0)
         self.true_positive_classes += np.diagonal(conf_matrix)
 
     def compute_iou(self):
         iou_list = []
         for n in range(0, self.cfg.num_classes, 1):
-            if float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n]) != 0:
-                iou = self.true_positive_classes[n] / float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n])
+            if (
+                float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
+                != 0
+            ):
+                iou = self.true_positive_classes[n] / float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
                 iou_list.append(iou)
             else:
                 iou_list.append(0.0)
         mean_iou = sum(iou_list) / float(self.cfg.num_classes)
         return mean_iou, iou_list
 
 
-
 class Dilated_res_block(nn.Module):
     def __init__(self, d_in, d_out):
         super().__init__()
 
-        self.mlp1 = pt_utils.Conv2d(d_in, d_out//2, kernel_size=(1,1), bn=True)
+        self.mlp1 = pt_utils.Conv2d(d_in, d_out // 2, kernel_size=(1, 1), bn=True)
         self.lfa = Building_block(d_out)
-        self.mlp2 = pt_utils.Conv2d(d_out, d_out*2, kernel_size=(1, 1), bn=True, activation=None)
-        self.shortcut = pt_utils.Conv2d(d_in, d_out*2, kernel_size=(1,1), bn=True, activation=None)
+        self.mlp2 = pt_utils.Conv2d(
+            d_out, d_out * 2, kernel_size=(1, 1), bn=True, activation=None
+        )
+        self.shortcut = pt_utils.Conv2d(
+            d_in, d_out * 2, kernel_size=(1, 1), bn=True, activation=None
+        )
 
     def forward(self, feature, xyz, neigh_idx):
         f_pc = self.mlp1(feature)  # Batch*channel*npoints*1
         f_pc = self.lfa(xyz, f_pc, neigh_idx)  # Batch*d_out*npoints*1
         f_pc = self.mlp2(f_pc)
         shortcut = self.shortcut(feature)
-        return F.leaky_relu(f_pc+shortcut, negative_slope=0.2)
+        return F.leaky_relu(f_pc + shortcut, negative_slope=0.2)
 
 
 class Building_block(nn.Module):
     def __init__(self, d_out):  #  d_in = d_out//2
         super().__init__()
-        self.mlp1 = pt_utils.Conv2d(10, d_out//2, kernel_size=(1,1), bn=True)
-        self.att_pooling_1 = Att_pooling(d_out, d_out//2)
-
-        self.mlp2 = pt_utils.Conv2d(d_out//2, d_out//2, kernel_size=(1, 1), bn=True)
+        self.mlp1 = pt_utils.Conv2d(10, d_out // 2, kernel_size=(1, 1), bn=True)
+        self.att_pooling_1 = Att_pooling(d_out, d_out // 2)
+
+        self.mlp2 = pt_utils.Conv2d(d_out // 2, d_out // 2, kernel_size=(1, 1), bn=True)
         self.att_pooling_2 = Att_pooling(d_out, d_out)
 
     def forward(self, xyz, feature, neigh_idx):  # feature: Batch*channel*npoints*1
         f_xyz = self.relative_pos_encoding(xyz, neigh_idx)  # batch*npoint*nsamples*10
         f_xyz = f_xyz.permute((0, 3, 1, 2))  # batch*10*npoint*nsamples
         f_xyz = self.mlp1(f_xyz)
-        f_neighbours = self.gather_neighbour(feature.squeeze(-1).permute((0, 2, 1)), neigh_idx)  # batch*npoint*nsamples*channel
-        f_neighbours = f_neighbours.permute((0, 3, 1, 2))  # batch*channel*npoint*nsamples
+        f_neighbours = self.gather_neighbour(
+            feature.squeeze(-1).permute((0, 2, 1)), neigh_idx
+        )  # batch*npoint*nsamples*channel
+        f_neighbours = f_neighbours.permute(
+            (0, 3, 1, 2)
+        )  # batch*channel*npoint*nsamples
         f_concat = torch.cat([f_neighbours, f_xyz], dim=1)
         f_pc_agg = self.att_pooling_1(f_concat)  # Batch*channel*npoints*1
 
         f_xyz = self.mlp2(f_xyz)
-        f_neighbours = self.gather_neighbour(f_pc_agg.squeeze(-1).permute((0, 2, 1)), neigh_idx)  # batch*npoint*nsamples*channel
-        f_neighbours = f_neighbours.permute((0, 3, 1, 2))  # batch*channel*npoint*nsamples
+        f_neighbours = self.gather_neighbour(
+            f_pc_agg.squeeze(-1).permute((0, 2, 1)), neigh_idx
+        )  # batch*npoint*nsamples*channel
+        f_neighbours = f_neighbours.permute(
+            (0, 3, 1, 2)
+        )  # batch*channel*npoint*nsamples
         f_concat = torch.cat([f_neighbours, f_xyz], dim=1)
         f_pc_agg = self.att_pooling_2(f_concat)
         return f_pc_agg
 
     def relative_pos_encoding(self, xyz, neigh_idx):
         neighbor_xyz = self.gather_neighbour(xyz, neigh_idx)  # batch*npoint*nsamples*3
 
-        xyz_tile = xyz.unsqueeze(2).repeat(1, 1, neigh_idx.shape[-1], 1)  # batch*npoint*nsamples*3
+        xyz_tile = xyz.unsqueeze(2).repeat(
+            1, 1, neigh_idx.shape[-1], 1
+        )  # batch*npoint*nsamples*3
         relative_xyz = xyz_tile - neighbor_xyz  # batch*npoint*nsamples*3
-        relative_dis = torch.sqrt(torch.sum(torch.pow(relative_xyz, 2), dim=-1, keepdim=True))  # batch*npoint*nsamples*1
-        relative_feature = torch.cat([relative_dis, relative_xyz, xyz_tile, neighbor_xyz], dim=-1)  # batch*npoint*nsamples*10
+        relative_dis = torch.sqrt(
+            torch.sum(torch.pow(relative_xyz, 2), dim=-1, keepdim=True)
+        )  # batch*npoint*nsamples*1
+        relative_feature = torch.cat(
+            [relative_dis, relative_xyz, xyz_tile, neighbor_xyz], dim=-1
+        )  # batch*npoint*nsamples*10
         return relative_feature
 
     @staticmethod
     def gather_neighbour(pc, neighbor_idx):  # pc: batch*npoint*channel
         # gather the coordinates or features of neighboring points
         batch_size = pc.shape[0]
         num_points = pc.shape[1]
         d = pc.shape[2]
         index_input = neighbor_idx.reshape(batch_size, -1)
-        features = torch.gather(pc, 1, index_input.unsqueeze(-1).repeat(1, 1, pc.shape[2]))
-        features = features.reshape(batch_size, num_points, neighbor_idx.shape[-1], d)  # batch*npoint*nsamples*channel
+        features = torch.gather(
+            pc, 1, index_input.unsqueeze(-1).repeat(1, 1, pc.shape[2])
+        )
+        features = features.reshape(
+            batch_size, num_points, neighbor_idx.shape[-1], d
+        )  # batch*npoint*nsamples*channel
         return features
 
 
 class Att_pooling(nn.Module):
     def __init__(self, d_in, d_out):
         super().__init__()
         self.fc = nn.Conv2d(d_in, d_in, (1, 1), bias=False)
-        self.mlp = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
+        self.mlp = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
 
     def forward(self, feature_set):
 
         att_activation = self.fc(feature_set)
         att_scores = F.softmax(att_activation, dim=3)
@@ -284,12 +331,12 @@
         return f_agg
 
 
 def compute_loss(end_points, cfg):
 
-    logits = end_points['logits']
-    labels = end_points['labels']
+    logits = end_points["logits"]
+    labels = end_points["labels"]
 
     logits = logits.transpose(1, 2).reshape(-1, cfg.num_classes)
     labels = labels.reshape(-1)
 
     # Boolean mask of points that should be ignored
@@ -304,22 +351,24 @@
 
     # Reduce label values in the range of logit shape
     reducing_list = torch.arange(0, cfg.num_classes).long().cuda()
     inserted_value = torch.zeros((1,)).long().cuda()
     for ign_label in cfg.ignored_label_inds:
-        reducing_list = torch.cat([reducing_list[:ign_label], inserted_value, reducing_list[ign_label:]], 0)
+        reducing_list = torch.cat(
+            [reducing_list[:ign_label], inserted_value, reducing_list[ign_label:]], 0
+        )
     valid_labels = torch.gather(reducing_list, 0, valid_labels_init)
     loss = get_loss(valid_logits, valid_labels, cfg.class_weights)
-    end_points['valid_logits'], end_points['valid_labels'] = valid_logits, valid_labels
-    end_points['loss'] = loss
+    end_points["valid_logits"], end_points["valid_labels"] = valid_logits, valid_labels
+    end_points["loss"] = loss
     return loss, end_points
 
 
 def get_loss(logits, labels, pre_cal_weights):
     # calculate the weighted cross entropy according to the inverse frequency
     class_weights = torch.from_numpy(pre_cal_weights).float().cuda()
     # one_hot_labels = F.one_hot(labels, self.config.num_classes)
 
-    criterion = nn.CrossEntropyLoss(weight=class_weights, reduction='none')
+    criterion = nn.CrossEntropyLoss(weight=class_weights, reduction="none")
     output_loss = criterion(logits, labels)
     output_loss = output_loss.mean()
     return output_loss
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/data.py	2024-07-08 10:32:16.156489+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/data.py	2024-07-08 11:53:40.163177+00:00
@@ -25,53 +25,53 @@
 from torch.utils.data import Dataset
 
 
 def download_S3DIS():
     BASE_DIR = os.path.dirname(os.path.abspath(__file__))
-    DATA_DIR = os.path.join(BASE_DIR, 'data')
+    DATA_DIR = os.path.join(BASE_DIR, "data")
     if not os.path.exists(DATA_DIR):
         os.mkdir(DATA_DIR)
-    if not os.path.exists(os.path.join(DATA_DIR, 'indoor3d_sem_seg_hdf5_data')):
-        print('No data avaialable')
+    if not os.path.exists(os.path.join(DATA_DIR, "indoor3d_sem_seg_hdf5_data")):
+        print("No data avaialable")
         sys.exit(0)
     # if not os.path.exists(os.path.join(DATA_DIR, 'Stanford3dDataset_v1.2_Aligned_Version')):
     #     if not os.path.exists(os.path.join(DATA_DIR, 'Stanford3dDataset_v1.2_Aligned_Version.zip')):
     #         print('Please download Stanford3dDataset_v1.2_Aligned_Version.zip \
     #             from https://goo.gl/forms/4SoGp4KtH1jfRqEj2 and place it under data/')
     #         sys.exit(0)
-        # else:
-        #     zippath = os.path.join(DATA_DIR, 'Stanford3dDataset_v1.2_Aligned_Version.zip')
-        #     os.system('unzip %s' % (zippath))
-        #     os.system('mv %s %s' % ('Stanford3dDataset_v1.2_Aligned_Version', DATA_DIR))
-        #     os.system('rm %s' % (zippath))
+    # else:
+    #     zippath = os.path.join(DATA_DIR, 'Stanford3dDataset_v1.2_Aligned_Version.zip')
+    #     os.system('unzip %s' % (zippath))
+    #     os.system('mv %s %s' % ('Stanford3dDataset_v1.2_Aligned_Version', DATA_DIR))
+    #     os.system('rm %s' % (zippath))
 
 
 def prepare_test_data_semseg():
     BASE_DIR = os.path.dirname(os.path.abspath(__file__))
-    DATA_DIR = os.path.join(BASE_DIR, 'data')
-    if not os.path.exists(os.path.join(DATA_DIR, 'stanford_indoor3d')):
-        os.system('python prepare_data/collect_indoor3d_data.py')
-    if not os.path.exists(os.path.join(DATA_DIR, 'indoor3d_sem_seg_hdf5_data_test')):
-        os.system('python prepare_data/gen_indoor3d_h5.py')
+    DATA_DIR = os.path.join(BASE_DIR, "data")
+    if not os.path.exists(os.path.join(DATA_DIR, "stanford_indoor3d")):
+        os.system("python prepare_data/collect_indoor3d_data.py")
+    if not os.path.exists(os.path.join(DATA_DIR, "indoor3d_sem_seg_hdf5_data_test")):
+        os.system("python prepare_data/gen_indoor3d_h5.py")
 
 
 def load_data_semseg(partition, test_area):
     BASE_DIR = os.path.dirname(os.path.abspath(__file__))
-    DATA_DIR = os.path.join(BASE_DIR, 'data')
-    download_S3DIS() # downloads both "Stanford3dDataset_v1.2_Aligned_Version" & "indoor3d_sem_seg_hdf5_data"
+    DATA_DIR = os.path.join(BASE_DIR, "data")
+    download_S3DIS()  # downloads both "Stanford3dDataset_v1.2_Aligned_Version" & "indoor3d_sem_seg_hdf5_data"
     # prepare_test_data_semseg()
-    if partition == 'train':
-        data_dir = os.path.join(DATA_DIR, 'indoor3d_sem_seg_hdf5_data')
+    if partition == "train":
+        data_dir = os.path.join(DATA_DIR, "indoor3d_sem_seg_hdf5_data")
     else:
-        data_dir = os.path.join(DATA_DIR, 'indoor3d_sem_seg_hdf5_data_test')
+        data_dir = os.path.join(DATA_DIR, "indoor3d_sem_seg_hdf5_data_test")
     with open(os.path.join(data_dir, "all_files.txt")) as f:
         all_files = [line.rstrip() for line in f]
     with open(os.path.join(data_dir, "room_filelist.txt")) as f:
         room_filelist = [line.rstrip() for line in f]
     data_batchlist, label_batchlist = [], []
     for f in all_files:
-        file = h5py.File(os.path.join(DATA_DIR, f), 'r+')
+        file = h5py.File(os.path.join(DATA_DIR, f), "r+")
         data = file["data"][:]
         label = file["label"][:]
         data_batchlist.append(data)
         label_batchlist.append(label)
     data_batches = np.concatenate(data_batchlist, 0)
@@ -81,76 +81,86 @@
     for i, room_name in enumerate(room_filelist):
         if test_area_name in room_name:
             test_idxs.append(i)
         else:
             train_idxs.append(i)
-    if partition == 'train':
+    if partition == "train":
         all_data = data_batches[train_idxs, ...]
         all_seg = seg_batches[train_idxs, ...]
     else:
         all_data = data_batches[test_idxs, ...]
         all_seg = seg_batches[test_idxs, ...]
     return all_data, all_seg
 
 
 def read_txt_file(file_path, num_points: np.int32):
-  data_app = []
-  labels_app = []
-  for f in file_path:
-      with open(f) as file:
-          count=0
-          data = []
-          labels = []
-          for line in file:
-              values = line.strip().split(' ')
-              data.append([np.float32(value) for value in values[:-1]])
-              labels.append(np.int32(float(values[-1])))
-          data = np.array(data)
-          labels = np.array(labels)
-          data_app = data if len(data_app) == 0 else np.dstack((data_app, data))
-          labels_app = labels if len(labels_app) == 0 else np.dstack((labels_app, labels))
-  return np.transpose(data_app, (2,0,1)), np.squeeze(np.transpose(labels_app))
-
-
-def get_data_files(data_path, num_points:int):
-    output_file = 'all_pts_cloud_data.h5'
-
-    str_fname = [line.rstrip() for line in open(os.path.join(data_path, 'synsetoffset2category.txt'))][0]
+    data_app = []
+    labels_app = []
+    for f in file_path:
+        with open(f) as file:
+            count = 0
+            data = []
+            labels = []
+            for line in file:
+                values = line.strip().split(" ")
+                data.append([np.float32(value) for value in values[:-1]])
+                labels.append(np.int32(float(values[-1])))
+            data = np.array(data)
+            labels = np.array(labels)
+            data_app = data if len(data_app) == 0 else np.dstack((data_app, data))
+            labels_app = (
+                labels if len(labels_app) == 0 else np.dstack((labels_app, labels))
+            )
+    return np.transpose(data_app, (2, 0, 1)), np.squeeze(np.transpose(labels_app))
+
+
+def get_data_files(data_path, num_points: int):
+    output_file = "all_pts_cloud_data.h5"
+
+    str_fname = [
+        line.rstrip()
+        for line in open(os.path.join(data_path, "synsetoffset2category.txt"))
+    ][0]
     sub_filename = str_fname.split()[1]
 
-    json_files = glob.glob(os.path.join(data_path, 'train_test_split', '*.json'))
+    json_files = glob.glob(os.path.join(data_path, "train_test_split", "*.json"))
     if os.path.isfile(os.path.join(data_path, output_file)) is False:
         for file in json_files:
-            fname = file.split('/')[-1]
-            stage_name = fname.split('_')[1]
+            fname = file.split("/")[-1]
+            stage_name = fname.split("_")[1]
             f = open(file)
             jsonf = json.load(f)
-            file_arr = [line.rstrip().split('/')[-1] for line in jsonf]
-            file_paths = [os.path.join(data_path, sub_filename,i+'.txt') for i in file_arr]
-            out_data, out_labels = read_txt_file(file_path=file_paths, num_points=num_points)
-            
-            with h5py.File(os.path.join(data_path, output_file), 'a') as hfile:
+            file_arr = [line.rstrip().split("/")[-1] for line in jsonf]
+            file_paths = [
+                os.path.join(data_path, sub_filename, i + ".txt") for i in file_arr
+            ]
+            out_data, out_labels = read_txt_file(
+                file_path=file_paths, num_points=num_points
+            )
+
+            with h5py.File(os.path.join(data_path, output_file), "a") as hfile:
                 group = hfile.create_group(str(stage_name))
-                group.create_dataset('data', data=out_data)
-                group.create_dataset('labels', data=out_labels)
-                print('%s data group created'%str(stage_name))
+                group.create_dataset("data", data=out_data)
+                group.create_dataset("labels", data=out_labels)
+                print("%s data group created" % str(stage_name))
+
 
 def load_data_file(data_path, stage_name):
-    file = os.path.join(data_path, 'all_pts_cloud_data.h5')
-    f = h5py.File(file, 'r')
-    data = f[str(stage_name)]['data'][:]
-    label = f[str(stage_name)]['labels'][:]
+    file = os.path.join(data_path, "all_pts_cloud_data.h5")
+    f = h5py.File(file, "r")
+    data = f[str(stage_name)]["data"][:]
+    label = f[str(stage_name)]["labels"][:]
     return (data, label)
 
 
 def load_color_partseg():
     colors = []
     labels = []
     f = open("prepare_data/meta/partseg_colors.txt")
     for line in json.load(f):
-        colors.append(line['color'])
-        labels.append(line['label'])
+        colors.append(line["color"])
+        labels.append(line["label"])
     partseg_colors = np.array(colors)
     partseg_colors = partseg_colors[:, [2, 1, 0]]
     partseg_labels = np.array(labels)
     font = cv2.FONT_HERSHEY_SIMPLEX
     img_size = 1350
@@ -166,35 +176,53 @@
         column_index = 32
         for column in range(0, img_size):
             color = partseg_colors[color_index]
             label = partseg_labels[label_index]
             length = len(str(label))
-            cv2.rectangle(img, (column_index, row_index), (column_index + color_size, row_index + color_size),
-                          color=(int(color[0]), int(color[1]), int(color[2])), thickness=-1)
-            img = cv2.putText(img, label, (column_index + int(color_size * 1.15), row_index + int(color_size / 2)),
-                              font,
-                              0.76, (0, 0, 0), 2)
+            cv2.rectangle(
+                img,
+                (column_index, row_index),
+                (column_index + color_size, row_index + color_size),
+                color=(int(color[0]), int(color[1]), int(color[2])),
+                thickness=-1,
+            )
+            img = cv2.putText(
+                img,
+                label,
+                (
+                    column_index + int(color_size * 1.15),
+                    row_index + int(color_size / 2),
+                ),
+                font,
+                0.76,
+                (0, 0, 0),
+                2,
+            )
             column_index = column_index + column_gaps[column]
             color_index = color_index + 1
             label_index = label_index + 1
             if color_index >= 50:
-                cv2.imwrite("prepare_data/meta/partseg_colors.png", img, [cv2.IMWRITE_PNG_COMPRESSION, 0])
+                cv2.imwrite(
+                    "prepare_data/meta/partseg_colors.png",
+                    img,
+                    [cv2.IMWRITE_PNG_COMPRESSION, 0],
+                )
                 return np.array(colors)
-            elif (column + 1 >= column_numbers[row]):
+            elif column + 1 >= column_numbers[row]:
                 break
         row_index = row_index + int(color_size * 1.3)
-        if (row_index >= img_size):
+        if row_index >= img_size:
             break
 
 
 def load_color_semseg():
     colors = []
     labels = []
     f = open("prepare_data/meta/semseg_colors.txt")
     for line in json.load(f):
-        colors.append(line['color'])
-        labels.append(line['label'])
+        colors.append(line["color"])
+        labels.append(line["label"])
     semseg_colors = np.array(colors)
     semseg_colors = semseg_colors[:, [2, 1, 0]]
     partseg_labels = np.array(labels)
     font = cv2.FONT_HERSHEY_SIMPLEX
     img_size = 1500
@@ -208,63 +236,87 @@
         column_index = 32
         for _ in range(0, img_size):
             color = semseg_colors[color_index]
             label = partseg_labels[label_index]
             length = len(str(label))
-            cv2.rectangle(img, (column_index, row_index), (column_index + color_size, row_index + color_size),
-                          color=(int(color[0]), int(color[1]), int(color[2])), thickness=-1)
-            img = cv2.putText(img, label, (column_index + int(color_size * 1.15), row_index + int(color_size / 2)),
-                              font,
-                              0.7, (0, 0, 0), 2)
+            cv2.rectangle(
+                img,
+                (column_index, row_index),
+                (column_index + color_size, row_index + color_size),
+                color=(int(color[0]), int(color[1]), int(color[2])),
+                thickness=-1,
+            )
+            img = cv2.putText(
+                img,
+                label,
+                (
+                    column_index + int(color_size * 1.15),
+                    row_index + int(color_size / 2),
+                ),
+                font,
+                0.7,
+                (0, 0, 0),
+                2,
+            )
             column_index = column_index + 200
             color_index = color_index + 1
             label_index = label_index + 1
             if color_index >= 13:
-                cv2.imwrite("prepare_data/meta/semseg_colors.png", img, [cv2.IMWRITE_PNG_COMPRESSION, 0])
+                cv2.imwrite(
+                    "prepare_data/meta/semseg_colors.png",
+                    img,
+                    [cv2.IMWRITE_PNG_COMPRESSION, 0],
+                )
                 return np.array(colors)
-            elif (column_index >= 1280):
+            elif column_index >= 1280:
                 break
         row_index = row_index + int(color_size * 1.3)
-        if (row_index >= img_size):
-            break  
-    
+        if row_index >= img_size:
+            break
+
 
 def translate_pointcloud(pointcloud):
-    xyz1 = np.random.uniform(low=2./3., high=3./2., size=[3])
+    xyz1 = np.random.uniform(low=2.0 / 3.0, high=3.0 / 2.0, size=[3])
     xyz2 = np.random.uniform(low=-0.2, high=0.2, size=[3])
-       
-    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype('float32')
+
+    translated_pointcloud = np.add(np.multiply(pointcloud, xyz1), xyz2).astype(
+        "float32"
+    )
     return translated_pointcloud
 
 
 def jitter_pointcloud(pointcloud, sigma=0.01, clip=0.02):
     N, C = pointcloud.shape
-    pointcloud += np.clip(sigma * np.random.randn(N, C), -1*clip, clip)
+    pointcloud += np.clip(sigma * np.random.randn(N, C), -1 * clip, clip)
     return pointcloud
 
 
 def rotate_pointcloud(pointcloud):
-    theta = np.pi*2 * np.random.uniform()
-    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],[np.sin(theta), np.cos(theta)]])
-    pointcloud[:,[0,2]] = pointcloud[:,[0,2]].dot(rotation_matrix) # random rotation (x,z)
+    theta = np.pi * 2 * np.random.uniform()
+    rotation_matrix = np.array(
+        [[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]]
+    )
+    pointcloud[:, [0, 2]] = pointcloud[:, [0, 2]].dot(
+        rotation_matrix
+    )  # random rotation (x,z)
     return pointcloud
 
 
 class S3DIS(Dataset):
-    def __init__(self, num_points=2048, partition='train', test_area='1'):
+    def __init__(self, num_points=2048, partition="train", test_area="1"):
         self.data, self.seg = load_data_semseg(partition, test_area)
-        self.data = self.data[:, :, :6] # use [x y z nx ny nz] features
-        print(self.data.shape, 'data shape')
-        print(self.seg.shape, 'seg shape')
+        self.data = self.data[:, :, :6]  # use [x y z nx ny nz] features
+        print(self.data.shape, "data shape")
+        print(self.seg.shape, "seg shape")
         self.num_points = num_points
-        self.partition = partition    
+        self.partition = partition
         self.semseg_colors = load_color_semseg()
 
     def __getitem__(self, item):
-        pointcloud = self.data[item][:self.num_points]
-        seg = self.seg[item][:self.num_points]
-        if self.partition == 'train':
+        pointcloud = self.data[item][: self.num_points]
+        seg = self.seg[item][: self.num_points]
+        if self.partition == "train":
             indices = list(range(pointcloud.shape[0]))
             np.random.shuffle(indices)
             pointcloud = pointcloud[indices]
             seg = seg[indices]
         seg = torch.LongTensor(seg)
@@ -273,27 +325,27 @@
     def __len__(self):
         return self.data.shape[0]
 
 
 class our_data(Dataset):
-    def __init__(self, num_points=2048, partition='train', data_path=None): 
+    def __init__(self, num_points=2048, partition="train", data_path=None):
         ALL_DATA = get_data_files(data_path, num_points)
-        print('.h5 file saved')
+        print(".h5 file saved")
         self.data, self.seg = load_data_file(data_path, partition)
         self.num_points = num_points
-        self.partition = partition    
+        self.partition = partition
         self.semseg_colors = load_color_semseg()
-        print('Original CLASSES: ', np.unique(self.seg))
+        print("Original CLASSES: ", np.unique(self.seg))
 
         class_map = {1: 0, 2: 1, 3: 2, 4: 3, 7: 4}
         self.seg = np.vectorize(class_map.get)(self.seg)
-        print('Remapped CLASSES: ', np.unique(self.seg))
+        print("Remapped CLASSES: ", np.unique(self.seg))
 
     def __getitem__(self, item):
-        pointcloud = self.data[item][:self.num_points]
-        seg = self.seg[item][:self.num_points]
-        if self.partition == 'train':
+        pointcloud = self.data[item][: self.num_points]
+        seg = self.seg[item][: self.num_points]
+        if self.partition == "train":
             indices = list(range(pointcloud.shape[0]))
             np.random.shuffle(indices)
             pointcloud = pointcloud[indices]
             seg = seg[indices]
         seg = torch.LongTensor(seg)
@@ -301,12 +353,11 @@
 
     def __len__(self):
         return self.data.shape[0]
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     train = S3DIS(4096)
-    test = S3DIS(4096, 'test')
+    test = S3DIS(4096, "test")
     data, seg = train[0]
     print(data.shape)
     print(seg.shape)
-
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/RandLANet_expand.py	2024-06-30 22:34:18.842571+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/RandLANet_expand.py	2024-07-08 11:53:40.246189+00:00
@@ -8,11 +8,11 @@
 
 
 class Network(nn.Module):
     def __init__(self, config):
         super().__init__()
-        '''
+        """
         Config settings:-
         
         k_n = 16  # KNN
         num_layers = 4  # Number of layers
         num_points = 4096 * 11  # Number of input points
@@ -35,141 +35,146 @@
 
         train_sum_dir = 'train_log'
         saving = True
         saving_path = None
         
-        '''
+        """
         self.config = config
-        self.class_weights = DP.get_class_weights('SemanticKITTI')
-        
+        self.class_weights = DP.get_class_weights("SemanticKITTI")
+
         self.fc0 = pt_utils.Conv1d(3, 8, kernel_size=1, bn=True)
-        
+
         self.dilated_res_blocks = nn.ModuleList()
-        
+
         d_in = 8
-        d_out = self.config.d_out[0] # 16
-        
+        d_out = self.config.d_out[0]  # 16
+
         self.e0 = Dilated_res_block(d_in, d_out)
-        
+
         d_in = 2 * d_out
-        d_out = self.config.d_out[1] # 64
-        
+        d_out = self.config.d_out[1]  # 64
+
         self.e1 = Dilated_res_block(d_in, d_out)
-        
+
         d_in = 2 * d_out
         d_out = self.config.d_out[2]
-        
-        self.e2 = Dilated_res_block(d_in, d_out) #128
-        
+
+        self.e2 = Dilated_res_block(d_in, d_out)  # 128
+
         d_in = 2 * d_out
-        d_out = self.config.d_out[3]  #256
-        
+        d_out = self.config.d_out[3]  # 256
+
         self.e3 = Dilated_res_block(d_in, d_out)
-        
+
         d_in = 2 * d_out
         d_out = d_in
-        
-        self.d0 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
-        
-        d_in = d_out + 2 * self.config.d_out[-0-2]
-        d_out = 2 * self.config.d_out[-0-2]
-        
-        self.d1 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
-        
-        d_in = d_out + 2 * self.config.d_out[-1-2]
-        d_out = 2 * self.config.d_out[-1-2]
-        
-        self.d2 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
-        
-        d_in = d_out + 2 * self.config.d_out[-2-2]
-        d_out = 2 * self.config.d_out[-2-2]
-        
-        self.d3 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
-        
+
+        self.d0 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+
+        d_in = d_out + 2 * self.config.d_out[-0 - 2]
+        d_out = 2 * self.config.d_out[-0 - 2]
+
+        self.d1 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+
+        d_in = d_out + 2 * self.config.d_out[-1 - 2]
+        d_out = 2 * self.config.d_out[-1 - 2]
+
+        self.d2 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+
+        d_in = d_out + 2 * self.config.d_out[-2 - 2]
+        d_out = 2 * self.config.d_out[-2 - 2]
+
+        self.d3 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+
         d_in = 4 * self.config.d_out[-4]
         d_out = 2 * self.config.d_out[-4]
-        
-        self.d4 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
-        
-        self.fc1 = pt_utils.Conv2d(d_out, 64, kernel_size=(1,1), bn=True)
-        self.fc2 = pt_utils.Conv2d(64, 32, kernel_size=(1,1), bn=True)
+
+        self.d4 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+
+        self.fc1 = pt_utils.Conv2d(d_out, 64, kernel_size=(1, 1), bn=True)
+        self.fc2 = pt_utils.Conv2d(64, 32, kernel_size=(1, 1), bn=True)
         self.dropout = nn.Dropout(0.5)
-        self.fc3 = pt_utils.Conv2d(32, self.config.num_classes, kernel_size=(1,1), bn=False, activation=None)
-        
+        self.fc3 = pt_utils.Conv2d(
+            32, self.config.num_classes, kernel_size=(1, 1), bn=False, activation=None
+        )
+
     def forward(self, end_points):
         f_encoder_list = []
-        
-        features = end_points['features']
+
+        features = end_points["features"]
         features = self.fc0(features)
-        
-        features = features.unsqueeze(dim=3) 
-        
-        f_e0 = self.e0(features, end_points['xyz'][0], end_points['neigh_idx'][0])
-        f_s0 = self.random_sample(f_e0, end_points['sub_idx'][0])
+
+        features = features.unsqueeze(dim=3)
+
+        f_e0 = self.e0(features, end_points["xyz"][0], end_points["neigh_idx"][0])
+        f_s0 = self.random_sample(f_e0, end_points["sub_idx"][0])
         features = f_s0
         f_encoder_list.append(f_e0)
-        
-        
-        f_e1 = self.e1(features, end_points['xyz'][1], end_points['neigh_idx'][1])
-        f_s1 = self.random_sample(f_e1, end_points['sub_idx'][1])
+
+        f_e1 = self.e1(features, end_points["xyz"][1], end_points["neigh_idx"][1])
+        f_s1 = self.random_sample(f_e1, end_points["sub_idx"][1])
         features = f_s1
         f_encoder_list.append(f_s1)
-        
-        f_e2 = self.e2(features, end_points['xyz'][2], end_points['neigh_idx'][2])
-        f_s2 = self.random_sample(f_e2, end_points['sub_idx'][2])
+
+        f_e2 = self.e2(features, end_points["xyz"][2], end_points["neigh_idx"][2])
+        f_s2 = self.random_sample(f_e2, end_points["sub_idx"][2])
         features = f_s2
         f_encoder_list.append(f_s2)
-        
-        
-        f_e3 = self.e3(features, end_points['xyz'][3], end_points['neigh_idx'][3])
-        f_s3 = self.random_sample(f_e3, end_points['sub_idx'][3])
+
+        f_e3 = self.e3(features, end_points["xyz"][3], end_points["neigh_idx"][3])
+        f_s3 = self.random_sample(f_e3, end_points["sub_idx"][3])
         features = f_s3
         f_encoder_list.append(f_s3)
-        
-        
-#         print(features.shape)
-#         print(f_encoder_list[-1].shape)
-        
+
+        #         print(features.shape)
+        #         print(f_encoder_list[-1].shape)
+
         features = self.d0(f_encoder_list[-1])
-        
-        
+
         f_decoder_list = []
-        
-        f_interp_1 = self.nearest_interpolation(features, end_points['interp_idx'][-0 - 1])
+
+        f_interp_1 = self.nearest_interpolation(
+            features, end_points["interp_idx"][-0 - 1]
+        )
         f_d1 = self.d1(torch.cat([f_encoder_list[-0 - 2], f_interp_1], dim=1))
         features = f_d1
         f_decoder_list.append(f_d1)
-        
-        f_interp_2 = self.nearest_interpolation(features, end_points['interp_idx'][-1 - 1])
+
+        f_interp_2 = self.nearest_interpolation(
+            features, end_points["interp_idx"][-1 - 1]
+        )
         print(f_interp_2.shape)
         print(f_encoder_list[-1 - 1].shape)
         f_d2 = self.d2(torch.cat([f_encoder_list[-1 - 2], f_interp_2], dim=1))
         features = f_d2
         f_decoder_list.append(f_d2)
-        
-        f_interp_3 = self.nearest_interpolation(features, end_points['interp_idx'][-2 - 1])
+
+        f_interp_3 = self.nearest_interpolation(
+            features, end_points["interp_idx"][-2 - 1]
+        )
         print(f_interp_3.shape)
         print(f_encoder_list[-2 - 2].shape)
         f_d3 = self.d3(torch.cat([f_encoder_list[-2 - 2], f_interp_3], dim=1))
         features = f_d3
         f_decoder_list.append(f_d3)
-        
-        f_interp_4 = self.nearest_interpolation(features, end_points['interp_idx'][-3 - 1])
+
+        f_interp_4 = self.nearest_interpolation(
+            features, end_points["interp_idx"][-3 - 1]
+        )
         f_d4 = self.d4(torch.cat([f_encoder_list[-3 - 2], f_interp_4], dim=1))
         features = f_d4
         f_decoder_list.append(f_d4)
-        
+
         features = self.fc1(features)
         features = self.fc2(features)
         features = self.dropout(features)
         features = self.fc3(features)
         f_out = features.squeeze(3)
-        
-        end_points['logits'] = f_out
+
+        end_points["logits"] = f_out
         return end_points
-    
-    
+
     @staticmethod
     def random_sample(feature, pool_idx):
         """
         :param feature: [B, N, d] input features matrix
         :param pool_idx: [B, N', max_num] N' < N, N' is the selected position after pooling
@@ -178,13 +183,17 @@
         feature = feature.squeeze(dim=3)  # batch*channel*npoints
         num_neigh = pool_idx.shape[-1]
         d = feature.shape[1]
         batch_size = pool_idx.shape[0]
         pool_idx = pool_idx.reshape(batch_size, -1)  # batch*(npoints,nsamples)
-        pool_features = torch.gather(feature, 2, pool_idx.unsqueeze(1).repeat(1, feature.shape[1], 1))
+        pool_features = torch.gather(
+            feature, 2, pool_idx.unsqueeze(1).repeat(1, feature.shape[1], 1)
+        )
         pool_features = pool_features.reshape(batch_size, d, -1, num_neigh)
-        pool_features = pool_features.max(dim=3, keepdim=True)[0]  # batch*channel*npoints*1
+        pool_features = pool_features.max(dim=3, keepdim=True)[
+            0
+        ]  # batch*channel*npoints*1
         return pool_features
 
     @staticmethod
     def nearest_interpolation(feature, interp_idx):
         """
@@ -194,23 +203,26 @@
         """
         feature = feature.squeeze(dim=3)  # batch*channel*npoints
         batch_size = interp_idx.shape[0]
         up_num_points = interp_idx.shape[1]
         interp_idx = interp_idx.reshape(batch_size, up_num_points)
-        interpolated_features = torch.gather(feature, 2, interp_idx.unsqueeze(1).repeat(1,feature.shape[1],1))
-        interpolated_features = interpolated_features.unsqueeze(3)  # batch*channel*npoints*1
+        interpolated_features = torch.gather(
+            feature, 2, interp_idx.unsqueeze(1).repeat(1, feature.shape[1], 1)
+        )
+        interpolated_features = interpolated_features.unsqueeze(
+            3
+        )  # batch*channel*npoints*1
         return interpolated_features
 
 
-
 def compute_acc(end_points):
 
-    logits = end_points['valid_logits']
-    labels = end_points['valid_labels']
+    logits = end_points["valid_logits"]
+    labels = end_points["valid_labels"]
     logits = logits.max(dim=1)[1]
     acc = (logits == labels).sum().float() / float(labels.shape[0])
-    end_points['acc'] = acc
+    end_points["acc"] = acc
     return acc, end_points
 
 
 class IoUCalculator:
     def __init__(self, cfg):
@@ -218,12 +230,12 @@
         self.positive_classes = [0 for _ in range(cfg.num_classes)]
         self.true_positive_classes = [0 for _ in range(cfg.num_classes)]
         self.cfg = cfg
 
     def add_data(self, end_points):
-        logits = end_points['valid_logits']
-        labels = end_points['valid_labels']
+        logits = end_points["valid_logits"]
+        labels = end_points["valid_labels"]
         pred = logits.max(dim=1)[1]
         pred_valid = pred.detach().cpu().numpy()
         labels_valid = labels.detach().cpu().numpy()
 
         val_total_correct = 0
@@ -231,96 +243,130 @@
 
         correct = np.sum(pred_valid == labels_valid)
         val_total_correct += correct
         val_total_seen += len(labels_valid)
 
-        conf_matrix = confusion_matrix(labels_valid, pred_valid, np.arange(0, self.cfg.num_classes, 1))
+        conf_matrix = confusion_matrix(
+            labels_valid, pred_valid, np.arange(0, self.cfg.num_classes, 1)
+        )
         self.gt_classes += np.sum(conf_matrix, axis=1)
         self.positive_classes += np.sum(conf_matrix, axis=0)
         self.true_positive_classes += np.diagonal(conf_matrix)
 
     def compute_iou(self):
         iou_list = []
         for n in range(0, self.cfg.num_classes, 1):
-            if float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n]) != 0:
-                iou = self.true_positive_classes[n] / float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n])
+            if (
+                float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
+                != 0
+            ):
+                iou = self.true_positive_classes[n] / float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
                 iou_list.append(iou)
             else:
                 iou_list.append(0.0)
         mean_iou = sum(iou_list) / float(self.cfg.num_classes)
         return mean_iou, iou_list
 
 
-
 class Dilated_res_block(nn.Module):
     def __init__(self, d_in, d_out):
         super().__init__()
 
-        self.mlp1 = pt_utils.Conv2d(d_in, d_out//2, kernel_size=(1,1), bn=True)
+        self.mlp1 = pt_utils.Conv2d(d_in, d_out // 2, kernel_size=(1, 1), bn=True)
         self.lfa = Building_block(d_out)
-        self.mlp2 = pt_utils.Conv2d(d_out, d_out*2, kernel_size=(1, 1), bn=True, activation=None)
-        self.shortcut = pt_utils.Conv2d(d_in, d_out*2, kernel_size=(1,1), bn=True, activation=None)
+        self.mlp2 = pt_utils.Conv2d(
+            d_out, d_out * 2, kernel_size=(1, 1), bn=True, activation=None
+        )
+        self.shortcut = pt_utils.Conv2d(
+            d_in, d_out * 2, kernel_size=(1, 1), bn=True, activation=None
+        )
 
     def forward(self, feature, xyz, neigh_idx):
         f_pc = self.mlp1(feature)  # Batch*channel*npoints*1
         f_pc = self.lfa(xyz, f_pc, neigh_idx)  # Batch*d_out*npoints*1
         f_pc = self.mlp2(f_pc)
         shortcut = self.shortcut(feature)
-        return F.leaky_relu(f_pc+shortcut, negative_slope=0.2)
+        return F.leaky_relu(f_pc + shortcut, negative_slope=0.2)
 
 
 class Building_block(nn.Module):
     def __init__(self, d_out):  #  d_in = d_out//2
         super().__init__()
-        self.mlp1 = pt_utils.Conv2d(10, d_out//2, kernel_size=(1,1), bn=True)
-        self.att_pooling_1 = Att_pooling(d_out, d_out//2)
-
-        self.mlp2 = pt_utils.Conv2d(d_out//2, d_out//2, kernel_size=(1, 1), bn=True)
+        self.mlp1 = pt_utils.Conv2d(10, d_out // 2, kernel_size=(1, 1), bn=True)
+        self.att_pooling_1 = Att_pooling(d_out, d_out // 2)
+
+        self.mlp2 = pt_utils.Conv2d(d_out // 2, d_out // 2, kernel_size=(1, 1), bn=True)
         self.att_pooling_2 = Att_pooling(d_out, d_out)
 
     def forward(self, xyz, feature, neigh_idx):  # feature: Batch*channel*npoints*1
         f_xyz = self.relative_pos_encoding(xyz, neigh_idx)  # batch*npoint*nsamples*10
         f_xyz = f_xyz.permute((0, 3, 1, 2))  # batch*10*npoint*nsamples
         f_xyz = self.mlp1(f_xyz)
-        f_neighbours = self.gather_neighbour(feature.squeeze(-1).permute((0, 2, 1)), neigh_idx)  # batch*npoint*nsamples*channel
-        f_neighbours = f_neighbours.permute((0, 3, 1, 2))  # batch*channel*npoint*nsamples
+        f_neighbours = self.gather_neighbour(
+            feature.squeeze(-1).permute((0, 2, 1)), neigh_idx
+        )  # batch*npoint*nsamples*channel
+        f_neighbours = f_neighbours.permute(
+            (0, 3, 1, 2)
+        )  # batch*channel*npoint*nsamples
         f_concat = torch.cat([f_neighbours, f_xyz], dim=1)
         f_pc_agg = self.att_pooling_1(f_concat)  # Batch*channel*npoints*1
 
         f_xyz = self.mlp2(f_xyz)
-        f_neighbours = self.gather_neighbour(f_pc_agg.squeeze(-1).permute((0, 2, 1)), neigh_idx)  # batch*npoint*nsamples*channel
-        f_neighbours = f_neighbours.permute((0, 3, 1, 2))  # batch*channel*npoint*nsamples
+        f_neighbours = self.gather_neighbour(
+            f_pc_agg.squeeze(-1).permute((0, 2, 1)), neigh_idx
+        )  # batch*npoint*nsamples*channel
+        f_neighbours = f_neighbours.permute(
+            (0, 3, 1, 2)
+        )  # batch*channel*npoint*nsamples
         f_concat = torch.cat([f_neighbours, f_xyz], dim=1)
         f_pc_agg = self.att_pooling_2(f_concat)
         return f_pc_agg
 
     def relative_pos_encoding(self, xyz, neigh_idx):
         neighbor_xyz = self.gather_neighbour(xyz, neigh_idx)  # batch*npoint*nsamples*3
 
-        xyz_tile = xyz.unsqueeze(2).repeat(1, 1, neigh_idx.shape[-1], 1)  # batch*npoint*nsamples*3
+        xyz_tile = xyz.unsqueeze(2).repeat(
+            1, 1, neigh_idx.shape[-1], 1
+        )  # batch*npoint*nsamples*3
         relative_xyz = xyz_tile - neighbor_xyz  # batch*npoint*nsamples*3
-        relative_dis = torch.sqrt(torch.sum(torch.pow(relative_xyz, 2), dim=-1, keepdim=True))  # batch*npoint*nsamples*1
-        relative_feature = torch.cat([relative_dis, relative_xyz, xyz_tile, neighbor_xyz], dim=-1)  # batch*npoint*nsamples*10
+        relative_dis = torch.sqrt(
+            torch.sum(torch.pow(relative_xyz, 2), dim=-1, keepdim=True)
+        )  # batch*npoint*nsamples*1
+        relative_feature = torch.cat(
+            [relative_dis, relative_xyz, xyz_tile, neighbor_xyz], dim=-1
+        )  # batch*npoint*nsamples*10
         return relative_feature
 
     @staticmethod
     def gather_neighbour(pc, neighbor_idx):  # pc: batch*npoint*channel
         # gather the coordinates or features of neighboring points
         batch_size = pc.shape[0]
         num_points = pc.shape[1]
         d = pc.shape[2]
         index_input = neighbor_idx.reshape(batch_size, -1)
-        features = torch.gather(pc, 1, index_input.unsqueeze(-1).repeat(1, 1, pc.shape[2]))
-        features = features.reshape(batch_size, num_points, neighbor_idx.shape[-1], d)  # batch*npoint*nsamples*channel
+        features = torch.gather(
+            pc, 1, index_input.unsqueeze(-1).repeat(1, 1, pc.shape[2])
+        )
+        features = features.reshape(
+            batch_size, num_points, neighbor_idx.shape[-1], d
+        )  # batch*npoint*nsamples*channel
         return features
 
 
 class Att_pooling(nn.Module):
     def __init__(self, d_in, d_out):
         super().__init__()
         self.fc = nn.Conv2d(d_in, d_in, (1, 1), bias=False)
-        self.mlp = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
+        self.mlp = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
 
     def forward(self, feature_set):
 
         att_activation = self.fc(feature_set)
         att_scores = F.softmax(att_activation, dim=3)
@@ -330,12 +376,12 @@
         return f_agg
 
 
 def compute_loss(end_points, cfg):
 
-    logits = end_points['logits']
-    labels = end_points['labels']
+    logits = end_points["logits"]
+    labels = end_points["labels"]
 
     logits = logits.transpose(1, 2).reshape(-1, cfg.num_classes)
     labels = labels.reshape(-1)
 
     # Boolean mask of points that should be ignored
@@ -350,27 +396,24 @@
 
     # Reduce label values in the range of logit shape
     reducing_list = torch.range(0, cfg.num_classes).long().cuda()
     inserted_value = torch.zeros((1,)).long().cuda()
     for ign_label in cfg.ignored_label_inds:
-        reducing_list = torch.cat([reducing_list[:ign_label], inserted_value, reducing_list[ign_label:]], 0)
+        reducing_list = torch.cat(
+            [reducing_list[:ign_label], inserted_value, reducing_list[ign_label:]], 0
+        )
     valid_labels = torch.gather(reducing_list, 0, valid_labels_init)
     loss = get_loss(valid_logits, valid_labels, cfg.class_weights)
-    end_points['valid_logits'], end_points['valid_labels'] = valid_logits, valid_labels
-    end_points['loss'] = loss
+    end_points["valid_logits"], end_points["valid_labels"] = valid_logits, valid_labels
+    end_points["loss"] = loss
     return loss, end_points
 
 
 def get_loss(logits, labels, pre_cal_weights):
     # calculate the weighted cross entropy according to the inverse frequency
     class_weights = torch.from_numpy(pre_cal_weights).float().cuda()
     # one_hot_labels = F.one_hot(labels, self.config.num_classes)
 
-    criterion = nn.CrossEntropyLoss(weight=class_weights, reduction='none')
+    criterion = nn.CrossEntropyLoss(weight=class_weights, reduction="none")
     output_loss = criterion(logits, labels)
     output_loss = output_loss.mean()
     return output_loss
-        
-            
-                            
-                            
-        
\ No newline at end of file
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/sync_bn/__init__.py	2024-06-30 23:19:44.678627+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/sync_bn/__init__.py	2024-07-08 11:53:40.281504+00:00
@@ -1,12 +1,16 @@
 # -*- coding: utf-8 -*-
 # File   : __init__.py
 # Author : Jiayuan Mao
 # Email  : maojiayuan@gmail.com
 # Date   : 27/01/2018
-# 
+#
 # This file is part of Synchronized-BatchNorm-PyTorch.
 # https://github.com/vacancy/Synchronized-BatchNorm-PyTorch
 # Distributed under MIT License.
 
-from .batchnorm import SynchronizedBatchNorm1d, SynchronizedBatchNorm2d, SynchronizedBatchNorm3d
+from .batchnorm import (
+    SynchronizedBatchNorm1d,
+    SynchronizedBatchNorm2d,
+    SynchronizedBatchNorm3d,
+)
 from .replicate import DataParallelWithCallback, patch_replication_callback
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/scannetv2_seg_dataset_rgb21c_pointid.py	2024-06-30 23:19:41.970201+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/scannetv2_seg_dataset_rgb21c_pointid.py	2024-07-08 11:53:40.361931+00:00
@@ -13,20 +13,18 @@
 import pickle
 from plyfile import PlyData, PlyElement
 
 
 def remove_unano(scene_data, scene_label, scene_data_id):
-    keep_idx = np.where((scene_label > 0) & (
-        scene_label < 41))  # 0: unanotated
+    keep_idx = np.where((scene_label > 0) & (scene_label < 41))  # 0: unanotated
     scene_data_clean = scene_data[keep_idx]
     scene_label_clean = scene_label[keep_idx]
     scene_data_id_clean = scene_data_id[keep_idx]
     return scene_data_clean, scene_label_clean, scene_data_id_clean
 
 
-test_class = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9,
-              10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39]
+test_class = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39]
 
 
 def gen_label_map():
     label_map = np.zeros(41)
     for i in range(41):
@@ -37,11 +35,11 @@
     print(label_map)
     return label_map
 
 
 def gen_pickle(split="val", keep_unanno=False, root="DataSet/Scannet_v2"):
-    if split == 'test':
+    if split == "test":
         root_new = root + "/scans_test"
     else:
         root_new = root + "/scans"
     file_list = "scannetv2_%s.txt" % (split)
     with open(file_list) as fl:
@@ -51,64 +49,77 @@
     scene_data_labels = []
     scene_data_id = []
     scene_data_num = []
     label_map = gen_label_map()
     for i in range(len(scene_id)):  # len(scene_id)
-        print('process...', i)
+        print("process...", i)
         scene_namergb = os.path.join(
-            root_new, scene_id[i], scene_id[i]+'_vh_clean_2.ply')
+            root_new, scene_id[i], scene_id[i] + "_vh_clean_2.ply"
+        )
         scene_xyzlabelrgb = PlyData.read(scene_namergb)
-        scene_vertex_rgb = scene_xyzlabelrgb['vertex']
-        scene_data_tmp = np.stack((scene_vertex_rgb['x'], scene_vertex_rgb['y'],
-                                   scene_vertex_rgb['z'], scene_vertex_rgb['red'],
-                                   scene_vertex_rgb['green'], scene_vertex_rgb['blue']), axis=-1).astype(np.float32)
+        scene_vertex_rgb = scene_xyzlabelrgb["vertex"]
+        scene_data_tmp = np.stack(
+            (
+                scene_vertex_rgb["x"],
+                scene_vertex_rgb["y"],
+                scene_vertex_rgb["z"],
+                scene_vertex_rgb["red"],
+                scene_vertex_rgb["green"],
+                scene_vertex_rgb["blue"],
+            ),
+            axis=-1,
+        ).astype(np.float32)
         scene_points_num = scene_data_tmp.shape[0]
         scene_point_id = np.array([c for c in range(scene_points_num)])
         if not keep_unanno:
             scene_name = os.path.join(
-                root_new, scene_id[i], scene_id[i]+'_vh_clean_2.labels.ply')
+                root_new, scene_id[i], scene_id[i] + "_vh_clean_2.labels.ply"
+            )
             scene_xyzlabel = PlyData.read(scene_name)
-            scene_vertex = scene_xyzlabel['vertex']
-            scene_data_label_tmp = scene_vertex['label']
+            scene_vertex = scene_xyzlabel["vertex"]
+            scene_data_label_tmp = scene_vertex["label"]
             scene_data_tmp, scene_data_label_tmp, scene_point_id_tmp = remove_unano(
-                scene_data_tmp, scene_data_label_tmp, scene_point_id)
+                scene_data_tmp, scene_data_label_tmp, scene_point_id
+            )
             scene_data_label_tmp = label_map[scene_data_label_tmp]
-        elif split != 'test':
+        elif split != "test":
             scene_name = os.path.join(
-                root_new, scene_id[i], scene_id[i]+'_vh_clean_2.labels.ply')
+                root_new, scene_id[i], scene_id[i] + "_vh_clean_2.labels.ply"
+            )
             scene_xyzlabel = PlyData.read(scene_name)
-            scene_vertex = scene_xyzlabel['vertex']
+            scene_vertex = scene_xyzlabel["vertex"]
             scene_point_id_tmp = scene_point_id
-            scene_data_label_tmp = scene_vertex['label']
+            scene_data_label_tmp = scene_vertex["label"]
             scene_data_label_tmp[np.where(scene_data_label_tmp > 40)] = 0
             scene_data_label_tmp = label_map[scene_data_label_tmp]
         else:
-            scene_data_label_tmp = np.zeros(
-                (scene_data_tmp.shape[0])).astype(np.int32)
+            scene_data_label_tmp = np.zeros((scene_data_tmp.shape[0])).astype(np.int32)
             scene_point_id_tmp = scene_point_id
         scene_data.append(scene_data_tmp)
         scene_data_labels.append(scene_data_label_tmp)
         scene_data_id.append(scene_point_id_tmp)
         scene_data_num.append(scene_points_num)
 
     if not keep_unanno:
         out_path = os.path.join(root, "scannet_%s_rgb21c_pointid.pickle" % (split))
     else:
-        out_path = os.path.join(root, "scannet_%s_rgb21c_pointid_keep_unanno.pickle" % (split))
+        out_path = os.path.join(
+            root, "scannet_%s_rgb21c_pointid_keep_unanno.pickle" % (split)
+        )
     pickle_out = open(out_path, "wb")
     pickle.dump(scene_data, pickle_out, protocol=0)
     pickle.dump(scene_data_labels, pickle_out, protocol=0)
     pickle.dump(scene_data_id, pickle_out, protocol=0)
     pickle.dump(scene_data_num, pickle_out, protocol=0)
     pickle_out.close()
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
 
     # modify this path to your Scannet v2 dataset Path
     root = "../data/ScanNet"
-    gen_pickle(split='train', keep_unanno=False, root=root)
-    gen_pickle(split='val', keep_unanno=False, root=root)
-    gen_pickle(split='val', keep_unanno=True, root=root)
-    gen_pickle(split='test', keep_unanno=True, root=root)
+    gen_pickle(split="train", keep_unanno=False, root=root)
+    gen_pickle(split="val", keep_unanno=False, root=root)
+    gen_pickle(split="val", keep_unanno=True, root=root)
+    gen_pickle(split="test", keep_unanno=True, root=root)
 
-    print('Done!!!')
+    print("Done!!!")
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/provider.py	2024-07-07 18:53:18.197521+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/provider.py	2024-07-08 11:53:40.441773+00:00
@@ -1,60 +1,72 @@
 import h5py
 
+
 def read_txt_file(file_path, num_points: np.int32):
-  data_app = []
-  labels_app = []
-  for f in file_path:
-      with open(f) as file:
-          count=0
-          data = []
-          labels = []
-          for line in file:
-              values = line.strip().split(' ')
-              data.append([np.float32(value) for value in values[:-1]])
-              labels.append(np.int32(float(values[-1])))
-          data = np.array(data)
-          labels = np.array(labels)
-          data_app = data if len(data_app) == 0 else np.dstack((data_app, data))
-          labels_app = labels if len(labels_app) == 0 else np.dstack((labels_app, labels))
-  return np.transpose(data_app, (2,0,1)), np.squeeze(np.transpose(labels_app))
+    data_app = []
+    labels_app = []
+    for f in file_path:
+        with open(f) as file:
+            count = 0
+            data = []
+            labels = []
+            for line in file:
+                values = line.strip().split(" ")
+                data.append([np.float32(value) for value in values[:-1]])
+                labels.append(np.int32(float(values[-1])))
+            data = np.array(data)
+            labels = np.array(labels)
+            data_app = data if len(data_app) == 0 else np.dstack((data_app, data))
+            labels_app = (
+                labels if len(labels_app) == 0 else np.dstack((labels_app, labels))
+            )
+    return np.transpose(data_app, (2, 0, 1)), np.squeeze(np.transpose(labels_app))
 
 
-def getDataFiles(data_path, num_points:int):
-  output_file = 'out.h5'
+def getDataFiles(data_path, num_points: int):
+    output_file = "out.h5"
 
-  str_fname = [line.rstrip() for line in open(os.path.join(data_path, 'synsetoffset2category.txt'))][0]
-  sub_filename = str_fname.split()[1]
+    str_fname = [
+        line.rstrip()
+        for line in open(os.path.join(data_path, "synsetoffset2category.txt"))
+    ][0]
+    sub_filename = str_fname.split()[1]
 
-  json_files = glob.glob(os.path.join(data_path, 'train_test_split', '*.json'))
-  if os.path.isfile(os.path.join(data_path, output_file)) is False:
-    for file in json_files:
-      fname = file.split('/')[-1]
-      stage_name = fname.split('_')[1]
-      f = open(file)
-      jsonf = json.load(f)
-      file_arr = [line.rstrip().split('/')[-1] for line in jsonf]
-      file_paths = [os.path.join(data_path, sub_filename,i+'.txt') for i in file_arr]
-      out_data, out_labels = read_txt_file(file_path=file_paths, num_points=num_points)
-      
-      with h5py.File(os.path.join(data_path, output_file), 'a') as hfile:
-        group = hfile.create_group(str(stage_name))
-        group.create_dataset('data', data=out_data)
-        group.create_dataset('labels', data=out_labels)
-        print('%s data group created'%str(stage_name))
+    json_files = glob.glob(os.path.join(data_path, "train_test_split", "*.json"))
+    if os.path.isfile(os.path.join(data_path, output_file)) is False:
+        for file in json_files:
+            fname = file.split("/")[-1]
+            stage_name = fname.split("_")[1]
+            f = open(file)
+            jsonf = json.load(f)
+            file_arr = [line.rstrip().split("/")[-1] for line in jsonf]
+            file_paths = [
+                os.path.join(data_path, sub_filename, i + ".txt") for i in file_arr
+            ]
+            out_data, out_labels = read_txt_file(
+                file_path=file_paths, num_points=num_points
+            )
+
+            with h5py.File(os.path.join(data_path, output_file), "a") as hfile:
+                group = hfile.create_group(str(stage_name))
+                group.create_dataset("data", data=out_data)
+                group.create_dataset("labels", data=out_labels)
+                print("%s data group created" % str(stage_name))
+
 
 def load_h5(data_path, stage_name):
-  file = os.path.join(data_path, 'out.h5')
-  f = h5py.File(file, 'r')
-  data = f[str(stage_name)]['data'][:]
-  label = f[str(stage_name)]['labels'][:]
-  return (data, label)
+    file = os.path.join(data_path, "out.h5")
+    f = h5py.File(file, "r")
+    data = f[str(stage_name)]["data"][:]
+    label = f[str(stage_name)]["labels"][:]
+    return (data, label)
+
 
 def loadDataFile(data_path, stage_name):
-  return load_h5(data_path, stage_name)
+    return load_h5(data_path, stage_name)
 
 
 def load_h5_data_label_seg(h5_filename):
-  f = h5py.File(h5_filename)
-  data = f['data'][:] # (2048, 2048, 3)
-  seg = f['labels'][:] # (2048, 2048)
-  return (data, seg)
\ No newline at end of file
+    f = h5py.File(h5_filename)
+    data = f["data"][:]  # (2048, 2048, 3)
+    seg = f["labels"][:]  # (2048, 2048)
+    return (data, seg)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/util.py	2024-06-30 23:19:41.985827+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/util.py	2024-07-08 11:53:40.509156+00:00
@@ -1,7 +1,8 @@
 import os, sys
 import csv
+
 try:
     import numpy as np
 except:
     print("Failed to import numpy package.")
     sys.exit(-1)
@@ -10,61 +11,62 @@
 except:
     print("Please install the module 'imageio' for image processing, e.g.")
     print("pip install imageio")
     sys.exit(-1)
 
+
 # print an error message and quit
 def print_error(message, user_fault=False):
-    sys.stderr.write('ERROR: ' + str(message) + '\n')
+    sys.stderr.write("ERROR: " + str(message) + "\n")
     if user_fault:
-      sys.exit(2)
+        sys.exit(2)
     sys.exit(-1)
 
 
 # if string s represents an int
 def represents_int(s):
-    try: 
+    try:
         int(s)
         return True
     except ValueError:
         return False
 
 
-def read_label_mapping(filename, label_from='raw_category', label_to='nyu40id'):
+def read_label_mapping(filename, label_from="raw_category", label_to="nyu40id"):
     assert os.path.isfile(filename)
     mapping = dict()
     with open(filename) as csvfile:
-        reader = csv.DictReader(csvfile, delimiter='\t')
+        reader = csv.DictReader(csvfile, delimiter="\t")
         for row in reader:
             mapping[row[label_from]] = int(row[label_to])
-    # if ints convert 
+    # if ints convert
     if represents_int(mapping.keys()[0]):
-        mapping = {int(k):v for k,v in mapping.items()}
+        mapping = {int(k): v for k, v in mapping.items()}
     return mapping
 
 
 # input: scene_types.txt or scene_types_all.txt
 def read_scene_types_mapping(filename, remove_spaces=True):
     assert os.path.isfile(filename)
     mapping = dict()
     lines = open(filename).read().splitlines()
-    lines = [line.split('\t') for line in lines]
+    lines = [line.split("\t") for line in lines]
     if remove_spaces:
-        mapping = { x[1].strip():int(x[0]) for x in lines }
+        mapping = {x[1].strip(): int(x[0]) for x in lines}
     else:
-        mapping = { x[1]:int(x[0]) for x in lines }        
+        mapping = {x[1]: int(x[0]) for x in lines}
     return mapping
 
 
 # color by label
 def visualize_label_image(filename, image):
     height = image.shape[0]
     width = image.shape[1]
     vis_image = np.zeros([height, width, 3], dtype=np.uint8)
     color_palette = create_color_palette()
     for idx, color in enumerate(color_palette):
-        vis_image[image==idx] = color
+        vis_image[image == idx] = color
     imageio.imwrite(filename, vis_image)
 
 
 # color by different instances (mod length of color palette)
 def visualize_instance_image(filename, image):
@@ -72,54 +74,54 @@
     width = image.shape[1]
     vis_image = np.zeros([height, width, 3], dtype=np.uint8)
     color_palette = create_color_palette()
     instances = np.unique(image)
     for idx, inst in enumerate(instances):
-        vis_image[image==inst] = color_palette[inst%len(color_palette)]
+        vis_image[image == inst] = color_palette[inst % len(color_palette)]
     imageio.imwrite(filename, vis_image)
 
 
 # color palette for nyu40 labels
 def create_color_palette():
     return [
-       (0, 0, 0),
-       (174, 199, 232),		# wall
-       (152, 223, 138),		# floor
-       (31, 119, 180), 		# cabinet
-       (255, 187, 120),		# bed
-       (188, 189, 34), 		# chair
-       (140, 86, 75),  		# sofa
-       (255, 152, 150),		# table
-       (214, 39, 40),  		# door
-       (197, 176, 213),		# window
-       (148, 103, 189),		# bookshelf
-       (196, 156, 148),		# picture
-       (23, 190, 207), 		# counter
-       (178, 76, 76),  
-       (247, 182, 210),		# desk
-       (66, 188, 102), 
-       (219, 219, 141),		# curtain
-       (140, 57, 197), 
-       (202, 185, 52), 
-       (51, 176, 203), 
-       (200, 54, 131), 
-       (92, 193, 61),  
-       (78, 71, 183),  
-       (172, 114, 82), 
-       (255, 127, 14), 		# refrigerator
-       (91, 163, 138), 
-       (153, 98, 156), 
-       (140, 153, 101),
-       (158, 218, 229),		# shower curtain
-       (100, 125, 154),
-       (178, 127, 135),
-       (120, 185, 128),
-       (146, 111, 194),
-       (44, 160, 44),  		# toilet
-       (112, 128, 144),		# sink
-       (96, 207, 209), 
-       (227, 119, 194),		# bathtub
-       (213, 92, 176), 
-       (94, 106, 211), 
-       (82, 84, 163),  		# otherfurn
-       (100, 85, 144)
+        (0, 0, 0),
+        (174, 199, 232),  # wall
+        (152, 223, 138),  # floor
+        (31, 119, 180),  # cabinet
+        (255, 187, 120),  # bed
+        (188, 189, 34),  # chair
+        (140, 86, 75),  # sofa
+        (255, 152, 150),  # table
+        (214, 39, 40),  # door
+        (197, 176, 213),  # window
+        (148, 103, 189),  # bookshelf
+        (196, 156, 148),  # picture
+        (23, 190, 207),  # counter
+        (178, 76, 76),
+        (247, 182, 210),  # desk
+        (66, 188, 102),
+        (219, 219, 141),  # curtain
+        (140, 57, 197),
+        (202, 185, 52),
+        (51, 176, 203),
+        (200, 54, 131),
+        (92, 193, 61),
+        (78, 71, 183),
+        (172, 114, 82),
+        (255, 127, 14),  # refrigerator
+        (91, 163, 138),
+        (153, 98, 156),
+        (140, 153, 101),
+        (158, 218, 229),  # shower curtain
+        (100, 125, 154),
+        (178, 127, 135),
+        (120, 185, 128),
+        (146, 111, 194),
+        (44, 160, 44),  # toilet
+        (112, 128, 144),  # sink
+        (96, 207, 209),
+        (227, 119, 194),  # bathtub
+        (213, 92, 176),
+        (94, 106, 211),
+        (82, 84, 163),  # otherfurn
+        (100, 85, 144),
     ]
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/sync_bn/replicate.py	2024-06-30 23:19:44.678627+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/sync_bn/replicate.py	2024-07-08 11:53:40.566991+00:00
@@ -1,24 +1,24 @@
 # -*- coding: utf-8 -*-
 # File   : replicate.py
 # Author : Jiayuan Mao
 # Email  : maojiayuan@gmail.com
 # Date   : 27/01/2018
-# 
+#
 # This file is part of Synchronized-BatchNorm-PyTorch.
 # https://github.com/vacancy/Synchronized-BatchNorm-PyTorch
 # Distributed under MIT License.
 
 import functools
 
 from torch.nn.parallel.data_parallel import DataParallel
 
 __all__ = [
-    'CallbackContext',
-    'execute_replication_callbacks',
-    'DataParallelWithCallback',
-    'patch_replication_callback'
+    "CallbackContext",
+    "execute_replication_callbacks",
+    "DataParallelWithCallback",
+    "patch_replication_callback",
 ]
 
 
 class CallbackContext(object):
     pass
@@ -41,11 +41,11 @@
     nr_modules = len(list(master_copy.modules()))
     ctxs = [CallbackContext() for _ in range(nr_modules)]
 
     for i, module in enumerate(modules):
         for j, m in enumerate(module.modules()):
-            if hasattr(m, '__data_parallel_replicate__'):
+            if hasattr(m, "__data_parallel_replicate__"):
                 m.__data_parallel_replicate__(ctxs[j], i)
 
 
 class DataParallelWithCallback(DataParallel):
     """
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/sync_bn/unittest.py	2024-06-30 23:19:44.695468+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/sync_bn/unittest.py	2024-07-08 11:53:40.586806+00:00
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # File   : unittest.py
 # Author : Jiayuan Mao
 # Email  : maojiayuan@gmail.com
 # Date   : 27/01/2018
-# 
+#
 # This file is part of Synchronized-BatchNorm-PyTorch.
 # https://github.com/vacancy/Synchronized-BatchNorm-PyTorch
 # Distributed under MIT License.
 
 import unittest
@@ -22,8 +22,13 @@
 
 class TorchTestCase(unittest.TestCase):
     def assertTensorClose(self, a, b, atol=1e-3, rtol=1e-3):
         npa, npb = as_numpy(a), as_numpy(b)
         self.assertTrue(
-                np.allclose(npa, npb, atol=atol),
-                'Tensor close check failed\n{}\n{}\nadiff={}, rdiff={}'.format(a, b, np.abs(npa - npb).max(), np.abs((npa - npb) / np.fmax(npa, 1e-5)).max())
+            np.allclose(npa, npb, atol=atol),
+            "Tensor close check failed\n{}\n{}\nadiff={}, rdiff={}".format(
+                a,
+                b,
+                np.abs(npa - npb).max(),
+                np.abs((npa - npb) / np.fmax(npa, 1e-5)).max(),
+            ),
         )
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/sync_bn/comm.py	2024-06-30 23:19:44.678627+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/sync_bn/comm.py	2024-07-08 11:53:40.616899+00:00
@@ -1,20 +1,20 @@
 # -*- coding: utf-8 -*-
 # File   : comm.py
 # Author : Jiayuan Mao
 # Email  : maojiayuan@gmail.com
 # Date   : 27/01/2018
-# 
+#
 # This file is part of Synchronized-BatchNorm-PyTorch.
 # https://github.com/vacancy/Synchronized-BatchNorm-PyTorch
 # Distributed under MIT License.
 
 import queue
 import collections
 import threading
 
-__all__ = ['FutureResult', 'SlavePipe', 'SyncMaster']
+__all__ = ["FutureResult", "SlavePipe", "SyncMaster"]
 
 
 class FutureResult(object):
     """A thread-safe future implementation. Used only as one-to-one pipe."""
 
@@ -23,11 +23,11 @@
         self._lock = threading.Lock()
         self._cond = threading.Condition(self._lock)
 
     def put(self, result):
         with self._lock:
-            assert self._result is None, 'Previous result has\'t been fetched.'
+            assert self._result is None, "Previous result has't been fetched."
             self._result = result
             self._cond.notify()
 
     def get(self):
         with self._lock:
@@ -37,12 +37,14 @@
             res = self._result
             self._result = None
             return res
 
 
-_MasterRegistry = collections.namedtuple('MasterRegistry', ['result'])
-_SlavePipeBase = collections.namedtuple('_SlavePipeBase', ['identifier', 'queue', 'result'])
+_MasterRegistry = collections.namedtuple("MasterRegistry", ["result"])
+_SlavePipeBase = collections.namedtuple(
+    "_SlavePipeBase", ["identifier", "queue", "result"]
+)
 
 
 class SlavePipe(_SlavePipeBase):
     """Pipe for master-slave communication."""
 
@@ -74,14 +76,14 @@
         self._queue = queue.Queue()
         self._registry = collections.OrderedDict()
         self._activated = False
 
     def __getstate__(self):
-        return {'master_callback': self._master_callback}
+        return {"master_callback": self._master_callback}
 
     def __setstate__(self, state):
-        self.__init__(state['master_callback'])
+        self.__init__(state["master_callback"])
 
     def register_slave(self, identifier):
         """
         Register an slave device.
 
@@ -90,11 +92,11 @@
 
         Returns: a `SlavePipe` object which can be used to communicate with the master device.
 
         """
         if self._activated:
-            assert self._queue.empty(), 'Queue is not clean before next initialization.'
+            assert self._queue.empty(), "Queue is not clean before next initialization."
             self._activated = False
             self._registry.clear()
         future = FutureResult()
         self._registry[identifier] = _MasterRegistry(future)
         return SlavePipe(identifier, self._queue, future)
@@ -118,11 +120,11 @@
         intermediates = [(0, master_msg)]
         for i in range(self.nr_slaves):
             intermediates.append(self._queue.get())
 
         results = self._master_callback(intermediates)
-        assert results[0][0] == 0, 'The first result should belongs to the master.'
+        assert results[0][0] == 0, "The first result should belongs to the master."
 
         for i, res in results:
             if i == 0:
                 continue
             self._registry[i].result.put(res)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/sync_bn/batchnorm.py	2024-06-30 23:19:44.678627+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/sync_bn/batchnorm.py	2024-07-08 11:53:40.736212+00:00
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 # File   : batchnorm.py
 # Author : Jiayuan Mao
 # Email  : maojiayuan@gmail.com
 # Date   : 27/01/2018
-# 
+#
 # This file is part of Synchronized-BatchNorm-PyTorch.
 # https://github.com/vacancy/Synchronized-BatchNorm-PyTorch
 # Distributed under MIT License.
 
 import collections
@@ -16,11 +16,15 @@
 from torch.nn.modules.batchnorm import _BatchNorm
 from torch.nn.parallel._functions import ReduceAddCoalesced, Broadcast
 
 from .comm import SyncMaster
 
-__all__ = ['SynchronizedBatchNorm1d', 'SynchronizedBatchNorm2d', 'SynchronizedBatchNorm3d']
+__all__ = [
+    "SynchronizedBatchNorm1d",
+    "SynchronizedBatchNorm2d",
+    "SynchronizedBatchNorm3d",
+]
 
 
 def _sum_ft(tensor):
     """sum over the first and last dimention"""
     return tensor.sum(dim=0).sum(dim=-1)
@@ -29,17 +33,19 @@
 def _unsqueeze_ft(tensor):
     """add new dementions at the front and the tail"""
     return tensor.unsqueeze(0).unsqueeze(-1)
 
 
-_ChildMessage = collections.namedtuple('_ChildMessage', ['sum', 'ssum', 'sum_size'])
-_MasterMessage = collections.namedtuple('_MasterMessage', ['sum', 'inv_std'])
+_ChildMessage = collections.namedtuple("_ChildMessage", ["sum", "ssum", "sum_size"])
+_MasterMessage = collections.namedtuple("_MasterMessage", ["sum", "inv_std"])
 
 
 class _SynchronizedBatchNorm(_BatchNorm):
     def __init__(self, num_features, eps=1e-5, momentum=0.1, affine=True):
-        super(_SynchronizedBatchNorm, self).__init__(num_features, eps=eps, momentum=momentum, affine=affine)
+        super(_SynchronizedBatchNorm, self).__init__(
+            num_features, eps=eps, momentum=momentum, affine=affine
+        )
 
         self._sync_master = SyncMaster(self._data_parallel_master)
 
         self._is_parallel = False
         self._parallel_id = None
@@ -47,32 +53,45 @@
 
     def forward(self, input):
         # If it is not parallel computation or is in evaluation mode, use PyTorch's implementation.
         if not (self._is_parallel and self.training):
             return F.batch_norm(
-                input, self.running_mean, self.running_var, self.weight, self.bias,
-                self.training, self.momentum, self.eps)
+                input,
+                self.running_mean,
+                self.running_var,
+                self.weight,
+                self.bias,
+                self.training,
+                self.momentum,
+                self.eps,
+            )
 
         # Resize the input to (B, C, -1).
         input_shape = input.size()
         input = input.view(input.size(0), self.num_features, -1)
 
         # Compute the sum and square-sum.
         sum_size = input.size(0) * input.size(2)
         input_sum = _sum_ft(input)
-        input_ssum = _sum_ft(input ** 2)
+        input_ssum = _sum_ft(input**2)
 
         # Reduce-and-broadcast the statistics.
         if self._parallel_id == 0:
-            mean, inv_std = self._sync_master.run_master(_ChildMessage(input_sum, input_ssum, sum_size))
+            mean, inv_std = self._sync_master.run_master(
+                _ChildMessage(input_sum, input_ssum, sum_size)
+            )
         else:
-            mean, inv_std = self._slave_pipe.run_slave(_ChildMessage(input_sum, input_ssum, sum_size))
+            mean, inv_std = self._slave_pipe.run_slave(
+                _ChildMessage(input_sum, input_ssum, sum_size)
+            )
 
         # Compute the output.
         if self.affine:
             # MJY:: Fuse the multiplication for speed.
-            output = (input - _unsqueeze_ft(mean)) * _unsqueeze_ft(inv_std * self.weight) + _unsqueeze_ft(self.bias)
+            output = (input - _unsqueeze_ft(mean)) * _unsqueeze_ft(
+                inv_std * self.weight
+            ) + _unsqueeze_ft(self.bias)
         else:
             output = (input - _unsqueeze_ft(mean)) * _unsqueeze_ft(inv_std)
 
         # Reshape it.
         return output.view(input_shape)
@@ -104,25 +123,31 @@
 
         broadcasted = Broadcast.apply(target_gpus, mean, inv_std)
 
         outputs = []
         for i, rec in enumerate(intermediates):
-            outputs.append((rec[0], _MasterMessage(*broadcasted[i*2:i*2+2])))
+            outputs.append((rec[0], _MasterMessage(*broadcasted[i * 2 : i * 2 + 2])))
 
         return outputs
 
     def _compute_mean_std(self, sum_, ssum, size):
         """Compute the mean and standard-deviation with sum and square-sum. This method
         also maintains the moving average on the master device."""
-        assert size > 1, 'BatchNorm computes unbiased standard-deviation, which requires size > 1.'
+        assert (
+            size > 1
+        ), "BatchNorm computes unbiased standard-deviation, which requires size > 1."
         mean = sum_ / size
         sumvar = ssum - sum_ * mean
         unbias_var = sumvar / (size - 1)
         bias_var = sumvar / size
 
-        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean.data
-        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * unbias_var.data
+        self.running_mean = (
+            1 - self.momentum
+        ) * self.running_mean + self.momentum * mean.data
+        self.running_var = (
+            1 - self.momentum
+        ) * self.running_var + self.momentum * unbias_var.data
 
         return mean, bias_var.clamp(self.eps) ** -0.5
 
 
 class SynchronizedBatchNorm1d(_SynchronizedBatchNorm):
@@ -140,11 +165,11 @@
     training, PyTorch's implementation normalize the tensor on each device using
     the statistics only on that device, which accelerated the computation and
     is also easy to implement, but the statistics might be inaccurate.
     Instead, in this synchronized version, the statistics will be computed
     over all training samples distributed on multiple devices.
-    
+
     Note that, for one-GPU or CPU-only case, this module behaves exactly same
     as the built-in PyTorch implementation.
 
     The mean and standard-deviation are calculated per-dimension over
     the mini-batches and gamma and beta are learnable parameter vectors
@@ -181,12 +206,13 @@
         >>> output = m(input)
     """
 
     def _check_input_dim(self, input):
         if input.dim() != 2 and input.dim() != 3:
-            raise ValueError('expected 2D or 3D input (got {}D input)'
-                             .format(input.dim()))
+            raise ValueError(
+                "expected 2D or 3D input (got {}D input)".format(input.dim())
+            )
         super(SynchronizedBatchNorm1d, self)._check_input_dim(input)
 
 
 class SynchronizedBatchNorm2d(_SynchronizedBatchNorm):
     r"""Applies Batch Normalization over a 4d input that is seen as a mini-batch
@@ -203,11 +229,11 @@
     training, PyTorch's implementation normalize the tensor on each device using
     the statistics only on that device, which accelerated the computation and
     is also easy to implement, but the statistics might be inaccurate.
     Instead, in this synchronized version, the statistics will be computed
     over all training samples distributed on multiple devices.
-    
+
     Note that, for one-GPU or CPU-only case, this module behaves exactly same
     as the built-in PyTorch implementation.
 
     The mean and standard-deviation are calculated per-dimension over
     the mini-batches and gamma and beta are learnable parameter vectors
@@ -244,12 +270,11 @@
         >>> output = m(input)
     """
 
     def _check_input_dim(self, input):
         if input.dim() != 4:
-            raise ValueError('expected 4D input (got {}D input)'
-                             .format(input.dim()))
+            raise ValueError("expected 4D input (got {}D input)".format(input.dim()))
         super(SynchronizedBatchNorm2d, self)._check_input_dim(input)
 
 
 class SynchronizedBatchNorm3d(_SynchronizedBatchNorm):
     r"""Applies Batch Normalization over a 5d input that is seen as a mini-batch
@@ -266,11 +291,11 @@
     training, PyTorch's implementation normalize the tensor on each device using
     the statistics only on that device, which accelerated the computation and
     is also easy to implement, but the statistics might be inaccurate.
     Instead, in this synchronized version, the statistics will be computed
     over all training samples distributed on multiple devices.
-    
+
     Note that, for one-GPU or CPU-only case, this module behaves exactly same
     as the built-in PyTorch implementation.
 
     The mean and standard-deviation are calculated per-dimension over
     the mini-batches and gamma and beta are learnable parameter vectors
@@ -308,8 +333,7 @@
         >>> output = m(input)
     """
 
     def _check_input_dim(self, input):
         if input.dim() != 5:
-            raise ValueError('expected 5D input (got {}D input)'
-                             .format(input.dim()))
+            raise ValueError("expected 5D input (got {}D input)".format(input.dim()))
         super(SynchronizedBatchNorm3d, self)._check_input_dim(input)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/main_semseg_s3dis.py	2024-07-07 12:26:43.820168+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/main_semseg_s3dis.py	2024-07-08 11:53:40.869481+00:00
@@ -29,21 +29,28 @@
 global room_pred
 room_pred = []
 global visual_warning
 visual_warning = True
 
+
 def _init_():
-    if not os.path.exists('outputs'):
-        os.makedirs('outputs')
-    if not os.path.exists('outputs/'+args.exp_name):
-        os.makedirs('outputs/'+args.exp_name)
-    if not os.path.exists('outputs/'+args.exp_name+'/'+'models'):
-        os.makedirs('outputs/'+args.exp_name+'/'+'models')
-    os.system('cp main_semseg_s3dis.py outputs'+'/'+args.exp_name+'/'+'main_semseg_s3dis.py.backup')
-    os.system('cp model.py outputs' + '/' + args.exp_name + '/' + 'model.py.backup')
-    os.system('cp util.py outputs' + '/' + args.exp_name + '/' + 'util.py.backup')
-    os.system('cp data.py outputs' + '/' + args.exp_name + '/' + 'data.py.backup')
+    if not os.path.exists("outputs"):
+        os.makedirs("outputs")
+    if not os.path.exists("outputs/" + args.exp_name):
+        os.makedirs("outputs/" + args.exp_name)
+    if not os.path.exists("outputs/" + args.exp_name + "/" + "models"):
+        os.makedirs("outputs/" + args.exp_name + "/" + "models")
+    os.system(
+        "cp main_semseg_s3dis.py outputs"
+        + "/"
+        + args.exp_name
+        + "/"
+        + "main_semseg_s3dis.py.backup"
+    )
+    os.system("cp model.py outputs" + "/" + args.exp_name + "/" + "model.py.backup")
+    os.system("cp util.py outputs" + "/" + args.exp_name + "/" + "util.py.backup")
+    os.system("cp data.py outputs" + "/" + args.exp_name + "/" + "data.py.backup")
 
 
 def calculate_sem_IoU(pred_np, seg_np, visual=False):
     I_all = np.zeros(13)
     U_all = np.zeros(13)
@@ -51,127 +58,359 @@
         for sem in range(13):
             I = np.sum(np.logical_and(pred_np[sem_idx] == sem, seg_np[sem_idx] == sem))
             U = np.sum(np.logical_or(pred_np[sem_idx] == sem, seg_np[sem_idx] == sem))
             I_all[sem] += I
             U_all[sem] += U
-    return I_all / U_all 
-
-
-def visualization(visu, visu_format, test_choice, data, seg, pred, visual_file_index, semseg_colors):
+    return I_all / U_all
+
+
+def visualization(
+    visu, visu_format, test_choice, data, seg, pred, visual_file_index, semseg_colors
+):
     global room_seg, room_pred
     global visual_warning
-    visu = visu.split('_')
+    visu = visu.split("_")
     for i in range(0, data.shape[0]):
         RGB = []
-        RGB_gt = [] 
+        RGB_gt = []
         skip = False
         with open("data/indoor3d_sem_seg_hdf5_data_test/room_filelist.txt") as f:
             files = f.readlines()
             test_area = files[visual_file_index][5]
             roomname = files[visual_file_index][7:-1]
             if visual_file_index + 1 < len(files):
-                roomname_next = files[visual_file_index+1][7:-1]
+                roomname_next = files[visual_file_index + 1][7:-1]
             else:
-                roomname_next = ''
-        if visu[0] != 'all':
+                roomname_next = ""
+        if visu[0] != "all":
             if len(visu) == 2:
-                if visu[0] != 'area' or visu[1] != test_area:
-                    skip = True 
+                if visu[0] != "area" or visu[1] != test_area:
+                    skip = True
                 else:
                     visual_warning = False
             elif len(visu) == 4:
-                if visu[0] != 'area' or visu[1] != test_area or visu[2] != roomname.split('_')[0] or visu[3] != roomname.split('_')[1]:
+                if (
+                    visu[0] != "area"
+                    or visu[1] != test_area
+                    or visu[2] != roomname.split("_")[0]
+                    or visu[3] != roomname.split("_")[1]
+                ):
                     skip = True
                 else:
-                    visual_warning = False  
+                    visual_warning = False
             else:
                 skip = True
-        elif test_choice !='all':
+        elif test_choice != "all":
             skip = True
         else:
             visual_warning = False
         if skip:
             visual_file_index = visual_file_index + 1
         else:
-            if not os.path.exists('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname):
-                os.makedirs('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname)
-            
-            data = np.loadtxt('data/indoor3d_sem_seg_hdf5_data_test/raw_data3d/Area_'+test_area+'/'+roomname+'('+str(visual_file_index)+').txt')
+            if not os.path.exists(
+                "outputs/"
+                + args.exp_name
+                + "/"
+                + "visualization"
+                + "/"
+                + "area_"
+                + test_area
+                + "/"
+                + roomname
+            ):
+                os.makedirs(
+                    "outputs/"
+                    + args.exp_name
+                    + "/"
+                    + "visualization"
+                    + "/"
+                    + "area_"
+                    + test_area
+                    + "/"
+                    + roomname
+                )
+
+            data = np.loadtxt(
+                "data/indoor3d_sem_seg_hdf5_data_test/raw_data3d/Area_"
+                + test_area
+                + "/"
+                + roomname
+                + "("
+                + str(visual_file_index)
+                + ").txt"
+            )
             visual_file_index = visual_file_index + 1
             for j in range(0, data.shape[0]):
                 RGB.append(semseg_colors[int(pred[i][j])])
                 RGB_gt.append(semseg_colors[int(seg[i][j])])
-            data = data[:,[1,2,0]]
+            data = data[:, [1, 2, 0]]
             xyzRGB = np.concatenate((data, np.array(RGB)), axis=1)
             xyzRGB_gt = np.concatenate((data, np.array(RGB_gt)), axis=1)
             room_seg.append(seg[i].cpu().numpy())
-            room_pred.append(pred[i].cpu().numpy()) 
-            f = open('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'.txt', "a")
-            f_gt = open('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_gt.txt', "a")
-            np.savetxt(f, xyzRGB, fmt='%s', delimiter=' ') 
-            np.savetxt(f_gt, xyzRGB_gt, fmt='%s', delimiter=' ') 
-            
+            room_pred.append(pred[i].cpu().numpy())
+            f = open(
+                "outputs/"
+                + args.exp_name
+                + "/"
+                + "visualization"
+                + "/"
+                + "area_"
+                + test_area
+                + "/"
+                + roomname
+                + "/"
+                + roomname
+                + ".txt",
+                "a",
+            )
+            f_gt = open(
+                "outputs/"
+                + args.exp_name
+                + "/"
+                + "visualization"
+                + "/"
+                + "area_"
+                + test_area
+                + "/"
+                + roomname
+                + "/"
+                + roomname
+                + "_gt.txt",
+                "a",
+            )
+            np.savetxt(f, xyzRGB, fmt="%s", delimiter=" ")
+            np.savetxt(f_gt, xyzRGB_gt, fmt="%s", delimiter=" ")
+
             if roomname != roomname_next:
-                mIoU = np.nanmean(calculate_sem_IoU(np.array(room_pred), np.array(room_seg)))
+                mIoU = np.nanmean(
+                    calculate_sem_IoU(np.array(room_pred), np.array(room_seg))
+                )
                 mIoU = str(round(mIoU, 4))
                 room_pred = []
                 room_seg = []
-                if visu_format == 'ply':
-                    filepath = 'outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_pred_'+mIoU+'.ply'
-                    filepath_gt = 'outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_gt.ply'
-                    xyzRGB = np.loadtxt('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'.txt')
-                    xyzRGB_gt = np.loadtxt('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_gt.txt')
-                    xyzRGB = [(xyzRGB[i, 0], xyzRGB[i, 1], xyzRGB[i, 2], xyzRGB[i, 3], xyzRGB[i, 4], xyzRGB[i, 5]) for i in range(xyzRGB.shape[0])]
-                    xyzRGB_gt = [(xyzRGB_gt[i, 0], xyzRGB_gt[i, 1], xyzRGB_gt[i, 2], xyzRGB_gt[i, 3], xyzRGB_gt[i, 4], xyzRGB_gt[i, 5]) for i in range(xyzRGB_gt.shape[0])]
-                    vertex = PlyElement.describe(np.array(xyzRGB, dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')]), 'vertex')
+                if visu_format == "ply":
+                    filepath = (
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + "_pred_"
+                        + mIoU
+                        + ".ply"
+                    )
+                    filepath_gt = (
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + "_gt.ply"
+                    )
+                    xyzRGB = np.loadtxt(
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + ".txt"
+                    )
+                    xyzRGB_gt = np.loadtxt(
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + "_gt.txt"
+                    )
+                    xyzRGB = [
+                        (
+                            xyzRGB[i, 0],
+                            xyzRGB[i, 1],
+                            xyzRGB[i, 2],
+                            xyzRGB[i, 3],
+                            xyzRGB[i, 4],
+                            xyzRGB[i, 5],
+                        )
+                        for i in range(xyzRGB.shape[0])
+                    ]
+                    xyzRGB_gt = [
+                        (
+                            xyzRGB_gt[i, 0],
+                            xyzRGB_gt[i, 1],
+                            xyzRGB_gt[i, 2],
+                            xyzRGB_gt[i, 3],
+                            xyzRGB_gt[i, 4],
+                            xyzRGB_gt[i, 5],
+                        )
+                        for i in range(xyzRGB_gt.shape[0])
+                    ]
+                    vertex = PlyElement.describe(
+                        np.array(
+                            xyzRGB,
+                            dtype=[
+                                ("x", "f4"),
+                                ("y", "f4"),
+                                ("z", "f4"),
+                                ("red", "u1"),
+                                ("green", "u1"),
+                                ("blue", "u1"),
+                            ],
+                        ),
+                        "vertex",
+                    )
                     PlyData([vertex]).write(filepath)
-                    print('PLY visualization file saved in', filepath)
-                    vertex = PlyElement.describe(np.array(xyzRGB_gt, dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')]), 'vertex')
+                    print("PLY visualization file saved in", filepath)
+                    vertex = PlyElement.describe(
+                        np.array(
+                            xyzRGB_gt,
+                            dtype=[
+                                ("x", "f4"),
+                                ("y", "f4"),
+                                ("z", "f4"),
+                                ("red", "u1"),
+                                ("green", "u1"),
+                                ("blue", "u1"),
+                            ],
+                        ),
+                        "vertex",
+                    )
                     PlyData([vertex]).write(filepath_gt)
-                    print('PLY visualization file saved in', filepath_gt)
-                    os.system('rm -rf '+'outputs/'+args.exp_name+'/visualization/area_'+test_area+'/'+roomname+'/*.txt')
+                    print("PLY visualization file saved in", filepath_gt)
+                    os.system(
+                        "rm -rf "
+                        + "outputs/"
+                        + args.exp_name
+                        + "/visualization/area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/*.txt"
+                    )
                 else:
-                    filename = 'outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'.txt'
-                    filename_gt = 'outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_gt.txt'
-                    filename_mIoU = 'outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_pred_'+mIoU+'.txt'
+                    filename = (
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + ".txt"
+                    )
+                    filename_gt = (
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + "_gt.txt"
+                    )
+                    filename_mIoU = (
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + "_pred_"
+                        + mIoU
+                        + ".txt"
+                    )
                     os.rename(filename, filename_mIoU)
-                    print('TXT visualization file saved in', filename_mIoU)
-                    print('TXT visualization file saved in', filename_gt)
-            elif visu_format != 'ply' and visu_format != 'txt':
-                print('ERROR!! Unknown visualization format: %s, please use txt or ply.' % \
-                (visu_format))
+                    print("TXT visualization file saved in", filename_mIoU)
+                    print("TXT visualization file saved in", filename_gt)
+            elif visu_format != "ply" and visu_format != "txt":
+                print(
+                    "ERROR!! Unknown visualization format: %s, please use txt or ply."
+                    % (visu_format)
+                )
                 exit()
-            
-        
+
+
 def train(args, io):
-    train_loader = DataLoader(S3DIS(partition='train', num_points=args.num_points, test_area=args.test_area), 
-                              num_workers=8, batch_size=args.batch_size, shuffle=True, drop_last=True)
-    test_loader = DataLoader(S3DIS(partition='test', num_points=args.num_points, test_area=args.test_area), 
-                            num_workers=8, batch_size=args.test_batch_size, shuffle=True, drop_last=False)
+    train_loader = DataLoader(
+        S3DIS(partition="train", num_points=args.num_points, test_area=args.test_area),
+        num_workers=8,
+        batch_size=args.batch_size,
+        shuffle=True,
+        drop_last=True,
+    )
+    test_loader = DataLoader(
+        S3DIS(partition="test", num_points=args.num_points, test_area=args.test_area),
+        num_workers=8,
+        batch_size=args.test_batch_size,
+        shuffle=True,
+        drop_last=False,
+    )
 
     device = torch.device("cuda" if args.cuda else "cpu")
 
-    #Try to load models
-    if args.model == 'dgcnn':
+    # Try to load models
+    if args.model == "dgcnn":
         model = DGCNN_semseg_s3dis(args).to(device)
     else:
         raise Exception("Not implemented")
     print(str(model))
 
     model = nn.DataParallel(model)
     print("Let's use", torch.cuda.device_count(), "GPUs!")
 
     if args.use_sgd:
         print("Use SGD")
-        opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)
+        opt = optim.SGD(
+            model.parameters(),
+            lr=args.lr * 100,
+            momentum=args.momentum,
+            weight_decay=1e-4,
+        )
     else:
         print("Use Adam")
         opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)
 
-    if args.scheduler == 'cos':
+    if args.scheduler == "cos":
         scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=1e-3)
-    elif args.scheduler == 'step':
+    elif args.scheduler == "step":
         scheduler = StepLR(opt, 20, 0.5, args.epochs)
 
     criterion = cal_loss
 
     best_test_iou = 0
@@ -192,42 +431,49 @@
             data = data.permute(0, 2, 1)
             batch_size = data.size()[0]
             opt.zero_grad()
             seg_pred = model(data)
             seg_pred = seg_pred.permute(0, 2, 1).contiguous()
-            loss = criterion(seg_pred.view(-1, 13), seg.view(-1,1).squeeze())
+            loss = criterion(seg_pred.view(-1, 13), seg.view(-1, 1).squeeze())
             loss.backward()
             opt.step()
-            pred = seg_pred.max(dim=2)[1]               # (batch_size, num_points)
+            pred = seg_pred.max(dim=2)[1]  # (batch_size, num_points)
             count += batch_size
             train_loss += loss.item() * batch_size
-            seg_np = seg.cpu().numpy()                  # (batch_size, num_points)
-            pred_np = pred.detach().cpu().numpy()       # (batch_size, num_points)
-            train_true_cls.append(seg_np.reshape(-1))       # (batch_size * num_points)
-            train_pred_cls.append(pred_np.reshape(-1))      # (batch_size * num_points)
+            seg_np = seg.cpu().numpy()  # (batch_size, num_points)
+            pred_np = pred.detach().cpu().numpy()  # (batch_size, num_points)
+            train_true_cls.append(seg_np.reshape(-1))  # (batch_size * num_points)
+            train_pred_cls.append(pred_np.reshape(-1))  # (batch_size * num_points)
             train_true_seg.append(seg_np)
             train_pred_seg.append(pred_np)
-        if args.scheduler == 'cos':
+        if args.scheduler == "cos":
             scheduler.step()
-        elif args.scheduler == 'step':
-            if opt.param_groups[0]['lr'] > 1e-5:
+        elif args.scheduler == "step":
+            if opt.param_groups[0]["lr"] > 1e-5:
                 scheduler.step()
-            if opt.param_groups[0]['lr'] < 1e-5:
+            if opt.param_groups[0]["lr"] < 1e-5:
                 for param_group in opt.param_groups:
-                    param_group['lr'] = 1e-5
+                    param_group["lr"] = 1e-5
         train_true_cls = np.concatenate(train_true_cls)
         train_pred_cls = np.concatenate(train_pred_cls)
         train_acc = metrics.accuracy_score(train_true_cls, train_pred_cls)
-        avg_per_class_acc = metrics.balanced_accuracy_score(train_true_cls, train_pred_cls)
+        avg_per_class_acc = metrics.balanced_accuracy_score(
+            train_true_cls, train_pred_cls
+        )
         train_true_seg = np.concatenate(train_true_seg, axis=0)
         train_pred_seg = np.concatenate(train_pred_seg, axis=0)
         train_ious = calculate_sem_IoU(train_pred_seg, train_true_seg)
-        outstr = 'Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f, train iou: %.6f' % (epoch, 
-                                                                                                  train_loss*1.0/count,
-                                                                                                  train_acc,
-                                                                                                  avg_per_class_acc,
-                                                                                                  np.mean(train_ious))
+        outstr = (
+            "Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f, train iou: %.6f"
+            % (
+                epoch,
+                train_loss * 1.0 / count,
+                train_acc,
+                avg_per_class_acc,
+                np.mean(train_ious),
+            )
+        )
         io.cprint(outstr)
 
         ####################
         # Test
         ####################
@@ -242,11 +488,11 @@
             data, seg = data.to(device), seg.to(device)
             data = data.permute(0, 2, 1)
             batch_size = data.size()[0]
             seg_pred = model(data)
             seg_pred = seg_pred.permute(0, 2, 1).contiguous()
-            loss = criterion(seg_pred.view(-1, 13), seg.view(-1,1).squeeze())
+            loss = criterion(seg_pred.view(-1, 13), seg.view(-1, 1).squeeze())
             pred = seg_pred.max(dim=2)[1]
             count += batch_size
             test_loss += loss.item() * batch_size
             seg_np = seg.cpu().numpy()
             pred_np = pred.detach().cpu().numpy()
@@ -255,54 +501,72 @@
             test_true_seg.append(seg_np)
             test_pred_seg.append(pred_np)
         test_true_cls = np.concatenate(test_true_cls)
         test_pred_cls = np.concatenate(test_pred_cls)
         test_acc = metrics.accuracy_score(test_true_cls, test_pred_cls)
-        avg_per_class_acc = metrics.balanced_accuracy_score(test_true_cls, test_pred_cls)
+        avg_per_class_acc = metrics.balanced_accuracy_score(
+            test_true_cls, test_pred_cls
+        )
         test_true_seg = np.concatenate(test_true_seg, axis=0)
         test_pred_seg = np.concatenate(test_pred_seg, axis=0)
         test_ious = calculate_sem_IoU(test_pred_seg, test_true_seg)
-        outstr = 'Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f, test iou: %.6f' % (epoch,
-                                                                                              test_loss*1.0/count,
-                                                                                              test_acc,
-                                                                                              avg_per_class_acc,
-                                                                                              np.mean(test_ious))
+        outstr = (
+            "Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f, test iou: %.6f"
+            % (
+                epoch,
+                test_loss * 1.0 / count,
+                test_acc,
+                avg_per_class_acc,
+                np.mean(test_ious),
+            )
+        )
         io.cprint(outstr)
         if np.mean(test_ious) >= best_test_iou:
             best_test_iou = np.mean(test_ious)
-            torch.save(model.state_dict(), 'outputs/%s/models/model_%s.tar' % (args.exp_name, args.test_area))
+            torch.save(
+                model.state_dict(),
+                "outputs/%s/models/model_%s.tar" % (args.exp_name, args.test_area),
+            )
 
 
 def test(args, io):
     all_true_cls = []
     all_pred_cls = []
     all_true_seg = []
     all_pred_seg = []
-    for test_area in range(1,7):
+    for test_area in range(1, 7):
         visual_file_index = 0
         test_area = str(test_area)
         if os.path.exists("data/indoor3d_sem_seg_hdf5_data_test/room_filelist.txt"):
             with open("data/indoor3d_sem_seg_hdf5_data_test/room_filelist.txt") as f:
                 for line in f:
                     if (line[5]) == test_area:
                         break
                     visual_file_index = visual_file_index + 1
-        if (args.test_area == 'all') or (test_area == args.test_area):
-            test_loader = DataLoader(S3DIS(partition='test', num_points=args.num_points, test_area=test_area),
-                                     batch_size=args.test_batch_size, shuffle=False, drop_last=False)
+        if (args.test_area == "all") or (test_area == args.test_area):
+            test_loader = DataLoader(
+                S3DIS(
+                    partition="test", num_points=args.num_points, test_area=test_area
+                ),
+                batch_size=args.test_batch_size,
+                shuffle=False,
+                drop_last=False,
+            )
 
             device = torch.device("cuda" if args.cuda else "cpu")
-                        
-            #Try to load models
+
+            # Try to load models
             semseg_colors = test_loader.dataset.semseg_colors
-            if args.model == 'dgcnn':
+            if args.model == "dgcnn":
                 model = DGCNN_semseg_s3dis(args).to(device)
             else:
                 raise Exception("Not implemented")
-                
+
             model = nn.DataParallel(model)
-            model.load_state_dict(torch.load(os.path.join(args.model_root, 'model_%s.t7' % test_area)))
+            model.load_state_dict(
+                torch.load(os.path.join(args.model_root, "model_%s.t7" % test_area))
+            )
             model = model.eval()
             test_acc = 0.0
             count = 0.0
             test_true_cls = []
             test_pred_cls = []
@@ -312,115 +576,187 @@
                 data, seg = data.to(device), seg.to(device)
                 data = data.permute(0, 2, 1)
                 batch_size = data.size()[0]
                 seg_pred = model(data)
                 seg_pred = seg_pred.permute(0, 2, 1).contiguous()
-                pred = seg_pred.max(dim=2)[1] 
+                pred = seg_pred.max(dim=2)[1]
                 seg_np = seg.cpu().numpy()
                 pred_np = pred.detach().cpu().numpy()
                 test_true_cls.append(seg_np.reshape(-1))
                 test_pred_cls.append(pred_np.reshape(-1))
                 test_true_seg.append(seg_np)
                 test_pred_seg.append(pred_np)
                 # visiualization
-                visualization(args.visu, args.visu_format, args.test_area, data, seg, pred, visual_file_index, semseg_colors) 
+                visualization(
+                    args.visu,
+                    args.visu_format,
+                    args.test_area,
+                    data,
+                    seg,
+                    pred,
+                    visual_file_index,
+                    semseg_colors,
+                )
                 visual_file_index = visual_file_index + data.shape[0]
-            if visual_warning and args.visu != '':
-                print('Visualization Failed: You can only choose a room to visualize within the scope of the test area')
+            if visual_warning and args.visu != "":
+                print(
+                    "Visualization Failed: You can only choose a room to visualize within the scope of the test area"
+                )
             test_true_cls = np.concatenate(test_true_cls)
             test_pred_cls = np.concatenate(test_pred_cls)
             test_acc = metrics.accuracy_score(test_true_cls, test_pred_cls)
-            avg_per_class_acc = metrics.balanced_accuracy_score(test_true_cls, test_pred_cls)
+            avg_per_class_acc = metrics.balanced_accuracy_score(
+                test_true_cls, test_pred_cls
+            )
             test_true_seg = np.concatenate(test_true_seg, axis=0)
             test_pred_seg = np.concatenate(test_pred_seg, axis=0)
             test_ious = calculate_sem_IoU(test_pred_seg, test_true_seg)
-            outstr = 'Test :: test area: %s, test acc: %.6f, test avg acc: %.6f, test iou: %.6f' % (test_area,
-                                                                                                    test_acc,
-                                                                                                    avg_per_class_acc,
-                                                                                                    np.mean(test_ious))
+            outstr = (
+                "Test :: test area: %s, test acc: %.6f, test avg acc: %.6f, test iou: %.6f"
+                % (test_area, test_acc, avg_per_class_acc, np.mean(test_ious))
+            )
             io.cprint(outstr)
             all_true_cls.append(test_true_cls)
             all_pred_cls.append(test_pred_cls)
             all_true_seg.append(test_true_seg)
             all_pred_seg.append(test_pred_seg)
 
-    if args.test_area == 'all':
+    if args.test_area == "all":
         all_true_cls = np.concatenate(all_true_cls)
         all_pred_cls = np.concatenate(all_pred_cls)
         all_acc = metrics.accuracy_score(all_true_cls, all_pred_cls)
         avg_per_class_acc = metrics.balanced_accuracy_score(all_true_cls, all_pred_cls)
         all_true_seg = np.concatenate(all_true_seg, axis=0)
         all_pred_seg = np.concatenate(all_pred_seg, axis=0)
         all_ious = calculate_sem_IoU(all_pred_seg, all_true_seg)
-        outstr = 'Overall Test :: test acc: %.6f, test avg acc: %.6f, test iou: %.6f' % (all_acc,
-                                                                                         avg_per_class_acc,
-                                                                                         np.mean(all_ious))
+        outstr = (
+            "Overall Test :: test acc: %.6f, test avg acc: %.6f, test iou: %.6f"
+            % (all_acc, avg_per_class_acc, np.mean(all_ious))
+        )
         io.cprint(outstr)
 
 
 if __name__ == "__main__":
     # Training settings
-    parser = argparse.ArgumentParser(description='Point Cloud Part Segmentation')
-    parser.add_argument('--exp_name', type=str, default='exp', metavar='N',
-                        help='Name of the experiment')
-    parser.add_argument('--model', type=str, default='dgcnn', metavar='N',
-                        choices=['dgcnn'],
-                        help='Model to use, [dgcnn]')
-    parser.add_argument('--dataset', type=str, default='S3DIS', metavar='N',
-                        choices=['S3DIS'])
-    parser.add_argument('--test_area', type=str, default=None, metavar='N',
-                        choices=['1', '2', '3', '4', '5', '6', 'all'])
-    parser.add_argument('--batch_size', type=int, default=32, metavar='batch_size',
-                        help='Size of batch)')
-    parser.add_argument('--test_batch_size', type=int, default=16, metavar='batch_size',
-                        help='Size of batch)')
-    parser.add_argument('--epochs', type=int, default=100, metavar='N',
-                        help='number of episode to train ')
-    parser.add_argument('--use_sgd', type=bool, default=True,
-                        help='Use SGD')
-    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',
-                        help='learning rate (default: 0.001, 0.1 if using sgd)')
-    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',
-                        help='SGD momentum (default: 0.9)')
-    parser.add_argument('--scheduler', type=str, default='cos', metavar='N',
-                        choices=['cos', 'step'],
-                        help='Scheduler to use, [cos, step]')
-    parser.add_argument('--no_cuda', type=bool, default=False,
-                        help='enables CUDA training')
-    parser.add_argument('--seed', type=int, default=1, metavar='S',
-                        help='random seed (default: 1)')
-    parser.add_argument('--eval', type=bool,  default=False,
-                        help='evaluate the model')
-    parser.add_argument('--num_points', type=int, default=2048,
-                        help='num of points to use')
-    parser.add_argument('--dropout', type=float, default=0.5,
-                        help='dropout rate')
-    parser.add_argument('--emb_dims', type=int, default=1024, metavar='N',
-                        help='Dimension of embeddings')
-    parser.add_argument('--k', type=int, default=20, metavar='N',
-                        help='Num of nearest neighbors to use')
-    parser.add_argument('--model_root', type=str, default='', metavar='N',
-                        help='Pretrained model root')
-    parser.add_argument('--visu', type=str, default='',
-                        help='visualize the model')
-    parser.add_argument('--visu_format', type=str, default='ply',
-                        help='file format of visualization')
+    parser = argparse.ArgumentParser(description="Point Cloud Part Segmentation")
+    parser.add_argument(
+        "--exp_name",
+        type=str,
+        default="exp",
+        metavar="N",
+        help="Name of the experiment",
+    )
+    parser.add_argument(
+        "--model",
+        type=str,
+        default="dgcnn",
+        metavar="N",
+        choices=["dgcnn"],
+        help="Model to use, [dgcnn]",
+    )
+    parser.add_argument(
+        "--dataset", type=str, default="S3DIS", metavar="N", choices=["S3DIS"]
+    )
+    parser.add_argument(
+        "--test_area",
+        type=str,
+        default=None,
+        metavar="N",
+        choices=["1", "2", "3", "4", "5", "6", "all"],
+    )
+    parser.add_argument(
+        "--batch_size",
+        type=int,
+        default=32,
+        metavar="batch_size",
+        help="Size of batch)",
+    )
+    parser.add_argument(
+        "--test_batch_size",
+        type=int,
+        default=16,
+        metavar="batch_size",
+        help="Size of batch)",
+    )
+    parser.add_argument(
+        "--epochs",
+        type=int,
+        default=100,
+        metavar="N",
+        help="number of episode to train ",
+    )
+    parser.add_argument("--use_sgd", type=bool, default=True, help="Use SGD")
+    parser.add_argument(
+        "--lr",
+        type=float,
+        default=0.001,
+        metavar="LR",
+        help="learning rate (default: 0.001, 0.1 if using sgd)",
+    )
+    parser.add_argument(
+        "--momentum",
+        type=float,
+        default=0.9,
+        metavar="M",
+        help="SGD momentum (default: 0.9)",
+    )
+    parser.add_argument(
+        "--scheduler",
+        type=str,
+        default="cos",
+        metavar="N",
+        choices=["cos", "step"],
+        help="Scheduler to use, [cos, step]",
+    )
+    parser.add_argument(
+        "--no_cuda", type=bool, default=False, help="enables CUDA training"
+    )
+    parser.add_argument(
+        "--seed", type=int, default=1, metavar="S", help="random seed (default: 1)"
+    )
+    parser.add_argument("--eval", type=bool, default=False, help="evaluate the model")
+    parser.add_argument(
+        "--num_points", type=int, default=2048, help="num of points to use"
+    )
+    parser.add_argument("--dropout", type=float, default=0.5, help="dropout rate")
+    parser.add_argument(
+        "--emb_dims",
+        type=int,
+        default=1024,
+        metavar="N",
+        help="Dimension of embeddings",
+    )
+    parser.add_argument(
+        "--k", type=int, default=20, metavar="N", help="Num of nearest neighbors to use"
+    )
+    parser.add_argument(
+        "--model_root", type=str, default="", metavar="N", help="Pretrained model root"
+    )
+    parser.add_argument("--visu", type=str, default="", help="visualize the model")
+    parser.add_argument(
+        "--visu_format", type=str, default="ply", help="file format of visualization"
+    )
     args = parser.parse_args()
 
     _init_()
 
-    io = IOStream('outputs/' + args.exp_name + '/run.log')
+    io = IOStream("outputs/" + args.exp_name + "/run.log")
     io.cprint(str(args))
 
     args.cuda = not args.no_cuda and torch.cuda.is_available()
     torch.manual_seed(args.seed)
     if args.cuda:
         io.cprint(
-            'Using GPU : ' + str(torch.cuda.current_device()) + ' from ' + str(torch.cuda.device_count()) + ' devices')
+            "Using GPU : "
+            + str(torch.cuda.current_device())
+            + " from "
+            + str(torch.cuda.device_count())
+            + " devices"
+        )
         torch.cuda.manual_seed(args.seed)
     else:
-        io.cprint('Using CPU')
+        io.cprint("Using CPU")
 
     if not args.eval:
         train(args, io)
     else:
         test(args, io)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/model.py	2024-07-08 10:33:35.552794+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/model.py	2024-07-08 11:53:41.051201+00:00
@@ -23,45 +23,47 @@
 import torch.nn.init as init
 import torch.nn.functional as F
 
 
 def knn(x, k):
-    inner = -2*torch.matmul(x.transpose(2, 1), x)
+    inner = -2 * torch.matmul(x.transpose(2, 1), x)
     xx = torch.sum(x**2, dim=1, keepdim=True)
     pairwise_distance = -xx - inner - xx.transpose(2, 1)
- 
-    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k)
+
+    idx = pairwise_distance.topk(k=k, dim=-1)[1]  # (batch_size, num_points, k)
     return idx
 
 
 def get_graph_feature(x, k=20, idx=None, dim9=False):
     batch_size = x.size(0)
     num_points = x.size(2)
     x = x.view(batch_size, -1, num_points)
     if idx is None:
         if dim9 == False:
-            idx = knn(x, k=k)   # (batch_size, num_points, k)
+            idx = knn(x, k=k)  # (batch_size, num_points, k)
         else:
             idx = knn(x[:, 6:], k=k)
-    device = torch.device('cuda')
-
-    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points
+    device = torch.device("cuda")
+
+    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1) * num_points
 
     idx = idx + idx_base
 
     idx = idx.view(-1)
- 
+
     _, num_dims, _ = x.size()
 
-    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)
-    feature = x.view(batch_size*num_points, -1)[idx, :]
-    feature = feature.view(batch_size, num_points, k, num_dims) 
+    x = x.transpose(
+        2, 1
+    ).contiguous()  # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)
+    feature = x.view(batch_size * num_points, -1)[idx, :]
+    feature = feature.view(batch_size, num_points, k, num_dims)
     x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)
-    
-    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()
-  
-    return feature      # (batch_size, 2*num_dims, num_points, k)
+
+    feature = torch.cat((feature - x, x), dim=3).permute(0, 3, 1, 2).contiguous()
+
+    return feature  # (batch_size, 2*num_dims, num_points, k)
 
 
 class PointNet(nn.Module):
     def __init__(self, args, output_channels=40):
         super(PointNet, self).__init__()
@@ -97,71 +99,117 @@
 class DGCNN_cls(nn.Module):
     def __init__(self, args, output_channels=40):
         super(DGCNN_cls, self).__init__()
         self.args = args
         self.k = args.k
-        
+
         self.bn1 = nn.BatchNorm2d(64)
         self.bn2 = nn.BatchNorm2d(64)
         self.bn3 = nn.BatchNorm2d(128)
         self.bn4 = nn.BatchNorm2d(256)
         self.bn5 = nn.BatchNorm1d(args.emb_dims)
 
-        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),
-                                   self.bn1,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),
-                                   self.bn2,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),
-                                   self.bn3,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),
-                                   self.bn4,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv5 = nn.Sequential(nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),
-                                   self.bn5,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.linear1 = nn.Linear(args.emb_dims*2, 512, bias=False)
+        self.conv1 = nn.Sequential(
+            nn.Conv2d(6, 64, kernel_size=1, bias=False),
+            self.bn1,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv2 = nn.Sequential(
+            nn.Conv2d(64 * 2, 64, kernel_size=1, bias=False),
+            self.bn2,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv3 = nn.Sequential(
+            nn.Conv2d(64 * 2, 128, kernel_size=1, bias=False),
+            self.bn3,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv4 = nn.Sequential(
+            nn.Conv2d(128 * 2, 256, kernel_size=1, bias=False),
+            self.bn4,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv5 = nn.Sequential(
+            nn.Conv1d(512, args.emb_dims, kernel_size=1, bias=False),
+            self.bn5,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.linear1 = nn.Linear(args.emb_dims * 2, 512, bias=False)
         self.bn6 = nn.BatchNorm1d(512)
         self.dp1 = nn.Dropout(p=args.dropout)
         self.linear2 = nn.Linear(512, 256)
         self.bn7 = nn.BatchNorm1d(256)
         self.dp2 = nn.Dropout(p=args.dropout)
         self.linear3 = nn.Linear(256, output_channels)
 
     def forward(self, x):
         batch_size = x.size(0)
-        x = get_graph_feature(x, k=self.k)      # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)
-        x = self.conv1(x)                       # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)
-        x1 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
-
-        x = get_graph_feature(x1, k=self.k)     # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
-        x = self.conv2(x)                       # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)
-        x2 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
-
-        x = get_graph_feature(x2, k=self.k)     # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
-        x = self.conv3(x)                       # (batch_size, 64*2, num_points, k) -> (batch_size, 128, num_points, k)
-        x3 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 128, num_points, k) -> (batch_size, 128, num_points)
-
-        x = get_graph_feature(x3, k=self.k)     # (batch_size, 128, num_points) -> (batch_size, 128*2, num_points, k)
-        x = self.conv4(x)                       # (batch_size, 128*2, num_points, k) -> (batch_size, 256, num_points, k)
-        x4 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 256, num_points, k) -> (batch_size, 256, num_points)
-
-        x = torch.cat((x1, x2, x3, x4), dim=1)  # (batch_size, 64+64+128+256, num_points)
-
-        x = self.conv5(x)                       # (batch_size, 64+64+128+256, num_points) -> (batch_size, emb_dims, num_points)
-        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)           # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)
-        x2 = F.adaptive_avg_pool1d(x, 1).view(batch_size, -1)           # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)
-        x = torch.cat((x1, x2), 1)              # (batch_size, emb_dims*2)
-
-        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2) # (batch_size, emb_dims*2) -> (batch_size, 512)
+        x = get_graph_feature(
+            x, k=self.k
+        )  # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)
+        x = self.conv1(
+            x
+        )  # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)
+        x1 = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
+
+        x = get_graph_feature(
+            x1, k=self.k
+        )  # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
+        x = self.conv2(
+            x
+        )  # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)
+        x2 = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
+
+        x = get_graph_feature(
+            x2, k=self.k
+        )  # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
+        x = self.conv3(
+            x
+        )  # (batch_size, 64*2, num_points, k) -> (batch_size, 128, num_points, k)
+        x3 = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 128, num_points, k) -> (batch_size, 128, num_points)
+
+        x = get_graph_feature(
+            x3, k=self.k
+        )  # (batch_size, 128, num_points) -> (batch_size, 128*2, num_points, k)
+        x = self.conv4(
+            x
+        )  # (batch_size, 128*2, num_points, k) -> (batch_size, 256, num_points, k)
+        x4 = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 256, num_points, k) -> (batch_size, 256, num_points)
+
+        x = torch.cat(
+            (x1, x2, x3, x4), dim=1
+        )  # (batch_size, 64+64+128+256, num_points)
+
+        x = self.conv5(
+            x
+        )  # (batch_size, 64+64+128+256, num_points) -> (batch_size, emb_dims, num_points)
+        x1 = F.adaptive_max_pool1d(x, 1).view(
+            batch_size, -1
+        )  # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)
+        x2 = F.adaptive_avg_pool1d(x, 1).view(
+            batch_size, -1
+        )  # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims)
+        x = torch.cat((x1, x2), 1)  # (batch_size, emb_dims*2)
+
+        x = F.leaky_relu(
+            self.bn6(self.linear1(x)), negative_slope=0.2
+        )  # (batch_size, emb_dims*2) -> (batch_size, 512)
         x = self.dp1(x)
-        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2) # (batch_size, 512) -> (batch_size, 256)
+        x = F.leaky_relu(
+            self.bn7(self.linear2(x)), negative_slope=0.2
+        )  # (batch_size, 512) -> (batch_size, 256)
         x = self.dp2(x)
-        x = self.linear3(x)                                             # (batch_size, 256) -> (batch_size, output_channels)
-        
+        x = self.linear3(x)  # (batch_size, 256) -> (batch_size, output_channels)
+
         return x
 
 
 class Transform_Net(nn.Module):
     def __init__(self, args):
@@ -171,44 +219,64 @@
 
         self.bn1 = nn.BatchNorm2d(64)
         self.bn2 = nn.BatchNorm2d(128)
         self.bn3 = nn.BatchNorm1d(1024)
 
-        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),
-                                   self.bn1,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=1, bias=False),
-                                   self.bn2,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv3 = nn.Sequential(nn.Conv1d(128, 1024, kernel_size=1, bias=False),
-                                   self.bn3,
-                                   nn.LeakyReLU(negative_slope=0.2))
+        self.conv1 = nn.Sequential(
+            nn.Conv2d(6, 64, kernel_size=1, bias=False),
+            self.bn1,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv2 = nn.Sequential(
+            nn.Conv2d(64, 128, kernel_size=1, bias=False),
+            self.bn2,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv3 = nn.Sequential(
+            nn.Conv1d(128, 1024, kernel_size=1, bias=False),
+            self.bn3,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
 
         self.linear1 = nn.Linear(1024, 512, bias=False)
         self.bn3 = nn.BatchNorm1d(512)
         self.linear2 = nn.Linear(512, 256, bias=False)
         self.bn4 = nn.BatchNorm1d(256)
 
-        self.transform = nn.Linear(256, 3*3)
+        self.transform = nn.Linear(256, 3 * 3)
         init.constant_(self.transform.weight, 0)
         init.eye_(self.transform.bias.view(3, 3))
 
     def forward(self, x):
         batch_size = x.size(0)
 
-        x = self.conv1(x)                       # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)
-        x = self.conv2(x)                       # (batch_size, 64, num_points, k) -> (batch_size, 128, num_points, k)
-        x = x.max(dim=-1, keepdim=False)[0]     # (batch_size, 128, num_points, k) -> (batch_size, 128, num_points)
-
-        x = self.conv3(x)                       # (batch_size, 128, num_points) -> (batch_size, 1024, num_points)
-        x = x.max(dim=-1, keepdim=False)[0]     # (batch_size, 1024, num_points) -> (batch_size, 1024)
-
-        x = F.leaky_relu(self.bn3(self.linear1(x)), negative_slope=0.2)     # (batch_size, 1024) -> (batch_size, 512)
-        x = F.leaky_relu(self.bn4(self.linear2(x)), negative_slope=0.2)     # (batch_size, 512) -> (batch_size, 256)
-
-        x = self.transform(x)                   # (batch_size, 256) -> (batch_size, 3*3)
-        x = x.view(batch_size, 3, 3)            # (batch_size, 3*3) -> (batch_size, 3, 3)
+        x = self.conv1(
+            x
+        )  # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)
+        x = self.conv2(
+            x
+        )  # (batch_size, 64, num_points, k) -> (batch_size, 128, num_points, k)
+        x = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 128, num_points, k) -> (batch_size, 128, num_points)
+
+        x = self.conv3(
+            x
+        )  # (batch_size, 128, num_points) -> (batch_size, 1024, num_points)
+        x = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 1024, num_points) -> (batch_size, 1024)
+
+        x = F.leaky_relu(
+            self.bn3(self.linear1(x)), negative_slope=0.2
+        )  # (batch_size, 1024) -> (batch_size, 512)
+        x = F.leaky_relu(
+            self.bn4(self.linear2(x)), negative_slope=0.2
+        )  # (batch_size, 512) -> (batch_size, 256)
+
+        x = self.transform(x)  # (batch_size, 256) -> (batch_size, 3*3)
+        x = x.view(batch_size, 3, 3)  # (batch_size, 3*3) -> (batch_size, 3, 3)
 
         return x
 
 
 class DGCNN_partseg(nn.Module):
@@ -216,11 +284,11 @@
         super(DGCNN_partseg, self).__init__()
         self.args = args
         self.seg_num_all = seg_num_all
         self.k = args.k
         self.transform_net = Transform_Net(args)
-        
+
         self.bn1 = nn.BatchNorm2d(64)
         self.bn2 = nn.BatchNorm2d(64)
         self.bn3 = nn.BatchNorm2d(64)
         self.bn4 = nn.BatchNorm2d(64)
         self.bn5 = nn.BatchNorm2d(64)
@@ -228,168 +296,276 @@
         self.bn7 = nn.BatchNorm1d(64)
         self.bn8 = nn.BatchNorm1d(256)
         self.bn9 = nn.BatchNorm1d(256)
         self.bn10 = nn.BatchNorm1d(128)
 
-        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),
-                                   self.bn1,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1, bias=False),
-                                   self.bn2,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),
-                                   self.bn3,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv4 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1, bias=False),
-                                   self.bn4,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv5 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),
-                                   self.bn5,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv6 = nn.Sequential(nn.Conv1d(192, args.emb_dims, kernel_size=1, bias=False),
-                                   self.bn6,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv7 = nn.Sequential(nn.Conv1d(16, 64, kernel_size=1, bias=False),
-                                   self.bn7,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv8 = nn.Sequential(nn.Conv1d(1280, 256, kernel_size=1, bias=False),
-                                   self.bn8,
-                                   nn.LeakyReLU(negative_slope=0.2))
+        self.conv1 = nn.Sequential(
+            nn.Conv2d(6, 64, kernel_size=1, bias=False),
+            self.bn1,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv2 = nn.Sequential(
+            nn.Conv2d(64, 64, kernel_size=1, bias=False),
+            self.bn2,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv3 = nn.Sequential(
+            nn.Conv2d(64 * 2, 64, kernel_size=1, bias=False),
+            self.bn3,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv4 = nn.Sequential(
+            nn.Conv2d(64, 64, kernel_size=1, bias=False),
+            self.bn4,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv5 = nn.Sequential(
+            nn.Conv2d(64 * 2, 64, kernel_size=1, bias=False),
+            self.bn5,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv6 = nn.Sequential(
+            nn.Conv1d(192, args.emb_dims, kernel_size=1, bias=False),
+            self.bn6,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv7 = nn.Sequential(
+            nn.Conv1d(16, 64, kernel_size=1, bias=False),
+            self.bn7,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv8 = nn.Sequential(
+            nn.Conv1d(1280, 256, kernel_size=1, bias=False),
+            self.bn8,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.dp1 = nn.Dropout(p=args.dropout)
-        self.conv9 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=1, bias=False),
-                                   self.bn9,
-                                   nn.LeakyReLU(negative_slope=0.2))
+        self.conv9 = nn.Sequential(
+            nn.Conv1d(256, 256, kernel_size=1, bias=False),
+            self.bn9,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.dp2 = nn.Dropout(p=args.dropout)
-        self.conv10 = nn.Sequential(nn.Conv1d(256, 128, kernel_size=1, bias=False),
-                                   self.bn10,
-                                   nn.LeakyReLU(negative_slope=0.2))
+        self.conv10 = nn.Sequential(
+            nn.Conv1d(256, 128, kernel_size=1, bias=False),
+            self.bn10,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.conv11 = nn.Conv1d(128, self.seg_num_all, kernel_size=1, bias=False)
-        
 
     def forward(self, x, l):
         batch_size = x.size(0)
         num_points = x.size(2)
 
-        x0 = get_graph_feature(x, k=self.k)     # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)
-        t = self.transform_net(x0)              # (batch_size, 3, 3)
-        x = x.transpose(2, 1)                   # (batch_size, 3, num_points) -> (batch_size, num_points, 3)
-        x = torch.bmm(x, t)                     # (batch_size, num_points, 3) * (batch_size, 3, 3) -> (batch_size, num_points, 3)
-        x = x.transpose(2, 1)                   # (batch_size, num_points, 3) -> (batch_size, 3, num_points)
-
-        x = get_graph_feature(x, k=self.k)      # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)
-        x = self.conv1(x)                       # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)
-        x = self.conv2(x)                       # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)
-        x1 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
-
-        x = get_graph_feature(x1, k=self.k)     # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
-        x = self.conv3(x)                       # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)
-        x = self.conv4(x)                       # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)
-        x2 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
-
-        x = get_graph_feature(x2, k=self.k)     # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
-        x = self.conv5(x)                       # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)
-        x3 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
-
-        x = torch.cat((x1, x2, x3), dim=1)      # (batch_size, 64*3, num_points)
-
-        x = self.conv6(x)                       # (batch_size, 64*3, num_points) -> (batch_size, emb_dims, num_points)
-        x = x.max(dim=-1, keepdim=True)[0]      # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims, 1)
-
-        l = l.view(batch_size, -1, 1)           # (batch_size, num_categoties, 1)
-        l = self.conv7(l)                       # (batch_size, num_categoties, 1) -> (batch_size, 64, 1)
-
-        x = torch.cat((x, l), dim=1)            # (batch_size, 1088, 1)
-        x = x.repeat(1, 1, num_points)          # (batch_size, 1088, num_points)
-
-        x = torch.cat((x, x1, x2, x3), dim=1)   # (batch_size, 1088+64*3, num_points)
-
-        x = self.conv8(x)                       # (batch_size, 1088+64*3, num_points) -> (batch_size, 256, num_points)
+        x0 = get_graph_feature(
+            x, k=self.k
+        )  # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)
+        t = self.transform_net(x0)  # (batch_size, 3, 3)
+        x = x.transpose(
+            2, 1
+        )  # (batch_size, 3, num_points) -> (batch_size, num_points, 3)
+        x = torch.bmm(
+            x, t
+        )  # (batch_size, num_points, 3) * (batch_size, 3, 3) -> (batch_size, num_points, 3)
+        x = x.transpose(
+            2, 1
+        )  # (batch_size, num_points, 3) -> (batch_size, 3, num_points)
+
+        x = get_graph_feature(
+            x, k=self.k
+        )  # (batch_size, 3, num_points) -> (batch_size, 3*2, num_points, k)
+        x = self.conv1(
+            x
+        )  # (batch_size, 3*2, num_points, k) -> (batch_size, 64, num_points, k)
+        x = self.conv2(
+            x
+        )  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)
+        x1 = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
+
+        x = get_graph_feature(
+            x1, k=self.k
+        )  # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
+        x = self.conv3(
+            x
+        )  # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)
+        x = self.conv4(
+            x
+        )  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)
+        x2 = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
+
+        x = get_graph_feature(
+            x2, k=self.k
+        )  # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
+        x = self.conv5(
+            x
+        )  # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)
+        x3 = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
+
+        x = torch.cat((x1, x2, x3), dim=1)  # (batch_size, 64*3, num_points)
+
+        x = self.conv6(
+            x
+        )  # (batch_size, 64*3, num_points) -> (batch_size, emb_dims, num_points)
+        x = x.max(dim=-1, keepdim=True)[
+            0
+        ]  # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims, 1)
+
+        l = l.view(batch_size, -1, 1)  # (batch_size, num_categoties, 1)
+        l = self.conv7(l)  # (batch_size, num_categoties, 1) -> (batch_size, 64, 1)
+
+        x = torch.cat((x, l), dim=1)  # (batch_size, 1088, 1)
+        x = x.repeat(1, 1, num_points)  # (batch_size, 1088, num_points)
+
+        x = torch.cat((x, x1, x2, x3), dim=1)  # (batch_size, 1088+64*3, num_points)
+
+        x = self.conv8(
+            x
+        )  # (batch_size, 1088+64*3, num_points) -> (batch_size, 256, num_points)
         x = self.dp1(x)
-        x = self.conv9(x)                       # (batch_size, 256, num_points) -> (batch_size, 256, num_points)
+        x = self.conv9(
+            x
+        )  # (batch_size, 256, num_points) -> (batch_size, 256, num_points)
         x = self.dp2(x)
-        x = self.conv10(x)                      # (batch_size, 256, num_points) -> (batch_size, 128, num_points)
-        x = self.conv11(x)                      # (batch_size, 256, num_points) -> (batch_size, seg_num_all, num_points)
-        
+        x = self.conv10(
+            x
+        )  # (batch_size, 256, num_points) -> (batch_size, 128, num_points)
+        x = self.conv11(
+            x
+        )  # (batch_size, 256, num_points) -> (batch_size, seg_num_all, num_points)
+
         return x
 
 
 class DGCNN_semseg_s3dis(nn.Module):
     def __init__(self, args):
         super(DGCNN_semseg_s3dis, self).__init__()
         self.args = args
         self.k = args.k
-        
+
         self.bn1 = nn.BatchNorm2d(64)
         self.bn2 = nn.BatchNorm2d(64)
         self.bn3 = nn.BatchNorm2d(64)
         self.bn4 = nn.BatchNorm2d(64)
         self.bn5 = nn.BatchNorm2d(64)
         self.bn6 = nn.BatchNorm1d(args.emb_dims)
         self.bn7 = nn.BatchNorm1d(512)
         self.bn8 = nn.BatchNorm1d(256)
 
-        self.conv1 = nn.Sequential(nn.Conv2d(12, 64, kernel_size=1, bias=False),
-                                   self.bn1,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1, bias=False),
-                                   self.bn2,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),
-                                   self.bn3,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv4 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1, bias=False),
-                                   self.bn4,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv5 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),
-                                   self.bn5,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv6 = nn.Sequential(nn.Conv1d(192, args.emb_dims, kernel_size=1, bias=False),
-                                   self.bn6,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv7 = nn.Sequential(nn.Conv1d(1216, 512, kernel_size=1, bias=False),
-                                   self.bn7,
-                                   nn.LeakyReLU(negative_slope=0.2))
-        self.conv8 = nn.Sequential(nn.Conv1d(512, 256, kernel_size=1, bias=False),
-                                   self.bn8,
-                                   nn.LeakyReLU(negative_slope=0.2))
+        self.conv1 = nn.Sequential(
+            nn.Conv2d(12, 64, kernel_size=1, bias=False),
+            self.bn1,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv2 = nn.Sequential(
+            nn.Conv2d(64, 64, kernel_size=1, bias=False),
+            self.bn2,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv3 = nn.Sequential(
+            nn.Conv2d(64 * 2, 64, kernel_size=1, bias=False),
+            self.bn3,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv4 = nn.Sequential(
+            nn.Conv2d(64, 64, kernel_size=1, bias=False),
+            self.bn4,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv5 = nn.Sequential(
+            nn.Conv2d(64 * 2, 64, kernel_size=1, bias=False),
+            self.bn5,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv6 = nn.Sequential(
+            nn.Conv1d(192, args.emb_dims, kernel_size=1, bias=False),
+            self.bn6,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv7 = nn.Sequential(
+            nn.Conv1d(1216, 512, kernel_size=1, bias=False),
+            self.bn7,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
+        self.conv8 = nn.Sequential(
+            nn.Conv1d(512, 256, kernel_size=1, bias=False),
+            self.bn8,
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.dp1 = nn.Dropout(p=args.dropout)
         self.conv9 = nn.Conv1d(256, 13, kernel_size=1, bias=False)
-        
 
     def forward(self, x):
         batch_size = x.size(0)
         num_points = x.size(2)
 
-        x = get_graph_feature(x, k=self.k, dim9=True)   # (batch_size, 9, num_points) -> (batch_size, 9*2, num_points, k)
-        x = self.conv1(x)                       # (batch_size, 9*2, num_points, k) -> (batch_size, 64, num_points, k)
-        x = self.conv2(x)                       # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)
-        x1 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
-
-        x = get_graph_feature(x1, k=self.k)     # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
-        x = self.conv3(x)                       # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)
-        x = self.conv4(x)                       # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)
-        x2 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
-
-        x = get_graph_feature(x2, k=self.k)     # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
-        x = self.conv5(x)                       # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)
-        x3 = x.max(dim=-1, keepdim=False)[0]    # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
-
-        x = torch.cat((x1, x2, x3), dim=1)      # (batch_size, 64*3, num_points)
-
-        x = self.conv6(x)                       # (batch_size, 64*3, num_points) -> (batch_size, emb_dims, num_points)
-        x = x.max(dim=-1, keepdim=True)[0]      # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims, 1)
-
-        x = x.repeat(1, 1, num_points)          # (batch_size, 1024, num_points)
-        x = torch.cat((x, x1, x2, x3), dim=1)   # (batch_size, 1024+64*3, num_points)
-
-        x = self.conv7(x)                       # (batch_size, 1024+64*3, num_points) -> (batch_size, 512, num_points)
-        x = self.conv8(x)                       # (batch_size, 512, num_points) -> (batch_size, 256, num_points)
+        x = get_graph_feature(
+            x, k=self.k, dim9=True
+        )  # (batch_size, 9, num_points) -> (batch_size, 9*2, num_points, k)
+        x = self.conv1(
+            x
+        )  # (batch_size, 9*2, num_points, k) -> (batch_size, 64, num_points, k)
+        x = self.conv2(
+            x
+        )  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)
+        x1 = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
+
+        x = get_graph_feature(
+            x1, k=self.k
+        )  # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
+        x = self.conv3(
+            x
+        )  # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)
+        x = self.conv4(
+            x
+        )  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points, k)
+        x2 = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
+
+        x = get_graph_feature(
+            x2, k=self.k
+        )  # (batch_size, 64, num_points) -> (batch_size, 64*2, num_points, k)
+        x = self.conv5(
+            x
+        )  # (batch_size, 64*2, num_points, k) -> (batch_size, 64, num_points, k)
+        x3 = x.max(dim=-1, keepdim=False)[
+            0
+        ]  # (batch_size, 64, num_points, k) -> (batch_size, 64, num_points)
+
+        x = torch.cat((x1, x2, x3), dim=1)  # (batch_size, 64*3, num_points)
+
+        x = self.conv6(
+            x
+        )  # (batch_size, 64*3, num_points) -> (batch_size, emb_dims, num_points)
+        x = x.max(dim=-1, keepdim=True)[
+            0
+        ]  # (batch_size, emb_dims, num_points) -> (batch_size, emb_dims, 1)
+
+        x = x.repeat(1, 1, num_points)  # (batch_size, 1024, num_points)
+        x = torch.cat((x, x1, x2, x3), dim=1)  # (batch_size, 1024+64*3, num_points)
+
+        x = self.conv7(
+            x
+        )  # (batch_size, 1024+64*3, num_points) -> (batch_size, 512, num_points)
+        x = self.conv8(
+            x
+        )  # (batch_size, 512, num_points) -> (batch_size, 256, num_points)
         x = self.dp1(x)
-        x = self.conv9(x)                       # (batch_size, 256, num_points) -> (batch_size, 13, num_points)
-        
+        x = self.conv9(
+            x
+        )  # (batch_size, 256, num_points) -> (batch_size, 13, num_points)
+
         return x
-        
+
 
 class DGCNN_semseg_scannet(nn.Module):
     def __init__(self, num_classes, k=20, emb_dims=1024, dropout=0.5):
         super(DGCNN_semseg_scannet, self).__init__()
 
@@ -405,39 +581,47 @@
         self.bn8 = nn.BatchNorm1d(256)
 
         self.conv1 = nn.Sequential(
             nn.Conv2d(18, 64, kernel_size=1, bias=False),
             self.bn1,
-            nn.LeakyReLU(negative_slope=0.2))
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.conv2 = nn.Sequential(
             nn.Conv2d(64, 64, kernel_size=1, bias=False),
             self.bn2,
-            nn.LeakyReLU(negative_slope=0.2))
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.conv3 = nn.Sequential(
-            nn.Conv2d(64*2, 64, kernel_size=1, bias=False),
+            nn.Conv2d(64 * 2, 64, kernel_size=1, bias=False),
             self.bn3,
-            nn.LeakyReLU(negative_slope=0.2))
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.conv4 = nn.Sequential(
             nn.Conv2d(64, 64, kernel_size=1, bias=False),
             self.bn4,
-            nn.LeakyReLU(negative_slope=0.2))
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.conv5 = nn.Sequential(
-            nn.Conv2d(64*2, 64, kernel_size=1, bias=False),
+            nn.Conv2d(64 * 2, 64, kernel_size=1, bias=False),
             self.bn5,
-            nn.LeakyReLU(negative_slope=0.2))
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.conv6 = nn.Sequential(
             nn.Conv1d(192, emb_dims, kernel_size=1, bias=False),
             self.bn6,
-            nn.LeakyReLU(negative_slope=0.2))
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.conv7 = nn.Sequential(
             nn.Conv1d(1216, 512, kernel_size=1, bias=False),
             self.bn7,
-            nn.LeakyReLU(negative_slope=0.2))
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.conv8 = nn.Sequential(
             nn.Conv1d(512, 256, kernel_size=1, bias=False),
             self.bn8,
-            nn.LeakyReLU(negative_slope=0.2))
+            nn.LeakyReLU(negative_slope=0.2),
+        )
         self.dp1 = nn.Dropout(p=dropout)
         self.conv9 = nn.Conv1d(256, num_classes, kernel_size=1, bias=False)
 
     def forward(self, x):
         bs = x.size(0)
@@ -466,19 +650,19 @@
         # (bs, 64*2, npoint, k) -> (bs, 64, npoint, k)
         x = self.conv5(x)
         # (bs, 64, npoint, k) -> (bs, 64, npoint)
         x3 = x.max(dim=-1, keepdim=False)[0]
 
-        x = torch.cat((x1, x2, x3), dim=1)      # (bs, 64*3, npoint)
+        x = torch.cat((x1, x2, x3), dim=1)  # (bs, 64*3, npoint)
 
         # (bs, 64*3, npoint) -> (bs, emb_dims, npoint)
         x = self.conv6(x)
         # (bs, emb_dims, npoint) -> (bs, emb_dims, 1)
         x = x.max(dim=-1, keepdim=True)[0]
 
-        x = x.repeat(1, 1, npoint)          # (bs, 1024, npoint)
-        x = torch.cat((x, x1, x2, x3), dim=1)   # (bs, 1024+64*3, npoint)
+        x = x.repeat(1, 1, npoint)  # (bs, 1024, npoint)
+        x = torch.cat((x, x1, x2, x3), dim=1)  # (bs, 1024+64*3, npoint)
 
         # (bs, 1024+64*3, npoint) -> (bs, 512, npoint)
         x = self.conv7(x)
         # (bs, 512, npoint) -> (bs, 256, npoint)
         x = self.conv8(x)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/main_semseg_ourData.py	2024-07-08 10:44:02.533966+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/main_semseg_ourData.py	2024-07-08 11:53:41.083382+00:00
@@ -29,174 +29,443 @@
 global room_pred
 room_pred = []
 global visual_warning
 visual_warning = True
 global custom_dataset
-custom_dataset = '/mnt/c/faps/data/Baseline_Model/'
+custom_dataset = "/mnt/c/faps/data/Baseline_Model/"
+
 
 def _init_():
-    if not os.path.exists('outputs'):
-        os.makedirs('outputs')
-    if not os.path.exists('outputs/'+args.exp_name):
-        os.makedirs('outputs/'+args.exp_name)
-    if not os.path.exists('outputs/'+args.exp_name+'/'+'models'):
-        os.makedirs('outputs/'+args.exp_name+'/'+'models')
-    os.system('cp main_semseg_s3dis.py outputs'+'/'+args.exp_name+'/'+'main_semseg_s3dis.py.backup')
-    os.system('cp model.py outputs' + '/' + args.exp_name + '/' + 'model.py.backup')
-    os.system('cp util.py outputs' + '/' + args.exp_name + '/' + 'util.py.backup')
-    os.system('cp data.py outputs' + '/' + args.exp_name + '/' + 'data.py.backup')
+    if not os.path.exists("outputs"):
+        os.makedirs("outputs")
+    if not os.path.exists("outputs/" + args.exp_name):
+        os.makedirs("outputs/" + args.exp_name)
+    if not os.path.exists("outputs/" + args.exp_name + "/" + "models"):
+        os.makedirs("outputs/" + args.exp_name + "/" + "models")
+    os.system(
+        "cp main_semseg_s3dis.py outputs"
+        + "/"
+        + args.exp_name
+        + "/"
+        + "main_semseg_s3dis.py.backup"
+    )
+    os.system("cp model.py outputs" + "/" + args.exp_name + "/" + "model.py.backup")
+    os.system("cp util.py outputs" + "/" + args.exp_name + "/" + "util.py.backup")
+    os.system("cp data.py outputs" + "/" + args.exp_name + "/" + "data.py.backup")
 
 
 def calculate_sem_IoU(pred_np, seg_np, visual=False):
     if args.custom_mode:
         I_all = np.zeros(args.num_features)
         U_all = np.zeros(args.num_features)
         for sem_idx in range(seg_np.shape[0]):
             for sem in range(args.num_features):
-                I = np.sum(np.logical_and(pred_np[sem_idx] == sem, seg_np[sem_idx] == sem))
-                U = np.sum(np.logical_or(pred_np[sem_idx] == sem, seg_np[sem_idx] == sem))
+                I = np.sum(
+                    np.logical_and(pred_np[sem_idx] == sem, seg_np[sem_idx] == sem)
+                )
+                U = np.sum(
+                    np.logical_or(pred_np[sem_idx] == sem, seg_np[sem_idx] == sem)
+                )
                 I_all[sem] += I
                 U_all[sem] += U
     else:
         I_all = np.zeros(13)
         U_all = np.zeros(13)
         for sem_idx in range(seg_np.shape[0]):
             for sem in range(13):
-                I = np.sum(np.logical_and(pred_np[sem_idx] == sem, seg_np[sem_idx] == sem))
-                U = np.sum(np.logical_or(pred_np[sem_idx] == sem, seg_np[sem_idx] == sem))
+                I = np.sum(
+                    np.logical_and(pred_np[sem_idx] == sem, seg_np[sem_idx] == sem)
+                )
+                U = np.sum(
+                    np.logical_or(pred_np[sem_idx] == sem, seg_np[sem_idx] == sem)
+                )
                 I_all[sem] += I
                 U_all[sem] += U
-    return I_all / U_all 
-
-
-def visualization(visu, visu_format, test_choice, data, seg, pred, visual_file_index, semseg_colors):
+    return I_all / U_all
+
+
+def visualization(
+    visu, visu_format, test_choice, data, seg, pred, visual_file_index, semseg_colors
+):
     global room_seg, room_pred
     global visual_warning
-    visu = visu.split('_')
+    visu = visu.split("_")
     for i in range(0, data.shape[0]):
         RGB = []
-        RGB_gt = [] 
+        RGB_gt = []
         skip = False
         with open("data/indoor3d_sem_seg_hdf5_data_test/room_filelist.txt") as f:
             files = f.readlines()
             test_area = files[visual_file_index][5]
             roomname = files[visual_file_index][7:-1]
             if visual_file_index + 1 < len(files):
-                roomname_next = files[visual_file_index+1][7:-1]
+                roomname_next = files[visual_file_index + 1][7:-1]
             else:
-                roomname_next = ''
-        if visu[0] != 'all':
+                roomname_next = ""
+        if visu[0] != "all":
             if len(visu) == 2:
-                if visu[0] != 'area' or visu[1] != test_area:
-                    skip = True 
+                if visu[0] != "area" or visu[1] != test_area:
+                    skip = True
                 else:
                     visual_warning = False
             elif len(visu) == 4:
-                if visu[0] != 'area' or visu[1] != test_area or visu[2] != roomname.split('_')[0] or visu[3] != roomname.split('_')[1]:
+                if (
+                    visu[0] != "area"
+                    or visu[1] != test_area
+                    or visu[2] != roomname.split("_")[0]
+                    or visu[3] != roomname.split("_")[1]
+                ):
                     skip = True
                 else:
-                    visual_warning = False  
+                    visual_warning = False
             else:
                 skip = True
-        elif test_choice !='all':
+        elif test_choice != "all":
             skip = True
         else:
             visual_warning = False
         if skip:
             visual_file_index = visual_file_index + 1
         else:
-            if not os.path.exists('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname):
-                os.makedirs('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname)
-            
-            data = np.loadtxt('data/indoor3d_sem_seg_hdf5_data_test/raw_data3d/Area_'+test_area+'/'+roomname+'('+str(visual_file_index)+').txt')
+            if not os.path.exists(
+                "outputs/"
+                + args.exp_name
+                + "/"
+                + "visualization"
+                + "/"
+                + "area_"
+                + test_area
+                + "/"
+                + roomname
+            ):
+                os.makedirs(
+                    "outputs/"
+                    + args.exp_name
+                    + "/"
+                    + "visualization"
+                    + "/"
+                    + "area_"
+                    + test_area
+                    + "/"
+                    + roomname
+                )
+
+            data = np.loadtxt(
+                "data/indoor3d_sem_seg_hdf5_data_test/raw_data3d/Area_"
+                + test_area
+                + "/"
+                + roomname
+                + "("
+                + str(visual_file_index)
+                + ").txt"
+            )
             visual_file_index = visual_file_index + 1
             for j in range(0, data.shape[0]):
                 RGB.append(semseg_colors[int(pred[i][j])])
                 RGB_gt.append(semseg_colors[int(seg[i][j])])
-            data = data[:,[1,2,0]]
+            data = data[:, [1, 2, 0]]
             xyzRGB = np.concatenate((data, np.array(RGB)), axis=1)
             xyzRGB_gt = np.concatenate((data, np.array(RGB_gt)), axis=1)
             room_seg.append(seg[i].cpu().numpy())
-            room_pred.append(pred[i].cpu().numpy()) 
-            f = open('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'.txt', "a")
-            f_gt = open('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_gt.txt', "a")
-            np.savetxt(f, xyzRGB, fmt='%s', delimiter=' ') 
-            np.savetxt(f_gt, xyzRGB_gt, fmt='%s', delimiter=' ') 
-            
+            room_pred.append(pred[i].cpu().numpy())
+            f = open(
+                "outputs/"
+                + args.exp_name
+                + "/"
+                + "visualization"
+                + "/"
+                + "area_"
+                + test_area
+                + "/"
+                + roomname
+                + "/"
+                + roomname
+                + ".txt",
+                "a",
+            )
+            f_gt = open(
+                "outputs/"
+                + args.exp_name
+                + "/"
+                + "visualization"
+                + "/"
+                + "area_"
+                + test_area
+                + "/"
+                + roomname
+                + "/"
+                + roomname
+                + "_gt.txt",
+                "a",
+            )
+            np.savetxt(f, xyzRGB, fmt="%s", delimiter=" ")
+            np.savetxt(f_gt, xyzRGB_gt, fmt="%s", delimiter=" ")
+
             if roomname != roomname_next:
-                mIoU = np.nanmean(calculate_sem_IoU(np.array(room_pred), np.array(room_seg)))
+                mIoU = np.nanmean(
+                    calculate_sem_IoU(np.array(room_pred), np.array(room_seg))
+                )
                 mIoU = str(round(mIoU, 4))
                 room_pred = []
                 room_seg = []
-                if visu_format == 'ply':
-                    filepath = 'outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_pred_'+mIoU+'.ply'
-                    filepath_gt = 'outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_gt.ply'
-                    xyzRGB = np.loadtxt('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'.txt')
-                    xyzRGB_gt = np.loadtxt('outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_gt.txt')
-                    xyzRGB = [(xyzRGB[i, 0], xyzRGB[i, 1], xyzRGB[i, 2], xyzRGB[i, 3], xyzRGB[i, 4], xyzRGB[i, 5]) for i in range(xyzRGB.shape[0])]
-                    xyzRGB_gt = [(xyzRGB_gt[i, 0], xyzRGB_gt[i, 1], xyzRGB_gt[i, 2], xyzRGB_gt[i, 3], xyzRGB_gt[i, 4], xyzRGB_gt[i, 5]) for i in range(xyzRGB_gt.shape[0])]
-                    vertex = PlyElement.describe(np.array(xyzRGB, dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')]), 'vertex')
+                if visu_format == "ply":
+                    filepath = (
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + "_pred_"
+                        + mIoU
+                        + ".ply"
+                    )
+                    filepath_gt = (
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + "_gt.ply"
+                    )
+                    xyzRGB = np.loadtxt(
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + ".txt"
+                    )
+                    xyzRGB_gt = np.loadtxt(
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + "_gt.txt"
+                    )
+                    xyzRGB = [
+                        (
+                            xyzRGB[i, 0],
+                            xyzRGB[i, 1],
+                            xyzRGB[i, 2],
+                            xyzRGB[i, 3],
+                            xyzRGB[i, 4],
+                            xyzRGB[i, 5],
+                        )
+                        for i in range(xyzRGB.shape[0])
+                    ]
+                    xyzRGB_gt = [
+                        (
+                            xyzRGB_gt[i, 0],
+                            xyzRGB_gt[i, 1],
+                            xyzRGB_gt[i, 2],
+                            xyzRGB_gt[i, 3],
+                            xyzRGB_gt[i, 4],
+                            xyzRGB_gt[i, 5],
+                        )
+                        for i in range(xyzRGB_gt.shape[0])
+                    ]
+                    vertex = PlyElement.describe(
+                        np.array(
+                            xyzRGB,
+                            dtype=[
+                                ("x", "f4"),
+                                ("y", "f4"),
+                                ("z", "f4"),
+                                ("red", "u1"),
+                                ("green", "u1"),
+                                ("blue", "u1"),
+                            ],
+                        ),
+                        "vertex",
+                    )
                     PlyData([vertex]).write(filepath)
-                    print('PLY visualization file saved in', filepath)
-                    vertex = PlyElement.describe(np.array(xyzRGB_gt, dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')]), 'vertex')
+                    print("PLY visualization file saved in", filepath)
+                    vertex = PlyElement.describe(
+                        np.array(
+                            xyzRGB_gt,
+                            dtype=[
+                                ("x", "f4"),
+                                ("y", "f4"),
+                                ("z", "f4"),
+                                ("red", "u1"),
+                                ("green", "u1"),
+                                ("blue", "u1"),
+                            ],
+                        ),
+                        "vertex",
+                    )
                     PlyData([vertex]).write(filepath_gt)
-                    print('PLY visualization file saved in', filepath_gt)
-                    os.system('rm -rf '+'outputs/'+args.exp_name+'/visualization/area_'+test_area+'/'+roomname+'/*.txt')
+                    print("PLY visualization file saved in", filepath_gt)
+                    os.system(
+                        "rm -rf "
+                        + "outputs/"
+                        + args.exp_name
+                        + "/visualization/area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/*.txt"
+                    )
                 else:
-                    filename = 'outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'.txt'
-                    filename_gt = 'outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_gt.txt'
-                    filename_mIoU = 'outputs/'+args.exp_name+'/'+'visualization'+'/'+'area_'+test_area+'/'+roomname+'/'+roomname+'_pred_'+mIoU+'.txt'
+                    filename = (
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + ".txt"
+                    )
+                    filename_gt = (
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + "_gt.txt"
+                    )
+                    filename_mIoU = (
+                        "outputs/"
+                        + args.exp_name
+                        + "/"
+                        + "visualization"
+                        + "/"
+                        + "area_"
+                        + test_area
+                        + "/"
+                        + roomname
+                        + "/"
+                        + roomname
+                        + "_pred_"
+                        + mIoU
+                        + ".txt"
+                    )
                     os.rename(filename, filename_mIoU)
-                    print('TXT visualization file saved in', filename_mIoU)
-                    print('TXT visualization file saved in', filename_gt)
-            elif visu_format != 'ply' and visu_format != 'txt':
-                print('ERROR!! Unknown visualization format: %s, please use txt or ply.' % \
-                (visu_format))
+                    print("TXT visualization file saved in", filename_mIoU)
+                    print("TXT visualization file saved in", filename_gt)
+            elif visu_format != "ply" and visu_format != "txt":
+                print(
+                    "ERROR!! Unknown visualization format: %s, please use txt or ply."
+                    % (visu_format)
+                )
                 exit()
-            
-        
+
+
 def train(args, io):
     if args.custom_mode:
-        train_loader = DataLoader(our_data(partition='train', num_points=args.num_points, data_path=custom_dataset), 
-                              num_workers=8, batch_size=args.batch_size, shuffle=True, drop_last=True)
-        test_loader = DataLoader(our_data(partition='val', num_points=args.num_points, data_path=custom_dataset), 
-                            num_workers=8, batch_size=args.test_batch_size, shuffle=True, drop_last=False)
+        train_loader = DataLoader(
+            our_data(
+                partition="train", num_points=args.num_points, data_path=custom_dataset
+            ),
+            num_workers=8,
+            batch_size=args.batch_size,
+            shuffle=True,
+            drop_last=True,
+        )
+        test_loader = DataLoader(
+            our_data(
+                partition="val", num_points=args.num_points, data_path=custom_dataset
+            ),
+            num_workers=8,
+            batch_size=args.test_batch_size,
+            shuffle=True,
+            drop_last=False,
+        )
     else:
-        train_loader = DataLoader(S3DIS(partition='train', num_points=args.num_points, test_area=args.test_area), 
-                              num_workers=8, batch_size=args.batch_size, shuffle=True, drop_last=True)
-        test_loader = DataLoader(S3DIS(partition='test', num_points=args.num_points, test_area=args.test_area), 
-                            num_workers=8, batch_size=args.test_batch_size, shuffle=True, drop_last=False)
+        train_loader = DataLoader(
+            S3DIS(
+                partition="train", num_points=args.num_points, test_area=args.test_area
+            ),
+            num_workers=8,
+            batch_size=args.batch_size,
+            shuffle=True,
+            drop_last=True,
+        )
+        test_loader = DataLoader(
+            S3DIS(
+                partition="test", num_points=args.num_points, test_area=args.test_area
+            ),
+            num_workers=8,
+            batch_size=args.test_batch_size,
+            shuffle=True,
+            drop_last=False,
+        )
     device = torch.device("cuda" if args.cuda else "cpu")
 
-    #Try to load models
-    if args.model == 'dgcnn':
+    # Try to load models
+    if args.model == "dgcnn":
         model = DGCNN_semseg_s3dis(args).to(device)
     else:
         raise Exception("Not implemented")
     model = nn.DataParallel(model)
-    if args.custom_mode: 
-        print('Loading pretrain model... ')
-        model.load_state_dict(torch.load(os.path.join(args.model_root, 'pretrained_model.tar' )))
-        print('Pretrain model loaded!')
     if args.custom_mode:
-        model.module.conv9 = nn.Conv1d(256, args.num_features, kernel_size=1, bias=False)
+        print("Loading pretrain model... ")
+        model.load_state_dict(
+            torch.load(os.path.join(args.model_root, "pretrained_model.tar"))
+        )
+        print("Pretrain model loaded!")
+    if args.custom_mode:
+        model.module.conv9 = nn.Conv1d(
+            256, args.num_features, kernel_size=1, bias=False
+        )
         nn.init.kaiming_normal_(model.module.conv9.weight)
     model = model.to(device)
     print(str(model))
-    
+
     print("Let's use", torch.cuda.device_count(), "GPUs!")
 
     if args.use_sgd:
         print("Use SGD")
-        opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)
+        opt = optim.SGD(
+            model.parameters(),
+            lr=args.lr * 100,
+            momentum=args.momentum,
+            weight_decay=1e-4,
+        )
     else:
         print("Use Adam")
         opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)
 
-    if args.scheduler == 'cos':
+    if args.scheduler == "cos":
         scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=1e-3)
-    elif args.scheduler == 'step':
+    elif args.scheduler == "step":
         scheduler = StepLR(opt, 20, 0.5, args.epochs)
 
     criterion = cal_loss
 
     best_test_iou = 0
@@ -218,44 +487,53 @@
             batch_size = data.size()[0]
             opt.zero_grad()
             seg_pred = model(data)
             seg_pred = seg_pred.permute(0, 2, 1).contiguous()
             if args.custom_mode:
-                loss = criterion(seg_pred.view(-1, args.num_features), seg.view(-1,1).squeeze())
+                loss = criterion(
+                    seg_pred.view(-1, args.num_features), seg.view(-1, 1).squeeze()
+                )
             else:
-                loss = criterion(seg_pred.view(-1, 13), seg.view(-1,1).squeeze())
+                loss = criterion(seg_pred.view(-1, 13), seg.view(-1, 1).squeeze())
             loss.backward()
             opt.step()
-            pred = seg_pred.max(dim=2)[1]               # (batch_size, num_points)
+            pred = seg_pred.max(dim=2)[1]  # (batch_size, num_points)
             count += batch_size
             train_loss += loss.item() * batch_size
-            seg_np = seg.cpu().numpy()                  # (batch_size, num_points)
-            pred_np = pred.detach().cpu().numpy()       # (batch_size, num_points)
-            train_true_cls.append(seg_np.reshape(-1))       # (batch_size * num_points)
-            train_pred_cls.append(pred_np.reshape(-1))      # (batch_size * num_points)
+            seg_np = seg.cpu().numpy()  # (batch_size, num_points)
+            pred_np = pred.detach().cpu().numpy()  # (batch_size, num_points)
+            train_true_cls.append(seg_np.reshape(-1))  # (batch_size * num_points)
+            train_pred_cls.append(pred_np.reshape(-1))  # (batch_size * num_points)
             train_true_seg.append(seg_np)
             train_pred_seg.append(pred_np)
-        if args.scheduler == 'cos':
+        if args.scheduler == "cos":
             scheduler.step()
-        elif args.scheduler == 'step':
-            if opt.param_groups[0]['lr'] > 1e-5:
+        elif args.scheduler == "step":
+            if opt.param_groups[0]["lr"] > 1e-5:
                 scheduler.step()
-            if opt.param_groups[0]['lr'] < 1e-5:
+            if opt.param_groups[0]["lr"] < 1e-5:
                 for param_group in opt.param_groups:
-                    param_group['lr'] = 1e-5
+                    param_group["lr"] = 1e-5
         train_true_cls = np.concatenate(train_true_cls)
         train_pred_cls = np.concatenate(train_pred_cls)
         train_acc = metrics.accuracy_score(train_true_cls, train_pred_cls)
-        avg_per_class_acc = metrics.balanced_accuracy_score(train_true_cls, train_pred_cls)
+        avg_per_class_acc = metrics.balanced_accuracy_score(
+            train_true_cls, train_pred_cls
+        )
         train_true_seg = np.concatenate(train_true_seg, axis=0)
         train_pred_seg = np.concatenate(train_pred_seg, axis=0)
         train_ious = calculate_sem_IoU(train_pred_seg, train_true_seg)
-        outstr = 'Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f, train iou: %.6f' % (epoch, 
-                                                                                                  train_loss*1.0/count,
-                                                                                                  train_acc,
-                                                                                                  avg_per_class_acc,
-                                                                                                  np.mean(train_ious))
+        outstr = (
+            "Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f, train iou: %.6f"
+            % (
+                epoch,
+                train_loss * 1.0 / count,
+                train_acc,
+                avg_per_class_acc,
+                np.mean(train_ious),
+            )
+        )
         io.cprint(outstr)
 
         ####################
         # Test
         ####################
@@ -271,13 +549,15 @@
             data = data.permute(0, 2, 1)
             batch_size = data.size()[0]
             seg_pred = model(data)
             seg_pred = seg_pred.permute(0, 2, 1).contiguous()
             if args.custom_mode:
-                loss = criterion(seg_pred.view(-1, args.num_features), seg.view(-1,1).squeeze())
+                loss = criterion(
+                    seg_pred.view(-1, args.num_features), seg.view(-1, 1).squeeze()
+                )
             else:
-                loss = criterion(seg_pred.view(-1, 13), seg.view(-1,1).squeeze())
+                loss = criterion(seg_pred.view(-1, 13), seg.view(-1, 1).squeeze())
             pred = seg_pred.max(dim=2)[1]
             count += batch_size
             test_loss += loss.item() * batch_size
             seg_np = seg.cpu().numpy()
             pred_np = pred.detach().cpu().numpy()
@@ -286,58 +566,81 @@
             test_true_seg.append(seg_np)
             test_pred_seg.append(pred_np)
         test_true_cls = np.concatenate(test_true_cls)
         test_pred_cls = np.concatenate(test_pred_cls)
         test_acc = metrics.accuracy_score(test_true_cls, test_pred_cls)
-        avg_per_class_acc = metrics.balanced_accuracy_score(test_true_cls, test_pred_cls)
+        avg_per_class_acc = metrics.balanced_accuracy_score(
+            test_true_cls, test_pred_cls
+        )
         test_true_seg = np.concatenate(test_true_seg, axis=0)
         test_pred_seg = np.concatenate(test_pred_seg, axis=0)
         test_ious = calculate_sem_IoU(test_pred_seg, test_true_seg)
-        outstr = 'Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f, test iou: %.6f' % (epoch,
-                                                                                              test_loss*1.0/count,
-                                                                                              test_acc,
-                                                                                              avg_per_class_acc,
-                                                                                              np.mean(test_ious))
+        outstr = (
+            "Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f, test iou: %.6f"
+            % (
+                epoch,
+                test_loss * 1.0 / count,
+                test_acc,
+                avg_per_class_acc,
+                np.mean(test_ious),
+            )
+        )
         io.cprint(outstr)
         if np.mean(test_ious) >= best_test_iou:
             best_test_iou = np.mean(test_ious)
-            torch.save(model.state_dict(), 'outputs/models/model_train.tar')
+            torch.save(model.state_dict(), "outputs/models/model_train.tar")
 
 
 def test(args, io):
     all_true_cls = []
     all_pred_cls = []
     all_true_seg = []
     all_pred_seg = []
-    for test_area in range(1,7):
+    for test_area in range(1, 7):
         visual_file_index = 0
         test_area = str(test_area)
         if os.path.exists("data/indoor3d_sem_seg_hdf5_data_test/room_filelist.txt"):
             with open("data/indoor3d_sem_seg_hdf5_data_test/room_filelist.txt") as f:
                 for line in f:
                     if (line[5]) == test_area:
                         break
                     visual_file_index = visual_file_index + 1
         if args.custom_mode:
-            test_loader = DataLoader(our_data(partition='test', num_points=args.num_points, test_area=test_area),
-                                     batch_size=args.test_batch_size, shuffle=False, drop_last=False)
+            test_loader = DataLoader(
+                our_data(
+                    partition="test", num_points=args.num_points, test_area=test_area
+                ),
+                batch_size=args.test_batch_size,
+                shuffle=False,
+                drop_last=False,
+            )
         else:
-            if (args.test_area == 'all') or (test_area == args.test_area):
-                test_loader = DataLoader(S3DIS(partition='test', num_points=args.num_points, test_area=test_area),
-                                        batch_size=args.test_batch_size, shuffle=False, drop_last=False)
+            if (args.test_area == "all") or (test_area == args.test_area):
+                test_loader = DataLoader(
+                    S3DIS(
+                        partition="test",
+                        num_points=args.num_points,
+                        test_area=test_area,
+                    ),
+                    batch_size=args.test_batch_size,
+                    shuffle=False,
+                    drop_last=False,
+                )
 
             device = torch.device("cuda" if args.cuda else "cpu")
-                        
-            #Try to load models
+
+            # Try to load models
             semseg_colors = test_loader.dataset.semseg_colors
-            if args.model == 'dgcnn':
+            if args.model == "dgcnn":
                 model = DGCNN_semseg_s3dis(args).to(device)
             else:
                 raise Exception("Not implemented")
-                
+
             model = nn.DataParallel(model)
-            model.load_state_dict(torch.load(os.path.join(args.model_root, 'model_%s.t7' % test_area)))
+            model.load_state_dict(
+                torch.load(os.path.join(args.model_root, "model_%s.t7" % test_area))
+            )
             model = model.eval()
             test_acc = 0.0
             count = 0.0
             test_true_cls = []
             test_pred_cls = []
@@ -347,119 +650,195 @@
                 data, seg = data.to(device), seg.to(device)
                 data = data.permute(0, 2, 1)
                 batch_size = data.size()[0]
                 seg_pred = model(data)
                 seg_pred = seg_pred.permute(0, 2, 1).contiguous()
-                pred = seg_pred.max(dim=2)[1] 
+                pred = seg_pred.max(dim=2)[1]
                 seg_np = seg.cpu().numpy()
                 pred_np = pred.detach().cpu().numpy()
                 test_true_cls.append(seg_np.reshape(-1))
                 test_pred_cls.append(pred_np.reshape(-1))
                 test_true_seg.append(seg_np)
                 test_pred_seg.append(pred_np)
                 # visiualization
-                visualization(args.visu, args.visu_format, args.test_area, data, seg, pred, visual_file_index, semseg_colors) 
+                visualization(
+                    args.visu,
+                    args.visu_format,
+                    args.test_area,
+                    data,
+                    seg,
+                    pred,
+                    visual_file_index,
+                    semseg_colors,
+                )
                 visual_file_index = visual_file_index + data.shape[0]
-            if visual_warning and args.visu != '':
-                print('Visualization Failed: You can only choose a room to visualize within the scope of the test area')
+            if visual_warning and args.visu != "":
+                print(
+                    "Visualization Failed: You can only choose a room to visualize within the scope of the test area"
+                )
             test_true_cls = np.concatenate(test_true_cls)
             test_pred_cls = np.concatenate(test_pred_cls)
             test_acc = metrics.accuracy_score(test_true_cls, test_pred_cls)
-            avg_per_class_acc = metrics.balanced_accuracy_score(test_true_cls, test_pred_cls)
+            avg_per_class_acc = metrics.balanced_accuracy_score(
+                test_true_cls, test_pred_cls
+            )
             test_true_seg = np.concatenate(test_true_seg, axis=0)
             test_pred_seg = np.concatenate(test_pred_seg, axis=0)
             test_ious = calculate_sem_IoU(test_pred_seg, test_true_seg)
-            outstr = 'Test :: test area: %s, test acc: %.6f, test avg acc: %.6f, test iou: %.6f' % (test_area,
-                                                                                                    test_acc,
-                                                                                                    avg_per_class_acc,
-                                                                                                    np.mean(test_ious))
+            outstr = (
+                "Test :: test area: %s, test acc: %.6f, test avg acc: %.6f, test iou: %.6f"
+                % (test_area, test_acc, avg_per_class_acc, np.mean(test_ious))
+            )
             io.cprint(outstr)
             all_true_cls.append(test_true_cls)
             all_pred_cls.append(test_pred_cls)
             all_true_seg.append(test_true_seg)
             all_pred_seg.append(test_pred_seg)
 
-    if args.test_area == 'all':
+    if args.test_area == "all":
         all_true_cls = np.concatenate(all_true_cls)
         all_pred_cls = np.concatenate(all_pred_cls)
         all_acc = metrics.accuracy_score(all_true_cls, all_pred_cls)
         avg_per_class_acc = metrics.balanced_accuracy_score(all_true_cls, all_pred_cls)
         all_true_seg = np.concatenate(all_true_seg, axis=0)
         all_pred_seg = np.concatenate(all_pred_seg, axis=0)
         all_ious = calculate_sem_IoU(all_pred_seg, all_true_seg)
-        outstr = 'Overall Test :: test acc: %.6f, test avg acc: %.6f, test iou: %.6f' % (all_acc,
-                                                                                         avg_per_class_acc,
-                                                                                         np.mean(all_ious))
+        outstr = (
+            "Overall Test :: test acc: %.6f, test avg acc: %.6f, test iou: %.6f"
+            % (all_acc, avg_per_class_acc, np.mean(all_ious))
+        )
         io.cprint(outstr)
 
 
 if __name__ == "__main__":
     # Training settings
-    parser = argparse.ArgumentParser(description='Point Cloud Part Segmentation')
-    parser.add_argument('--exp_name', type=str, default='exp', metavar='N',
-                        help='Name of the experiment')
-    parser.add_argument('--model', type=str, default='dgcnn', metavar='N',
-                        choices=['dgcnn'],
-                        help='Model to use, [dgcnn]')
-    parser.add_argument('--dataset', type=str, default='S3DIS', metavar='N',
-                        choices=['S3DIS'])
-    parser.add_argument('--test_area', type=str, default=None, metavar='N',
-                        choices=['1', '2', '3', '4', '5', '6', 'all'])
-    parser.add_argument('--batch_size', type=int, default=32, metavar='batch_size',
-                        help='Size of batch)')
-    parser.add_argument('--test_batch_size', type=int, default=16, metavar='batch_size',
-                        help='Size of batch)')
-    parser.add_argument('--epochs', type=int, default=100, metavar='N',
-                        help='number of episode to train ')
-    parser.add_argument('--use_sgd', type=bool, default=True,
-                        help='Use SGD')
-    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',
-                        help='learning rate (default: 0.001, 0.1 if using sgd)')
-    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',
-                        help='SGD momentum (default: 0.9)')
-    parser.add_argument('--scheduler', type=str, default='cos', metavar='N',
-                        choices=['cos', 'step'],
-                        help='Scheduler to use, [cos, step]')
-    parser.add_argument('--no_cuda', type=bool, default=False,
-                        help='enables CUDA training')
-    parser.add_argument('--seed', type=int, default=1, metavar='S',
-                        help='random seed (default: 1)')
-    parser.add_argument('--eval', type=bool,  default=False,
-                        help='evaluate the model')
-    parser.add_argument('--num_points', type=int, default=2048,
-                        help='num of points to use')
-    parser.add_argument('--dropout', type=float, default=0.5,
-                        help='dropout rate')
-    parser.add_argument('--emb_dims', type=int, default=1024, metavar='N',
-                        help='Dimension of embeddings')
-    parser.add_argument('--k', type=int, default=20, metavar='N',
-                        help='Num of nearest neighbors to use')
-    parser.add_argument('--model_root', type=str, default='./outputs/models/', metavar='N',
-                        help='Pretrained model root')
-    parser.add_argument('--visu', type=str, default='',
-                        help='visualize the model')
-    parser.add_argument('--visu_format', type=str, default='ply',
-                        help='file format of visualization')
-    parser.add_argument('--custom_mode', type=bool, required=True,
-                        help='True when using custom dataset')
-    parser.add_argument('--num_features', type=int, default=5,
-                        help='Number of classes')
+    parser = argparse.ArgumentParser(description="Point Cloud Part Segmentation")
+    parser.add_argument(
+        "--exp_name",
+        type=str,
+        default="exp",
+        metavar="N",
+        help="Name of the experiment",
+    )
+    parser.add_argument(
+        "--model",
+        type=str,
+        default="dgcnn",
+        metavar="N",
+        choices=["dgcnn"],
+        help="Model to use, [dgcnn]",
+    )
+    parser.add_argument(
+        "--dataset", type=str, default="S3DIS", metavar="N", choices=["S3DIS"]
+    )
+    parser.add_argument(
+        "--test_area",
+        type=str,
+        default=None,
+        metavar="N",
+        choices=["1", "2", "3", "4", "5", "6", "all"],
+    )
+    parser.add_argument(
+        "--batch_size",
+        type=int,
+        default=32,
+        metavar="batch_size",
+        help="Size of batch)",
+    )
+    parser.add_argument(
+        "--test_batch_size",
+        type=int,
+        default=16,
+        metavar="batch_size",
+        help="Size of batch)",
+    )
+    parser.add_argument(
+        "--epochs",
+        type=int,
+        default=100,
+        metavar="N",
+        help="number of episode to train ",
+    )
+    parser.add_argument("--use_sgd", type=bool, default=True, help="Use SGD")
+    parser.add_argument(
+        "--lr",
+        type=float,
+        default=0.001,
+        metavar="LR",
+        help="learning rate (default: 0.001, 0.1 if using sgd)",
+    )
+    parser.add_argument(
+        "--momentum",
+        type=float,
+        default=0.9,
+        metavar="M",
+        help="SGD momentum (default: 0.9)",
+    )
+    parser.add_argument(
+        "--scheduler",
+        type=str,
+        default="cos",
+        metavar="N",
+        choices=["cos", "step"],
+        help="Scheduler to use, [cos, step]",
+    )
+    parser.add_argument(
+        "--no_cuda", type=bool, default=False, help="enables CUDA training"
+    )
+    parser.add_argument(
+        "--seed", type=int, default=1, metavar="S", help="random seed (default: 1)"
+    )
+    parser.add_argument("--eval", type=bool, default=False, help="evaluate the model")
+    parser.add_argument(
+        "--num_points", type=int, default=2048, help="num of points to use"
+    )
+    parser.add_argument("--dropout", type=float, default=0.5, help="dropout rate")
+    parser.add_argument(
+        "--emb_dims",
+        type=int,
+        default=1024,
+        metavar="N",
+        help="Dimension of embeddings",
+    )
+    parser.add_argument(
+        "--k", type=int, default=20, metavar="N", help="Num of nearest neighbors to use"
+    )
+    parser.add_argument(
+        "--model_root",
+        type=str,
+        default="./outputs/models/",
+        metavar="N",
+        help="Pretrained model root",
+    )
+    parser.add_argument("--visu", type=str, default="", help="visualize the model")
+    parser.add_argument(
+        "--visu_format", type=str, default="ply", help="file format of visualization"
+    )
+    parser.add_argument(
+        "--custom_mode", type=bool, required=True, help="True when using custom dataset"
+    )
+    parser.add_argument("--num_features", type=int, default=5, help="Number of classes")
     args = parser.parse_args()
 
     _init_()
 
-    io = IOStream('outputs/' + args.exp_name + '/run.log')
+    io = IOStream("outputs/" + args.exp_name + "/run.log")
     io.cprint(str(args))
 
     args.cuda = not args.no_cuda and torch.cuda.is_available()
     torch.manual_seed(args.seed)
     if args.cuda:
         io.cprint(
-            'Using GPU : ' + str(torch.cuda.current_device()) + ' from ' + str(torch.cuda.device_count()) + ' devices')
+            "Using GPU : "
+            + str(torch.cuda.current_device())
+            + " from "
+            + str(torch.cuda.device_count())
+            + " devices"
+        )
         torch.cuda.manual_seed(args.seed)
     else:
-        io.cprint('Using CPU')
+        io.cprint("Using CPU")
 
     if not args.eval:
         train(args, io)
     else:
         test(args, io)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/main_DGCNN.py	2024-07-08 11:20:10.523382+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/main_DGCNN.py	2024-07-08 11:53:41.267202+00:00
@@ -11,56 +11,77 @@
 from datetime import datetime
 from pGSCAM import PowerCAM, TSNE_cls, Drop_attack, piecewise_pGSCAM
 from tqdm import tqdm
 
 
-
 parser = argparse.ArgumentParser()
-parser.add_argument('--checkpoint_path', default='dgcnn_pytorch/outputs/segmseg_s3dis_6/model_6.tar', help='Model checkpoint path [default: None]')
-parser.add_argument('--log_dir', default='output', help='Dump dir to save model checkpoint [default: log]')
-parser.add_argument('--max_epoch', type=int, default=400, help='Epoch to run [default: 180]')
-parser.add_argument('--batch_size', type=int, default=1, help='Batch Size during training [default: 8]')
+parser.add_argument(
+    "--checkpoint_path",
+    default="dgcnn_pytorch/outputs/segmseg_s3dis_6/model_6.tar",
+    help="Model checkpoint path [default: None]",
+)
+parser.add_argument(
+    "--log_dir",
+    default="output",
+    help="Dump dir to save model checkpoint [default: log]",
+)
+parser.add_argument(
+    "--max_epoch", type=int, default=400, help="Epoch to run [default: 180]"
+)
+parser.add_argument(
+    "--batch_size", type=int, default=1, help="Batch Size during training [default: 8]"
+)
 FLAGS = parser.parse_args()
 
 #################################################   log   #################################################
 LOG_DIR = FLAGS.log_dir
 if not os.path.exists(LOG_DIR):
     os.mkdir(LOG_DIR)
-LOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'a')
+LOG_FOUT = open(os.path.join(LOG_DIR, "log_train.txt"), "a")
+
 
 def log_string(out_str):
-    LOG_FOUT.write(out_str + '\n')
+    LOG_FOUT.write(out_str + "\n")
     LOG_FOUT.flush()
     print(out_str)
 
 
 #################################################   dataset   #################################################
 # Init datasets and dataloaders
 def my_worker_init_fn(worker_id):
     np.random.seed(np.random.get_state()[1][0] + worker_id)
 
-transform_map = {
-          1: "a",
-          2: "b",
-          3: "c",
-          4: "d",
-          7: "e"
-}    
-
-
-eval_class = 1 # b
+
+transform_map = {1: "a", 2: "b", 3: "c", 4: "d", 7: "e"}
+
+
+eval_class = 1  # b
 # EVAL_DATASET = SemanticKITTI('cam_eval', transform_map[eval_class])
 # EVAL_DATALOADER = DataLoader(EVAL_DATASET, batch_size=FLAGS.batch_size, shuffle=True, num_workers=20,
 #                             worker_init_fn=my_worker_init_fn, collate_fn=EVAL_DATASET.collate_fn)
 
 # Create Dataset and Dataloader
-TRAIN_DATASET = SemanticKITTI('training', None)
-TEST_DATASET = SemanticKITTI('validation', None)
+TRAIN_DATASET = SemanticKITTI("training", None)
+TEST_DATASET = SemanticKITTI("validation", None)
 
 print(len(TRAIN_DATASET), len(TEST_DATASET))
-TRAIN_DATALOADER = DataLoader(TRAIN_DATASET, batch_size=FLAGS.batch_size, shuffle=True, num_workers=20, worker_init_fn=my_worker_init_fn, collate_fn=TRAIN_DATASET.collate_fn)
-TEST_DATALOADER = DataLoader(TEST_DATASET, batch_size=FLAGS.batch_size, shuffle=False, num_workers=20, worker_init_fn=my_worker_init_fn, collate_fn=TEST_DATASET.collate_fn)
+TRAIN_DATALOADER = DataLoader(
+    TRAIN_DATASET,
+    batch_size=FLAGS.batch_size,
+    shuffle=True,
+    num_workers=20,
+    worker_init_fn=my_worker_init_fn,
+    collate_fn=TRAIN_DATASET.collate_fn,
+)
+TEST_DATALOADER = DataLoader(
+    TEST_DATASET,
+    batch_size=FLAGS.batch_size,
+    shuffle=False,
+    num_workers=20,
+    worker_init_fn=my_worker_init_fn,
+    collate_fn=TEST_DATASET.collate_fn,
+)
 
 # print(len(TRAIN_DATALOADER), len(TEST_DATALOADER))
 
 
 #################################################   network   #################################################
@@ -73,37 +94,35 @@
 
 # Load the Adam optimizer
 optimizer = optim.Adam(net.parameters(), lr=cfg.learning_rate)
 
 # Load checkpoint if there is any
-it = -1 # for the initialize value of `LambdaLR` and `BNMomentumScheduler`
+it = -1  # for the initialize value of `LambdaLR` and `BNMomentumScheduler`
 start_epoch = 0
 CHECKPOINT_PATH = FLAGS.checkpoint_path
 if CHECKPOINT_PATH is not None and os.path.isfile(CHECKPOINT_PATH):
     checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)
-    net.load_state_dict(checkpoint['model_state_dict'])
-    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
-    start_epoch = checkpoint['epoch']
-    log_string("-> loaded checkpoint %s (epoch: %d)"%(CHECKPOINT_PATH, start_epoch))
+    net.load_state_dict(checkpoint["model_state_dict"])
+    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
+    start_epoch = checkpoint["epoch"]
+    log_string("-> loaded checkpoint %s (epoch: %d)" % (CHECKPOINT_PATH, start_epoch))
 
 
 if torch.cuda.device_count() > 1:
     log_string("Let's use %d GPUs!" % (torch.cuda.device_count()))
     # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs
     net = nn.DataParallel(net)
 
 
-
-
 #################################################   training functions   ###########################################
 
 
 def adjust_learning_rate(optimizer, epoch):
-    lr = optimizer.param_groups[0]['lr']
+    lr = optimizer.param_groups[0]["lr"]
     lr = lr * cfg.lr_decays[epoch]
     for param_group in optimizer.param_groups:
-        param_group['lr'] = lr
+        param_group["lr"] = lr
 
 
 def train_one_epoch():
     stat_dict = {}  # collect statistics
     adjust_learning_rate(optimizer, EPOCH_CNT)
@@ -128,33 +147,34 @@
         acc, end_points = compute_acc(end_points)
         iou_calc.add_data(end_points)
 
         # Accumulate statistics and print out
         for key in end_points:
-            if 'loss' in key or 'acc' in key or 'iou' in key:
-                if key not in stat_dict: stat_dict[key] = 0
+            if "loss" in key or "acc" in key or "iou" in key:
+                if key not in stat_dict:
+                    stat_dict[key] = 0
                 stat_dict[key] += end_points[key].item()
 
         batch_interval = 10
         if (batch_idx + 1) % batch_interval == 0:
-            log_string(' ---- batch: %03d ----' % (batch_idx + 1))
+            log_string(" ---- batch: %03d ----" % (batch_idx + 1))
             # TRAIN_VISUALIZER.log_scalars({key:stat_dict[key]/batch_interval for key in stat_dict},
             #     (EPOCH_CNT*len(TRAIN_DATALOADER)+batch_idx)*BATCH_SIZE)
             for key in sorted(stat_dict.keys()):
-                log_string('mean %s: %f' % (key, stat_dict[key] / batch_interval))
+                log_string("mean %s: %f" % (key, stat_dict[key] / batch_interval))
                 stat_dict[key] = 0
     mean_iou, iou_list = iou_calc.compute_iou()
-    log_string('mean IoU:{:.1f}'.format(mean_iou * 100))
-    s = 'IoU:'
+    log_string("mean IoU:{:.1f}".format(mean_iou * 100))
+    s = "IoU:"
     for iou_tmp in iou_list:
-        s += '{:5.2f} '.format(100 * iou_tmp)
+        s += "{:5.2f} ".format(100 * iou_tmp)
     log_string(s)
 
 
 def evaluate_one_epoch():
-    stat_dict = {} # collect statistics
-    net.eval() # set model to eval mode (for bn and dp)
+    stat_dict = {}  # collect statistics
+    net.eval()  # set model to eval mode (for bn and dp)
     iou_calc = IoUCalculator(cfg)
     for batch_idx, batch_data in enumerate(TEST_DATALOADER):
         for key in batch_data:
             if type(batch_data[key]) is list:
                 for i in range(len(batch_data[key])):
@@ -172,118 +192,122 @@
         acc, end_points = compute_acc(end_points)
         iou_calc.add_data(end_points)
 
         # Accumulate statistics and print out
         for key in end_points:
-            if 'loss' in key or 'acc' in key or 'iou' in key:
-                if key not in stat_dict: stat_dict[key] = 0
+            if "loss" in key or "acc" in key or "iou" in key:
+                if key not in stat_dict:
+                    stat_dict[key] = 0
                 stat_dict[key] += end_points[key].item()
 
         batch_interval = 10
         if (batch_idx + 1) % batch_interval == 0:
-            log_string(' ---- batch: %03d ----' % (batch_idx + 1))
+            log_string(" ---- batch: %03d ----" % (batch_idx + 1))
 
     for key in sorted(stat_dict.keys()):
-        log_string('eval mean %s: %f'%(key, stat_dict[key]/(float(batch_idx+1))))
+        log_string("eval mean %s: %f" % (key, stat_dict[key] / (float(batch_idx + 1))))
     mean_iou, iou_list = iou_calc.compute_iou()
-    log_string('mean IoU:{:.1f}'.format(mean_iou * 100))
-    s = 'IoU:'
+    log_string("mean IoU:{:.1f}".format(mean_iou * 100))
+    s = "IoU:"
     for iou_tmp in iou_list:
-        s += '{:5.2f} '.format(100 * iou_tmp)
+        s += "{:5.2f} ".format(100 * iou_tmp)
     log_string(s)
 
 
 def train(start_epoch):
     global EPOCH_CNT
     loss = 0
     for epoch in range(start_epoch, FLAGS.max_epoch):
         EPOCH_CNT = epoch
-        log_string('**** EPOCH %03d ****' % (epoch))
+        log_string("**** EPOCH %03d ****" % (epoch))
 
         log_string(str(datetime.now()))
 
         np.random.seed()
         train_one_epoch()
 
-        if EPOCH_CNT == 0 or EPOCH_CNT % 10 == 9: # Eval every 10 epochs
-            log_string('**** EVAL EPOCH %03d START****' % (epoch))
+        if EPOCH_CNT == 0 or EPOCH_CNT % 10 == 9:  # Eval every 10 epochs
+            log_string("**** EVAL EPOCH %03d START****" % (epoch))
             evaluate_one_epoch()
-            log_string('**** EVAL EPOCH %03d END****' % (epoch))
+            log_string("**** EVAL EPOCH %03d END****" % (epoch))
         # Save checkpoint
-        save_dict = {'epoch': epoch+1, # after training one epoch, the start_epoch should be epoch+1
-                    'optimizer_state_dict': optimizer.state_dict(),
-                    'loss': loss,
-                    }
-        try: # with nn.DataParallel() the net is added as a submodule of DataParallel
-            save_dict['model_state_dict'] = net.module.state_dict()
+        save_dict = {
+            "epoch": epoch
+            + 1,  # after training one epoch, the start_epoch should be epoch+1
+            "optimizer_state_dict": optimizer.state_dict(),
+            "loss": loss,
+        }
+        try:  # with nn.DataParallel() the net is added as a submodule of DataParallel
+            save_dict["model_state_dict"] = net.module.state_dict()
         except:
-            save_dict['model_state_dict'] = net.state_dict()
-        torch.save(save_dict, os.path.join(LOG_DIR, 'checkpoint.tar'))
+            save_dict["model_state_dict"] = net.state_dict()
+        torch.save(save_dict, os.path.join(LOG_DIR, "checkpoint.tar"))
 
 
 # For testing pGS-CAM
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     # mean_IoU = np.array([0])
     # counter = 0
     print(len(TEST_DATALOADER))
     # MIOU_HIGH = []
     # CIOU_HIGH = []
     # MIOU_LOW = []
     # CIOU_LOW = []
-    
+
     for num_batch, batch_data in enumerate(tqdm(TEST_DATALOADER)):
-#         for key in batch_data:
-#             if type(batch_data[key]) is list:
-#                 for i in range(len(batch_data[key])):
-#                     batch_data[key][i] = batch_data[key][i].cuda()
-#             else:
-#                 batch_data[key] = batch_data[key].cuda()
-        
-# #         print("Points shape: ", batch_data['xyz'][0].shape)
-        
-#         attack = Drop_attack()
-#         miou_high_collect, ciou_high_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='high')
-#         miou_low_collect, ciou_low_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='low')
-#         MIOU_HIGH.append(miou_high_collect)
-#         CIOU_HIGH.append(ciou_high_collect)
-#         MIOU_LOW.append(miou_low_collect)
-    #     CIOU_LOW.append(ciou_low_collect)
-        
-    #     if num_batch > 100:
-    #         break
-        
-    # MIOU_HIGH = np.array(MIOU_HIGH)
-    # CIOU_HIGH = np.array(CIOU_HIGH)
-    # MIOU_LOW = np.array(MIOU_LOW)
-    # CIOU_LOW = np.array(CIOU_LOW)
-    
-    # MIOU_HIGH_AVERAGE = np.sum(MIOU_HIGH, axis=0) / (MIOU_HIGH.shape[0])
-    # CIOU_HIGH_AVERAGE = np.sum(CIOU_HIGH, axis=0) / (CIOU_HIGH.shape[0])
-    # MIOU_LOW_AVERAGE = np.sum(MIOU_LOW, axis=0) / (MIOU_LOW.shape[0])
-    # CIOU_LOW_AVERAGE = np.sum(CIOU_LOW, axis=0) / (CIOU_LOW.shape[0])
-    # print("MIOU_HIGH_AVERAGE: ", MIOU_HIGH_AVERAGE)
-    # print("Class HIGH IOU AVERAGE: ", CIOU_HIGH_AVERAGE)
-    # print("MIOU_LOW_AVERAGE: ", MIOU_LOW_AVERAGE)
-    # print("Class LOW IOU AVERAGE: ", CIOU_LOW_AVERAGE)
-    
-        
-        
-        
-        
+        #         for key in batch_data:
+        #             if type(batch_data[key]) is list:
+        #                 for i in range(len(batch_data[key])):
+        #                     batch_data[key][i] = batch_data[key][i].cuda()
+        #             else:
+        #                 batch_data[key] = batch_data[key].cuda()
+
+        # #         print("Points shape: ", batch_data['xyz'][0].shape)
+
+        #         attack = Drop_attack()
+        #         miou_high_collect, ciou_high_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='high')
+        #         miou_low_collect, ciou_low_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='low')
+        #         MIOU_HIGH.append(miou_high_collect)
+        #         CIOU_HIGH.append(ciou_high_collect)
+        #         MIOU_LOW.append(miou_low_collect)
+        #     CIOU_LOW.append(ciou_low_collect)
+
+        #     if num_batch > 100:
+        #         break
+
+        # MIOU_HIGH = np.array(MIOU_HIGH)
+        # CIOU_HIGH = np.array(CIOU_HIGH)
+        # MIOU_LOW = np.array(MIOU_LOW)
+        # CIOU_LOW = np.array(CIOU_LOW)
+
+        # MIOU_HIGH_AVERAGE = np.sum(MIOU_HIGH, axis=0) / (MIOU_HIGH.shape[0])
+        # CIOU_HIGH_AVERAGE = np.sum(CIOU_HIGH, axis=0) / (CIOU_HIGH.shape[0])
+        # MIOU_LOW_AVERAGE = np.sum(MIOU_LOW, axis=0) / (MIOU_LOW.shape[0])
+        # CIOU_LOW_AVERAGE = np.sum(CIOU_LOW, axis=0) / (CIOU_LOW.shape[0])
+        # print("MIOU_HIGH_AVERAGE: ", MIOU_HIGH_AVERAGE)
+        # print("Class HIGH IOU AVERAGE: ", CIOU_HIGH_AVERAGE)
+        # print("MIOU_LOW_AVERAGE: ", MIOU_LOW_AVERAGE)
+        # print("Class LOW IOU AVERAGE: ", CIOU_LOW_AVERAGE)
+
         if num_points > 1000:
             break
         else:
             continue
-        
-        
-        cam = PowerCAM(net, batch_data, cfg, norm=True, cls=8, mode='counterfactual', mask_type='none')
+
+        cam = PowerCAM(
+            net,
+            batch_data,
+            cfg,
+            norm=True,
+            cls=8,
+            mode="counterfactual",
+            mask_type="none",
+        )
         num_points = cam.runCAM()
         print(num_points)
 
 
-    
-
 # Training Loop
 
 # if __name__ == "__main__":
 #     train(0)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/main_SemanticKITTI.py	2024-06-30 22:34:19.201896+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/main_SemanticKITTI.py	2024-07-08 11:53:41.483924+00:00
@@ -11,70 +11,97 @@
 from datetime import datetime
 from pGSCAM import PowerCAM, TSNE_cls, Drop_attack, piecewise_pGSCAM
 from tqdm import tqdm
 
 
-
 parser = argparse.ArgumentParser()
-parser.add_argument('--checkpoint_path', default='output/checkpoint_60.tar', help='Model checkpoint path [default: None]')
-parser.add_argument('--log_dir', default='output', help='Dump dir to save model checkpoint [default: log]')
-parser.add_argument('--max_epoch', type=int, default=400, help='Epoch to run [default: 180]')
-parser.add_argument('--batch_size', type=int, default=1, help='Batch Size during training [default: 8]')
+parser.add_argument(
+    "--checkpoint_path",
+    default="output/checkpoint_60.tar",
+    help="Model checkpoint path [default: None]",
+)
+parser.add_argument(
+    "--log_dir",
+    default="output",
+    help="Dump dir to save model checkpoint [default: log]",
+)
+parser.add_argument(
+    "--max_epoch", type=int, default=400, help="Epoch to run [default: 180]"
+)
+parser.add_argument(
+    "--batch_size", type=int, default=1, help="Batch Size during training [default: 8]"
+)
 FLAGS = parser.parse_args()
 
 #################################################   log   #################################################
 LOG_DIR = FLAGS.log_dir
 if not os.path.exists(LOG_DIR):
     os.mkdir(LOG_DIR)
-LOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'a')
+LOG_FOUT = open(os.path.join(LOG_DIR, "log_train.txt"), "a")
+
 
 def log_string(out_str):
-    LOG_FOUT.write(out_str + '\n')
+    LOG_FOUT.write(out_str + "\n")
     LOG_FOUT.flush()
     print(out_str)
 
 
 #################################################   dataset   #################################################
 # Init datasets and dataloaders
 def my_worker_init_fn(worker_id):
     np.random.seed(np.random.get_state()[1][0] + worker_id)
 
+
 transform_map = {
-          0: "car",
-          1: "bicycle",
-          2: "motorcycle",
-          3: "truck",
-          4: "other-vehicle",
-          5: "person",
-          6: "bicyclist",
-          7: "motorcyclist",
-          8: "road",
-          9: "parking",
-          10: "sidewalk",
-          11: "other-ground",
-          12: "building",
-          13: "fence",
-          14: "vegetation",
-          15: "trunk",
-          16: "terrain",
-          17: "pole",
-          18: "traffic-sign"
-}    
-
-
-eval_class = 0 # car
+    0: "car",
+    1: "bicycle",
+    2: "motorcycle",
+    3: "truck",
+    4: "other-vehicle",
+    5: "person",
+    6: "bicyclist",
+    7: "motorcyclist",
+    8: "road",
+    9: "parking",
+    10: "sidewalk",
+    11: "other-ground",
+    12: "building",
+    13: "fence",
+    14: "vegetation",
+    15: "trunk",
+    16: "terrain",
+    17: "pole",
+    18: "traffic-sign",
+}
+
+
+eval_class = 0  # car
 # EVAL_DATASET = SemanticKITTI('cam_eval', transform_map[eval_class])
 # EVAL_DATALOADER = DataLoader(EVAL_DATASET, batch_size=FLAGS.batch_size, shuffle=True, num_workers=20,
 #                             worker_init_fn=my_worker_init_fn, collate_fn=EVAL_DATASET.collate_fn)
 
 # Create Dataset and Dataloader
-TRAIN_DATASET = SemanticKITTI('training', None)
-TEST_DATASET = SemanticKITTI('validation', None)
+TRAIN_DATASET = SemanticKITTI("training", None)
+TEST_DATASET = SemanticKITTI("validation", None)
 
 print(len(TRAIN_DATASET), len(TEST_DATASET))
-TRAIN_DATALOADER = DataLoader(TRAIN_DATASET, batch_size=FLAGS.batch_size, shuffle=True, num_workers=20, worker_init_fn=my_worker_init_fn, collate_fn=TRAIN_DATASET.collate_fn)
-TEST_DATALOADER = DataLoader(TEST_DATASET, batch_size=FLAGS.batch_size, shuffle=False, num_workers=20, worker_init_fn=my_worker_init_fn, collate_fn=TEST_DATASET.collate_fn)
+TRAIN_DATALOADER = DataLoader(
+    TRAIN_DATASET,
+    batch_size=FLAGS.batch_size,
+    shuffle=True,
+    num_workers=20,
+    worker_init_fn=my_worker_init_fn,
+    collate_fn=TRAIN_DATASET.collate_fn,
+)
+TEST_DATALOADER = DataLoader(
+    TEST_DATASET,
+    batch_size=FLAGS.batch_size,
+    shuffle=False,
+    num_workers=20,
+    worker_init_fn=my_worker_init_fn,
+    collate_fn=TEST_DATASET.collate_fn,
+)
 
 # print(len(TRAIN_DATALOADER), len(TEST_DATALOADER))
 
 
 #################################################   network   #################################################
@@ -87,37 +114,35 @@
 
 # Load the Adam optimizer
 optimizer = optim.Adam(net.parameters(), lr=cfg.learning_rate)
 
 # Load checkpoint if there is any
-it = -1 # for the initialize value of `LambdaLR` and `BNMomentumScheduler`
+it = -1  # for the initialize value of `LambdaLR` and `BNMomentumScheduler`
 start_epoch = 0
 CHECKPOINT_PATH = FLAGS.checkpoint_path
 if CHECKPOINT_PATH is not None and os.path.isfile(CHECKPOINT_PATH):
     checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)
-    net.load_state_dict(checkpoint['model_state_dict'])
-    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
-    start_epoch = checkpoint['epoch']
-    log_string("-> loaded checkpoint %s (epoch: %d)"%(CHECKPOINT_PATH, start_epoch))
+    net.load_state_dict(checkpoint["model_state_dict"])
+    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
+    start_epoch = checkpoint["epoch"]
+    log_string("-> loaded checkpoint %s (epoch: %d)" % (CHECKPOINT_PATH, start_epoch))
 
 
 if torch.cuda.device_count() > 1:
     log_string("Let's use %d GPUs!" % (torch.cuda.device_count()))
     # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs
     net = nn.DataParallel(net)
 
 
-
-
 #################################################   training functions   ###########################################
 
 
 def adjust_learning_rate(optimizer, epoch):
-    lr = optimizer.param_groups[0]['lr']
+    lr = optimizer.param_groups[0]["lr"]
     lr = lr * cfg.lr_decays[epoch]
     for param_group in optimizer.param_groups:
-        param_group['lr'] = lr
+        param_group["lr"] = lr
 
 
 def train_one_epoch():
     stat_dict = {}  # collect statistics
     adjust_learning_rate(optimizer, EPOCH_CNT)
@@ -142,33 +167,34 @@
         acc, end_points = compute_acc(end_points)
         iou_calc.add_data(end_points)
 
         # Accumulate statistics and print out
         for key in end_points:
-            if 'loss' in key or 'acc' in key or 'iou' in key:
-                if key not in stat_dict: stat_dict[key] = 0
+            if "loss" in key or "acc" in key or "iou" in key:
+                if key not in stat_dict:
+                    stat_dict[key] = 0
                 stat_dict[key] += end_points[key].item()
 
         batch_interval = 10
         if (batch_idx + 1) % batch_interval == 0:
-            log_string(' ---- batch: %03d ----' % (batch_idx + 1))
+            log_string(" ---- batch: %03d ----" % (batch_idx + 1))
             # TRAIN_VISUALIZER.log_scalars({key:stat_dict[key]/batch_interval for key in stat_dict},
             #     (EPOCH_CNT*len(TRAIN_DATALOADER)+batch_idx)*BATCH_SIZE)
             for key in sorted(stat_dict.keys()):
-                log_string('mean %s: %f' % (key, stat_dict[key] / batch_interval))
+                log_string("mean %s: %f" % (key, stat_dict[key] / batch_interval))
                 stat_dict[key] = 0
     mean_iou, iou_list = iou_calc.compute_iou()
-    log_string('mean IoU:{:.1f}'.format(mean_iou * 100))
-    s = 'IoU:'
+    log_string("mean IoU:{:.1f}".format(mean_iou * 100))
+    s = "IoU:"
     for iou_tmp in iou_list:
-        s += '{:5.2f} '.format(100 * iou_tmp)
+        s += "{:5.2f} ".format(100 * iou_tmp)
     log_string(s)
 
 
 def evaluate_one_epoch():
-    stat_dict = {} # collect statistics
-    net.eval() # set model to eval mode (for bn and dp)
+    stat_dict = {}  # collect statistics
+    net.eval()  # set model to eval mode (for bn and dp)
     iou_calc = IoUCalculator(cfg)
     for batch_idx, batch_data in enumerate(TEST_DATALOADER):
         for key in batch_data:
             if type(batch_data[key]) is list:
                 for i in range(len(batch_data[key])):
@@ -186,118 +212,122 @@
         acc, end_points = compute_acc(end_points)
         iou_calc.add_data(end_points)
 
         # Accumulate statistics and print out
         for key in end_points:
-            if 'loss' in key or 'acc' in key or 'iou' in key:
-                if key not in stat_dict: stat_dict[key] = 0
+            if "loss" in key or "acc" in key or "iou" in key:
+                if key not in stat_dict:
+                    stat_dict[key] = 0
                 stat_dict[key] += end_points[key].item()
 
         batch_interval = 10
         if (batch_idx + 1) % batch_interval == 0:
-            log_string(' ---- batch: %03d ----' % (batch_idx + 1))
+            log_string(" ---- batch: %03d ----" % (batch_idx + 1))
 
     for key in sorted(stat_dict.keys()):
-        log_string('eval mean %s: %f'%(key, stat_dict[key]/(float(batch_idx+1))))
+        log_string("eval mean %s: %f" % (key, stat_dict[key] / (float(batch_idx + 1))))
     mean_iou, iou_list = iou_calc.compute_iou()
-    log_string('mean IoU:{:.1f}'.format(mean_iou * 100))
-    s = 'IoU:'
+    log_string("mean IoU:{:.1f}".format(mean_iou * 100))
+    s = "IoU:"
     for iou_tmp in iou_list:
-        s += '{:5.2f} '.format(100 * iou_tmp)
+        s += "{:5.2f} ".format(100 * iou_tmp)
     log_string(s)
 
 
 def train(start_epoch):
     global EPOCH_CNT
     loss = 0
     for epoch in range(start_epoch, FLAGS.max_epoch):
         EPOCH_CNT = epoch
-        log_string('**** EPOCH %03d ****' % (epoch))
+        log_string("**** EPOCH %03d ****" % (epoch))
 
         log_string(str(datetime.now()))
 
         np.random.seed()
         train_one_epoch()
 
-        if EPOCH_CNT == 0 or EPOCH_CNT % 10 == 9: # Eval every 10 epochs
-            log_string('**** EVAL EPOCH %03d START****' % (epoch))
+        if EPOCH_CNT == 0 or EPOCH_CNT % 10 == 9:  # Eval every 10 epochs
+            log_string("**** EVAL EPOCH %03d START****" % (epoch))
             evaluate_one_epoch()
-            log_string('**** EVAL EPOCH %03d END****' % (epoch))
+            log_string("**** EVAL EPOCH %03d END****" % (epoch))
         # Save checkpoint
-        save_dict = {'epoch': epoch+1, # after training one epoch, the start_epoch should be epoch+1
-                    'optimizer_state_dict': optimizer.state_dict(),
-                    'loss': loss,
-                    }
-        try: # with nn.DataParallel() the net is added as a submodule of DataParallel
-            save_dict['model_state_dict'] = net.module.state_dict()
+        save_dict = {
+            "epoch": epoch
+            + 1,  # after training one epoch, the start_epoch should be epoch+1
+            "optimizer_state_dict": optimizer.state_dict(),
+            "loss": loss,
+        }
+        try:  # with nn.DataParallel() the net is added as a submodule of DataParallel
+            save_dict["model_state_dict"] = net.module.state_dict()
         except:
-            save_dict['model_state_dict'] = net.state_dict()
-        torch.save(save_dict, os.path.join(LOG_DIR, 'checkpoint.tar'))
+            save_dict["model_state_dict"] = net.state_dict()
+        torch.save(save_dict, os.path.join(LOG_DIR, "checkpoint.tar"))
 
 
 # For testing pGS-CAM
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     # mean_IoU = np.array([0])
     # counter = 0
     print(len(TEST_DATALOADER))
     # MIOU_HIGH = []
     # CIOU_HIGH = []
     # MIOU_LOW = []
     # CIOU_LOW = []
-    
+
     for num_batch, batch_data in enumerate(tqdm(TEST_DATALOADER)):
-#         for key in batch_data:
-#             if type(batch_data[key]) is list:
-#                 for i in range(len(batch_data[key])):
-#                     batch_data[key][i] = batch_data[key][i].cuda()
-#             else:
-#                 batch_data[key] = batch_data[key].cuda()
-        
-# #         print("Points shape: ", batch_data['xyz'][0].shape)
-        
-#         attack = Drop_attack()
-#         miou_high_collect, ciou_high_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='high')
-#         miou_low_collect, ciou_low_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='low')
-#         MIOU_HIGH.append(miou_high_collect)
-#         CIOU_HIGH.append(ciou_high_collect)
-#         MIOU_LOW.append(miou_low_collect)
-    #     CIOU_LOW.append(ciou_low_collect)
-        
-    #     if num_batch > 100:
-    #         break
-        
-    # MIOU_HIGH = np.array(MIOU_HIGH)
-    # CIOU_HIGH = np.array(CIOU_HIGH)
-    # MIOU_LOW = np.array(MIOU_LOW)
-    # CIOU_LOW = np.array(CIOU_LOW)
-    
-    # MIOU_HIGH_AVERAGE = np.sum(MIOU_HIGH, axis=0) / (MIOU_HIGH.shape[0])
-    # CIOU_HIGH_AVERAGE = np.sum(CIOU_HIGH, axis=0) / (CIOU_HIGH.shape[0])
-    # MIOU_LOW_AVERAGE = np.sum(MIOU_LOW, axis=0) / (MIOU_LOW.shape[0])
-    # CIOU_LOW_AVERAGE = np.sum(CIOU_LOW, axis=0) / (CIOU_LOW.shape[0])
-    # print("MIOU_HIGH_AVERAGE: ", MIOU_HIGH_AVERAGE)
-    # print("Class HIGH IOU AVERAGE: ", CIOU_HIGH_AVERAGE)
-    # print("MIOU_LOW_AVERAGE: ", MIOU_LOW_AVERAGE)
-    # print("Class LOW IOU AVERAGE: ", CIOU_LOW_AVERAGE)
-    
-        
-        
-        
-        
+        #         for key in batch_data:
+        #             if type(batch_data[key]) is list:
+        #                 for i in range(len(batch_data[key])):
+        #                     batch_data[key][i] = batch_data[key][i].cuda()
+        #             else:
+        #                 batch_data[key] = batch_data[key].cuda()
+
+        # #         print("Points shape: ", batch_data['xyz'][0].shape)
+
+        #         attack = Drop_attack()
+        #         miou_high_collect, ciou_high_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='high')
+        #         miou_low_collect, ciou_low_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='low')
+        #         MIOU_HIGH.append(miou_high_collect)
+        #         CIOU_HIGH.append(ciou_high_collect)
+        #         MIOU_LOW.append(miou_low_collect)
+        #     CIOU_LOW.append(ciou_low_collect)
+
+        #     if num_batch > 100:
+        #         break
+
+        # MIOU_HIGH = np.array(MIOU_HIGH)
+        # CIOU_HIGH = np.array(CIOU_HIGH)
+        # MIOU_LOW = np.array(MIOU_LOW)
+        # CIOU_LOW = np.array(CIOU_LOW)
+
+        # MIOU_HIGH_AVERAGE = np.sum(MIOU_HIGH, axis=0) / (MIOU_HIGH.shape[0])
+        # CIOU_HIGH_AVERAGE = np.sum(CIOU_HIGH, axis=0) / (CIOU_HIGH.shape[0])
+        # MIOU_LOW_AVERAGE = np.sum(MIOU_LOW, axis=0) / (MIOU_LOW.shape[0])
+        # CIOU_LOW_AVERAGE = np.sum(CIOU_LOW, axis=0) / (CIOU_LOW.shape[0])
+        # print("MIOU_HIGH_AVERAGE: ", MIOU_HIGH_AVERAGE)
+        # print("Class HIGH IOU AVERAGE: ", CIOU_HIGH_AVERAGE)
+        # print("MIOU_LOW_AVERAGE: ", MIOU_LOW_AVERAGE)
+        # print("Class LOW IOU AVERAGE: ", CIOU_LOW_AVERAGE)
+
         if num_points > 1000:
             break
         else:
             continue
-        
-        
-        cam = PowerCAM(net, batch_data, cfg, norm=True, cls=8, mode='counterfactual', mask_type='none')
+
+        cam = PowerCAM(
+            net,
+            batch_data,
+            cfg,
+            norm=True,
+            cls=8,
+            mode="counterfactual",
+            mask_type="none",
+        )
         num_points = cam.runCAM()
         print(num_points)
 
 
-    
-
 # Training Loop
 
 # if __name__ == "__main__":
 #     train(0)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/cpp_wrappers/cpp_subsampling/setup.py	2024-06-30 22:34:20.889281+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/cpp_wrappers/cpp_subsampling/setup.py	2024-07-08 11:53:41.588101+00:00
@@ -7,23 +7,21 @@
 # Adding sources of the project
 # *****************************
 
 m_name = "grid_subsampling"
 
-SOURCES = ["../cpp_utils/cloud/cloud.cpp",
-           "grid_subsampling/grid_subsampling.cpp",
-           "wrapper.cpp"]
+SOURCES = [
+    "../cpp_utils/cloud/cloud.cpp",
+    "grid_subsampling/grid_subsampling.cpp",
+    "wrapper.cpp",
+]
 
-module = Extension(m_name,
-                   sources=SOURCES,
-                   extra_compile_args=['-std=c++11',
-                                       '-D_GLIBCXX_USE_CXX11_ABI=0'])
+module = Extension(
+    m_name,
+    sources=SOURCES,
+    extra_compile_args=["-std=c++11", "-D_GLIBCXX_USE_CXX11_ABI=0"],
+)
 
-setup(ext_modules=[module], include_dirs=numpy.distutils.misc_util.get_numpy_include_dirs())
-
-
-
-
-
-
-
-
+setup(
+    ext_modules=[module],
+    include_dirs=numpy.distutils.misc_util.get_numpy_include_dirs(),
+)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/helper_tool.py	2024-06-30 22:34:19.196927+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/helper_tool.py	2024-07-08 11:53:41.586893+00:00
@@ -2,44 +2,49 @@
 from os.path import join
 import numpy as np
 import colorsys, random, os, sys
 import pandas as pd
 
-os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
+os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
 
 BASE_DIR = os.path.dirname(os.path.abspath(__file__))
 
 sys.path.append(BASE_DIR)
-sys.path.append(os.path.join(BASE_DIR, 'utils'))
+sys.path.append(os.path.join(BASE_DIR, "utils"))
 
 import utils.cpp_wrappers.cpp_subsampling.grid_subsampling as cpp_subsampling
 import utils.nearest_neighbors.lib.python.nearest_neighbors as nearest_neighbors
 
 
 class ConfigSemanticKITTI:
     k_n = 16  # KNN
     num_layers = 4  # Number of layers
     num_points = 4096 * 11  # Number of input points
-#     num_points = 40000
+    #     num_points = 40000
     num_classes = 19  # Number of valid classes
     sub_grid_size = 0.06  # preprocess_parameter
 
     batch_size = 6  # batch_size during training
     val_batch_size = 20  # batch_size during validation and test
     train_steps = 500  # Number of steps per epochs
     val_steps = 100  # Number of validation steps per epoch
 
     sub_sampling_ratio = [4, 4, 4, 4]  # sampling ratio of random sampling at each layer
     d_out = [16, 64, 128, 256]  # feature dimension
-    num_sub_points = [num_points // 4, num_points // 16, num_points // 64, num_points // 256]
+    num_sub_points = [
+        num_points // 4,
+        num_points // 16,
+        num_points // 64,
+        num_points // 256,
+    ]
 
     noise_init = 3.5  # noise initial parameter
     max_epoch = 100  # maximum epoch during training
     learning_rate = 1e-2  # initial learning rate
     lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate
 
-    train_sum_dir = 'train_log'
+    train_sum_dir = "train_log"
     saving = True
     saving_path = None
 
 
 class ConfigS3DIS:
@@ -52,19 +57,25 @@
     batch_size = 6  # batch_size during training
     val_batch_size = 20  # batch_size during validation and test
     train_steps = 500  # Number of steps per epochs
     val_steps = 100  # Number of validation steps per epoch
 
-    sub_sampling_ratio = [4, 4, 4, 4, 2]  # sampling ratio of random sampling at each layer
+    sub_sampling_ratio = [
+        4,
+        4,
+        4,
+        4,
+        2,
+    ]  # sampling ratio of random sampling at each layer
     d_out = [16, 64, 128, 256, 512]  # feature dimension
 
     noise_init = 3.5  # noise initial parameter
     max_epoch = 100  # maximum epoch during training
     learning_rate = 1e-2  # initial learning rate
     lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate
 
-    train_sum_dir = 'train_log'
+    train_sum_dir = "train_log"
     saving = True
     saving_path = None
 
 
 class ConfigSemantic3D:
@@ -77,42 +88,52 @@
     batch_size = 4  # batch_size during training
     val_batch_size = 16  # batch_size during validation and test
     train_steps = 500  # Number of steps per epochs
     val_steps = 100  # Number of validation steps per epoch
 
-    sub_sampling_ratio = [4, 4, 4, 4, 2]  # sampling ratio of random sampling at each layer
+    sub_sampling_ratio = [
+        4,
+        4,
+        4,
+        4,
+        2,
+    ]  # sampling ratio of random sampling at each layer
     d_out = [16, 64, 128, 256, 512]  # feature dimension
 
     noise_init = 3.5  # noise initial parameter
     max_epoch = 100  # maximum epoch during training
     learning_rate = 1e-2  # initial learning rate
     lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate
 
-    train_sum_dir = 'train_log'
+    train_sum_dir = "train_log"
     saving = True
     saving_path = None
 
     augment_scale_anisotropic = True
     augment_symmetries = [True, False, False]
-    augment_rotation = 'vertical'
+    augment_rotation = "vertical"
     augment_scale_min = 0.8
     augment_scale_max = 1.2
     augment_noise = 0.001
-    augment_occlusion = 'none'
+    augment_occlusion = "none"
     augment_color = 0.8
 
 
 class DataProcessing:
     @staticmethod
     def load_pc_semantic3d(filename):
-        pc_pd = pd.read_csv(filename, header=None, delim_whitespace=True, dtype=np.float16)
+        pc_pd = pd.read_csv(
+            filename, header=None, delim_whitespace=True, dtype=np.float16
+        )
         pc = pc_pd.values
         return pc
 
     @staticmethod
     def load_label_semantic3d(filename):
-        label_pd = pd.read_csv(filename, header=None, delim_whitespace=True, dtype=np.uint8)
+        label_pd = pd.read_csv(
+            filename, header=None, delim_whitespace=True, dtype=np.uint8
+        )
         cloud_labels = label_pd.values
         return cloud_labels
 
     @staticmethod
     def load_pc_kitti(pc_path):
@@ -125,11 +146,11 @@
     def load_label_kitti(label_path, remap_lut):
         label = np.fromfile(label_path, dtype=np.uint32)
         label = label.reshape((-1))
         sem_label = label & 0xFFFF  # semantic label in lower half
         inst_label = label >> 16  # instance id in upper half
-        assert ((sem_label + (inst_label << 16) == label).all())
+        assert (sem_label + (inst_label << 16) == label).all()
         sem_label = remap_lut[sem_label]
         return sem_label.astype(np.int32)
 
     @staticmethod
     def get_file_list(dataset_path, test_scan_num):
@@ -138,23 +159,31 @@
         train_file_list = []
         test_file_list = []
         val_file_list = []
         for seq_id in seq_list:
             seq_path = join(dataset_path, seq_id)
-            pc_path = join(seq_path, 'velodyne')
-            if seq_id == '08':
-                val_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])
+            pc_path = join(seq_path, "velodyne")
+            if seq_id == "08":
+                val_file_list.append(
+                    [join(pc_path, f) for f in np.sort(os.listdir(pc_path))]
+                )
                 if seq_id == test_scan_num:
-                    test_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])
+                    test_file_list.append(
+                        [join(pc_path, f) for f in np.sort(os.listdir(pc_path))]
+                    )
             elif int(seq_id) >= 11 and seq_id == test_scan_num:
-                test_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])
-            elif seq_id in ['00', '01', '02', '03', '04', '05', '06', '07', '09', '10']:
-                train_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])
+                test_file_list.append(
+                    [join(pc_path, f) for f in np.sort(os.listdir(pc_path))]
+                )
+            elif seq_id in ["00", "01", "02", "03", "04", "05", "06", "07", "09", "10"]:
+                train_file_list.append(
+                    [join(pc_path, f) for f in np.sort(os.listdir(pc_path))]
+                )
 
         train_file_list = np.concatenate(train_file_list, axis=0)
         val_file_list = np.concatenate(val_file_list, axis=0)
-        if test_scan_num != 'None':
+        if test_scan_num != "None":
             test_file_list = np.concatenate(test_file_list, axis=0)
         else:
             test_file_list = None
         return train_file_list, val_file_list, test_file_list
 
@@ -210,16 +239,25 @@
         """
 
         if (features is None) and (labels is None):
             return cpp_subsampling.compute(points, sampleDl=grid_size, verbose=verbose)
         elif labels is None:
-            return cpp_subsampling.compute(points, features=features, sampleDl=grid_size, verbose=verbose)
+            return cpp_subsampling.compute(
+                points, features=features, sampleDl=grid_size, verbose=verbose
+            )
         elif features is None:
-            return cpp_subsampling.compute(points, classes=labels, sampleDl=grid_size, verbose=verbose)
+            return cpp_subsampling.compute(
+                points, classes=labels, sampleDl=grid_size, verbose=verbose
+            )
         else:
-            return cpp_subsampling.compute(points, features=features, classes=labels, sampleDl=grid_size,
-                                           verbose=verbose)
+            return cpp_subsampling.compute(
+                points,
+                features=features,
+                classes=labels,
+                sampleDl=grid_size,
+                verbose=verbose,
+            )
 
     @staticmethod
     def IoU_from_confusions(confusions):
         """
         Computes IoU from confusion matrices.
@@ -248,23 +286,63 @@
 
     @staticmethod
     def get_class_weights(dataset_name):
         # pre-calculate the number of points in each category
         num_per_class = []
-        if dataset_name is 'S3DIS':
-            num_per_class = np.array([3370714, 2856755, 4919229, 318158, 375640, 478001, 974733,
-                                      650464, 791496, 88727, 1284130, 229758, 2272837], dtype=np.int32)
-        elif dataset_name is 'Semantic3D':
-            num_per_class = np.array([5181602, 5012952, 6830086, 1311528, 10476365, 946982, 334860, 269353],
-                                     dtype=np.int32)
-        elif dataset_name is 'SemanticKITTI':
-            num_per_class = np.array([55437630, 320797, 541736, 2578735, 3274484, 552662, 184064, 78858,
-                                      240942562, 17294618, 170599734, 6369672, 230413074, 101130274, 476491114,
-                                      9833174, 129609852, 4506626, 1168181])
+        if dataset_name is "S3DIS":
+            num_per_class = np.array(
+                [
+                    3370714,
+                    2856755,
+                    4919229,
+                    318158,
+                    375640,
+                    478001,
+                    974733,
+                    650464,
+                    791496,
+                    88727,
+                    1284130,
+                    229758,
+                    2272837,
+                ],
+                dtype=np.int32,
+            )
+        elif dataset_name is "Semantic3D":
+            num_per_class = np.array(
+                [5181602, 5012952, 6830086, 1311528, 10476365, 946982, 334860, 269353],
+                dtype=np.int32,
+            )
+        elif dataset_name is "SemanticKITTI":
+            num_per_class = np.array(
+                [
+                    55437630,
+                    320797,
+                    541736,
+                    2578735,
+                    3274484,
+                    552662,
+                    184064,
+                    78858,
+                    240942562,
+                    17294618,
+                    170599734,
+                    6369672,
+                    230413074,
+                    101130274,
+                    476491114,
+                    9833174,
+                    129609852,
+                    4506626,
+                    1168181,
+                ]
+            )
         weight = num_per_class / float(sum(num_per_class))
         ce_label_weight = 1 / (weight + 0.02)
         return ce_label_weight
+
+
 #         return np.expand_dims(ce_label_weight, axis=0)
 
 
 class Plot:
     @staticmethod
@@ -319,17 +397,22 @@
             Y_colors[valid_ind] = tp
 
             ### bbox
             valid_xyz = pc_xyz[valid_ind]
 
-            xmin = np.min(valid_xyz[:, 0]);
+            xmin = np.min(valid_xyz[:, 0])
             xmax = np.max(valid_xyz[:, 0])
-            ymin = np.min(valid_xyz[:, 1]);
+            ymin = np.min(valid_xyz[:, 1])
             ymax = np.max(valid_xyz[:, 1])
-            zmin = np.min(valid_xyz[:, 2]);
+            zmin = np.min(valid_xyz[:, 2])
             zmax = np.max(valid_xyz[:, 2])
             sem_ins_bbox.append(
-                [[xmin, ymin, zmin], [xmax, ymax, zmax], [min(tp[0], 1.), min(tp[1], 1.), min(tp[2], 1.)]])
+                [
+                    [xmin, ymin, zmin],
+                    [xmax, ymax, zmax],
+                    [min(tp[0], 1.0), min(tp[1], 1.0), min(tp[2], 1.0)],
+                ]
+            )
 
         Y_semins = np.concatenate([pc_xyz[:, 0:3], Y_colors], axis=-1)
         Plot.draw_pc(Y_semins)
         return Y_semins
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/6_fold_cv.py	2024-06-30 22:34:20.472685+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/6_fold_cv.py	2024-07-08 11:53:41.629339+00:00
@@ -5,14 +5,14 @@
 ROOT_DIR = os.path.dirname(BASE_DIR)
 sys.path.append(ROOT_DIR)
 from helper_ply import read_ply
 from helper_tool import Plot
 
-if __name__ == '__main__':
-    base_dir = '/data/S3DIS/results'
-    original_data_dir = '/data/S3DIS/original_ply'
-    data_path = glob.glob(os.path.join(base_dir, '*.ply'))
+if __name__ == "__main__":
+    base_dir = "/data/S3DIS/results"
+    original_data_dir = "/data/S3DIS/original_ply"
+    data_path = glob.glob(os.path.join(base_dir, "*.ply"))
     data_path = np.sort(data_path)
 
     test_total_correct = 0
     test_total_seen = 0
     gt_classes = [0 for _ in range(13)]
@@ -20,27 +20,37 @@
     true_positive_classes = [0 for _ in range(13)]
     visualization = False
 
     for file_name in data_path:
         pred_data = read_ply(file_name)
-        pred = pred_data['pred']
-        original_data = read_ply(os.path.join(original_data_dir, file_name.split('/')[-1][:-4] + '.ply'))
-        labels = original_data['class']
-        points = np.vstack((original_data['x'], original_data['y'], original_data['z'])).T
+        pred = pred_data["pred"]
+        original_data = read_ply(
+            os.path.join(original_data_dir, file_name.split("/")[-1][:-4] + ".ply")
+        )
+        labels = original_data["class"]
+        points = np.vstack(
+            (original_data["x"], original_data["y"], original_data["z"])
+        ).T
 
         ##################
         # Visualize data #
         ##################
         if visualization:
-            colors = np.vstack((original_data['red'], original_data['green'], original_data['blue'])).T
+            colors = np.vstack(
+                (original_data["red"], original_data["green"], original_data["blue"])
+            ).T
             xyzrgb = np.concatenate([points, colors], axis=-1)
             Plot.draw_pc(xyzrgb)  # visualize raw point clouds
             Plot.draw_pc_sem_ins(points, labels)  # visualize ground-truth
             Plot.draw_pc_sem_ins(points, pred)  # visualize prediction
 
         correct = np.sum(pred == labels)
-        print(str(file_name.split('/')[-1][:-4]) + '_acc:' + str(correct / float(len(labels))))
+        print(
+            str(file_name.split("/")[-1][:-4])
+            + "_acc:"
+            + str(correct / float(len(labels)))
+        )
         test_total_correct += correct
         test_total_seen += len(labels)
 
         for j in range(len(labels)):
             gt_l = int(labels[j])
@@ -49,18 +59,20 @@
             positive_classes[pred_l] += 1
             true_positive_classes[gt_l] += int(gt_l == pred_l)
 
     iou_list = []
     for n in range(13):
-        iou = true_positive_classes[n] / float(gt_classes[n] + positive_classes[n] - true_positive_classes[n])
+        iou = true_positive_classes[n] / float(
+            gt_classes[n] + positive_classes[n] - true_positive_classes[n]
+        )
         iou_list.append(iou)
     mean_iou = sum(iou_list) / 13.0
-    print('eval accuracy: {}'.format(test_total_correct / float(test_total_seen)))
-    print('mean IOU:{}'.format(mean_iou))
+    print("eval accuracy: {}".format(test_total_correct / float(test_total_seen)))
+    print("mean IOU:{}".format(mean_iou))
     print(iou_list)
 
     acc_list = []
     for n in range(13):
         acc = true_positive_classes[n] / float(gt_classes[n])
         acc_list.append(acc)
     mean_acc = sum(acc_list) / 13.0
-    print('mAcc value is :{}'.format(mean_acc))
+    print("mAcc value is :{}".format(mean_acc))
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/pytorch_utils.py	2024-06-30 22:34:19.826779+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/pytorch_utils.py	2024-07-08 11:53:41.728187+00:00
@@ -3,67 +3,68 @@
 
 
 class SharedMLP(nn.Sequential):
 
     def __init__(
-            self,
-            args: List[int],
-            *,
-            bn: bool = False,
-            activation=nn.ReLU(inplace=True),
-            preact: bool = False,
-            first: bool = False,
-            name: str = "",
-            instance_norm: bool = False
+        self,
+        args: List[int],
+        *,
+        bn: bool = False,
+        activation=nn.ReLU(inplace=True),
+        preact: bool = False,
+        first: bool = False,
+        name: str = "",
+        instance_norm: bool = False
     ):
         super().__init__()
 
         for i in range(len(args) - 1):
             self.add_module(
-                name + 'layer{}'.format(i),
+                name + "layer{}".format(i),
                 Conv2d(
                     args[i],
                     args[i + 1],
                     bn=(not first or not preact or (i != 0)) and bn,
-                    activation=activation
-                    if (not first or not preact or (i != 0)) else None,
+                    activation=(
+                        activation if (not first or not preact or (i != 0)) else None
+                    ),
                     preact=preact,
-                    instance_norm=instance_norm
-                )
+                    instance_norm=instance_norm,
+                ),
             )
 
 
 class _ConvBase(nn.Sequential):
 
     def __init__(
-            self,
-            in_size,
-            out_size,
-            kernel_size,
-            stride,
-            padding,
-            activation,
-            bn,
-            init,
-            conv=None,
-            batch_norm=None,
-            bias=True,
-            preact=False,
-            name="",
-            instance_norm=False,
-            instance_norm_func=None
+        self,
+        in_size,
+        out_size,
+        kernel_size,
+        stride,
+        padding,
+        activation,
+        bn,
+        init,
+        conv=None,
+        batch_norm=None,
+        bias=True,
+        preact=False,
+        name="",
+        instance_norm=False,
+        instance_norm_func=None,
     ):
         super().__init__()
 
         bias = bias and (not bn)
         conv_unit = conv(
             in_size,
             out_size,
             kernel_size=kernel_size,
             stride=stride,
             padding=padding,
-            bias=bias
+            bias=bias,
         )
         init(conv_unit.weight)
         if bias:
             nn.init.constant_(conv_unit.bias, 0)
 
@@ -72,35 +73,39 @@
                 bn_unit = batch_norm(out_size)
             else:
                 bn_unit = batch_norm(in_size)
         if instance_norm:
             if not preact:
-                in_unit = instance_norm_func(out_size, affine=False, track_running_stats=False)
+                in_unit = instance_norm_func(
+                    out_size, affine=False, track_running_stats=False
+                )
             else:
-                in_unit = instance_norm_func(in_size, affine=False, track_running_stats=False)
+                in_unit = instance_norm_func(
+                    in_size, affine=False, track_running_stats=False
+                )
 
         if preact:
             if bn:
-                self.add_module(name + 'bn', bn_unit)
-
-            if activation is not None:
-                self.add_module(name + 'activation', activation)
+                self.add_module(name + "bn", bn_unit)
+
+            if activation is not None:
+                self.add_module(name + "activation", activation)
 
             if not bn and instance_norm:
-                self.add_module(name + 'in', in_unit)
-
-        self.add_module(name + 'conv', conv_unit)
+                self.add_module(name + "in", in_unit)
+
+        self.add_module(name + "conv", conv_unit)
 
         if not preact:
             if bn:
-                self.add_module(name + 'bn', bn_unit)
-
-            if activation is not None:
-                self.add_module(name + 'activation', activation)
+                self.add_module(name + "bn", bn_unit)
+
+            if activation is not None:
+                self.add_module(name + "activation", activation)
 
             if not bn and instance_norm:
-                self.add_module(name + 'in', in_unit)
+                self.add_module(name + "in", in_unit)
 
 
 class _BNBase(nn.Sequential):
 
     def __init__(self, in_size, batch_norm=None, name=""):
@@ -124,24 +129,24 @@
 
 
 class Conv1d(_ConvBase):
 
     def __init__(
-            self,
-            in_size: int,
-            out_size: int,
-            *,
-            kernel_size: int = 1,
-            stride: int = 1,
-            padding: int = 0,
-            activation=nn.LeakyReLU(negative_slope=0.2, inplace=True),
-            bn: bool = False,
-            init=nn.init.kaiming_normal_,
-            bias: bool = True,
-            preact: bool = False,
-            name: str = "",
-            instance_norm=False
+        self,
+        in_size: int,
+        out_size: int,
+        *,
+        kernel_size: int = 1,
+        stride: int = 1,
+        padding: int = 0,
+        activation=nn.LeakyReLU(negative_slope=0.2, inplace=True),
+        bn: bool = False,
+        init=nn.init.kaiming_normal_,
+        bias: bool = True,
+        preact: bool = False,
+        name: str = "",
+        instance_norm=False
     ):
         super().__init__(
             in_size,
             out_size,
             kernel_size,
@@ -154,31 +159,31 @@
             batch_norm=BatchNorm1d,
             bias=bias,
             preact=preact,
             name=name,
             instance_norm=instance_norm,
-            instance_norm_func=nn.InstanceNorm1d
+            instance_norm_func=nn.InstanceNorm1d,
         )
 
 
 class Conv2d(_ConvBase):
 
     def __init__(
-            self,
-            in_size: int,
-            out_size: int,
-            *,
-            kernel_size: Tuple[int, int] = (1, 1),
-            stride: Tuple[int, int] = (1, 1),
-            padding: Tuple[int, int] = (0, 0),
-            activation=nn.LeakyReLU(negative_slope=0.2, inplace=True),
-            bn: bool = False,
-            init=nn.init.kaiming_normal_,
-            bias: bool = True,
-            preact: bool = False,
-            name: str = "",
-            instance_norm=False
+        self,
+        in_size: int,
+        out_size: int,
+        *,
+        kernel_size: Tuple[int, int] = (1, 1),
+        stride: Tuple[int, int] = (1, 1),
+        padding: Tuple[int, int] = (0, 0),
+        activation=nn.LeakyReLU(negative_slope=0.2, inplace=True),
+        bn: bool = False,
+        init=nn.init.kaiming_normal_,
+        bias: bool = True,
+        preact: bool = False,
+        name: str = "",
+        instance_norm=False
     ):
         super().__init__(
             in_size,
             out_size,
             kernel_size,
@@ -191,26 +196,26 @@
             batch_norm=BatchNorm2d,
             bias=bias,
             preact=preact,
             name=name,
             instance_norm=instance_norm,
-            instance_norm_func=nn.InstanceNorm2d
+            instance_norm_func=nn.InstanceNorm2d,
         )
 
 
 class FC(nn.Sequential):
 
     def __init__(
-            self,
-            in_size: int,
-            out_size: int,
-            *,
-            activation=nn.ReLU(inplace=True),
-            bn: bool = False,
-            init=None,
-            preact: bool = False,
-            name: str = ""
+        self,
+        in_size: int,
+        out_size: int,
+        *,
+        activation=nn.ReLU(inplace=True),
+        bn: bool = False,
+        init=None,
+        preact: bool = False,
+        name: str = ""
     ):
         super().__init__()
 
         fc = nn.Linear(in_size, out_size, bias=not bn)
         if init is not None:
@@ -218,23 +223,23 @@
         if not bn:
             nn.init.constant(fc.bias, 0)
 
         if preact:
             if bn:
-                self.add_module(name + 'bn', BatchNorm1d(in_size))
-
-            if activation is not None:
-                self.add_module(name + 'activation', activation)
-
-        self.add_module(name + 'fc', fc)
+                self.add_module(name + "bn", BatchNorm1d(in_size))
+
+            if activation is not None:
+                self.add_module(name + "activation", activation)
+
+        self.add_module(name + "fc", fc)
 
         if not preact:
             if bn:
-                self.add_module(name + 'bn', BatchNorm1d(out_size))
-
-            if activation is not None:
-                self.add_module(name + 'activation', activation)
+                self.add_module(name + "bn", BatchNorm1d(out_size))
+
+            if activation is not None:
+                self.add_module(name + "activation", activation)
 
 
 def set_bn_momentum_default(bn_momentum):
 
     def fn(m):
@@ -244,19 +249,14 @@
     return fn
 
 
 class BNMomentumScheduler(object):
 
-    def __init__(
-            self, model, bn_lambda, last_epoch=-1,
-            setter=set_bn_momentum_default
-    ):
+    def __init__(self, model, bn_lambda, last_epoch=-1, setter=set_bn_momentum_default):
         if not isinstance(model, nn.Module):
             raise RuntimeError(
-                "Class '{}' is not a PyTorch nn Module".format(
-                    type(model).__name__
-                )
+                "Class '{}' is not a PyTorch nn Module".format(type(model).__name__)
             )
 
         self.model = model
         self.setter = setter
         self.lmbd = bn_lambda
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/data_prepare_s3dis.py	2024-06-30 22:34:20.930953+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/data_prepare_s3dis.py	2024-07-08 11:53:41.887485+00:00
@@ -9,23 +9,23 @@
 sys.path.append(BASE_DIR)
 sys.path.append(ROOT_DIR)
 from helper_ply import write_ply
 from helper_tool import DataProcessing as DP
 
-dataset_path = '/data/S3DIS/Stanford3dDataset_v1.2_Aligned_Version'
-anno_paths = [line.rstrip() for line in open(join(BASE_DIR, 'meta/anno_paths.txt'))]
+dataset_path = "/data/S3DIS/Stanford3dDataset_v1.2_Aligned_Version"
+anno_paths = [line.rstrip() for line in open(join(BASE_DIR, "meta/anno_paths.txt"))]
 anno_paths = [join(dataset_path, p) for p in anno_paths]
 
-gt_class = [x.rstrip() for x in open(join(BASE_DIR, 'meta/class_names.txt'))]
+gt_class = [x.rstrip() for x in open(join(BASE_DIR, "meta/class_names.txt"))]
 gt_class2label = {cls: i for i, cls in enumerate(gt_class)}
 
 sub_grid_size = 0.04
-original_pc_folder = join(dirname(dataset_path), 'original_ply')
-sub_pc_folder = join(dirname(dataset_path), 'input_{:.3f}'.format(sub_grid_size))
+original_pc_folder = join(dirname(dataset_path), "original_ply")
+sub_pc_folder = join(dirname(dataset_path), "input_{:.3f}".format(sub_grid_size))
 os.mkdir(original_pc_folder) if not exists(original_pc_folder) else None
 os.mkdir(sub_pc_folder) if not exists(sub_pc_folder) else None
-out_format = '.ply'
+out_format = ".ply"
 
 
 def convert_pc2ply(anno_path, save_path):
     """
     Convert original dataset files to ply file (each line is XYZRGBL).
@@ -34,14 +34,14 @@
     :param save_path: path to save original point clouds (each line is XYZRGBL)
     :return: None
     """
     data_list = []
 
-    for f in glob.glob(join(anno_path, '*.txt')):
-        class_name = os.path.basename(f).split('_')[0]
+    for f in glob.glob(join(anno_path, "*.txt")):
+        class_name = os.path.basename(f).split("_")[0]
         if class_name not in gt_class:  # note: in some room there is 'staris' class..
-            class_name = 'clutter'
+            class_name = "clutter"
         pc = pd.read_csv(f, header=None, delim_whitespace=True).values
         labels = np.ones((pc.shape[0], 1)) * gt_class2label[class_name]
         data_list.append(np.concatenate([pc, labels], 1))  # Nx7
 
     pc_label = np.concatenate(data_list, 0)
@@ -49,32 +49,44 @@
     pc_label[:, 0:3] -= xyz_min
 
     xyz = pc_label[:, :3].astype(np.float32)
     colors = pc_label[:, 3:6].astype(np.uint8)
     labels = pc_label[:, 6].astype(np.uint8)
-    write_ply(save_path, (xyz, colors, labels), ['x', 'y', 'z', 'red', 'green', 'blue', 'class'])
+    write_ply(
+        save_path,
+        (xyz, colors, labels),
+        ["x", "y", "z", "red", "green", "blue", "class"],
+    )
 
     # save sub_cloud and KDTree file
-    sub_xyz, sub_colors, sub_labels = DP.grid_sub_sampling(xyz, colors, labels, sub_grid_size)
+    sub_xyz, sub_colors, sub_labels = DP.grid_sub_sampling(
+        xyz, colors, labels, sub_grid_size
+    )
     sub_colors = sub_colors / 255.0
-    sub_ply_file = join(sub_pc_folder, save_path.split('/')[-1][:-4] + '.ply')
-    write_ply(sub_ply_file, [sub_xyz, sub_colors, sub_labels], ['x', 'y', 'z', 'red', 'green', 'blue', 'class'])
+    sub_ply_file = join(sub_pc_folder, save_path.split("/")[-1][:-4] + ".ply")
+    write_ply(
+        sub_ply_file,
+        [sub_xyz, sub_colors, sub_labels],
+        ["x", "y", "z", "red", "green", "blue", "class"],
+    )
 
     search_tree = KDTree(sub_xyz)
-    kd_tree_file = join(sub_pc_folder, str(save_path.split('/')[-1][:-4]) + '_KDTree.pkl')
-    with open(kd_tree_file, 'wb') as f:
+    kd_tree_file = join(
+        sub_pc_folder, str(save_path.split("/")[-1][:-4]) + "_KDTree.pkl"
+    )
+    with open(kd_tree_file, "wb") as f:
         pickle.dump(search_tree, f)
 
     proj_idx = np.squeeze(search_tree.query(xyz, return_distance=False))
     proj_idx = proj_idx.astype(np.int32)
-    proj_save = join(sub_pc_folder, str(save_path.split('/')[-1][:-4]) + '_proj.pkl')
-    with open(proj_save, 'wb') as f:
+    proj_save = join(sub_pc_folder, str(save_path.split("/")[-1][:-4]) + "_proj.pkl")
+    with open(proj_save, "wb") as f:
         pickle.dump([proj_idx, labels], f)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     # Note: there is an extra character in the v1.2 data in Area_5/hallway_6. It's fixed manually.
     for annotation_path in anno_paths:
         print(annotation_path)
-        elements = str(annotation_path).split('/')
-        out_file_name = elements[-3] + '_' + elements[-2] + out_format
+        elements = str(annotation_path).split("/")
+        out_file_name = elements[-3] + "_" + elements[-2] + out_format
         convert_pc2ply(annotation_path, join(original_pc_folder, out_file_name))
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/semantic_kitti_dataset.py	2024-06-30 22:34:19.847934+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/semantic_kitti_dataset.py	2024-07-08 11:53:41.948697+00:00
@@ -6,152 +6,163 @@
 import torch.utils.data as torch_data
 import torch
 import glob
 
 
-
 class SemanticKITTI(torch_data.Dataset):
     def __init__(self, mode, cls=None, test_id=None):
-        self.name = 'SemanticKITTI'
-        self.dataset_path = '../../SemanticKitti/unzipped/dataset/sequences_0.06'
-        self.label_to_names = {0: 'unlabeled',
-                               1: 'car',
-                               2: 'bicycle',
-                               3: 'motorcycle',
-                               4: 'truck',
-                               5: 'other-vehicle',
-                               6: 'person',
-                               7: 'bicyclist',
-                               8: 'motorcyclist',
-                               9: 'road',
-                               10: 'parking',
-                               11: 'sidewalk',
-                               12: 'other-ground',
-                               13: 'building',
-                               14: 'fence',
-                               15: 'vegetation',
-                               16: 'trunk',
-                               17: 'terrain',
-                               18: 'pole',
-                               19: 'traffic-sign'}
+        self.name = "SemanticKITTI"
+        self.dataset_path = "../../SemanticKitti/unzipped/dataset/sequences_0.06"
+        self.label_to_names = {
+            0: "unlabeled",
+            1: "car",
+            2: "bicycle",
+            3: "motorcycle",
+            4: "truck",
+            5: "other-vehicle",
+            6: "person",
+            7: "bicyclist",
+            8: "motorcyclist",
+            9: "road",
+            10: "parking",
+            11: "sidewalk",
+            12: "other-ground",
+            13: "building",
+            14: "fence",
+            15: "vegetation",
+            16: "trunk",
+            17: "terrain",
+            18: "pole",
+            19: "traffic-sign",
+        }
         self.num_classes = len(self.label_to_names)
         self.label_values = np.sort([k for k, v in self.label_to_names.items()])
         self.label_to_idx = {l: i for i, l in enumerate(self.label_values)}
         self.ignored_labels = np.sort([0])
         self.cls = cls
 
         self.seq_list = np.sort(os.listdir(self.dataset_path))
 
-        if mode == 'test':
+        if mode == "test":
             self.test_scan_number = str(test_id)
 
         self.mode = mode
-        
-        if mode == 'cam_eval':
-            eval_path = self.dataset_path + f'/{self.cls}/velodyne/*'
+
+        if mode == "cam_eval":
+            eval_path = self.dataset_path + f"/{self.cls}/velodyne/*"
             self.data_list = np.array(glob.glob(eval_path))
-            
-            
+
         else:
-            train_list, val_list, test_list = DP.get_file_list(self.dataset_path, str(test_id))
-
-            if mode == 'training':
+            train_list, val_list, test_list = DP.get_file_list(
+                self.dataset_path, str(test_id)
+            )
+
+            if mode == "training":
                 self.data_list = train_list
-            elif mode == 'validation':
+            elif mode == "validation":
                 self.data_list = val_list
-            elif mode == 'test':
+            elif mode == "test":
                 self.data_list = test_list
-        
+
             # self.data_list = self.data_list[0:1]
             self.data_list = DP.shuffle_list(self.data_list)
 
-
         self.possibility = []
         self.min_possibility = []
-        if mode == 'test':
+        if mode == "test":
             path_list = self.data_list
             for test_file_name in path_list:
                 points = np.load(test_file_name)
                 self.possibility += [np.random.rand(points.shape[0]) * 1e-3]
                 self.min_possibility += [float(np.min(self.possibility[-1]))]
 
-        cfg.ignored_label_inds = [self.label_to_idx[ign_label] for ign_label in self.ignored_labels]
-        cfg.class_weights = DP.get_class_weights('SemanticKITTI')
-
-
+        cfg.ignored_label_inds = [
+            self.label_to_idx[ign_label] for ign_label in self.ignored_labels
+        ]
+        cfg.class_weights = DP.get_class_weights("SemanticKITTI")
 
     def __len__(self):
         return len(self.data_list)
 
-
     def __getitem__(self, item):
 
-        selected_pc, selected_labels, selected_idx, cloud_ind = self.spatially_regular_gen(item)
+        selected_pc, selected_labels, selected_idx, cloud_ind = (
+            self.spatially_regular_gen(item)
+        )
         return selected_pc, selected_labels, selected_idx, cloud_ind
-
-
 
     def spatially_regular_gen(self, item):
         # Generator loop
-        if self.mode == 'cam_eval':
+        if self.mode == "cam_eval":
             cloud_ind = item
             pc_path = self.data_list[cloud_ind]
-            
+
             pc, tree, labels = self.get_data_eval(pc_path)
             pick_idx = np.random.choice(len(pc), 1)
             # We bypass crop_pc in cam_eval
-            selected_pc, selected_labels, selected_idx = self.crop_pc(pc, labels, tree, pick_idx)
-            
-            
-        elif self.mode != 'test':
+            selected_pc, selected_labels, selected_idx = self.crop_pc(
+                pc, labels, tree, pick_idx
+            )
+
+        elif self.mode != "test":
             cloud_ind = item
             pc_path = self.data_list[cloud_ind]
             pc, tree, labels = self.get_data(pc_path)
             # crop a small point cloud
             pick_idx = np.random.choice(len(pc), 1)
-            selected_pc, selected_labels, selected_idx = self.crop_pc(pc, labels, tree, pick_idx)
+            selected_pc, selected_labels, selected_idx = self.crop_pc(
+                pc, labels, tree, pick_idx
+            )
         else:
             cloud_ind = int(np.argmin(self.min_possibility))
             pick_idx = np.argmin(self.possibility[cloud_ind])
             pc_path = path_list[cloud_ind]
             pc, tree, labels = self.get_data(pc_path)
-            selected_pc, selected_labels, selected_idx = self.crop_pc(pc, labels, tree, pick_idx)
+            selected_pc, selected_labels, selected_idx = self.crop_pc(
+                pc, labels, tree, pick_idx
+            )
 
             # update the possibility of the selected pc
-            dists = np.sum(np.square((selected_pc - pc[pick_idx]).astype(np.float32)), axis=1)
+            dists = np.sum(
+                np.square((selected_pc - pc[pick_idx]).astype(np.float32)), axis=1
+            )
             delta = np.square(1 - dists / np.max(dists))
             self.possibility[cloud_ind][selected_idx] += delta
             self.min_possibility[cloud_ind] = np.min(self.possibility[cloud_ind])
 
-        return selected_pc.astype(np.float32), selected_labels.astype(np.int32), selected_idx.astype(np.int32), np.array([cloud_ind], dtype=np.int32)
-    
-    
+        return (
+            selected_pc.astype(np.float32),
+            selected_labels.astype(np.int32),
+            selected_idx.astype(np.int32),
+            np.array([cloud_ind], dtype=np.int32),
+        )
+
     def get_data_eval(self, file_path):
-        frame_id = file_path.split('/')[-1][:-4]
-        kd_tree_path = join(self.dataset_path, self.cls, 'KDTree', frame_id + '.pkl')
-        with open(kd_tree_path, 'rb') as f:
+        frame_id = file_path.split("/")[-1][:-4]
+        kd_tree_path = join(self.dataset_path, self.cls, "KDTree", frame_id + ".pkl")
+        with open(kd_tree_path, "rb") as f:
             search_tree = pickle.load(f)
         points = np.array(search_tree.data, copy=False)
-        
-        label_path = join(self.dataset_path, self.cls, 'labels', frame_id + '.npy')
+
+        label_path = join(self.dataset_path, self.cls, "labels", frame_id + ".npy")
         labels = np.squeeze(np.load(label_path))
-        
+
         return points, search_tree, labels
 
     def get_data(self, file_path):
-        seq_id = file_path.split('/')[-3]
-        frame_id = file_path.split('/')[-1][:-4]
-        kd_tree_path = join(self.dataset_path, seq_id, 'KDTree', frame_id + '.pkl')
+        seq_id = file_path.split("/")[-3]
+        frame_id = file_path.split("/")[-1][:-4]
+        kd_tree_path = join(self.dataset_path, seq_id, "KDTree", frame_id + ".pkl")
         # Read pkl with search tree
-        with open(kd_tree_path, 'rb') as f:
+        with open(kd_tree_path, "rb") as f:
             search_tree = pickle.load(f)
         points = np.array(search_tree.data, copy=False)
         # Load labels
         if int(seq_id) >= 11:
             labels = np.zeros(np.shape(points)[0], dtype=np.uint8)
         else:
-            label_path = join(self.dataset_path, seq_id, 'labels', frame_id + '.npy')
+            label_path = join(self.dataset_path, seq_id, "labels", frame_id + ".npy")
             labels = np.squeeze(np.load(label_path))
         return points, search_tree, labels
 
     @staticmethod
     def crop_pc(points, labels, search_tree, pick_idx):
@@ -170,12 +181,16 @@
         input_pools = []
         input_up_samples = []
 
         for i in range(cfg.num_layers):
             neighbour_idx = DP.knn_search(batch_pc, batch_pc, cfg.k_n)
-            sub_points = batch_pc[:, :batch_pc.shape[1] // cfg.sub_sampling_ratio[i], :]
-            pool_i = neighbour_idx[:, :batch_pc.shape[1] // cfg.sub_sampling_ratio[i], :]
+            sub_points = batch_pc[
+                :, : batch_pc.shape[1] // cfg.sub_sampling_ratio[i], :
+            ]
+            pool_i = neighbour_idx[
+                :, : batch_pc.shape[1] // cfg.sub_sampling_ratio[i], :
+            ]
             up_i = DP.knn_search(sub_points, batch_pc, 1)
             input_points.append(batch_pc)
             input_neighbors.append(neighbour_idx)
             input_pools.append(pool_i)
             input_up_samples.append(up_i)
@@ -184,13 +199,13 @@
         input_list = input_points + input_neighbors + input_pools + input_up_samples
         input_list += [features, batch_label, batch_pc_idx, batch_cloud_idx]
 
         return input_list
 
-    def collate_fn(self,batch):
-
-        selected_pc, selected_labels, selected_idx, cloud_ind = [],[],[],[]
+    def collate_fn(self, batch):
+
+        selected_pc, selected_labels, selected_idx, cloud_ind = [], [], [], []
         for i in range(len(batch)):
             selected_pc.append(batch[i][0])
             selected_labels.append(batch[i][1])
             selected_idx.append(batch[i][2])
             cloud_ind.append(batch[i][3])
@@ -202,25 +217,25 @@
 
         flat_inputs = self.tf_map(selected_pc, selected_labels, selected_idx, cloud_ind)
 
         num_layers = cfg.num_layers
         inputs = {}
-        inputs['xyz'] = []
+        inputs["xyz"] = []
         for tmp in flat_inputs[:num_layers]:
-            inputs['xyz'].append(torch.from_numpy(tmp).float())
-        inputs['neigh_idx'] = []
-        for tmp in flat_inputs[num_layers: 2 * num_layers]:
-            inputs['neigh_idx'].append(torch.from_numpy(tmp).long())
-        inputs['sub_idx'] = []
-        for tmp in flat_inputs[2 * num_layers:3 * num_layers]:
-            inputs['sub_idx'].append(torch.from_numpy(tmp).long())
-        inputs['interp_idx'] = []
-        for tmp in flat_inputs[3 * num_layers:4 * num_layers]:
-            inputs['interp_idx'].append(torch.from_numpy(tmp).long())
-        inputs['features'] = torch.from_numpy(flat_inputs[4 * num_layers]).transpose(1,2).float()
-        inputs['labels'] = torch.from_numpy(flat_inputs[4 * num_layers + 1]).long()
-        inputs['input_inds'] = torch.from_numpy(flat_inputs[4 * num_layers + 2]).long()
-        inputs['cloud_inds'] = torch.from_numpy(flat_inputs[4 * num_layers + 3]).long()
+            inputs["xyz"].append(torch.from_numpy(tmp).float())
+        inputs["neigh_idx"] = []
+        for tmp in flat_inputs[num_layers : 2 * num_layers]:
+            inputs["neigh_idx"].append(torch.from_numpy(tmp).long())
+        inputs["sub_idx"] = []
+        for tmp in flat_inputs[2 * num_layers : 3 * num_layers]:
+            inputs["sub_idx"].append(torch.from_numpy(tmp).long())
+        inputs["interp_idx"] = []
+        for tmp in flat_inputs[3 * num_layers : 4 * num_layers]:
+            inputs["interp_idx"].append(torch.from_numpy(tmp).long())
+        inputs["features"] = (
+            torch.from_numpy(flat_inputs[4 * num_layers]).transpose(1, 2).float()
+        )
+        inputs["labels"] = torch.from_numpy(flat_inputs[4 * num_layers + 1]).long()
+        inputs["input_inds"] = torch.from_numpy(flat_inputs[4 * num_layers + 2]).long()
+        inputs["cloud_inds"] = torch.from_numpy(flat_inputs[4 * num_layers + 3]).long()
 
         return inputs
-    
-    
\ No newline at end of file
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/indoor3d_util.py	2024-06-30 23:19:41.949493+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/prepare_data/indoor3d_util.py	2024-07-08 11:53:41.962302+00:00
@@ -1,45 +1,49 @@
 import numpy as np
 import glob
 import os
 import sys
+
 BASE_DIR = os.path.dirname(os.path.abspath(__file__))
 ROOT_DIR = os.path.dirname(BASE_DIR)
 sys.path.append(BASE_DIR)
 
 # -----------------------------------------------------------------------------
 # CONSTANTS
 # -----------------------------------------------------------------------------
 
-DATA_PATH = os.path.join(ROOT_DIR, 'data', 'Stanford3dDataset_v1.2_Aligned_Version')
-g_classes = [x.rstrip() for x in open(os.path.join(BASE_DIR, 'meta/class_names.txt'))]
-g_class2label = {cls: i for i,cls in enumerate(g_classes)}
-g_class2color = {'ceiling':	[0,255,0],
-                 'floor':	[0,0,255],
-                 'wall':	[0,255,255],
-                 'beam':        [255,255,0],
-                 'column':      [255,0,255],
-                 'window':      [100,100,255],
-                 'door':        [200,200,100],
-                 'table':       [170,120,200],
-                 'chair':       [255,0,0],
-                 'sofa':        [200,100,100],
-                 'bookcase':    [10,200,100],
-                 'board':       [200,200,200],
-                 'clutter':     [50,50,50]} 
-g_easy_view_labels = [7,8,9,10,11,1]
+DATA_PATH = os.path.join(ROOT_DIR, "data", "Stanford3dDataset_v1.2_Aligned_Version")
+g_classes = [x.rstrip() for x in open(os.path.join(BASE_DIR, "meta/class_names.txt"))]
+g_class2label = {cls: i for i, cls in enumerate(g_classes)}
+g_class2color = {
+    "ceiling": [0, 255, 0],
+    "floor": [0, 0, 255],
+    "wall": [0, 255, 255],
+    "beam": [255, 255, 0],
+    "column": [255, 0, 255],
+    "window": [100, 100, 255],
+    "door": [200, 200, 100],
+    "table": [170, 120, 200],
+    "chair": [255, 0, 0],
+    "sofa": [200, 100, 100],
+    "bookcase": [10, 200, 100],
+    "board": [200, 200, 200],
+    "clutter": [50, 50, 50],
+}
+g_easy_view_labels = [7, 8, 9, 10, 11, 1]
 g_label2color = {g_classes.index(cls): g_class2color[cls] for cls in g_classes}
 
 global raw_data_index
 raw_data_index = 0
-    
+
 # -----------------------------------------------------------------------------
 # CONVERT ORIGINAL DATA TO OUR DATA_LABEL FILES
 # -----------------------------------------------------------------------------
 
-def collect_point_label(anno_path, out_filename, file_format='txt'):
-    """ Convert original dataset files to data_label file (each line is XYZRGBL).
+
+def collect_point_label(anno_path, out_filename, file_format="txt"):
+    """Convert original dataset files to data_label file (each line is XYZRGBL).
         We aggregated all the points from each instance in the room.
 
     Args:
         anno_path: path to annotations. e.g. Area_1/office_2/Annotations/
         out_filename: path to save collected points and labels (each line is XYZRGBL)
@@ -48,94 +52,128 @@
         None
     Note:
         the points are shifted before save, the most negative point is now at origin.
     """
     points_list = []
-    
-    for f in glob.glob(os.path.join(anno_path, '*.txt')):
-        cls = os.path.basename(f).split('_')[0]
-        if cls not in g_classes: # note: in some room there is 'staris' class..
-            cls = 'clutter'
+
+    for f in glob.glob(os.path.join(anno_path, "*.txt")):
+        cls = os.path.basename(f).split("_")[0]
+        if cls not in g_classes:  # note: in some room there is 'staris' class..
+            cls = "clutter"
         points = np.loadtxt(f)
-        labels = np.ones((points.shape[0],1)) * g_class2label[cls]
-        points_list.append(np.concatenate([points, labels], 1)) # Nx7
-    
+        labels = np.ones((points.shape[0], 1)) * g_class2label[cls]
+        points_list.append(np.concatenate([points, labels], 1))  # Nx7
+
     data_label = np.concatenate(points_list, 0)
     xyz_min = np.amin(data_label, axis=0)[0:3]
     data_label[:, 0:3] -= xyz_min
-    
-    if file_format=='txt':
-        fout = open(out_filename, 'w')
+
+    if file_format == "txt":
+        fout = open(out_filename, "w")
         for i in range(data_label.shape[0]):
-            fout.write('%f %f %f %d %d %d %d\n' % \
-                          (data_label[i,0], data_label[i,1], data_label[i,2],
-                           data_label[i,3], data_label[i,4], data_label[i,5],
-                           data_label[i,6]))
+            fout.write(
+                "%f %f %f %d %d %d %d\n"
+                % (
+                    data_label[i, 0],
+                    data_label[i, 1],
+                    data_label[i, 2],
+                    data_label[i, 3],
+                    data_label[i, 4],
+                    data_label[i, 5],
+                    data_label[i, 6],
+                )
+            )
         fout.close()
-    elif file_format=='numpy':
+    elif file_format == "numpy":
         np.save(out_filename, data_label)
     else:
-        print('ERROR!! Unknown file format: %s, please use txt or numpy.' % \
-            (file_format))
+        print(
+            "ERROR!! Unknown file format: %s, please use txt or numpy." % (file_format)
+        )
         exit()
 
-def point_label_to_obj(input_filename, out_filename, label_color=True, easy_view=False, no_wall=False):
-    """ For visualization of a room from data_label file,
-	input_filename: each line is X Y Z R G B L
-	out_filename: OBJ filename,
-            visualize input file by coloring point with label color
-        easy_view: only visualize furnitures and floor
+
+def point_label_to_obj(
+    input_filename, out_filename, label_color=True, easy_view=False, no_wall=False
+):
+    """For visualization of a room from data_label file,
+    input_filename: each line is X Y Z R G B L
+    out_filename: OBJ filename,
+        visualize input file by coloring point with label color
+    easy_view: only visualize furnitures and floor
     """
     data_label = np.loadtxt(input_filename)
     data = data_label[:, 0:6]
     label = data_label[:, -1].astype(int)
-    fout = open(out_filename, 'w')
+    fout = open(out_filename, "w")
     for i in range(data.shape[0]):
         color = g_label2color[label[i]]
         if easy_view and (label[i] not in g_easy_view_labels):
             continue
-        if no_wall and ((label[i] == 2) or (label[i]==0)):
+        if no_wall and ((label[i] == 2) or (label[i] == 0)):
             continue
         if label_color:
-            fout.write('v %f %f %f %d %d %d\n' % \
-                (data[i,0], data[i,1], data[i,2], color[0], color[1], color[2]))
+            fout.write(
+                "v %f %f %f %d %d %d\n"
+                % (data[i, 0], data[i, 1], data[i, 2], color[0], color[1], color[2])
+            )
         else:
-            fout.write('v %f %f %f %d %d %d\n' % \
-                (data[i,0], data[i,1], data[i,2], data[i,3], data[i,4], data[i,5]))
+            fout.write(
+                "v %f %f %f %d %d %d\n"
+                % (
+                    data[i, 0],
+                    data[i, 1],
+                    data[i, 2],
+                    data[i, 3],
+                    data[i, 4],
+                    data[i, 5],
+                )
+            )
     fout.close()
- 
 
 
 # -----------------------------------------------------------------------------
 # PREPARE BLOCK DATA FOR DEEPNETS TRAINING/TESTING
 # -----------------------------------------------------------------------------
 
+
 def sample_data(data, num_sample):
-    """ data is in N x ...
-        we want to keep num_samplexC of them.
-        if N > num_sample, we will randomly keep num_sample of them.
-        if N < num_sample, we will randomly duplicate samples.
+    """data is in N x ...
+    we want to keep num_samplexC of them.
+    if N > num_sample, we will randomly keep num_sample of them.
+    if N < num_sample, we will randomly duplicate samples.
     """
     N = data.shape[0]
-    if (N == num_sample):
+    if N == num_sample:
         return data, range(N)
-    elif (N > num_sample):
+    elif N > num_sample:
         sample = np.random.choice(N, num_sample)
         return data[sample, ...], sample
     else:
-        sample = np.random.choice(N, num_sample-N)
+        sample = np.random.choice(N, num_sample - N)
         dup_data = data[sample, ...]
-        return np.concatenate([data, dup_data], 0), list(range(N))+list(sample)
+        return np.concatenate([data, dup_data], 0), list(range(N)) + list(sample)
+
 
 def sample_data_label(data, label, num_sample):
     new_data, sample_indices = sample_data(data, num_sample)
     new_label = label[sample_indices]
     return new_data, new_label
-    
-def room2blocks(data_label_filename, data, label, num_point, block_size=1.0, stride=1.0,
-                random_sample=False, sample_num=None, sample_aug=1):
-    """ Prepare block training data.
+
+
+def room2blocks(
+    data_label_filename,
+    data,
+    label,
+    num_point,
+    block_size=1.0,
+    stride=1.0,
+    random_sample=False,
+    sample_num=None,
+    sample_aug=1,
+):
+    """Prepare block training data.
     Args:
         data: N x 6 numpy array, 012 are XYZ in meters, 345 are RGB in [0,1]
             assumes the data is shifted (min point is origin) and aligned
             (aligned with XYZ axis)
         label: N size uint8 numpy array from 0-12
@@ -147,136 +185,200 @@
             [default: room area]
         sample_aug: if random sample, how much aug
     Returns:
         block_datas: K x num_point x 6 np array of XYZRGB, RGB is in [0,1]
         block_labels: K x num_point x 1 np array of uint8 labels
-        
+
     TODO: for this version, blocking is in fixed, non-overlapping pattern.
     """
-    assert(stride<=block_size)
+    assert stride <= block_size
 
     limit = np.amax(data, 0)[0:3]
-     
-    # Get the corner location for our sampling blocks    
+
+    # Get the corner location for our sampling blocks
     xbeg_list = []
     ybeg_list = []
     if not random_sample:
         num_block_x = int(np.ceil((limit[0] - block_size) / stride)) + 1
         num_block_y = int(np.ceil((limit[1] - block_size) / stride)) + 1
         for i in range(num_block_x):
             for j in range(num_block_y):
-                xbeg_list.append(i*stride)
-                ybeg_list.append(j*stride)
+                xbeg_list.append(i * stride)
+                ybeg_list.append(j * stride)
     else:
         num_block_x = int(np.ceil(limit[0] / block_size))
         num_block_y = int(np.ceil(limit[1] / block_size))
         if sample_num is None:
             sample_num = num_block_x * num_block_y * sample_aug
         for _ in range(sample_num):
-            xbeg = np.random.uniform(-block_size, limit[0]) 
-            ybeg = np.random.uniform(-block_size, limit[1]) 
+            xbeg = np.random.uniform(-block_size, limit[0])
+            ybeg = np.random.uniform(-block_size, limit[1])
             xbeg_list.append(xbeg)
             ybeg_list.append(ybeg)
-    data_label_filename = data_label_filename[:-4].split('/')
+    data_label_filename = data_label_filename[:-4].split("/")
     data_label_filename = data_label_filename[len(data_label_filename) - 1]
     test_area = data_label_filename[5]
     room_name = data_label_filename[7:]
     if not os.path.exists("data/indoor3d_sem_seg_hdf5_data_test/raw_data3d"):
         os.makedirs("data/indoor3d_sem_seg_hdf5_data_test/raw_data3d")
-    if not os.path.exists("data/indoor3d_sem_seg_hdf5_data_test/raw_data3d/Area_"+str(test_area)):
-        os.makedirs("data/indoor3d_sem_seg_hdf5_data_test/raw_data3d/Area_"+str(test_area))
+    if not os.path.exists(
+        "data/indoor3d_sem_seg_hdf5_data_test/raw_data3d/Area_" + str(test_area)
+    ):
+        os.makedirs(
+            "data/indoor3d_sem_seg_hdf5_data_test/raw_data3d/Area_" + str(test_area)
+        )
     # Collect blocks
     block_data_list = []
     block_label_list = []
     global raw_data_index
-    for idx in range(len(xbeg_list)): 
-       xbeg = xbeg_list[idx]
-       ybeg = ybeg_list[idx]
-       xcond = (data[:,0]<=xbeg+block_size) & (data[:,0]>=xbeg)
-       ycond = (data[:,1]<=ybeg+block_size) & (data[:,1]>=ybeg)
-       cond = xcond & ycond
-       if np.sum(cond) < 100: # discard block if there are less than 100 pts.
-           continue
-       
-       block_data = data[cond, :]
-       block_label = label[cond]
-       
-       # randomly subsample data
-       block_data_sampled, block_label_sampled = \
-           sample_data_label(block_data, block_label, num_point)
-       block_data_list.append(np.expand_dims(block_data_sampled, 0))
-       block_label_list.append(np.expand_dims(block_label_sampled, 0))   
-       f = open('data/indoor3d_sem_seg_hdf5_data_test/raw_data3d/Area_'+str(test_area)+'/'+str(room_name)+'('+str(raw_data_index)+').txt', "a")
-       np.savetxt(f, block_data_sampled[:,0:3], fmt='%s', delimiter=' ')     
-       raw_data_index = raw_data_index + 1
-    return np.concatenate(block_data_list, 0), \
-           np.concatenate(block_label_list, 0)
-
-
-def room2blocks_plus(data_label, num_point, block_size, stride,
-                     random_sample, sample_num, sample_aug):
-    """ room2block with input filename and RGB preprocessing.
-    """
-    data = data_label[:,0:6]
-    data[:,3:6] /= 255.0
-    label = data_label[:,-1].astype(np.uint8)
-    
-    return room2blocks(data, label, num_point, block_size, stride,
-                       random_sample, sample_num, sample_aug)
-   
-def room2blocks_wrapper(data_label_filename, num_point, block_size=1.0, stride=1.0,
-                        random_sample=False, sample_num=None, sample_aug=1):
-    if data_label_filename[-3:] == 'txt':
+    for idx in range(len(xbeg_list)):
+        xbeg = xbeg_list[idx]
+        ybeg = ybeg_list[idx]
+        xcond = (data[:, 0] <= xbeg + block_size) & (data[:, 0] >= xbeg)
+        ycond = (data[:, 1] <= ybeg + block_size) & (data[:, 1] >= ybeg)
+        cond = xcond & ycond
+        if np.sum(cond) < 100:  # discard block if there are less than 100 pts.
+            continue
+
+        block_data = data[cond, :]
+        block_label = label[cond]
+
+        # randomly subsample data
+        block_data_sampled, block_label_sampled = sample_data_label(
+            block_data, block_label, num_point
+        )
+        block_data_list.append(np.expand_dims(block_data_sampled, 0))
+        block_label_list.append(np.expand_dims(block_label_sampled, 0))
+        f = open(
+            "data/indoor3d_sem_seg_hdf5_data_test/raw_data3d/Area_"
+            + str(test_area)
+            + "/"
+            + str(room_name)
+            + "("
+            + str(raw_data_index)
+            + ").txt",
+            "a",
+        )
+        np.savetxt(f, block_data_sampled[:, 0:3], fmt="%s", delimiter=" ")
+        raw_data_index = raw_data_index + 1
+    return np.concatenate(block_data_list, 0), np.concatenate(block_label_list, 0)
+
+
+def room2blocks_plus(
+    data_label, num_point, block_size, stride, random_sample, sample_num, sample_aug
+):
+    """room2block with input filename and RGB preprocessing."""
+    data = data_label[:, 0:6]
+    data[:, 3:6] /= 255.0
+    label = data_label[:, -1].astype(np.uint8)
+
+    return room2blocks(
+        data,
+        label,
+        num_point,
+        block_size,
+        stride,
+        random_sample,
+        sample_num,
+        sample_aug,
+    )
+
+
+def room2blocks_wrapper(
+    data_label_filename,
+    num_point,
+    block_size=1.0,
+    stride=1.0,
+    random_sample=False,
+    sample_num=None,
+    sample_aug=1,
+):
+    if data_label_filename[-3:] == "txt":
         data_label = np.loadtxt(data_label_filename)
-    elif data_label_filename[-3:] == 'npy':
+    elif data_label_filename[-3:] == "npy":
         data_label = np.load(data_label_filename)
     else:
-        print('Unknown file type! exiting.')
+        print("Unknown file type! exiting.")
         exit()
-    return room2blocks_plus(data_label, num_point, block_size, stride,
-                            random_sample, sample_num, sample_aug)
-
-def room2blocks_plus_normalized(data_label_filename, data_label, num_point, block_size, stride,
-                                random_sample, sample_num, sample_aug):
-    """ room2block, with input filename and RGB preprocessing.
-        for each block centralize XYZ, add normalized XYZ as 678 channels
-    """
-    data = data_label[:,0:6]
-    data[:,3:6] /= 255.0
-    label = data_label[:,-1].astype(np.uint8)
-    max_room_x = max(data[:,0])
-    max_room_y = max(data[:,1])
-    max_room_z = max(data[:,2])
-    data_batch, label_batch = room2blocks(data_label_filename, data, label, num_point, block_size, stride,
-                                          random_sample, sample_num, sample_aug)
+    return room2blocks_plus(
+        data_label, num_point, block_size, stride, random_sample, sample_num, sample_aug
+    )
+
+
+def room2blocks_plus_normalized(
+    data_label_filename,
+    data_label,
+    num_point,
+    block_size,
+    stride,
+    random_sample,
+    sample_num,
+    sample_aug,
+):
+    """room2block, with input filename and RGB preprocessing.
+    for each block centralize XYZ, add normalized XYZ as 678 channels
+    """
+    data = data_label[:, 0:6]
+    data[:, 3:6] /= 255.0
+    label = data_label[:, -1].astype(np.uint8)
+    max_room_x = max(data[:, 0])
+    max_room_y = max(data[:, 1])
+    max_room_z = max(data[:, 2])
+    data_batch, label_batch = room2blocks(
+        data_label_filename,
+        data,
+        label,
+        num_point,
+        block_size,
+        stride,
+        random_sample,
+        sample_num,
+        sample_aug,
+    )
     new_data_batch = np.zeros((data_batch.shape[0], num_point, 9))
     for b in range(data_batch.shape[0]):
-        new_data_batch[b, :, 6] = data_batch[b, :, 0]/max_room_x
-        new_data_batch[b, :, 7] = data_batch[b, :, 1]/max_room_y
-        new_data_batch[b, :, 8] = data_batch[b, :, 2]/max_room_z
+        new_data_batch[b, :, 6] = data_batch[b, :, 0] / max_room_x
+        new_data_batch[b, :, 7] = data_batch[b, :, 1] / max_room_y
+        new_data_batch[b, :, 8] = data_batch[b, :, 2] / max_room_z
         minx = min(data_batch[b, :, 0])
         miny = min(data_batch[b, :, 1])
-        data_batch[b, :, 0] -= (minx+block_size/2)
-        data_batch[b, :, 1] -= (miny+block_size/2)
+        data_batch[b, :, 0] -= minx + block_size / 2
+        data_batch[b, :, 1] -= miny + block_size / 2
     new_data_batch[:, :, 0:6] = data_batch
     return new_data_batch, label_batch
 
 
-def room2blocks_wrapper_normalized(data_label_filename, num_point, block_size=1.0, stride=1.0,
-                                   random_sample=False, sample_num=None, sample_aug=1):
-    if data_label_filename[-3:] == 'txt':
+def room2blocks_wrapper_normalized(
+    data_label_filename,
+    num_point,
+    block_size=1.0,
+    stride=1.0,
+    random_sample=False,
+    sample_num=None,
+    sample_aug=1,
+):
+    if data_label_filename[-3:] == "txt":
         data_label = np.loadtxt(data_label_filename)
-    elif data_label_filename[-3:] == 'npy':
+    elif data_label_filename[-3:] == "npy":
         data_label = np.load(data_label_filename)
     else:
-        print('Unknown file type! exiting.')
+        print("Unknown file type! exiting.")
         exit()
-    return room2blocks_plus_normalized(data_label_filename, data_label, num_point, block_size, stride,
-                                       random_sample, sample_num, sample_aug)
+    return room2blocks_plus_normalized(
+        data_label_filename,
+        data_label,
+        num_point,
+        block_size,
+        stride,
+        random_sample,
+        sample_num,
+        sample_aug,
+    )
+
 
 def room2samples(data, label, sample_num_point):
-    """ Prepare whole room samples.
+    """Prepare whole room samples.
 
     Args:
         data: N x 6 numpy array, 012 are XYZ in meters, 345 are RGB in [0,1]
             assumes the data is shifted (min point is origin) and
             aligned (aligned with XYZ axis)
@@ -287,75 +389,77 @@
                      numpy array of XYZRGBX'Y'Z', RGB is in [0,1]
         sample_labels: K x sample_num_point x 1 np array of uint8 labels
     """
     N = data.shape[0]
     order = np.arange(N)
-    np.random.shuffle(order) 
+    np.random.shuffle(order)
     data = data[order, :]
     label = label[order]
 
     batch_num = int(np.ceil(N / float(sample_num_point)))
     sample_datas = np.zeros((batch_num, sample_num_point, 6))
     sample_labels = np.zeros((batch_num, sample_num_point, 1))
 
     for i in range(batch_num):
-        beg_idx = i*sample_num_point
-        end_idx = min((i+1)*sample_num_point, N)
+        beg_idx = i * sample_num_point
+        end_idx = min((i + 1) * sample_num_point, N)
         num = end_idx - beg_idx
-        sample_datas[i,0:num,:] = data[beg_idx:end_idx, :]
-        sample_labels[i,0:num,0] = label[beg_idx:end_idx]
+        sample_datas[i, 0:num, :] = data[beg_idx:end_idx, :]
+        sample_labels[i, 0:num, 0] = label[beg_idx:end_idx]
         if num < sample_num_point:
             makeup_indices = np.random.choice(N, sample_num_point - num)
-            sample_datas[i,num:,:] = data[makeup_indices, :]
-            sample_labels[i,num:,0] = label[makeup_indices]
+            sample_datas[i, num:, :] = data[makeup_indices, :]
+            sample_labels[i, num:, 0] = label[makeup_indices]
     return sample_datas, sample_labels
 
+
 def room2samples_plus_normalized(data_label, num_point):
-    """ room2sample, with input filename and RGB preprocessing.
-        for each block centralize XYZ, add normalized XYZ as 678 channels
-    """
-    data = data_label[:,0:6]
-    data[:,3:6] /= 255.0
-    label = data_label[:,-1].astype(np.uint8)
-    max_room_x = max(data[:,0])
-    max_room_y = max(data[:,1])
-    max_room_z = max(data[:,2])
-    #print(max_room_x, max_room_y, max_room_z)
-    
+    """room2sample, with input filename and RGB preprocessing.
+    for each block centralize XYZ, add normalized XYZ as 678 channels
+    """
+    data = data_label[:, 0:6]
+    data[:, 3:6] /= 255.0
+    label = data_label[:, -1].astype(np.uint8)
+    max_room_x = max(data[:, 0])
+    max_room_y = max(data[:, 1])
+    max_room_z = max(data[:, 2])
+    # print(max_room_x, max_room_y, max_room_z)
+
     data_batch, label_batch = room2samples(data, label, num_point)
     new_data_batch = np.zeros((data_batch.shape[0], num_point, 9))
     for b in range(data_batch.shape[0]):
-        new_data_batch[b, :, 6] = data_batch[b, :, 0]/max_room_x
-        new_data_batch[b, :, 7] = data_batch[b, :, 1]/max_room_y
-        new_data_batch[b, :, 8] = data_batch[b, :, 2]/max_room_z
-        #minx = min(data_batch[b, :, 0])
-        #miny = min(data_batch[b, :, 1])
-        #data_batch[b, :, 0] -= (minx+block_size/2)
-        #data_batch[b, :, 1] -= (miny+block_size/2)
+        new_data_batch[b, :, 6] = data_batch[b, :, 0] / max_room_x
+        new_data_batch[b, :, 7] = data_batch[b, :, 1] / max_room_y
+        new_data_batch[b, :, 8] = data_batch[b, :, 2] / max_room_z
+        # minx = min(data_batch[b, :, 0])
+        # miny = min(data_batch[b, :, 1])
+        # data_batch[b, :, 0] -= (minx+block_size/2)
+        # data_batch[b, :, 1] -= (miny+block_size/2)
     new_data_batch[:, :, 0:6] = data_batch
     return new_data_batch, label_batch
 
 
 def room2samples_wrapper_normalized(data_label_filename, num_point):
-    if data_label_filename[-3:] == 'txt':
+    if data_label_filename[-3:] == "txt":
         data_label = np.loadtxt(data_label_filename)
-    elif data_label_filename[-3:] == 'npy':
+    elif data_label_filename[-3:] == "npy":
         data_label = np.load(data_label_filename)
     else:
-        print('Unknown file type! exiting.')
+        print("Unknown file type! exiting.")
         exit()
     return room2samples_plus_normalized(data_label, num_point)
 
 
 # -----------------------------------------------------------------------------
 # EXTRACT INSTANCE BBOX FROM ORIGINAL DATA (for detection evaluation)
 # -----------------------------------------------------------------------------
 
+
 def collect_bounding_box(anno_path, out_filename):
-    """ Compute bounding boxes from each instance in original dataset files on
+    """Compute bounding boxes from each instance in original dataset files on
         one room. **We assume the bbox is aligned with XYZ coordinate.**
-    
+
     Args:
         anno_path: path to annotations. e.g. Area_1/office_2/Annotations/
         out_filename: path to save instance bounding boxes for that room.
             each line is x1 y1 z1 x2 y2 z2 label,
             where (x1,y1,z1) is the point on the diagonal closer to origin
@@ -364,39 +468,49 @@
     Note:
         room points are shifted, the most negative point is now at origin.
     """
     bbox_label_list = []
 
-    for f in glob.glob(os.path.join(anno_path, '*.txt')):
-        cls = os.path.basename(f).split('_')[0]
-        if cls not in g_classes: # note: in some room there is 'staris' class..
-            cls = 'clutter'
+    for f in glob.glob(os.path.join(anno_path, "*.txt")):
+        cls = os.path.basename(f).split("_")[0]
+        if cls not in g_classes:  # note: in some room there is 'staris' class..
+            cls = "clutter"
         points = np.loadtxt(f)
         label = g_class2label[cls]
         # Compute tightest axis aligned bounding box
         xyz_min = np.amin(points[:, 0:3], axis=0)
         xyz_max = np.amax(points[:, 0:3], axis=0)
         ins_bbox_label = np.expand_dims(
-            np.concatenate([xyz_min, xyz_max, np.array([label])], 0), 0)
+            np.concatenate([xyz_min, xyz_max, np.array([label])], 0), 0
+        )
         bbox_label_list.append(ins_bbox_label)
 
     bbox_label = np.concatenate(bbox_label_list, 0)
     room_xyz_min = np.amin(bbox_label[:, 0:3], axis=0)
-    bbox_label[:, 0:3] -= room_xyz_min 
-    bbox_label[:, 3:6] -= room_xyz_min 
-
-    fout = open(out_filename, 'w')
+    bbox_label[:, 0:3] -= room_xyz_min
+    bbox_label[:, 3:6] -= room_xyz_min
+
+    fout = open(out_filename, "w")
     for i in range(bbox_label.shape[0]):
-        fout.write('%f %f %f %f %f %f %d\n' % \
-                      (bbox_label[i,0], bbox_label[i,1], bbox_label[i,2],
-                       bbox_label[i,3], bbox_label[i,4], bbox_label[i,5],
-                       bbox_label[i,6]))
+        fout.write(
+            "%f %f %f %f %f %f %d\n"
+            % (
+                bbox_label[i, 0],
+                bbox_label[i, 1],
+                bbox_label[i, 2],
+                bbox_label[i, 3],
+                bbox_label[i, 4],
+                bbox_label[i, 5],
+                bbox_label[i, 6],
+            )
+        )
     fout.close()
 
+
 def bbox_label_to_obj(input_filename, out_filename_prefix, easy_view=False):
-    """ Visualization of bounding boxes.
-    
+    """Visualization of bounding boxes.
+
     Args:
         input_filename: each line is x1 y1 z1 x2 y2 z2 label
         out_filename_prefix: OBJ filename prefix,
             visualize object by g_label2color
         easy_view: if True, only visualize furniture and floor
@@ -404,62 +518,84 @@
         output a list of OBJ file and MTL files with the same prefix
     """
     bbox_label = np.loadtxt(input_filename)
     bbox = bbox_label[:, 0:6]
     label = bbox_label[:, -1].astype(int)
-    v_cnt = 0 # count vertex
-    ins_cnt = 0 # count instance
+    v_cnt = 0  # count vertex
+    ins_cnt = 0  # count instance
     for i in range(bbox.shape[0]):
         if easy_view and (label[i] not in g_easy_view_labels):
             continue
-        obj_filename = out_filename_prefix+'_'+g_classes[label[i]]+'_'+str(ins_cnt)+'.obj'
-        mtl_filename = out_filename_prefix+'_'+g_classes[label[i]]+'_'+str(ins_cnt)+'.mtl'
-        fout_obj = open(obj_filename, 'w')
-        fout_mtl = open(mtl_filename, 'w')
-        fout_obj.write('mtllib %s\n' % (os.path.basename(mtl_filename)))
+        obj_filename = (
+            out_filename_prefix
+            + "_"
+            + g_classes[label[i]]
+            + "_"
+            + str(ins_cnt)
+            + ".obj"
+        )
+        mtl_filename = (
+            out_filename_prefix
+            + "_"
+            + g_classes[label[i]]
+            + "_"
+            + str(ins_cnt)
+            + ".mtl"
+        )
+        fout_obj = open(obj_filename, "w")
+        fout_mtl = open(mtl_filename, "w")
+        fout_obj.write("mtllib %s\n" % (os.path.basename(mtl_filename)))
 
         length = bbox[i, 3:6] - bbox[i, 0:3]
         a = length[0]
         b = length[1]
         c = length[2]
         x = bbox[i, 0]
         y = bbox[i, 1]
         z = bbox[i, 2]
         color = np.array(g_label2color[label[i]], dtype=float) / 255.0
 
-        material = 'material%d' % (ins_cnt)
-        fout_obj.write('usemtl %s\n' % (material))
-        fout_obj.write('v %f %f %f\n' % (x,y,z+c))
-        fout_obj.write('v %f %f %f\n' % (x,y+b,z+c))
-        fout_obj.write('v %f %f %f\n' % (x+a,y+b,z+c))
-        fout_obj.write('v %f %f %f\n' % (x+a,y,z+c))
-        fout_obj.write('v %f %f %f\n' % (x,y,z))
-        fout_obj.write('v %f %f %f\n' % (x,y+b,z))
-        fout_obj.write('v %f %f %f\n' % (x+a,y+b,z))
-        fout_obj.write('v %f %f %f\n' % (x+a,y,z))
-        fout_obj.write('g default\n')
-        v_cnt = 0 # for individual box
-        fout_obj.write('f %d %d %d %d\n' % (4+v_cnt, 3+v_cnt, 2+v_cnt, 1+v_cnt))
-        fout_obj.write('f %d %d %d %d\n' % (1+v_cnt, 2+v_cnt, 6+v_cnt, 5+v_cnt))
-        fout_obj.write('f %d %d %d %d\n' % (7+v_cnt, 6+v_cnt, 2+v_cnt, 3+v_cnt))
-        fout_obj.write('f %d %d %d %d\n' % (4+v_cnt, 8+v_cnt, 7+v_cnt, 3+v_cnt))
-        fout_obj.write('f %d %d %d %d\n' % (5+v_cnt, 8+v_cnt, 4+v_cnt, 1+v_cnt))
-        fout_obj.write('f %d %d %d %d\n' % (5+v_cnt, 6+v_cnt, 7+v_cnt, 8+v_cnt))
-        fout_obj.write('\n')
-
-        fout_mtl.write('newmtl %s\n' % (material))
-        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
-        fout_mtl.write('\n')
+        material = "material%d" % (ins_cnt)
+        fout_obj.write("usemtl %s\n" % (material))
+        fout_obj.write("v %f %f %f\n" % (x, y, z + c))
+        fout_obj.write("v %f %f %f\n" % (x, y + b, z + c))
+        fout_obj.write("v %f %f %f\n" % (x + a, y + b, z + c))
+        fout_obj.write("v %f %f %f\n" % (x + a, y, z + c))
+        fout_obj.write("v %f %f %f\n" % (x, y, z))
+        fout_obj.write("v %f %f %f\n" % (x, y + b, z))
+        fout_obj.write("v %f %f %f\n" % (x + a, y + b, z))
+        fout_obj.write("v %f %f %f\n" % (x + a, y, z))
+        fout_obj.write("g default\n")
+        v_cnt = 0  # for individual box
+        fout_obj.write("f %d %d %d %d\n" % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
+        fout_obj.write("f %d %d %d %d\n" % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
+        fout_obj.write("f %d %d %d %d\n" % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
+        fout_obj.write("f %d %d %d %d\n" % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
+        fout_obj.write("f %d %d %d %d\n" % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
+        fout_obj.write("f %d %d %d %d\n" % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
+        fout_obj.write("\n")
+
+        fout_mtl.write("newmtl %s\n" % (material))
+        fout_mtl.write("Kd %f %f %f\n" % (color[0], color[1], color[2]))
+        fout_mtl.write("\n")
         fout_obj.close()
-        fout_mtl.close() 
+        fout_mtl.close()
 
         v_cnt += 8
         ins_cnt += 1
 
-def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
-    """ Visualization of bounding boxes.
-    
+
+def bbox_label_to_obj_room(
+    input_filename,
+    out_filename_prefix,
+    easy_view=False,
+    permute=None,
+    center=False,
+    exclude_table=False,
+):
+    """Visualization of bounding boxes.
+
     Args:
         input_filename: each line is x1 y1 z1 x2 y2 z2 label
         out_filename_prefix: OBJ filename prefix,
             visualize object by g_label2color
         easy_view: if True, only visualize furniture and floor
@@ -469,32 +605,32 @@
         output a list of OBJ file and MTL files with the same prefix
     """
     bbox_label = np.loadtxt(input_filename)
     bbox = bbox_label[:, 0:6]
     if permute is not None:
-        assert(len(permute)==3)
+        assert len(permute) == 3
         permute = np.array(permute)
-        bbox[:,0:3] = bbox[:,permute]
-        bbox[:,3:6] = bbox[:,permute+3]
+        bbox[:, 0:3] = bbox[:, permute]
+        bbox[:, 3:6] = bbox[:, permute + 3]
     if center:
-        xyz_max = np.amax(bbox[:,3:6], 0)
-        bbox[:,0:3] -= (xyz_max/2.0)
-        bbox[:,3:6] -= (xyz_max/2.0)
-        bbox /= np.max(xyz_max/2.0)
+        xyz_max = np.amax(bbox[:, 3:6], 0)
+        bbox[:, 0:3] -= xyz_max / 2.0
+        bbox[:, 3:6] -= xyz_max / 2.0
+        bbox /= np.max(xyz_max / 2.0)
     label = bbox_label[:, -1].astype(int)
-    obj_filename = out_filename_prefix+'.obj' 
-    mtl_filename = out_filename_prefix+'.mtl'
-
-    fout_obj = open(obj_filename, 'w')
-    fout_mtl = open(mtl_filename, 'w')
-    fout_obj.write('mtllib %s\n' % (os.path.basename(mtl_filename)))
-    v_cnt = 0 # count vertex
-    ins_cnt = 0 # count instance
+    obj_filename = out_filename_prefix + ".obj"
+    mtl_filename = out_filename_prefix + ".mtl"
+
+    fout_obj = open(obj_filename, "w")
+    fout_mtl = open(mtl_filename, "w")
+    fout_obj.write("mtllib %s\n" % (os.path.basename(mtl_filename)))
+    v_cnt = 0  # count vertex
+    ins_cnt = 0  # count instance
     for i in range(bbox.shape[0]):
         if easy_view and (label[i] not in g_easy_view_labels):
             continue
-        if exclude_table and label[i] == g_classes.index('table'):
+        if exclude_table and label[i] == g_classes.index("table"):
             continue
 
         length = bbox[i, 3:6] - bbox[i, 0:3]
         a = length[0]
         b = length[1]
@@ -502,46 +638,46 @@
         x = bbox[i, 0]
         y = bbox[i, 1]
         z = bbox[i, 2]
         color = np.array(g_label2color[label[i]], dtype=float) / 255.0
 
-        material = 'material%d' % (ins_cnt)
-        fout_obj.write('usemtl %s\n' % (material))
-        fout_obj.write('v %f %f %f\n' % (x,y,z+c))
-        fout_obj.write('v %f %f %f\n' % (x,y+b,z+c))
-        fout_obj.write('v %f %f %f\n' % (x+a,y+b,z+c))
-        fout_obj.write('v %f %f %f\n' % (x+a,y,z+c))
-        fout_obj.write('v %f %f %f\n' % (x,y,z))
-        fout_obj.write('v %f %f %f\n' % (x,y+b,z))
-        fout_obj.write('v %f %f %f\n' % (x+a,y+b,z))
-        fout_obj.write('v %f %f %f\n' % (x+a,y,z))
-        fout_obj.write('g default\n')
-        fout_obj.write('f %d %d %d %d\n' % (4+v_cnt, 3+v_cnt, 2+v_cnt, 1+v_cnt))
-        fout_obj.write('f %d %d %d %d\n' % (1+v_cnt, 2+v_cnt, 6+v_cnt, 5+v_cnt))
-        fout_obj.write('f %d %d %d %d\n' % (7+v_cnt, 6+v_cnt, 2+v_cnt, 3+v_cnt))
-        fout_obj.write('f %d %d %d %d\n' % (4+v_cnt, 8+v_cnt, 7+v_cnt, 3+v_cnt))
-        fout_obj.write('f %d %d %d %d\n' % (5+v_cnt, 8+v_cnt, 4+v_cnt, 1+v_cnt))
-        fout_obj.write('f %d %d %d %d\n' % (5+v_cnt, 6+v_cnt, 7+v_cnt, 8+v_cnt))
-        fout_obj.write('\n')
-
-        fout_mtl.write('newmtl %s\n' % (material))
-        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
-        fout_mtl.write('\n')
+        material = "material%d" % (ins_cnt)
+        fout_obj.write("usemtl %s\n" % (material))
+        fout_obj.write("v %f %f %f\n" % (x, y, z + c))
+        fout_obj.write("v %f %f %f\n" % (x, y + b, z + c))
+        fout_obj.write("v %f %f %f\n" % (x + a, y + b, z + c))
+        fout_obj.write("v %f %f %f\n" % (x + a, y, z + c))
+        fout_obj.write("v %f %f %f\n" % (x, y, z))
+        fout_obj.write("v %f %f %f\n" % (x, y + b, z))
+        fout_obj.write("v %f %f %f\n" % (x + a, y + b, z))
+        fout_obj.write("v %f %f %f\n" % (x + a, y, z))
+        fout_obj.write("g default\n")
+        fout_obj.write("f %d %d %d %d\n" % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
+        fout_obj.write("f %d %d %d %d\n" % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
+        fout_obj.write("f %d %d %d %d\n" % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
+        fout_obj.write("f %d %d %d %d\n" % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
+        fout_obj.write("f %d %d %d %d\n" % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
+        fout_obj.write("f %d %d %d %d\n" % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
+        fout_obj.write("\n")
+
+        fout_mtl.write("newmtl %s\n" % (material))
+        fout_mtl.write("Kd %f %f %f\n" % (color[0], color[1], color[2]))
+        fout_mtl.write("\n")
 
         v_cnt += 8
         ins_cnt += 1
 
     fout_obj.close()
-    fout_mtl.close() 
+    fout_mtl.close()
 
 
 def collect_point_bounding_box(anno_path, out_filename, file_format):
-    """ Compute bounding boxes from each instance in original dataset files on
+    """Compute bounding boxes from each instance in original dataset files on
         one room. **We assume the bbox is aligned with XYZ coordinate.**
         Save both the point XYZRGB and the bounding box for the point's
         parent element.
- 
+
     Args:
         anno_path: path to annotations. e.g. Area_1/office_2/Annotations/
         out_filename: path to save instance bounding boxes for each point,
             plus the point's XYZRGBL
             each line is XYZRGBL offsetX offsetY offsetZ a b c,
@@ -555,46 +691,58 @@
     Note:
         room points are shifted, the most negative point is now at origin.
     """
     point_bbox_list = []
 
-    for f in glob.glob(os.path.join(anno_path, '*.txt')):
-        cls = os.path.basename(f).split('_')[0]
-        if cls not in g_classes: # note: in some room there is 'staris' class..
-            cls = 'clutter'
-        points = np.loadtxt(f) # Nx6
-        label = g_class2label[cls] # N,
+    for f in glob.glob(os.path.join(anno_path, "*.txt")):
+        cls = os.path.basename(f).split("_")[0]
+        if cls not in g_classes:  # note: in some room there is 'staris' class..
+            cls = "clutter"
+        points = np.loadtxt(f)  # Nx6
+        label = g_class2label[cls]  # N,
         # Compute tightest axis aligned bounding box
-        xyz_min = np.amin(points[:, 0:3], axis=0) # 3,
-        xyz_max = np.amax(points[:, 0:3], axis=0) # 3,
+        xyz_min = np.amin(points[:, 0:3], axis=0)  # 3,
+        xyz_max = np.amax(points[:, 0:3], axis=0)  # 3,
         xyz_center = (xyz_min + xyz_max) / 2
         dimension = (xyz_max - xyz_min) / 2
 
-        xyz_offsets = xyz_center - points[:,0:3] # Nx3
-        dimensions = np.ones((points.shape[0],3)) * dimension # Nx3
-        labels = np.ones((points.shape[0],1)) * label # N
-        point_bbox_list.append(np.concatenate([points, labels,
-                                           xyz_offsets, dimensions], 1)) # Nx13
-
-    point_bbox = np.concatenate(point_bbox_list, 0) # KxNx13
+        xyz_offsets = xyz_center - points[:, 0:3]  # Nx3
+        dimensions = np.ones((points.shape[0], 3)) * dimension  # Nx3
+        labels = np.ones((points.shape[0], 1)) * label  # N
+        point_bbox_list.append(
+            np.concatenate([points, labels, xyz_offsets, dimensions], 1)
+        )  # Nx13
+
+    point_bbox = np.concatenate(point_bbox_list, 0)  # KxNx13
     room_xyz_min = np.amin(point_bbox[:, 0:3], axis=0)
-    point_bbox[:, 0:3] -= room_xyz_min 
-
-    if file_format == 'txt':
-        fout = open(out_filename, 'w')
+    point_bbox[:, 0:3] -= room_xyz_min
+
+    if file_format == "txt":
+        fout = open(out_filename, "w")
         for i in range(point_bbox.shape[0]):
-            fout.write('%f %f %f %d %d %d %d %f %f %f %f %f %f\n' % \
-                          (point_bbox[i,0], point_bbox[i,1], point_bbox[i,2],
-                           point_bbox[i,3], point_bbox[i,4], point_bbox[i,5],
-                           point_bbox[i,6],
-                           point_bbox[i,7], point_bbox[i,8], point_bbox[i,9],
-                           point_bbox[i,10], point_bbox[i,11], point_bbox[i,12]))
-        
+            fout.write(
+                "%f %f %f %d %d %d %d %f %f %f %f %f %f\n"
+                % (
+                    point_bbox[i, 0],
+                    point_bbox[i, 1],
+                    point_bbox[i, 2],
+                    point_bbox[i, 3],
+                    point_bbox[i, 4],
+                    point_bbox[i, 5],
+                    point_bbox[i, 6],
+                    point_bbox[i, 7],
+                    point_bbox[i, 8],
+                    point_bbox[i, 9],
+                    point_bbox[i, 10],
+                    point_bbox[i, 11],
+                    point_bbox[i, 12],
+                )
+            )
+
         fout.close()
-    elif file_format == 'numpy':
+    elif file_format == "numpy":
         np.save(out_filename, point_bbox)
     else:
-        print('ERROR!! Unknown file format: %s, please use txt or numpy.' % \
-            (file_format))
+        print(
+            "ERROR!! Unknown file format: %s, please use txt or numpy." % (file_format)
+        )
         exit()
-
-
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/data_prepare_gender.py	2024-06-30 22:34:20.930953+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/data_prepare_gender.py	2024-07-08 11:53:41.994903+00:00
@@ -7,70 +7,74 @@
 ROOT_DIR = dirname(BASE_DIR)
 sys.path.append(BASE_DIR)
 sys.path.append(ROOT_DIR)
 from helper_tool import DataProcessing as DP
 
-data_config = os.path.join(BASE_DIR, 'gender.yaml')
-DATA = yaml.safe_load(open(data_config, 'r'))
+data_config = os.path.join(BASE_DIR, "gender.yaml")
+DATA = yaml.safe_load(open(data_config, "r"))
 remap_dict = DATA["learning_map"]
 max_key = max(remap_dict.keys())
 remap_lut = np.zeros((max_key + 100), dtype=np.int32)
 remap_lut[list(remap_dict.keys())] = list(remap_dict.values())
 
 
 grid_size = 0.06
-dataset_path = '/DATA1/Scene_scans/sequences'
-output_path = '/DATA1/Scene_scans/sequences' + '_' + str(grid_size)
+dataset_path = "/DATA1/Scene_scans/sequences"
+output_path = "/DATA1/Scene_scans/sequences" + "_" + str(grid_size)
 seq_list = np.sort(os.listdir(dataset_path))
 for seq_id in seq_list:
-    print('sequence' + seq_id + ' start')
+    print("sequence" + seq_id + " start")
     seq_path = join(dataset_path, seq_id)
     seq_path_out = join(output_path, seq_id)
-    pc_path = join(seq_path, 'velodyne')
-    pc_path_out = join(seq_path_out, 'velodyne')
-    KDTree_path_out = join(seq_path_out, 'KDTree')
+    pc_path = join(seq_path, "velodyne")
+    pc_path_out = join(seq_path_out, "velodyne")
+    KDTree_path_out = join(seq_path_out, "KDTree")
     os.makedirs(seq_path_out) if not exists(seq_path_out) else None
     os.makedirs(pc_path_out) if not exists(pc_path_out) else None
     os.makedirs(KDTree_path_out) if not exists(KDTree_path_out) else None
 
     if int(seq_id) < 11:
-        label_path = join(seq_path, 'labels')
-        label_path_out = join(seq_path_out, 'labels')
+        label_path = join(seq_path, "labels")
+        label_path_out = join(seq_path_out, "labels")
         os.makedirs(label_path_out) if not exists(label_path_out) else None
         scan_list = np.sort(os.listdir(pc_path))
         for scan_id in scan_list:
             print(scan_id)
             points = DP.load_pc_gender(join(pc_path, scan_id))
-            labels = DP.load_label_gender(join(label_path, str(scan_id[:-4]) + '.label'), remap_lut)
-            sub_points, sub_labels = DP.grid_sub_sampling(points, labels=labels, grid_size=grid_size)
+            labels = DP.load_label_gender(
+                join(label_path, str(scan_id[:-4]) + ".label"), remap_lut
+            )
+            sub_points, sub_labels = DP.grid_sub_sampling(
+                points, labels=labels, grid_size=grid_size
+            )
             search_tree = KDTree(sub_points)
-            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + '.pkl')
+            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + ".pkl")
             np.save(join(pc_path_out, scan_id)[:-4], sub_points)
             np.save(join(label_path_out, scan_id)[:-4], sub_labels)
-            with open(KDTree_save, 'wb') as f:
+            with open(KDTree_save, "wb") as f:
                 pickle.dump(search_tree, f)
-            if seq_id == '10':
-                proj_path = join(seq_path_out, 'proj')
+            if seq_id == "10":
+                proj_path = join(seq_path_out, "proj")
                 os.makedirs(proj_path) if not exists(proj_path) else None
                 proj_inds = np.squeeze(search_tree.query(points, return_distance=False))
                 proj_inds = proj_inds.astype(np.int32)
-                proj_save = join(proj_path, str(scan_id[:-4]) + '_proj.pkl')
-                with open(proj_save, 'wb') as f:
+                proj_save = join(proj_path, str(scan_id[:-4]) + "_proj.pkl")
+                with open(proj_save, "wb") as f:
                     pickle.dump([proj_inds], f)
     else:
-        proj_path = join(seq_path_out, 'proj')
+        proj_path = join(seq_path_out, "proj")
         os.makedirs(proj_path) if not exists(proj_path) else None
         scan_list = np.sort(os.listdir(pc_path))
         for scan_id in scan_list:
             print(scan_id)
             points = DP.load_pc_gender(join(pc_path, scan_id))
             sub_points = DP.grid_sub_sampling(points, grid_size=0.06)
             search_tree = KDTree(sub_points)
             proj_inds = np.squeeze(search_tree.query(points, return_distance=False))
             proj_inds = proj_inds.astype(np.int32)
-            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + '.pkl')
-            proj_save = join(proj_path, str(scan_id[:-4]) + '_proj.pkl')
+            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + ".pkl")
+            proj_save = join(proj_path, str(scan_id[:-4]) + "_proj.pkl")
             np.save(join(pc_path_out, scan_id)[:-4], sub_points)
-            with open(KDTree_save, 'wb') as f:
+            with open(KDTree_save, "wb") as f:
                 pickle.dump(search_tree, f)
-            with open(proj_save, 'wb') as f:
+            with open(proj_save, "wb") as f:
                 pickle.dump([proj_inds], f)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/data_prepare_semantic3d.py	2024-06-30 22:34:20.946582+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/data_prepare_semantic3d.py	2024-07-08 11:53:42.005820+00:00
@@ -10,74 +10,95 @@
 sys.path.append(ROOT_DIR)
 from helper_ply import write_ply
 from helper_tool import DataProcessing as DP
 
 grid_size = 0.06
-dataset_path = '/data/semantic3d/original_data'
-original_pc_folder = join(dirname(dataset_path), 'original_ply')
-sub_pc_folder = join(dirname(dataset_path), 'input_{:.3f}'.format(grid_size))
+dataset_path = "/data/semantic3d/original_data"
+original_pc_folder = join(dirname(dataset_path), "original_ply")
+sub_pc_folder = join(dirname(dataset_path), "input_{:.3f}".format(grid_size))
 os.mkdir(original_pc_folder) if not exists(original_pc_folder) else None
 os.mkdir(sub_pc_folder) if not exists(sub_pc_folder) else None
 
-for pc_path in glob.glob(join(dataset_path, '*.txt')):
+for pc_path in glob.glob(join(dataset_path, "*.txt")):
     print(pc_path)
-    file_name = pc_path.split('/')[-1][:-4]
+    file_name = pc_path.split("/")[-1][:-4]
 
     # check if it has already calculated
-    if exists(join(sub_pc_folder, file_name + '_KDTree.pkl')):
+    if exists(join(sub_pc_folder, file_name + "_KDTree.pkl")):
         continue
 
     pc = DP.load_pc_semantic3d(pc_path)
     # check if label exists
-    label_path = pc_path[:-4] + '.labels'
+    label_path = pc_path[:-4] + ".labels"
     if exists(label_path):
         labels = DP.load_label_semantic3d(label_path)
-        full_ply_path = join(original_pc_folder, file_name + '.ply')
+        full_ply_path = join(original_pc_folder, file_name + ".ply")
 
         # Subsample to save space
-        sub_points, sub_colors, sub_labels = DP.grid_sub_sampling(pc[:, :3].astype(np.float32),
-                                                                  pc[:, 4:7].astype(np.uint8), labels, 0.01)
+        sub_points, sub_colors, sub_labels = DP.grid_sub_sampling(
+            pc[:, :3].astype(np.float32), pc[:, 4:7].astype(np.uint8), labels, 0.01
+        )
         sub_labels = np.squeeze(sub_labels)
 
-        write_ply(full_ply_path, (sub_points, sub_colors, sub_labels), ['x', 'y', 'z', 'red', 'green', 'blue', 'class'])
+        write_ply(
+            full_ply_path,
+            (sub_points, sub_colors, sub_labels),
+            ["x", "y", "z", "red", "green", "blue", "class"],
+        )
 
         # save sub_cloud and KDTree file
-        sub_xyz, sub_colors, sub_labels = DP.grid_sub_sampling(sub_points, sub_colors, sub_labels, grid_size)
+        sub_xyz, sub_colors, sub_labels = DP.grid_sub_sampling(
+            sub_points, sub_colors, sub_labels, grid_size
+        )
         sub_colors = sub_colors / 255.0
         sub_labels = np.squeeze(sub_labels)
-        sub_ply_file = join(sub_pc_folder, file_name + '.ply')
-        write_ply(sub_ply_file, [sub_xyz, sub_colors, sub_labels], ['x', 'y', 'z', 'red', 'green', 'blue', 'class'])
+        sub_ply_file = join(sub_pc_folder, file_name + ".ply")
+        write_ply(
+            sub_ply_file,
+            [sub_xyz, sub_colors, sub_labels],
+            ["x", "y", "z", "red", "green", "blue", "class"],
+        )
 
         search_tree = KDTree(sub_xyz, leaf_size=50)
-        kd_tree_file = join(sub_pc_folder, file_name + '_KDTree.pkl')
-        with open(kd_tree_file, 'wb') as f:
+        kd_tree_file = join(sub_pc_folder, file_name + "_KDTree.pkl")
+        with open(kd_tree_file, "wb") as f:
             pickle.dump(search_tree, f)
 
         proj_idx = np.squeeze(search_tree.query(sub_points, return_distance=False))
         proj_idx = proj_idx.astype(np.int32)
-        proj_save = join(sub_pc_folder, file_name + '_proj.pkl')
-        with open(proj_save, 'wb') as f:
+        proj_save = join(sub_pc_folder, file_name + "_proj.pkl")
+        with open(proj_save, "wb") as f:
             pickle.dump([proj_idx, labels], f)
 
     else:
-        full_ply_path = join(original_pc_folder, file_name + '.ply')
-        write_ply(full_ply_path, (pc[:, :3].astype(np.float32), pc[:, 4:7].astype(np.uint8)),
-                  ['x', 'y', 'z', 'red', 'green', 'blue'])
+        full_ply_path = join(original_pc_folder, file_name + ".ply")
+        write_ply(
+            full_ply_path,
+            (pc[:, :3].astype(np.float32), pc[:, 4:7].astype(np.uint8)),
+            ["x", "y", "z", "red", "green", "blue"],
+        )
 
         # save sub_cloud and KDTree file
-        sub_xyz, sub_colors = DP.grid_sub_sampling(pc[:, :3].astype(np.float32), pc[:, 4:7].astype(np.uint8),
-                                                   grid_size=grid_size)
+        sub_xyz, sub_colors = DP.grid_sub_sampling(
+            pc[:, :3].astype(np.float32),
+            pc[:, 4:7].astype(np.uint8),
+            grid_size=grid_size,
+        )
         sub_colors = sub_colors / 255.0
-        sub_ply_file = join(sub_pc_folder, file_name + '.ply')
-        write_ply(sub_ply_file, [sub_xyz, sub_colors], ['x', 'y', 'z', 'red', 'green', 'blue'])
+        sub_ply_file = join(sub_pc_folder, file_name + ".ply")
+        write_ply(
+            sub_ply_file, [sub_xyz, sub_colors], ["x", "y", "z", "red", "green", "blue"]
+        )
         labels = np.zeros(pc.shape[0], dtype=np.uint8)
 
         search_tree = KDTree(sub_xyz, leaf_size=50)
-        kd_tree_file = join(sub_pc_folder, file_name + '_KDTree.pkl')
-        with open(kd_tree_file, 'wb') as f:
+        kd_tree_file = join(sub_pc_folder, file_name + "_KDTree.pkl")
+        with open(kd_tree_file, "wb") as f:
             pickle.dump(search_tree, f)
 
-        proj_idx = np.squeeze(search_tree.query(pc[:, :3].astype(np.float32), return_distance=False))
+        proj_idx = np.squeeze(
+            search_tree.query(pc[:, :3].astype(np.float32), return_distance=False)
+        )
         proj_idx = proj_idx.astype(np.int32)
-        proj_save = join(sub_pc_folder, file_name + '_proj.pkl')
-        with open(proj_save, 'wb') as f:
+        proj_save = join(sub_pc_folder, file_name + "_proj.pkl")
+        with open(proj_save, "wb") as f:
             pickle.dump([proj_idx, labels], f)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/nearest_neighbors/lib/python/KNN_NanoFLANN-0.0.0-py3.7-linux-x86_64.egg/nearest_neighbors.py	2024-06-30 22:34:21.535224+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/nearest_neighbors/lib/python/KNN_NanoFLANN-0.0.0-py3.7-linux-x86_64.egg/nearest_neighbors.py	2024-07-08 11:53:42.018379+00:00
@@ -1,9 +1,15 @@
 def __bootstrap__():
     global __bootstrap__, __loader__, __file__
     import sys, pkg_resources, importlib.util
-    __file__ = pkg_resources.resource_filename(__name__, 'nearest_neighbors.cpython-37m-x86_64-linux-gnu.so')
-    __loader__ = None; del __bootstrap__, __loader__
-    spec = importlib.util.spec_from_file_location(__name__,__file__)
+
+    __file__ = pkg_resources.resource_filename(
+        __name__, "nearest_neighbors.cpython-37m-x86_64-linux-gnu.so"
+    )
+    __loader__ = None
+    del __bootstrap__, __loader__
+    spec = importlib.util.spec_from_file_location(__name__, __file__)
     mod = importlib.util.module_from_spec(spec)
     spec.loader.exec_module(mod)
+
+
 __bootstrap__()
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/data_prepare_semantickitti.py	2024-06-30 22:34:20.951973+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/data_prepare_semantickitti.py	2024-07-08 11:53:42.075344+00:00
@@ -7,70 +7,76 @@
 ROOT_DIR = dirname(BASE_DIR)
 sys.path.append(BASE_DIR)
 sys.path.append(ROOT_DIR)
 from helper_tool import DataProcessing as DP
 
-data_config = os.path.join(BASE_DIR, 'semantic-kitti.yaml')
-DATA = yaml.safe_load(open(data_config, 'r'))
+data_config = os.path.join(BASE_DIR, "semantic-kitti.yaml")
+DATA = yaml.safe_load(open(data_config, "r"))
 remap_dict = DATA["learning_map"]
 max_key = max(remap_dict.keys())
 remap_lut = np.zeros((max_key + 100), dtype=np.int32)
 remap_lut[list(remap_dict.keys())] = list(remap_dict.values())
 
 grid_size = 0.06
-dataset_path = '/DATA/abhishek/SemanticKitti/unzipped/dataset/sequences'
-output_path = '/DATA/abhishek/SemanticKitti/unzipped/dataset/sequences' + '_' + str(grid_size)
+dataset_path = "/DATA/abhishek/SemanticKitti/unzipped/dataset/sequences"
+output_path = (
+    "/DATA/abhishek/SemanticKitti/unzipped/dataset/sequences" + "_" + str(grid_size)
+)
 seq_list = np.sort(os.listdir(dataset_path))[1:]
 
 for seq_id in seq_list:
-    print('sequence' + seq_id + ' start')
+    print("sequence" + seq_id + " start")
     seq_path = join(dataset_path, seq_id)
     seq_path_out = join(output_path, seq_id)
-    pc_path = join(seq_path, 'velodyne')
-    pc_path_out = join(seq_path_out, 'velodyne')
-    KDTree_path_out = join(seq_path_out, 'KDTree')
+    pc_path = join(seq_path, "velodyne")
+    pc_path_out = join(seq_path_out, "velodyne")
+    KDTree_path_out = join(seq_path_out, "KDTree")
     os.makedirs(seq_path_out) if not exists(seq_path_out) else None
     os.makedirs(pc_path_out) if not exists(pc_path_out) else None
     os.makedirs(KDTree_path_out) if not exists(KDTree_path_out) else None
 
-    if int(seq_id) < 11 or int(seq_id)==22:
-        label_path = join(seq_path, 'labels')
-        label_path_out = join(seq_path_out, 'labels')
+    if int(seq_id) < 11 or int(seq_id) == 22:
+        label_path = join(seq_path, "labels")
+        label_path_out = join(seq_path_out, "labels")
         os.makedirs(label_path_out) if not exists(label_path_out) else None
         scan_list = np.sort(os.listdir(pc_path))
         for scan_id in scan_list:
             print(scan_id)
             points = DP.load_pc_kitti(join(pc_path, scan_id))
-            labels = DP.load_label_kitti(join(label_path, str(scan_id[:-4]) + '.label'), remap_lut)
-            sub_points, sub_labels = DP.grid_sub_sampling(points, labels=labels, grid_size=grid_size)
+            labels = DP.load_label_kitti(
+                join(label_path, str(scan_id[:-4]) + ".label"), remap_lut
+            )
+            sub_points, sub_labels = DP.grid_sub_sampling(
+                points, labels=labels, grid_size=grid_size
+            )
             search_tree = KDTree(sub_points)
-            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + '.pkl')
+            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + ".pkl")
             np.save(join(pc_path_out, scan_id)[:-4], sub_points)
             np.save(join(label_path_out, scan_id)[:-4], sub_labels)
-            with open(KDTree_save, 'wb') as f:
+            with open(KDTree_save, "wb") as f:
                 pickle.dump(search_tree, f)
-            if seq_id == '08':
-                proj_path = join(seq_path_out, 'proj')
+            if seq_id == "08":
+                proj_path = join(seq_path_out, "proj")
                 os.makedirs(proj_path) if not exists(proj_path) else None
                 proj_inds = np.squeeze(search_tree.query(points, return_distance=False))
                 proj_inds = proj_inds.astype(np.int32)
-                proj_save = join(proj_path, str(scan_id[:-4]) + '_proj.pkl')
-                with open(proj_save, 'wb') as f:
+                proj_save = join(proj_path, str(scan_id[:-4]) + "_proj.pkl")
+                with open(proj_save, "wb") as f:
                     pickle.dump([proj_inds], f)
     else:
-        proj_path = join(seq_path_out, 'proj')
+        proj_path = join(seq_path_out, "proj")
         os.makedirs(proj_path) if not exists(proj_path) else None
         scan_list = np.sort(os.listdir(pc_path))
         for scan_id in scan_list:
             print(scan_id)
             points = DP.load_pc_kitti(join(pc_path, scan_id))
             sub_points = DP.grid_sub_sampling(points, grid_size=0.06)
             search_tree = KDTree(sub_points)
             proj_inds = np.squeeze(search_tree.query(points, return_distance=False))
             proj_inds = proj_inds.astype(np.int32)
-            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + '.pkl')
-            proj_save = join(proj_path, str(scan_id[:-4]) + '_proj.pkl')
+            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + ".pkl")
+            proj_save = join(proj_path, str(scan_id[:-4]) + "_proj.pkl")
             np.save(join(pc_path_out, scan_id)[:-4], sub_points)
-            with open(KDTree_save, 'wb') as f:
+            with open(KDTree_save, "wb") as f:
                 pickle.dump(search_tree, f)
-            with open(proj_save, 'wb') as f:
+            with open(proj_save, "wb") as f:
                 pickle.dump([proj_inds], f)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/nearest_neighbors/setup.py	2024-06-30 22:34:21.613259+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/nearest_neighbors/setup.py	2024-07-08 11:53:42.099015+00:00
@@ -2,20 +2,27 @@
 from distutils.extension import Extension
 from Cython.Distutils import build_ext
 import numpy
 
 
-
-ext_modules = [Extension(
-       "nearest_neighbors",
-       sources=["knn.pyx", "knn_.cxx",],  # source file(s)
-       include_dirs=["./", numpy.get_include()],
-       language="c++",            
-       extra_compile_args = [ "-std=c++11", "-fopenmp",],
-       extra_link_args=["-std=c++11", '-fopenmp'],
-  )]
+ext_modules = [
+    Extension(
+        "nearest_neighbors",
+        sources=[
+            "knn.pyx",
+            "knn_.cxx",
+        ],  # source file(s)
+        include_dirs=["./", numpy.get_include()],
+        language="c++",
+        extra_compile_args=[
+            "-std=c++11",
+            "-fopenmp",
+        ],
+        extra_link_args=["-std=c++11", "-fopenmp"],
+    )
+]
 
 setup(
-    name = "KNN NanoFLANN",
-    ext_modules = ext_modules,
-    cmdclass = {'build_ext': build_ext},
+    name="KNN NanoFLANN",
+    ext_modules=ext_modules,
+    cmdclass={"build_ext": build_ext},
 )
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/nearest_neighbors/test.py	2024-06-30 22:34:21.618443+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/nearest_neighbors/test.py	2024-07-08 11:53:42.113296+00:00
@@ -9,7 +9,5 @@
 
 # nearest neighbours
 start = time.time()
 neigh_idx = nearest_neighbors.knn_batch(pc, pc, K, omp=True)
 print(time.time() - start)
-
-
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/cpp_wrappers/cpp_neighbors/setup.py	2024-06-30 22:34:17.847766+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/cpp_wrappers/cpp_neighbors/setup.py	2024-07-08 11:53:42.115561+00:00
@@ -5,24 +5,18 @@
 # ************************
 
 # Adding sources of the project
 # *****************************
 
-SOURCES = ["../cpp_utils/cloud/cloud.cpp",
-             "neighbors/neighbors.cpp",
-             "wrapper.cpp"]
+SOURCES = ["../cpp_utils/cloud/cloud.cpp", "neighbors/neighbors.cpp", "wrapper.cpp"]
 
-module = Extension(name="radius_neighbors",
-                    sources=SOURCES,
-                    extra_compile_args=['-std=c++11',
-                                        '-D_GLIBCXX_USE_CXX11_ABI=0'])
+module = Extension(
+    name="radius_neighbors",
+    sources=SOURCES,
+    extra_compile_args=["-std=c++11", "-D_GLIBCXX_USE_CXX11_ABI=0"],
+)
 
 
-setup(ext_modules=[module], include_dirs=numpy.distutils.misc_util.get_numpy_include_dirs())
-
-
-
-
-
-
-
-
+setup(
+    ext_modules=[module],
+    include_dirs=numpy.distutils.misc_util.get_numpy_include_dirs(),
+)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/cpp_wrappers/cpp_subsampling/setup.py	2024-06-30 22:34:18.014276+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/cpp_wrappers/cpp_subsampling/setup.py	2024-07-08 11:53:42.147127+00:00
@@ -5,24 +5,22 @@
 # ************************
 
 # Adding sources of the project
 # *****************************
 
-SOURCES = ["../cpp_utils/cloud/cloud.cpp",
-             "grid_subsampling/grid_subsampling.cpp",
-             "wrapper.cpp"]
+SOURCES = [
+    "../cpp_utils/cloud/cloud.cpp",
+    "grid_subsampling/grid_subsampling.cpp",
+    "wrapper.cpp",
+]
 
-module = Extension(name="grid_subsampling",
-                    sources=SOURCES,
-                    extra_compile_args=['-std=c++11',
-                                        '-D_GLIBCXX_USE_CXX11_ABI=0'])
+module = Extension(
+    name="grid_subsampling",
+    sources=SOURCES,
+    extra_compile_args=["-std=c++11", "-D_GLIBCXX_USE_CXX11_ABI=0"],
+)
 
 
-setup(ext_modules=[module], include_dirs=numpy.distutils.misc_util.get_numpy_include_dirs())
-
-
-
-
-
-
-
-
+setup(
+    ext_modules=[module],
+    include_dirs=numpy.distutils.misc_util.get_numpy_include_dirs(),
+)
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/util.py	2024-06-30 23:19:44.697467+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/dgcnn_pytorch/util.py	2024-07-08 11:53:42.243169+00:00
@@ -32,11 +32,11 @@
         self.count += n
         self.avg = self.sum / self.count
 
 
 def set_seed(seed=1):
-    print('Using random seed', seed)
+    print("Using random seed", seed)
     random.seed(seed)
     np.random.seed(seed)
     torch.manual_seed(seed)
     torch.cuda.manual_seed_all(seed)
 
@@ -44,52 +44,51 @@
 def str2bool(v):
     return v.lower() in ("yes", "true", "t", "1")
 
 
 def get_lr(optimizer):
-    return optimizer.param_groups[0]['lr']
+    return optimizer.param_groups[0]["lr"]
 
 
 def adjust_lr(optimizer, new_lr):
     for param_group in optimizer.param_groups:
-        param_group['lr'] = new_lr
+        param_group["lr"] = new_lr
 
 
 def weights_init(m):
     classname = m.__class__.__name__
-    if classname.find('Conv2d') != -1:
+    if classname.find("Conv2d") != -1:
         nn.init.xavier_normal_(m.weight.data)
         try:
             nn.init.constant_(m.bias.data, 0.0)
         except AttributeError:
             pass
-    elif classname.find('Linear') != -1:
+    elif classname.find("Linear") != -1:
         nn.init.xavier_normal_(m.weight.data)
         try:
             nn.init.constant_(m.bias.data, 0.0)
         except AttributeError:
             pass
 
 
 def bn_momentum_adjust(m, momentum):
-    if isinstance(m, nn.BatchNorm2d) or \
-            isinstance(m, nn.BatchNorm1d):
+    if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):
         m.momentum = momentum
 
 
 def intersectionAndUnion(output, target, K, ignore_index=255):
     # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.
-    assert (output.ndim in [1, 2, 3])
+    assert output.ndim in [1, 2, 3]
     assert output.shape == target.shape
     output = output.reshape(output.size).copy()
     target = target.reshape(target.size)
     output[np.where(target == ignore_index)[0]] = 255
     target[np.where(target == ignore_index)[0]] = 255
     intersection = output[np.where(output == target)[0]]
-    area_intersection, _ = np.histogram(intersection, bins=np.arange(K+1))
-    area_output, _ = np.histogram(output, bins=np.arange(K+1))
-    area_target, _ = np.histogram(target, bins=np.arange(K+1))
+    area_intersection, _ = np.histogram(intersection, bins=np.arange(K + 1))
+    area_output, _ = np.histogram(output, bins=np.arange(K + 1))
+    area_target, _ = np.histogram(target, bins=np.arange(K + 1))
     area_union = area_output + area_target - area_intersection
     return area_intersection, area_union, area_target
 
 
 def calc_victim_value(class_value, label, victim_class):
@@ -103,329 +102,346 @@
 def check_makedirs(dir_name):
     if not os.path.exists(dir_name):
         os.makedirs(dir_name)
 
 
-def init_weights(model, conv='kaiming', batchnorm='normal', linear='kaiming', lstm='kaiming'):
+def init_weights(
+    model, conv="kaiming", batchnorm="normal", linear="kaiming", lstm="kaiming"
+):
     """
     :param model: Pytorch Model which is nn.Module
     :param conv:  'kaiming' or 'xavier'
     :param batchnorm: 'normal' or 'constant'
     :param linear: 'kaiming' or 'xavier'
     :param lstm: 'kaiming' or 'xavier'
     """
     for m in model.modules():
         if isinstance(m, (_ConvNd)):
-            if conv == 'kaiming':
+            if conv == "kaiming":
                 initer.kaiming_normal_(m.weight)
-            elif conv == 'xavier':
+            elif conv == "xavier":
                 initer.xavier_normal_(m.weight)
             else:
                 raise ValueError("init type of conv error.\n")
             if m.bias is not None:
                 initer.constant_(m.bias, 0)
 
         elif isinstance(m, _BatchNorm):
-            if batchnorm == 'normal':
+            if batchnorm == "normal":
                 initer.normal_(m.weight, 1.0, 0.02)
-            elif batchnorm == 'constant':
+            elif batchnorm == "constant":
                 initer.constant_(m.weight, 1.0)
             else:
                 raise ValueError("init type of batchnorm error.\n")
             initer.constant_(m.bias, 0.0)
 
         elif isinstance(m, nn.Linear):
-            if linear == 'kaiming':
+            if linear == "kaiming":
                 initer.kaiming_normal_(m.weight)
-            elif linear == 'xavier':
+            elif linear == "xavier":
                 initer.xavier_normal_(m.weight)
             else:
                 raise ValueError("init type of linear error.\n")
             if m.bias is not None:
                 initer.constant_(m.bias, 0)
 
         elif isinstance(m, nn.LSTM):
             for name, param in m.named_parameters():
-                if 'weight' in name:
-                    if lstm == 'kaiming':
+                if "weight" in name:
+                    if lstm == "kaiming":
                         initer.kaiming_normal_(param)
-                    elif lstm == 'xavier':
+                    elif lstm == "xavier":
                         initer.xavier_normal_(param)
                     else:
                         raise ValueError("init type of lstm error.\n")
-                elif 'bias' in name:
+                elif "bias" in name:
                     initer.constant_(param, 0)
 
 
 def convert_to_syncbn(model):
     def recursive_set(cur_module, name, module):
-        if len(name.split('.')) > 1:
+        if len(name.split(".")) > 1:
             recursive_set(
-                getattr(cur_module, name[:name.find('.')]), name[name.find('.')+1:], module)
+                getattr(cur_module, name[: name.find(".")]),
+                name[name.find(".") + 1 :],
+                module,
+            )
         else:
             setattr(cur_module, name, module)
-    from sync_bn import SynchronizedBatchNorm1d, SynchronizedBatchNorm2d, \
-        SynchronizedBatchNorm3d
+
+    from sync_bn import (
+        SynchronizedBatchNorm1d,
+        SynchronizedBatchNorm2d,
+        SynchronizedBatchNorm3d,
+    )
+
     for name, m in model.named_modules():
         if isinstance(m, nn.BatchNorm1d):
-            recursive_set(model, name, SynchronizedBatchNorm1d(
-                m.num_features, m.eps, m.momentum, m.affine))
+            recursive_set(
+                model,
+                name,
+                SynchronizedBatchNorm1d(m.num_features, m.eps, m.momentum, m.affine),
+            )
         elif isinstance(m, nn.BatchNorm2d):
-            recursive_set(model, name, SynchronizedBatchNorm2d(
-                m.num_features, m.eps, m.momentum, m.affine))
+            recursive_set(
+                model,
+                name,
+                SynchronizedBatchNorm2d(m.num_features, m.eps, m.momentum, m.affine),
+            )
         elif isinstance(m, nn.BatchNorm3d):
-            recursive_set(model, name, SynchronizedBatchNorm3d(
-                m.num_features, m.eps, m.momentum, m.affine))
+            recursive_set(
+                model,
+                name,
+                SynchronizedBatchNorm3d(m.num_features, m.eps, m.momentum, m.affine),
+            )
 
 
 def lbl2rgb(label, names):
     """Convert label to rgb colors.
     label: [N]
     """
     from config import NAME2COLOR
+
     if len(names) == 13:
-        colors = NAME2COLOR['S3DIS']
+        colors = NAME2COLOR["S3DIS"]
     else:
-        colors = NAME2COLOR['ScanNet']
+        colors = NAME2COLOR["ScanNet"]
     rgb = np.zeros((label.shape[0], 3))
     uni_lbl = np.unique(label).astype(np.uint8)
     for lbl in uni_lbl:
-        mask = (label == lbl)
-        rgb[mask] = np.tile(np.array(
-            colors[names[lbl]])[None, :], (mask.sum(), 1))
+        mask = label == lbl
+        rgb[mask] = np.tile(np.array(colors[names[lbl]])[None, :], (mask.sum(), 1))
     return rgb
 
 
 def convert2vis(xyz, label, names):
     """Assign color to each point according to label."""
-    rgb = lbl2rgb(label, names) * 255.
+    rgb = lbl2rgb(label, names) * 255.0
     data = np.concatenate([xyz, rgb], axis=1)
     return data
 
 
-def proc_pert(points, gt, pred, folder,
-              names, part=False, ignore_label=255):
+def proc_pert(points, gt, pred, folder, names, part=False, ignore_label=255):
     """Process and save files for visulization in perturbation attack."""
     check_makedirs(folder)
     lbl2cls = {i: names[i] for i in range(len(names))}
 
-    np.savetxt(os.path.join(folder, 'all_points.txt'), points, delimiter=';')
-    gt_seg = convert2vis(points[gt != ignore_label, :3],
-                         gt[gt != ignore_label], names)
-    pred_seg = convert2vis(points[gt != ignore_label, :3],
-                           pred[gt != ignore_label], names)
-    np.savetxt(os.path.join(folder, 'gt.txt'),
-               gt_seg, delimiter=';')
-    np.savetxt(os.path.join(folder, 'pred.txt'),
-               pred_seg, delimiter=';')
+    np.savetxt(os.path.join(folder, "all_points.txt"), points, delimiter=";")
+    gt_seg = convert2vis(points[gt != ignore_label, :3], gt[gt != ignore_label], names)
+    pred_seg = convert2vis(
+        points[gt != ignore_label, :3], pred[gt != ignore_label], names
+    )
+    np.savetxt(os.path.join(folder, "gt.txt"), gt_seg, delimiter=";")
+    np.savetxt(os.path.join(folder, "pred.txt"), pred_seg, delimiter=";")
     if part:
         uni_lbl = np.unique(gt[gt != ignore_label]).astype(np.uint8)
         for lbl in uni_lbl:
             lbl = int(lbl)
-            mask = (gt == lbl)
+            mask = gt == lbl
             sel_points = points[mask]
-            mask = (gt[gt != ignore_label] == lbl)
+            mask = gt[gt != ignore_label] == lbl
             sel_seg = pred_seg[mask]
             np.savetxt(
-                os.path.join(folder, '{}_{}_points.txt'.format(
-                    lbl, lbl2cls[lbl])),
-                sel_points, delimiter=';')
+                os.path.join(folder, "{}_{}_points.txt".format(lbl, lbl2cls[lbl])),
+                sel_points,
+                delimiter=";",
+            )
             np.savetxt(
-                os.path.join(folder, '{}_{}_pred.txt'.format(
-                    lbl, lbl2cls[lbl])),
-                sel_seg, delimiter=';')
-
-
-def proc_add(points, noise, gt, pred, noise_pred, folder,
-             names, part=False, ignore_label=255):
+                os.path.join(folder, "{}_{}_pred.txt".format(lbl, lbl2cls[lbl])),
+                sel_seg,
+                delimiter=";",
+            )
+
+
+def proc_add(
+    points, noise, gt, pred, noise_pred, folder, names, part=False, ignore_label=255
+):
     """Process and save files for visulization in adding attack."""
     check_makedirs(folder)
     lbl2cls = {i: names[i] for i in range(len(names))}
 
-    np.savetxt(os.path.join(folder, 'all_points.txt'), points, delimiter=';')
-    np.savetxt(os.path.join(folder, 'noise_points.txt'), noise, delimiter=';')
-    gt_seg = convert2vis(points[gt != ignore_label, :3],
-                         gt[gt != ignore_label], names)
-    pred_seg = convert2vis(points[gt != ignore_label, :3],
-                           pred[gt != ignore_label], names)
+    np.savetxt(os.path.join(folder, "all_points.txt"), points, delimiter=";")
+    np.savetxt(os.path.join(folder, "noise_points.txt"), noise, delimiter=";")
+    gt_seg = convert2vis(points[gt != ignore_label, :3], gt[gt != ignore_label], names)
+    pred_seg = convert2vis(
+        points[gt != ignore_label, :3], pred[gt != ignore_label], names
+    )
     noise_seg = convert2vis(noise[:, :3], noise_pred, names)
-    np.savetxt(os.path.join(folder, 'gt.txt'),
-               gt_seg, delimiter=';')
-    np.savetxt(os.path.join(folder, 'pred.txt'),
-               pred_seg, delimiter=';')
-    np.savetxt(os.path.join(folder, 'noise_pred.txt'),
-               noise_seg, delimiter=';')
+    np.savetxt(os.path.join(folder, "gt.txt"), gt_seg, delimiter=";")
+    np.savetxt(os.path.join(folder, "pred.txt"), pred_seg, delimiter=";")
+    np.savetxt(os.path.join(folder, "noise_pred.txt"), noise_seg, delimiter=";")
     if part:
         uni_lbl = np.unique(gt[gt != ignore_label]).astype(np.uint8)
         for lbl in uni_lbl:
             lbl = int(lbl)
-            mask = (gt == lbl)
+            mask = gt == lbl
             sel_points = points[mask]
-            mask = (gt[gt != ignore_label] == lbl)
+            mask = gt[gt != ignore_label] == lbl
             sel_seg = pred_seg[mask]
             np.savetxt(
-                os.path.join(folder, '{}_{}_points.txt'.format(
-                    lbl, lbl2cls[lbl])),
-                sel_points, delimiter=';')
+                os.path.join(folder, "{}_{}_points.txt".format(lbl, lbl2cls[lbl])),
+                sel_points,
+                delimiter=";",
+            )
             np.savetxt(
-                os.path.join(folder, '{}_{}_pred.txt'.format(
-                    lbl, lbl2cls[lbl])),
-                sel_seg, delimiter=';')
+                os.path.join(folder, "{}_{}_pred.txt".format(lbl, lbl2cls[lbl])),
+                sel_seg,
+                delimiter=";",
+            )
 
 
 def save_vis(pred_root, save_root, data_root):
     from config import CLASS_NAMES
-    if 'S3DIS' in data_root:  # save Area5 data
-        names = CLASS_NAMES['S3DIS']['other']
-        gt_save = load_pickle(
-            os.path.join(pred_root, 'gt_5.pickle'))['gt']
-        pred_save = load_pickle(
-            os.path.join(pred_root, 'pred_5.pickle'))['pred']
+
+    if "S3DIS" in data_root:  # save Area5 data
+        names = CLASS_NAMES["S3DIS"]["other"]
+        gt_save = load_pickle(os.path.join(pred_root, "gt_5.pickle"))["gt"]
+        pred_save = load_pickle(os.path.join(pred_root, "pred_5.pickle"))["pred"]
         assert len(gt_save) == len(pred_save)
         all_rooms = sorted(os.listdir(data_root))
-        all_rooms = [
-            room for room in all_rooms if 'Area_5' in room
-        ]
+        all_rooms = [room for room in all_rooms if "Area_5" in room]
         assert len(gt_save) == len(all_rooms)
         check_makedirs(save_root)
         for i, room in enumerate(all_rooms):
             points = np.load(os.path.join(data_root, room))[:, :6]
             folder = os.path.join(save_root, room[:-4])
             check_makedirs(folder)
-            proc_pert(points, gt_save[i], pred_save[i],
-                      folder, names, part=True)
-    elif 'ScanNet' in data_root:  # save val set data
-        names = CLASS_NAMES['ScanNet']['other']
-        gt_save = load_pickle(
-            os.path.join(pred_root, 'gt_val.pickle'))['gt']
-        pred_save = load_pickle(
-            os.path.join(pred_root, 'pred_val.pickle'))['pred']
+            proc_pert(points, gt_save[i], pred_save[i], folder, names, part=True)
+    elif "ScanNet" in data_root:  # save val set data
+        names = CLASS_NAMES["ScanNet"]["other"]
+        gt_save = load_pickle(os.path.join(pred_root, "gt_val.pickle"))["gt"]
+        pred_save = load_pickle(os.path.join(pred_root, "pred_val.pickle"))["pred"]
         assert len(gt_save) == len(pred_save)
-        data_file = os.path.join(
-            data_root, 'scannet_val_rgb21c_pointid.pickle')
-        file_pickle = open(data_file, 'rb')
+        data_file = os.path.join(data_root, "scannet_val_rgb21c_pointid.pickle")
+        file_pickle = open(data_file, "rb")
         xyz_all = pickle.load(file_pickle)
         file_pickle.close()
         assert len(xyz_all) == len(gt_save)
-        with open(os.path.join(
-                data_root, 'meta_data/scannetv2_val.txt')) as fl:
+        with open(os.path.join(data_root, "meta_data/scannetv2_val.txt")) as fl:
             scene_id = fl.read().splitlines()
         assert len(scene_id) == len(gt_save)
         check_makedirs(save_root)
         for i in range(len(gt_save)):
             points = xyz_all[i][:, :6]
             folder = os.path.join(save_root, scene_id[i])
             check_makedirs(folder)
-            proc_pert(points, gt_save[i], pred_save[i],
-                      folder, names, part=True)
+            proc_pert(points, gt_save[i], pred_save[i], folder, names, part=True)
 
 
 def save_vis_mink(pred_root, save_root, data_root):
     from config import CLASS_NAMES
 
     def load_data(file_name):
         plydata = PlyData.read(file_name)
         data = plydata.elements[0].data
-        coords = np.array([data['x'], data['y'], data['z']],
-                          dtype=np.float32).T
-        colors = np.array([data['red'], data['green'],
-                           data['blue']], dtype=np.float32).T
+        coords = np.array([data["x"], data["y"], data["z"]], dtype=np.float32).T
+        colors = np.array(
+            [data["red"], data["green"], data["blue"]], dtype=np.float32
+        ).T
         return np.concatenate([coords, colors], axis=1)
 
-    if 'S3DIS' in data_root:  # save Area5 data
-        names = CLASS_NAMES['S3DIS']['mink']
-        gt_save = load_pickle(
-            os.path.join(pred_root, 'gt_5.pickle'))['gt']
-        pred_save = load_pickle(
-            os.path.join(pred_root, 'pred_5.pickle'))['pred']
+    if "S3DIS" in data_root:  # save Area5 data
+        names = CLASS_NAMES["S3DIS"]["mink"]
+        gt_save = load_pickle(os.path.join(pred_root, "gt_5.pickle"))["gt"]
+        pred_save = load_pickle(os.path.join(pred_root, "pred_5.pickle"))["pred"]
         assert len(gt_save) == len(pred_save)
-        data_root = os.path.join(data_root, 'Area_5')
+        data_root = os.path.join(data_root, "Area_5")
         all_rooms = sorted(os.listdir(data_root))
         assert len(all_rooms) == len(gt_save)
         check_makedirs(save_root)
 
         for i, room in enumerate(all_rooms):
             data = os.path.join(data_root, room)
             points = load_data(data)
-            folder = os.path.join(
-                save_root, 'Area_5_{}'.format(room[:-4]))
+            folder = os.path.join(save_root, "Area_5_{}".format(room[:-4]))
             check_makedirs(folder)
-            proc_pert(points, gt_save[i], pred_save[i],
-                      folder, names, part=True)
-    elif 'ScanNet' in data_root:  # save val set
-        names = CLASS_NAMES['ScanNet']['mink']
-        gt_save = load_pickle(
-            os.path.join(pred_root, 'gt_val.pickle'))['gt']
-        pred_save = load_pickle(
-            os.path.join(pred_root, 'pred_val.pickle'))['pred']
+            proc_pert(points, gt_save[i], pred_save[i], folder, names, part=True)
+    elif "ScanNet" in data_root:  # save val set
+        names = CLASS_NAMES["ScanNet"]["mink"]
+        gt_save = load_pickle(os.path.join(pred_root, "gt_val.pickle"))["gt"]
+        pred_save = load_pickle(os.path.join(pred_root, "pred_val.pickle"))["pred"]
         assert len(gt_save) == len(pred_save)
-        data_root = os.path.join(data_root, 'train')
-        with open(os.path.join(
-                data_root, 'scannetv2_val.txt'), 'r') as f:
+        data_root = os.path.join(data_root, "train")
+        with open(os.path.join(data_root, "scannetv2_val.txt"), "r") as f:
             all_rooms = f.readlines()
         all_rooms = [room[:-1] for room in all_rooms]
         assert len(all_rooms) == len(gt_save)
         check_makedirs(save_root)
 
         for i, room in enumerate(all_rooms):
             data = os.path.join(data_root, room)
             points = load_data(data)
             folder = os.path.join(save_root, room[:-4])
             check_makedirs(folder)
-            proc_pert(points, gt_save[i], pred_save[i],
-                      folder, names, part=True)
-
-
-def save_vis_from_pickle(pkl_root, save_root=None, room_idx=52,
-                         room_name='scene0354_00'):
+            proc_pert(points, gt_save[i], pred_save[i], folder, names, part=True)
+
+
+def save_vis_from_pickle(
+    pkl_root, save_root=None, room_idx=52, room_name="scene0354_00"
+):
     names = [
-        'wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table',
-        'door', 'window', 'bookshelf', 'picture', 'counter', 'desk',
-        'curtain', 'refrigerator', 'showercurtain', 'toilet', 'sink',
-        'bathtub', 'otherfurniture'
+        "wall",
+        "floor",
+        "cabinet",
+        "bed",
+        "chair",
+        "sofa",
+        "table",
+        "door",
+        "window",
+        "bookshelf",
+        "picture",
+        "counter",
+        "desk",
+        "curtain",
+        "refrigerator",
+        "showercurtain",
+        "toilet",
+        "sink",
+        "bathtub",
+        "otherfurniture",
     ]
     data = load_pickle(pkl_root)
-    points = data['data'][room_idx]
-    pred = data['pred'][room_idx]
-    gt = data['gt'][room_idx]
+    points = data["data"][room_idx]
+    pred = data["pred"][room_idx]
+    gt = data["gt"][room_idx]
     if save_root is None:
         save_root = os.path.dirname(pkl_root)
     save_folder = os.path.join(save_root, room_name)
     proc_pert(points, gt, pred, save_folder, names, part=True)
 
 
 def save_pickle(filename, dict_data):
-    with open(filename, 'wb') as handle:
-        pickle.dump(dict_data, handle,
-                    protocol=pickle.HIGHEST_PROTOCOL)
+    with open(filename, "wb") as handle:
+        pickle.dump(dict_data, handle, protocol=pickle.HIGHEST_PROTOCOL)
 
 
 def load_pickle(filename):
-    with open(filename, 'rb') as f:
+    with open(filename, "rb") as f:
         data = pickle.load(f)
     return data
 
 
-def load_s3dis_instance(folder, name2cls, load_name=['chair']):
+def load_s3dis_instance(folder, name2cls, load_name=["chair"]):
     """Load S3DIS room in a Inst Seg format.
     Get each instance separately.
 
     If load_name is None or [], return all instances.
     Returns a list of [np.array of [N, 6], label]
     """
     cls2name = {name2cls[name]: name for name in name2cls.keys()}
-    anno_path = os.path.join(folder, 'Annotations')
+    anno_path = os.path.join(folder, "Annotations")
     points_list = []
     labels_list = []
     idx = 0
-    files = glob.glob(os.path.join(anno_path, '*.txt'))
+    files = glob.glob(os.path.join(anno_path, "*.txt"))
     files.sort()
 
     for f in files:
-        cls = os.path.basename(f).split('_')[0]
+        cls = os.path.basename(f).split("_")[0]
         if cls not in name2cls.keys():
-            cls = 'clutter'
+            cls = "clutter"
         points = np.loadtxt(f)  # [N, 6]
         num = points.shape[0]
         points_list.append(points)
         labels_list.append((idx, idx + num, name2cls[cls]))
         idx += num
@@ -437,18 +453,19 @@
 
     # rearrange to separate instances
     if load_name is None or not load_name:
         load_name = list(name2cls.keys())
     instances = [
-        [data[pair[0]:pair[1]], pair[2]] for pair in labels_list if
-        cls2name[pair[2]] in load_name
+        [data[pair[0] : pair[1]], pair[2]]
+        for pair in labels_list
+        if cls2name[pair[2]] in load_name
     ]
     return instances
 
 
 def cal_loss(pred, gold, smoothing=False, ignore_index=255):
-    ''' Calculate cross entropy loss, apply label smoothing if needed. '''
+    """Calculate cross entropy loss, apply label smoothing if needed."""
 
     gold = gold.contiguous().view(-1)
 
     if smoothing:
         eps = 0.2
@@ -458,23 +475,21 @@
         one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)
         log_prb = F.log_softmax(pred, dim=1)
 
         loss = -(one_hot * log_prb).sum(dim=1).mean()
     else:
-        loss = F.cross_entropy(
-            pred, gold, reduction='mean',
-            ignore_index=ignore_index)
+        loss = F.cross_entropy(pred, gold, reduction="mean", ignore_index=ignore_index)
 
     return loss
 
 
-class IOStream():
+class IOStream:
     def __init__(self, path):
-        self.f = open(path, 'a')
+        self.f = open(path, "a")
 
     def cprint(self, text):
         print(text)
-        self.f.write(text+'\n')
+        self.f.write(text + "\n")
         self.f.flush()
 
     def close(self):
-        self.f.close()
\ No newline at end of file
+        self.f.close()
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/ply.py	2024-06-30 22:34:21.618443+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/utils/ply.py	2024-07-08 11:53:42.629885+00:00
@@ -26,32 +26,33 @@
 import numpy as np
 import sys
 
 
 # Define PLY types
-ply_dtypes = dict([
-    (b'int8', 'i1'),
-    (b'char', 'i1'),
-    (b'uint8', 'u1'),
-    (b'uchar', 'u1'),
-    (b'int16', 'i2'),
-    (b'short', 'i2'),
-    (b'uint16', 'u2'),
-    (b'ushort', 'u2'),
-    (b'int32', 'i4'),
-    (b'int', 'i4'),
-    (b'uint32', 'u4'),
-    (b'uint', 'u4'),
-    (b'float32', 'f4'),
-    (b'float', 'f4'),
-    (b'float64', 'f8'),
-    (b'double', 'f8')
-])
+ply_dtypes = dict(
+    [
+        (b"int8", "i1"),
+        (b"char", "i1"),
+        (b"uint8", "u1"),
+        (b"uchar", "u1"),
+        (b"int16", "i2"),
+        (b"short", "i2"),
+        (b"uint16", "u2"),
+        (b"ushort", "u2"),
+        (b"int32", "i4"),
+        (b"int", "i4"),
+        (b"uint32", "u4"),
+        (b"uint", "u4"),
+        (b"float32", "f4"),
+        (b"float", "f4"),
+        (b"float64", "f8"),
+        (b"double", "f8"),
+    ]
+)
 
 # Numpy reader format
-valid_formats = {'ascii': '', 'binary_big_endian': '>',
-                 'binary_little_endian': '<'}
+valid_formats = {"ascii": "", "binary_big_endian": ">", "binary_little_endian": "<"}
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Functions
@@ -63,18 +64,18 @@
     # Variables
     line = []
     properties = []
     num_points = None
 
-    while b'end_header' not in line and line != b'':
+    while b"end_header" not in line and line != b"":
         line = plyfile.readline()
 
-        if b'element' in line:
+        if b"element" in line:
             line = line.split()
             num_points = int(line[2])
 
-        elif b'property' in line:
+        elif b"property" in line:
             line = line.split()
             properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))
 
     return num_points, properties
 
@@ -85,32 +86,31 @@
     vertex_properties = []
     num_points = None
     num_faces = None
     current_element = None
 
-
-    while b'end_header' not in line and line != b'':
+    while b"end_header" not in line and line != b"":
         line = plyfile.readline()
 
         # Find point element
-        if b'element vertex' in line:
-            current_element = 'vertex'
+        if b"element vertex" in line:
+            current_element = "vertex"
             line = line.split()
             num_points = int(line[2])
 
-        elif b'element face' in line:
-            current_element = 'face'
+        elif b"element face" in line:
+            current_element = "face"
             line = line.split()
             num_faces = int(line[2])
 
-        elif b'property' in line:
-            if current_element == 'vertex':
+        elif b"property" in line:
+            if current_element == "vertex":
                 line = line.split()
                 vertex_properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))
-            elif current_element == 'vertex':
-                if not line.startswith('property list uchar int'):
-                    raise ValueError('Unsupported faces property : ' + line)
+            elif current_element == "vertex":
+                if not line.startswith("property list uchar int"):
+                    raise ValueError("Unsupported faces property : " + line)
 
     return num_points, num_faces, vertex_properties
 
 
 def read_ply(filename, triangular_mesh=False):
@@ -138,31 +138,30 @@
     Read the file
 
     >>> data = read_ply('example.ply')
     >>> values = data['values']
     array([0, 0, 1, 1, 0])
-    
+
     >>> points = np.vstack((data['x'], data['y'], data['z'])).T
     array([[ 0.466  0.595  0.324]
            [ 0.538  0.407  0.654]
            [ 0.850  0.018  0.988]
            [ 0.395  0.394  0.363]
            [ 0.873  0.996  0.092]])
 
     """
 
-    with open(filename, 'rb') as plyfile:
-
+    with open(filename, "rb") as plyfile:
 
         # Check if the file start with ply
-        if b'ply' not in plyfile.readline():
-            raise ValueError('The file does not start whith the word ply')
+        if b"ply" not in plyfile.readline():
+            raise ValueError("The file does not start whith the word ply")
 
         # get binary_little/big or ascii
         fmt = plyfile.readline().split()[1].decode()
         if fmt == "ascii":
-            raise ValueError('The file is not binary')
+            raise ValueError("The file is not binary")
 
         # get extension for building the numpy dtypes
         ext = valid_formats[fmt]
 
         # PointCloud reader vs mesh reader
@@ -173,18 +172,20 @@
 
             # Get point data
             vertex_data = np.fromfile(plyfile, dtype=properties, count=num_points)
 
             # Get face data
-            face_properties = [('k', ext + 'u1'),
-                               ('v1', ext + 'i4'),
-                               ('v2', ext + 'i4'),
-                               ('v3', ext + 'i4')]
+            face_properties = [
+                ("k", ext + "u1"),
+                ("v1", ext + "i4"),
+                ("v2", ext + "i4"),
+                ("v3", ext + "i4"),
+            ]
             faces_data = np.fromfile(plyfile, dtype=face_properties, count=num_faces)
 
             # Return vertex data and concatenated faces
-            faces = np.vstack((faces_data['v1'], faces_data['v2'], faces_data['v3'])).T
+            faces = np.vstack((faces_data["v1"], faces_data["v2"], faces_data["v3"])).T
             data = [vertex_data, faces]
 
         else:
 
             # Parse header
@@ -200,17 +201,17 @@
 
     # List of lines to write
     lines = []
 
     # First line describing element vertex
-    lines.append('element vertex %d' % field_list[0].shape[0])
+    lines.append("element vertex %d" % field_list[0].shape[0])
 
     # Properties lines
     i = 0
     for fields in field_list:
         for field in fields.T:
-            lines.append('property %s %s' % (field.dtype.name, field_names[i]))
+            lines.append("property %s %s" % (field.dtype.name, field_names[i]))
             i += 1
 
     return lines
 
 
@@ -219,20 +220,20 @@
     Write ".ply" files
 
     Parameters
     ----------
     filename : string
-        the name of the file to which the data is saved. A '.ply' extension will be appended to the 
+        the name of the file to which the data is saved. A '.ply' extension will be appended to the
         file name if it does no already have one.
 
     field_list : list, tuple, numpy array
-        the fields to be saved in the ply file. Either a numpy array, a list of numpy arrays or a 
-        tuple of numpy arrays. Each 1D numpy array and each column of 2D numpy arrays are considered 
-        as one field. 
+        the fields to be saved in the ply file. Either a numpy array, a list of numpy arrays or a
+        tuple of numpy arrays. Each 1D numpy array and each column of 2D numpy arrays are considered
+        as one field.
 
     field_names : list
-        the name of each fields as a list of strings. Has to be the same length as the number of 
+        the name of each fields as a list of strings. Has to be the same length as the number of
         fields.
 
     Examples
     --------
     >>> points = np.random.rand(10, 3)
@@ -246,60 +247,64 @@
     >>> write_ply('example3.ply', [points, colors, values], field_names)
 
     """
 
     # Format list input to the right form
-    field_list = list(field_list) if (type(field_list) == list or type(field_list) == tuple) else list((field_list,))
+    field_list = (
+        list(field_list)
+        if (type(field_list) == list or type(field_list) == tuple)
+        else list((field_list,))
+    )
     for i, field in enumerate(field_list):
         if field.ndim < 2:
             field_list[i] = field.reshape(-1, 1)
         if field.ndim > 2:
-            print('fields have more than 2 dimensions')
-            return False    
+            print("fields have more than 2 dimensions")
+            return False
 
     # check all fields have the same number of data
     n_points = [field.shape[0] for field in field_list]
     if not np.all(np.equal(n_points, n_points[0])):
-        print('wrong field dimensions')
-        return False    
+        print("wrong field dimensions")
+        return False
 
     # Check if field_names and field_list have same nb of column
     n_fields = np.sum([field.shape[1] for field in field_list])
-    if (n_fields != len(field_names)):
-        print('wrong number of field names')
+    if n_fields != len(field_names):
+        print("wrong number of field names")
         return False
 
     # Add extension if not there
-    if not filename.endswith('.ply'):
-        filename += '.ply'
+    if not filename.endswith(".ply"):
+        filename += ".ply"
 
     # open in text mode to write the header
-    with open(filename, 'w') as plyfile:
+    with open(filename, "w") as plyfile:
 
         # First magical word
-        header = ['ply']
+        header = ["ply"]
 
         # Encoding format
-        header.append('format binary_' + sys.byteorder + '_endian 1.0')
+        header.append("format binary_" + sys.byteorder + "_endian 1.0")
 
         # Points properties description
         header.extend(header_properties(field_list, field_names))
 
         # Add faces if needded
         if triangular_faces is not None:
-            header.append('element face {:d}'.format(triangular_faces.shape[0]))
-            header.append('property list uchar int vertex_indices')
+            header.append("element face {:d}".format(triangular_faces.shape[0]))
+            header.append("property list uchar int vertex_indices")
 
         # End of header
-        header.append('end_header')
+        header.append("end_header")
 
         # Write all lines
         for line in header:
             plyfile.write("%s\n" % line)
 
     # open in binary/append to use tofile
-    with open(filename, 'ab') as plyfile:
+    with open(filename, "ab") as plyfile:
 
         # Create a structured array
         i = 0
         type_list = []
         for fields in field_list:
@@ -315,41 +320,41 @@
 
         data.tofile(plyfile)
 
         if triangular_faces is not None:
             triangular_faces = triangular_faces.astype(np.int32)
-            type_list = [('k', 'uint8')] + [(str(ind), 'int32') for ind in range(3)]
+            type_list = [("k", "uint8")] + [(str(ind), "int32") for ind in range(3)]
             data = np.empty(triangular_faces.shape[0], dtype=type_list)
-            data['k'] = np.full((triangular_faces.shape[0],), 3, dtype=np.uint8)
-            data['0'] = triangular_faces[:, 0]
-            data['1'] = triangular_faces[:, 1]
-            data['2'] = triangular_faces[:, 2]
+            data["k"] = np.full((triangular_faces.shape[0],), 3, dtype=np.uint8)
+            data["0"] = triangular_faces[:, 0]
+            data["1"] = triangular_faces[:, 1]
+            data["2"] = triangular_faces[:, 2]
             data.tofile(plyfile)
 
     return True
 
 
 def describe_element(name, df):
-    """ Takes the columns of the dataframe and builds a ply-like description
+    """Takes the columns of the dataframe and builds a ply-like description
 
     Parameters
     ----------
     name: str
     df: pandas DataFrame
 
     Returns
     -------
     element: list[str]
     """
-    property_formats = {'f': 'float', 'u': 'uchar', 'i': 'int'}
-    element = ['element ' + name + ' ' + str(len(df))]
-
-    if name == 'face':
+    property_formats = {"f": "float", "u": "uchar", "i": "int"}
+    element = ["element " + name + " " + str(len(df))]
+
+    if name == "face":
         element.append("property list uchar int points_indices")
 
     else:
         for i in range(len(df.columns)):
             # get first letter of dtype to infer format
             f = property_formats[str(df.dtypes[i])[0]]
-            element.append('property ' + f + ' ' + df.columns.values[i])
-
-    return element
\ No newline at end of file
+            element.append("property " + f + " " + df.columns.values[i])
+
+    return element
--- /mnt/c/faps/XAI/pGS-CAM/DGCNN/pGSCAM.py	2024-06-30 22:34:19.800754+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/DGCNN/pGSCAM.py	2024-07-08 11:53:42.777197+00:00
@@ -1,6 +1,6 @@
-import numpy as np 
+import numpy as np
 import torch
 from utils.ply import read_ply, write_ply
 from torch.autograd import grad
 from sklearn.metrics import confusion_matrix
 from sklearn.neighbors import KDTree
@@ -12,423 +12,457 @@
 from drop_dataset import SemanticKITTI
 from torch.utils.data import DataLoader
 from sklearn.cluster import DBSCAN
 import umap
 
-        
-        
+
 class PowerCAM:
     """
-    Vanilla gradient class activation mapping 
+    Vanilla gradient class activation mapping
     """
-    
-    def __init__(self, input_model, batch, config, mask_type="none", mode="normal", norm=False, cls=-1):
+
+    def __init__(
+        self,
+        input_model,
+        batch,
+        config,
+        mask_type="none",
+        mode="normal",
+        norm=False,
+        cls=-1,
+    ):
         # mode: [normal, counterfactual]
         # mask_type: [none, single, subset]:- none(no mask), single(only single point), subset(collection of points)
-        
+
         self.input_model = input_model
         self.batch = batch
         self.cls = cls
         self.config = config
         self.norm = norm
         self.is_masked = True
         self.threshold = [0.1, 0.3, 0.3]
         self.mode = mode
         self.mask_type = mask_type
-        
+
         # actuall labels starts from unlabelled but we are ignoring it
         self.transform_map = {
-          0: "car",
-          1: "bicycle",
-          2: "motorcycle",
-          3: "truck",
-          4: "other-vehicle",
-          5: "person",
-          6: "bicyclist",
-          7: "motorcyclist",
-          8: "road",
-          9: "parking",
-          10: "sidewalk",
-          11: "other-ground",
-          12: "building",
-          13: "fence",
-          14: "vegetation",
-          15: "trunk",
-          16: "terrain",
-          17: "pole",
-          18: "traffic-sign"
-      }
-        
+            0: "car",
+            1: "bicycle",
+            2: "motorcycle",
+            3: "truck",
+            4: "other-vehicle",
+            5: "person",
+            6: "bicyclist",
+            7: "motorcyclist",
+            8: "road",
+            9: "parking",
+            10: "sidewalk",
+            11: "other-ground",
+            12: "building",
+            13: "fence",
+            14: "vegetation",
+            15: "trunk",
+            16: "terrain",
+            17: "pole",
+            18: "traffic-sign",
+        }
+
     def create_mask(self):
         # logits: [1, d, N]
         # points: [1, N, 3]
         # preds: [1, N]
-        logits = self.end_points['logits']
+        logits = self.end_points["logits"]
         softmax = torch.nn.Softmax(1)
         preds = softmax(logits).argmax(dim=1)
-        point_0 = self.end_points['xyz'][0]
-        if self.mask_type == 'none':
+        point_0 = self.end_points["xyz"][0]
+        if self.mask_type == "none":
             logits_mask = torch.ones_like(logits)
-            
-        elif self.mask_type == 'subset':
+
+        elif self.mask_type == "subset":
             # Create Mask
             pred_mask = (preds == self.cls).int()
             inds_mask = torch.argwhere(pred_mask.squeeze()).squeeze()
             masked_point = point_0[:, inds_mask, :].detach().cpu().numpy()
-            
+
             # Perform DBSCAN clustering to seperate entities of class self.cls
-            clustering = DBSCAN(eps=0.5, min_samples=5, metric='euclidean', algorithm='auto').fit(masked_point.squeeze())
-            
+            clustering = DBSCAN(
+                eps=0.5, min_samples=5, metric="euclidean", algorithm="auto"
+            ).fit(masked_point.squeeze())
+
             cluster_labels = clustering.labels_
-            
+
             # Let's extract cluster 0
             inds_clust = np.argwhere((cluster_labels == 0).astype(int)).squeeze()
-            clust_point = point_0[:, inds_mask[inds_clust], :]            
+            clust_point = point_0[:, inds_mask[inds_clust], :]
             logits_mask = torch.zeros_like(logits)
             logits_mask[:, :, inds_mask[inds_clust]] = 1
-            
-            preds_mask  = -torch.ones_like(preds)
+
+            preds_mask = -torch.ones_like(preds)
             preds_mask[:, inds_mask[inds_clust]] = 1
-            
-            entities = [point_0[0].detach().cpu().numpy(), preds_mask[0].cpu().numpy().astype(np.int32)]
-            
-            write_ply('vis_cluster.ply', entities, ['x', 'y', 'z', 'preds'])
-
-        elif self.mask_type == 'single':
+
+            entities = [
+                point_0[0].detach().cpu().numpy(),
+                preds_mask[0].cpu().numpy().astype(np.int32),
+            ]
+
+            write_ply("vis_cluster.ply", entities, ["x", "y", "z", "preds"])
+
+        elif self.mask_type == "single":
             # Create Mask
             pred_mask = (preds == self.cls).int()
             inds_mask = torch.argwhere(pred_mask.squeeze()).squeeze()
-            
+
             # First element of inds mask as ROI
             logits_mask = torch.zeros_like(logits)
-            
-            # Logits 
+
+            # Logits
             logits_mask[:, :, inds_mask[0]] = 1
-            
-            
-        
+
         return logits_mask
-#         return inds_mask[inds_clust]
-        
+
+    #         return inds_mask[inds_clust]
+
     def getGradients(self):
-#         print(f"Current class: {self.transform_map[self.cls]}")
+        #         print(f"Current class: {self.transform_map[self.cls]}")
         self.input_model.eval()
         self.end_points = self.input_model(self.batch)
-        logits = self.end_points['logits']
-                
-#         logits = self.create_mask()*logits
+        logits = self.end_points["logits"]
+
+        #         logits = self.create_mask()*logits
         softmax = torch.nn.Softmax(1)
         preds = softmax(logits).argmax(dim=1)
-                
-#         logits = logits[:, :, self.create_mask()]
-        logits = self.create_mask()*logits
-        
+
+        #         logits = logits[:, :, self.create_mask()]
+        logits = self.create_mask() * logits
+
         logits = softmax(logits)
         mask = ((preds.squeeze(0) == self.cls).unsqueeze(0)).unsqueeze(1)
-#         print(f"Number of points for class {self.transform_map[self.cls]}: ", torch.sum(mask.squeeze()).item())
+        #         print(f"Number of points for class {self.transform_map[self.cls]}: ", torch.sum(mask.squeeze()).item())
 
         logits = logits[:, self.cls, :]
         logits = torch.sum(logits, axis=-1)
-        
+
         logits = logits.squeeze()
-        
+
         self.logits = logits
 
         self.logits.backward(retain_graph=True)
-                
-        self.activations = self.end_points['activations']
-        
+
+        self.activations = self.end_points["activations"]
+
         return torch.sum(mask.squeeze()).item()
-    
-    
+
     def heatmap(self):
-#         self.logits.backward(retain_graph=True)
-#         self.logits.backward()
-        
+        #         self.logits.backward(retain_graph=True)
+        #         self.logits.backward()
+
         heatmaps_III = []
         heatmaps_III_kdtree = []
-        point_0 = self.end_points['xyz'][0].cpu().numpy().squeeze()
-#         tree = KDTree(point_0.cpu().numpy().squeeze())
-#         print(point_0.shape)
-        
+        point_0 = self.end_points["xyz"][0].cpu().numpy().squeeze()
+        #         tree = KDTree(point_0.cpu().numpy().squeeze())
+        #         print(point_0.shape)
+
         for i, act in enumerate(self.activations):
             grads = act.grad
-            if self.mode == 'normal':
-                alpha = torch.sum(grads, axis=(2,3))
-            elif self.mode == 'counterfactual':
-                alpha = -torch.sum(grads, axis=(2,3))
+            if self.mode == "normal":
+                alpha = torch.sum(grads, axis=(2, 3))
+            elif self.mode == "counterfactual":
+                alpha = -torch.sum(grads, axis=(2, 3))
             activation = act.squeeze()
             heatmap = torch.matmul(alpha, activation)
-            
+
             # Apply ReLU
             heatmap = torch.maximum(heatmap, torch.zeros_like(heatmap))
-            
+
             # Normalize
             max_val = torch.max(heatmap, dim=-1, keepdim=True)[0]
             min_val = torch.min(heatmap, dim=-1, keepdim=True)[0]
             heatmap = (heatmap - min_val) / (max_val - min_val)
             heatmap = heatmap.cpu().detach().numpy()
-            
+
             # Fill NaN values
             heatmap = np.nan_to_num(heatmap)
-            
+
             heatmaps_III.append(heatmap)
-            
+
             heatmap = heatmap.squeeze()
-            
-
-            
+
             if act.shape[2] != point_0.shape[1]:
-                for pt in self.end_points['xyz']:
+                for pt in self.end_points["xyz"]:
                     if pt.shape[1] == act.shape[2]:
                         tree = KDTree(pt.cpu().numpy().squeeze(), leaf_size=40)
                         idx = tree.query(point_0, return_distance=False).squeeze()
                         heatmaps_III_kdtree.append(np.expand_dims(heatmap[idx], 0))
             else:
-                heatmaps_III_kdtree.append(np.expand_dims(heatmap[idx],0))
-#             print(act.shape, heatmap.shape)
-         
+                heatmaps_III_kdtree.append(np.expand_dims(heatmap[idx], 0))
+        #             print(act.shape, heatmap.shape)
+
         self.heatmaps_III = heatmaps_III
         self.heatmaps_III_kdtree = heatmaps_III_kdtree
-        
-        
-        
+
     def refinement(self):
         hm = self.heatmaps_III_kdtree[-1].squeeze()
-        logits = self.end_points['logits']
-#         logits = self.create_mask()*logits
+        logits = self.end_points["logits"]
+        #         logits = self.create_mask()*logits
         softmax = torch.nn.Softmax(1)
         preds = softmax(logits).argmax(dim=1).squeeze().detach().cpu().numpy()
-        
+
         preds_mask = (preds == self.cls).astype(np.int32)
-        
+
         hm_mask = (hm > 0.5).astype(np.int32)
-        
+
         pred_final = hm_mask * preds_mask
-        
+
         print(pred_final.shape, np.unique(hm_mask), np.unique(preds_mask))
 
-        
     def visCAM(self):
         print("Saving visuals...")
-        points = self.end_points['xyz']
-        labels = self.end_points['labels'].cpu().numpy().astype(np.int32)
-        preds = self.end_points['logits'].cpu()
-        
+        points = self.end_points["xyz"]
+        labels = self.end_points["labels"].cpu().numpy().astype(np.int32)
+        preds = self.end_points["logits"].cpu()
+
         for hm_i, hm in enumerate(self.heatmaps_III):
             for p_i, p in enumerate(points):
                 if hm.shape[1] == p.shape[1]:
                     entities = [p[0].detach().cpu().numpy(), hm[0]]
                     break
-            
-            write_ply(f'./visuals/{self.mask_type}_{self.mode}_{self.transform_map[self.cls]}_{hm_i}_pgscam.ply', entities, ['x', 'y', 'z', 'heatmap'])
-            
-        
+
+            write_ply(
+                f"./visuals/{self.mask_type}_{self.mode}_{self.transform_map[self.cls]}_{hm_i}_pgscam.ply",
+                entities,
+                ["x", "y", "z", "heatmap"],
+            )
+
         for hm_i, hm in enumerate(self.heatmaps_III_kdtree):
             for p_i, p in enumerate(points):
                 if hm.shape[1] == p.shape[1]:
                     entities = [p[0].detach().cpu().numpy(), hm[0]]
                     break
-                    
-            write_ply(f'./visuals/{self.mask_type}_{self.mode}_{self.transform_map[self.cls]}_{hm_i}_pgscam_kdtree.ply', entities, ['x', 'y', 'z', 'heatmap'])       
-        
-#     def visCAM(self):
-#         print("Saving visuals...")
-#         points = self.end_points['xyz']  # list
-#         labels = self.end_points['labels'].cpu().numpy().astype(np.int32)  # [1, N]
-#         preds = self.end_points['logits'].cpu()
-#         softmax = torch.nn.Softmax(1)
-#         preds = softmax(preds).argmax(dim=1).detach().numpy().astype(np.int32) # [1, N]
-            
-#         for hm_i, hm in enumerate(self.heatmaps_I_II_III):
-#             for p_i, p in enumerate(points):
-#                 if hm.shape[1] == p.shape[1]:
-#                     entities = [p[0].detach().cpu().numpy(), hm[0].detach().cpu().numpy()]
-#             if hm.shape[1] == points[0].shape[1]:
-#                 entities += [labels[0], preds[0]]    
-#                 write_ply(f'./visuals/{self.transform_map[self.cls]}_{hm_i}_vanillaCam.ply', entities, ['x', 'y', 'z', 'heatmap', 'labels', 'preds'])
-#                 continue
-#             write_ply(f'./visuals/{self.transform_map[self.cls]}_{hm_i}_vanillaCam.ply', entities, ['x', 'y', 'z', 'heatmap'])
-
-    
-    
+
+            write_ply(
+                f"./visuals/{self.mask_type}_{self.mode}_{self.transform_map[self.cls]}_{hm_i}_pgscam_kdtree.ply",
+                entities,
+                ["x", "y", "z", "heatmap"],
+            )
+
+    #     def visCAM(self):
+    #         print("Saving visuals...")
+    #         points = self.end_points['xyz']  # list
+    #         labels = self.end_points['labels'].cpu().numpy().astype(np.int32)  # [1, N]
+    #         preds = self.end_points['logits'].cpu()
+    #         softmax = torch.nn.Softmax(1)
+    #         preds = softmax(preds).argmax(dim=1).detach().numpy().astype(np.int32) # [1, N]
+
+    #         for hm_i, hm in enumerate(self.heatmaps_I_II_III):
+    #             for p_i, p in enumerate(points):
+    #                 if hm.shape[1] == p.shape[1]:
+    #                     entities = [p[0].detach().cpu().numpy(), hm[0].detach().cpu().numpy()]
+    #             if hm.shape[1] == points[0].shape[1]:
+    #                 entities += [labels[0], preds[0]]
+    #                 write_ply(f'./visuals/{self.transform_map[self.cls]}_{hm_i}_vanillaCam.ply', entities, ['x', 'y', 'z', 'heatmap', 'labels', 'preds'])
+    #                 continue
+    #             write_ply(f'./visuals/{self.transform_map[self.cls]}_{hm_i}_vanillaCam.ply', entities, ['x', 'y', 'z', 'heatmap'])
+
     def runCAM(self):
         num_points = self.getGradients()
         self.heatmap()
-#         self.refinement()
-#         self.visCAM()
+        #         self.refinement()
+        #         self.visCAM()
         return num_points
-    
-class Drop_attack():
+
+
+class Drop_attack:
     def __init__(self):
         self.transform_map = {
-          0: "car",
-          1: "bicycle",
-          2: "motorcycle",
-          3: "truck",
-          4: "other-vehicle",
-          5: "person",
-          6: "bicyclist",
-          7: "motorcyclist",
-          8: "road",
-          9: "parking",
-          10: "sidewalk",
-          11: "other-ground",
-          12: "building",
-          13: "fence",
-          14: "vegetation",
-          15: "trunk",
-          16: "terrain",
-          17: "pole",
-          18: "traffic-sign"
-      }
-        
+            0: "car",
+            1: "bicycle",
+            2: "motorcycle",
+            3: "truck",
+            4: "other-vehicle",
+            5: "person",
+            6: "bicyclist",
+            7: "motorcyclist",
+            8: "road",
+            9: "parking",
+            10: "sidewalk",
+            11: "other-ground",
+            12: "building",
+            13: "fence",
+            14: "vegetation",
+            15: "trunk",
+            16: "terrain",
+            17: "pole",
+            18: "traffic-sign",
+        }
+
     @staticmethod
     def my_worker_init_fn(worker_id):
-#         np.random.seed(np.random.get_state()[1][0] + worker_id)
+        #         np.random.seed(np.random.get_state()[1][0] + worker_id)
         np.random.seed(0)
-    
-    def drop(self, input_model, batch, config, n_drop=[0, 1000, 2000, 3000, 4000, 5000], cls=-1, drop_type='high'):
+
+    def drop(
+        self,
+        input_model,
+        batch,
+        config,
+        n_drop=[0, 1000, 2000, 3000, 4000, 5000],
+        cls=-1,
+        drop_type="high",
+    ):
         self.cls = cls
         cam = PowerCAM(input_model, batch, config, norm=False, cls=cls)
         _ = cam.runCAM()
         heatmaps = cam.heatmaps_III
         end_points = cam.end_points
-        
+
         hm = heatmaps[-1]
-        point_0 = batch['xyz'][0].detach().cpu().numpy()
-        label_0 = batch['labels'].detach().cpu().numpy()
-        preds = batch['logits'].detach().cpu().numpy()
-        
+        point_0 = batch["xyz"][0].detach().cpu().numpy()
+        label_0 = batch["labels"].detach().cpu().numpy()
+        preds = batch["logits"].detach().cpu().numpy()
+
         point_collect = []
         miou_collect = []
         ciou_collect = []
-        
+
         for drop_ in n_drop:
             # Sorts in descending order
-#             print(f"Drop: {drop_}")
-            if drop_type == 'high':
+            #             print(f"Drop: {drop_}")
+            if drop_type == "high":
                 ind = np.argsort(hm.squeeze())[::-1]
             else:
                 ind = np.argsort(hm.squeeze())
-                
+
             point_sort = point_0[:, ind, :]
             label_sort = label_0[:, ind]
             hm_sort = hm[:, ind]
-            
+
             drop_points = point_sort[:, :drop_, :].squeeze()
             drop_labels = label_sort[:, :drop_].squeeze()
             drop_hm = hm_sort[:, :drop_].squeeze()
-            
+
             point_collect.append((drop_points, drop_labels, drop_hm))
-            
-            ent_ = [drop_points.squeeze(), drop_labels.squeeze().astype(np.int32), drop_hm.squeeze()]
-#             write_ply(f'drop_{drop_}', ent_, ['x', 'y', 'z', 'cls', 'hm'])
-            
+
+            ent_ = [
+                drop_points.squeeze(),
+                drop_labels.squeeze().astype(np.int32),
+                drop_hm.squeeze(),
+            ]
+            #             write_ply(f'drop_{drop_}', ent_, ['x', 'y', 'z', 'cls', 'hm'])
+
             rem_points = point_sort[:, drop_:, :].squeeze()
             rem_labels = label_sort[:, drop_:].squeeze()
-            
+
             DATASET = SemanticKITTI(rem_points, rem_labels)
-    
-            DATALOADER = DataLoader(DATASET, batch_size=1, shuffle=True, num_workers=20, worker_init_fn=self.my_worker_init_fn, collate_fn=DATASET.collate_fn)
-    
+
+            DATALOADER = DataLoader(
+                DATASET,
+                batch_size=1,
+                shuffle=True,
+                num_workers=20,
+                worker_init_fn=self.my_worker_init_fn,
+                collate_fn=DATASET.collate_fn,
+            )
+
             for batch_ in DATALOADER:
                 for key in batch_:
                     if type(batch_[key]) is list:
                         for i in range(len(batch_[key])):
                             batch_[key][i] = batch_[key][i].cuda()
                     else:
                         batch_[key] = batch_[key].cuda()
                 continue
-                
+
             end_points_ = input_model(batch_)
             mean_iou_, iou_list_, loss_ = self.compute_iou_(end_points_, config)
-            miou_100, ciou_100 = self.display_iou(mean_iou_, iou_list_, end_points_['xyz'][0].squeeze())
-            
+            miou_100, ciou_100 = self.display_iou(
+                mean_iou_, iou_list_, end_points_["xyz"][0].squeeze()
+            )
+
             miou_collect.append(miou_100)
             ciou_collect.append(ciou_100)
-            
-            
-            
+
             cam_ = PowerCAM(input_model, batch_, config, norm=False, cls=cls)
             _ = cam_.runCAM()
             heatmaps_ = cam_.heatmaps_III_kdtree
-            
+
             point_0 = np.expand_dims(rem_points, axis=0)
             label_0 = np.expand_dims(rem_labels, axis=0)
             hm = heatmaps_[-1]
-            
-#             entities = [batch_['xyz'][0].squeeze().detach().cpu().numpy(), batch_['labels'].squeeze().cpu().numpy().astype(np.int32), hm.squeeze()]
-            
-#             write_ply(f'./accumulated_piecewise/{self.transform_map[self.cls]}_SemanticKITTI_drop_{drop_}', entities, ['x', 'y', 'z', 'cls', 'hm'])
-            
-            
-#         pt_full = np.empty(shape=(0,3))
-#         hm_full = np.empty(shape=(0,))
-#         label_full = np.empty(shape=(0,))
-#         for entity in point_collect:
-#             pt_, lb_, hm_ = entity
-#             pt_full = np.concatenate((pt_full, pt_.squeeze()), axis=0)
-#             hm_full = np.concatenate((hm_full, hm_.squeeze()), axis=0)
-#             label_full = np.concatenate((label_full, lb_.squeeze()), axis=0)
-        
-#         pt_full = np.concatenate((pt_full, point_0.squeeze()), axis=0)
-#         hm_full = np.concatenate((hm_full, hm.squeeze()), axis=0)
-#         label_full = np.concatenate((label_full, label_0.squeeze()), axis=0)
-        
-#         ent_ = [pt_full, label_full.astype(np.int32), hm_full]
-#         write_ply(f'./accumulated_piecewise/pt_full.ply', ent_, ['x', 'y', 'z', 'label', 'pgscam'])
-#         print(pt_full.shape, hm_full.shape, label_full.shape)
-            
-            
-            
-            
-#             end_points_ = input_model(batch_)
-            
-#             mean_iou_, iou_list_, loss_ = self.compute_iou_(end_points_, config)
-#             self.display_iou(mean_iou_, iou_list_, end_points_['xyz'][0].squeeze())
-            
-#             logits = end_points_['logits']
-        
-#             softmax = torch.nn.Softmax(1)
-#             preds = softmax(logits).argmax(dim=1).squeeze().detach().cpu().numpy().astype(np.int32)
-            
-#             entities = [end_points_['xyz'][0].squeeze().detach().cpu().numpy(), end_points_['labels'].squeeze().detach().cpu().numpy().astype(np.int32), preds]
-            
-#             write_ply(f'./drop_vis/{self.transform_map[self.cls]}_SemanticKITTI_drop_{drop_}', entities, ['x', 'y', 'z', 'cls', 'preds'])
+
+        #             entities = [batch_['xyz'][0].squeeze().detach().cpu().numpy(), batch_['labels'].squeeze().cpu().numpy().astype(np.int32), hm.squeeze()]
+
+        #             write_ply(f'./accumulated_piecewise/{self.transform_map[self.cls]}_SemanticKITTI_drop_{drop_}', entities, ['x', 'y', 'z', 'cls', 'hm'])
+
+        #         pt_full = np.empty(shape=(0,3))
+        #         hm_full = np.empty(shape=(0,))
+        #         label_full = np.empty(shape=(0,))
+        #         for entity in point_collect:
+        #             pt_, lb_, hm_ = entity
+        #             pt_full = np.concatenate((pt_full, pt_.squeeze()), axis=0)
+        #             hm_full = np.concatenate((hm_full, hm_.squeeze()), axis=0)
+        #             label_full = np.concatenate((label_full, lb_.squeeze()), axis=0)
+
+        #         pt_full = np.concatenate((pt_full, point_0.squeeze()), axis=0)
+        #         hm_full = np.concatenate((hm_full, hm.squeeze()), axis=0)
+        #         label_full = np.concatenate((label_full, label_0.squeeze()), axis=0)
+
+        #         ent_ = [pt_full, label_full.astype(np.int32), hm_full]
+        #         write_ply(f'./accumulated_piecewise/pt_full.ply', ent_, ['x', 'y', 'z', 'label', 'pgscam'])
+        #         print(pt_full.shape, hm_full.shape, label_full.shape)
+
+        #             end_points_ = input_model(batch_)
+
+        #             mean_iou_, iou_list_, loss_ = self.compute_iou_(end_points_, config)
+        #             self.display_iou(mean_iou_, iou_list_, end_points_['xyz'][0].squeeze())
+
+        #             logits = end_points_['logits']
+
+        #             softmax = torch.nn.Softmax(1)
+        #             preds = softmax(logits).argmax(dim=1).squeeze().detach().cpu().numpy().astype(np.int32)
+
+        #             entities = [end_points_['xyz'][0].squeeze().detach().cpu().numpy(), end_points_['labels'].squeeze().detach().cpu().numpy().astype(np.int32), preds]
+
+        #             write_ply(f'./drop_vis/{self.transform_map[self.cls]}_SemanticKITTI_drop_{drop_}', entities, ['x', 'y', 'z', 'cls', 'preds'])
         return miou_collect, ciou_collect
-        
-        
+
     def compute_iou_(self, end_points, config):
         loss, end_points = compute_loss(end_points, config)
         acc, end_points = compute_acc(end_points)
-        
+
         iou_calc = IoUCalculator(config)
         iou_calc.add_data(end_points)
         mean_iou, iou_list = iou_calc.compute_iou()
-        
+
         return mean_iou, iou_list, loss
-        
+
     def display_iou(self, mean_iou, iou_list, points):
-#         print(f"Points shape: {points.shape}\n")
-#         print("Class Wise IoU: \n")
-#         for i in range(len(iou_list)):
-#             print(f'{self.transform_map[i]}: {iou_list[i]*100}')
-            
-#         print(f"\nMean IoU: {mean_iou * 100}\n")
-        
-#         print(f"Class IoU: {iou_list[self.cls]*100}\n")
-        
-        return (mean_iou * 100, iou_list[self.cls]*100)
-        
- 
-
-class piecewise_pGSCAM():
-    def __init__(self, input_model, batch, config, mask_type="subset", mode="normal", norm=False, cls=-1):
+        #         print(f"Points shape: {points.shape}\n")
+        #         print("Class Wise IoU: \n")
+        #         for i in range(len(iou_list)):
+        #             print(f'{self.transform_map[i]}: {iou_list[i]*100}')
+
+        #         print(f"\nMean IoU: {mean_iou * 100}\n")
+
+        #         print(f"Class IoU: {iou_list[self.cls]*100}\n")
+
+        return (mean_iou * 100, iou_list[self.cls] * 100)
+
+
+class piecewise_pGSCAM:
+    def __init__(
+        self,
+        input_model,
+        batch,
+        config,
+        mask_type="subset",
+        mode="normal",
+        norm=False,
+        cls=-1,
+    ):
         # mode: [normal, counterfactual]
         # mask_type: [none, single, subset]:- none(no mask), single(only single point), subset(collection of points)
-        
+
         self.input_model = input_model
         self.batch = batch
         self.cls = cls
         self.config = config
         self.norm = norm
@@ -437,134 +471,135 @@
         self.mode = mode
         self.mask_type = mask_type
         self.partial_heatmaps = []
         # actuall labels starts from unlabelled but we are ignoring it
         self.transform_map = {
-          0: "car",
-          1: "bicycle",
-          2: "motorcycle",
-          3: "truck",
-          4: "other-vehicle",
-          5: "person",
-          6: "bicyclist",
-          7: "motorcyclist",
-          8: "road",
-          9: "parking",
-          10: "sidewalk",
-          11: "other-ground",
-          12: "building",
-          13: "fence",
-          14: "vegetation",
-          15: "trunk",
-          16: "terrain",
-          17: "pole",
-          18: "traffic-sign"
-      }
-        
+            0: "car",
+            1: "bicycle",
+            2: "motorcycle",
+            3: "truck",
+            4: "other-vehicle",
+            5: "person",
+            6: "bicyclist",
+            7: "motorcyclist",
+            8: "road",
+            9: "parking",
+            10: "sidewalk",
+            11: "other-ground",
+            12: "building",
+            13: "fence",
+            14: "vegetation",
+            15: "trunk",
+            16: "terrain",
+            17: "pole",
+            18: "traffic-sign",
+        }
+
     @staticmethod
     def my_worker_init_fn(worker_id):
-#         np.random.seed(np.random.get_state()[1][0] + worker_id)
+        #         np.random.seed(np.random.get_state()[1][0] + worker_id)
         np.random.seed(0)
-        
+
     def runCAM(self):
         net = self.input_model
         net.eval()
         batch = self.batch
         config = self.config
-        
-#         while True:
+
+        #         while True:
         cam = PowerCAM(net, batch, config, norm=False, cls=self.cls)
         _ = cam.runCAM()
         vanilla_heatmaps = cam.heatmaps_III_kdtree
         activations = cam.activations
 
         # I am interested in act -1
         act = activations[-1]
         hm_orig = vanilla_heatmaps[-1]
-        point_orig = self.batch['xyz'][0].detach().cpu().numpy()
-        label_orig = self.batch['labels'].cpu().numpy()
-        
+        point_orig = self.batch["xyz"][0].detach().cpu().numpy()
+        label_orig = self.batch["labels"].cpu().numpy()
+
         point = point_orig
         label = label_orig
-        hm  = hm_orig
+        hm = hm_orig
         point_temp = []
-#         partial_ind_delete = ['dummy']
+        #         partial_ind_delete = ['dummy']
         itr = 5
-        
+
         while itr:
-                partial_ind_delete = np.argwhere(hm.squeeze() >= 0.8).squeeze()
-                partial_ind_accept = np.argwhere(hm.squeeze() <= 0.8).squeeze()
-                point_ = point[:, partial_ind_delete, :]
-                label_ = label[:, partial_ind_delete]
-                hm_ = hm[:, partial_ind_delete]
-                point_temp.append((point_, label_, hm_))
-                
-                point = point[:, partial_ind_accept, :]
-                label = label[:, partial_ind_accept]
-                
-                print(point.shape, label.shape, partial_ind_delete)
-
-                DATASET = SemanticKITTI(point.squeeze(), label.squeeze())
-
-                DATALOADER = DataLoader(DATASET, batch_size=1, shuffle=True, num_workers=20, worker_init_fn=self.my_worker_init_fn, collate_fn=DATASET.collate_fn)
-
-                for batch_ in DATALOADER:
-                    for key in batch_:
-                        if type(batch_[key]) is list:
-                            for i in range(len(batch_[key])):
-                                batch_[key][i] = batch_[key][i].cuda()
-                        else:
-                            batch_[key] = batch_[key].cuda()
-                    continue
-
-
-                cam_ = PowerCAM(net, batch_, config, norm=False, cls=self.cls)
-                _ = cam_.runCAM()
-                heatmaps_ = cam_.heatmaps_III_kdtree
-                hm = heatmaps_[-1]
-                
-                ent_ = [point.squeeze(), label.squeeze().astype(np.int32), hm.squeeze()]
-                write_ply(f'./accumulated_piecewise/{point.shape[1]}.ply', ent_, ['x', 'y', 'z', 'label', 'pgscam'])
-                itr = itr - 1
-                
-#             except:
-#                 break
-            
-        pt_full = np.empty(shape=(0,3))
+            partial_ind_delete = np.argwhere(hm.squeeze() >= 0.8).squeeze()
+            partial_ind_accept = np.argwhere(hm.squeeze() <= 0.8).squeeze()
+            point_ = point[:, partial_ind_delete, :]
+            label_ = label[:, partial_ind_delete]
+            hm_ = hm[:, partial_ind_delete]
+            point_temp.append((point_, label_, hm_))
+
+            point = point[:, partial_ind_accept, :]
+            label = label[:, partial_ind_accept]
+
+            print(point.shape, label.shape, partial_ind_delete)
+
+            DATASET = SemanticKITTI(point.squeeze(), label.squeeze())
+
+            DATALOADER = DataLoader(
+                DATASET,
+                batch_size=1,
+                shuffle=True,
+                num_workers=20,
+                worker_init_fn=self.my_worker_init_fn,
+                collate_fn=DATASET.collate_fn,
+            )
+
+            for batch_ in DATALOADER:
+                for key in batch_:
+                    if type(batch_[key]) is list:
+                        for i in range(len(batch_[key])):
+                            batch_[key][i] = batch_[key][i].cuda()
+                    else:
+                        batch_[key] = batch_[key].cuda()
+                continue
+
+            cam_ = PowerCAM(net, batch_, config, norm=False, cls=self.cls)
+            _ = cam_.runCAM()
+            heatmaps_ = cam_.heatmaps_III_kdtree
+            hm = heatmaps_[-1]
+
+            ent_ = [point.squeeze(), label.squeeze().astype(np.int32), hm.squeeze()]
+            write_ply(
+                f"./accumulated_piecewise/{point.shape[1]}.ply",
+                ent_,
+                ["x", "y", "z", "label", "pgscam"],
+            )
+            itr = itr - 1
+
+        #             except:
+        #                 break
+
+        pt_full = np.empty(shape=(0, 3))
         hm_full = np.empty(shape=(0,))
         label_full = np.empty(shape=(0,))
         for entity in point_temp:
             pt_, lb_, hm_ = entity
             pt_full = np.concatenate((pt_full, pt_.squeeze()), axis=0)
             hm_full = np.concatenate((hm_full, hm_.squeeze()), axis=0)
             label_full = np.concatenate((label_full, lb_.squeeze()), axis=0)
-        
+
         pt_full = np.concatenate((pt_full, point.squeeze()), axis=0)
         hm_full = np.concatenate((hm_full, hm.squeeze()), axis=0)
         label_full = np.concatenate((label_full, label.squeeze()), axis=0)
-        
+
         ent_ = [pt_full, label_full.astype(np.int32), hm_full]
-        write_ply(f'./accumulated_piecewise/pt_full.ply', ent_, ['x', 'y', 'z', 'label', 'pgscam'])
+        write_ply(
+            f"./accumulated_piecewise/pt_full.ply",
+            ent_,
+            ["x", "y", "z", "label", "pgscam"],
+        )
         print(pt_full.shape, hm_full.shape, label_full.shape)
-        
-            
-            
-            
+
 
 #         print(point_.shape)
-            
-            
-        
-        
-        
-        
-        
-        
-        
-        
-        
-        
+
+
 #     def getmIoU(self):
 # #         num_points = self.getGradients()
 #         hm_IoU = []
 #         hm_1_list, hm_2_list, hm_3_list = self.heatmaps_I, self.heatmaps_I_II, self.heatmaps_I_II_III
 # #         hm_1_list, hm_2_list, hm_3_list = self.heatmap()
@@ -574,137 +609,143 @@
 # #         print(hm_1.shape, hm_2.shape, hm_3.shape)
 #         logits = self.end_points['logits']
 #         softmax = torch.nn.Softmax(1)
 #         preds = softmax(logits).argmax(dim=1).squeeze()
 
-        
+
 #         pred_mask = (preds == self.cls).type(torch.int32)
 #         hm_1 = (hm_1 > self.threshold[0]).type(torch.int32)
 #         hm_2 = (hm_2 > self.threshold[1]).type(torch.int32)
 #         hm_3 = (hm_3 > self.threshold[2]).type(torch.int32)
 #         iou_metric = IoUCalculator()
 #         iou_metric.add_data(hm_1, pred_mask)
 #         mean_iou, iou_list = iou_metric.compute_iou()
 #         cls_iou = iou_list[1]*100
 #         hm_IoU.append(cls_iou)
-        
+
 # #         iou_metric = IoUCalculator()
 #         iou_metric.add_data(hm_2, pred_mask)
 #         mean_iou, iou_list = iou_metric.compute_iou()
 #         cls_iou = iou_list[1]*100
 #         hm_IoU.append(cls_iou)
-        
-        
+
+
 # #         iou_metric = IoUCalculator()
 #         iou_metric.add_data(hm_3, pred_mask)
 #         mean_iou, iou_list = iou_metric.compute_iou()
 #         cls_iou = iou_list[1]*100
 #         hm_IoU.append(cls_iou)
 
 #         return hm_IoU
 #         self.visCAM()
 
 
-class TSNE_cls():
+class TSNE_cls:
     def __init__(self, input_model, batch, config, norm=False, cls=-1):
         self.input_model = input_model
         self.batch = batch
         self.cls = cls
         self.config = config
         self.norm = norm
         self.is_masked = True
         self.threshold = [0.1, 0.3, 0.3]
-        
+
         # actuall labels starts from unlabelled but we are ignoring it
         self.transform_map = {
-          0: "car",
-          1: "bicycle",
-          2: "motorcycle",
-          3: "truck",
-          4: "other-vehicle",
-          5: "person",
-          6: "bicyclist",
-          7: "motorcyclist",
-          8: "road",
-          9: "parking",
-          10: "sidewalk",
-          11: "other-ground",
-          12: "building",
-          13: "fence",
-          14: "vegetation",
-          15: "trunk",
-          16: "terrain",
-          17: "pole",
-          18: "traffic-sign"
-      }
-        
+            0: "car",
+            1: "bicycle",
+            2: "motorcycle",
+            3: "truck",
+            4: "other-vehicle",
+            5: "person",
+            6: "bicyclist",
+            7: "motorcyclist",
+            8: "road",
+            9: "parking",
+            10: "sidewalk",
+            11: "other-ground",
+            12: "building",
+            13: "fence",
+            14: "vegetation",
+            15: "trunk",
+            16: "terrain",
+            17: "pole",
+            18: "traffic-sign",
+        }
+
     def getActivations(self):
         print(f"Current class: {self.transform_map[self.cls]}")
         self.input_model.eval()
         self.end_points = self.input_model(self.batch)
-        logits = self.end_points['logits']
-        
+        logits = self.end_points["logits"]
+
         softmax = torch.nn.Softmax(1)
         preds = softmax(logits).argmax(dim=1)
-        
+
         logits = softmax(logits)
         mask = ((preds.squeeze(0) == self.cls).unsqueeze(0)).unsqueeze(1)
-        print(f"Number of points for class {self.transform_map[self.cls]}: ", torch.sum(mask.squeeze()).item())
-        
-        self.activations = self.end_points['activations']
-        
+        print(
+            f"Number of points for class {self.transform_map[self.cls]}: ",
+            torch.sum(mask.squeeze()).item(),
+        )
+
+        self.activations = self.end_points["activations"]
+
         print(len(self.activations))
-        
+
         return torch.sum(mask.squeeze()).item()
-    
-    
+
     def t_sne(self, i_act):
         act = self.activations[i_act]
-        
-        labels = self.end_points['labels'].cpu().numpy().astype(np.int32).squeeze()
-        logits = self.end_points['logits']
+
+        labels = self.end_points["labels"].cpu().numpy().astype(np.int32).squeeze()
+        logits = self.end_points["logits"]
         softmax = torch.nn.Softmax(1)
         preds = softmax(logits).argmax(dim=1).squeeze().cpu().numpy().astype(np.int32)
-        
+
         act = act.squeeze().T
-#         tsne = TSNE()
+        #         tsne = TSNE()
         reducer = PCA(n_components=2)
         act_reduce = reducer.fit_transform(act.detach().cpu().numpy())
-        np.save(f'./tsne_vis/pca_act_{i_act}', act_reduce)
-        
+        np.save(f"./tsne_vis/pca_act_{i_act}", act_reduce)
+
         print("Computing umap:")
         reducer = TSNE()
         act_reduce = reducer.fit_transform(act.detach().cpu().numpy())
-        np.save(f'./tsne_vis/tsne_act_{i_act}', act_reduce)
-        
-        np.save(f'./tsne_vis/preds', preds)
-        np.save(f'./tsne_vis/labels', labels)
-        palette = sns.color_palette('bright', 10)
-#         sns.scatterplot(act_reduce[:, 0], act_reduce[:, 1], hue=labels, legend='full', palette=palette)
-
-        
-        
+        np.save(f"./tsne_vis/tsne_act_{i_act}", act_reduce)
+
+        np.save(f"./tsne_vis/preds", preds)
+        np.save(f"./tsne_vis/labels", labels)
+        palette = sns.color_palette("bright", 10)
+
+    #         sns.scatterplot(act_reduce[:, 0], act_reduce[:, 1], hue=labels, legend='full', palette=palette)
+
     def runCAM(self):
-        cam = PowerCAM(self.input_model, self.batch, self.config, norm=True, cls=self.cls, mode='normal', mask_type='none')
+        cam = PowerCAM(
+            self.input_model,
+            self.batch,
+            self.config,
+            norm=True,
+            cls=self.cls,
+            mode="normal",
+            mask_type="none",
+        )
         num_points = cam.runCAM()
         print(num_points)
-        
+
         num_points = self.getActivations()
         for act_i in [0, 7, 8, 9, 10]:
             self.t_sne(act_i)
         return num_points
-        
-    
 
 
 class IoUCalculator_heatmaps:
     def __init__(self):
         self.num_classes = 2
         self.gt_classes = [0 for _ in range(self.num_classes)]
         self.positive_classes = [0 for _ in range(self.num_classes)]
         self.true_positive_classes = [0 for _ in range(self.num_classes)]
-       
 
     def add_data(self, hm, pred_mask):
         hm_valid = hm.detach().cpu().numpy()
         pred_mask_valid = pred_mask.detach().cpu().numpy()
 
@@ -713,20 +754,33 @@
 
         correct = np.sum(hm_valid == pred_mask_valid)
         val_total_correct += correct
         val_total_seen += len(pred_mask_valid)
 
-        conf_matrix = confusion_matrix(pred_mask_valid, hm_valid, labels=np.arange(0, self.num_classes, 1))
+        conf_matrix = confusion_matrix(
+            pred_mask_valid, hm_valid, labels=np.arange(0, self.num_classes, 1)
+        )
         self.gt_classes += np.sum(conf_matrix, axis=1)
         self.positive_classes += np.sum(conf_matrix, axis=0)
         self.true_positive_classes += np.diagonal(conf_matrix)
 
     def compute_iou(self):
         iou_list = []
         for n in range(0, self.num_classes, 1):
-            if float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n]) != 0:
-                iou = self.true_positive_classes[n] / float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n])
+            if (
+                float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
+                != 0
+            ):
+                iou = self.true_positive_classes[n] / float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
                 iou_list.append(iou)
             else:
                 iou_list.append(0.0)
         mean_iou = sum(iou_list) / float(self.num_classes)
         return mean_iou, iou_list
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/evaluate_DALES.py	2024-06-30 22:34:18.118484+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/evaluate_DALES.py	2024-07-08 11:53:43.121621+00:00
@@ -39,58 +39,61 @@
 #
 #           Config Class
 #       \******************/
 #
 
+
 class NPM3DConfig(Config):
     """
     Override the parameters you want to modify for this dataset
     """
 
     ####################
     # Dataset parameters
     ####################
 
     # Dataset name
-    dataset = 'NPM3D'
+    dataset = "NPM3D"
 
     # Number of classes in the dataset (This value is overwritten by dataset class when Initializating dataset).
     num_classes = None
 
     # Type of task performed on this dataset (also overwritten)
-    dataset_task = ''
+    dataset_task = ""
 
     # Number of CPU threads for the input pipeline
     input_threads = 10
 
     #########################
     # Architecture definition
     #########################
 
     # # Define layers
-    architecture = ['simple',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary']
+    architecture = [
+        "simple",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+    ]
 
     ###################
     # KPConv parameters
     ###################
 
@@ -111,14 +114,14 @@
 
     # Radius of the area of influence of each kernel point in "number grid cell". (1.0 is the standard value)
     KP_extent = 1.2
 
     # Behavior of convolutions in ('constant', 'linear', 'gaussian')
-    KP_influence = 'linear'
+    KP_influence = "linear"
 
     # Aggregation function of KPConv in ('closest', 'sum')
-    aggregation_mode = 'sum'
+    aggregation_mode = "sum"
 
     # Choice of input features
     first_features_dim = 128
     in_features_dim = 1
 
@@ -130,14 +133,14 @@
     batch_norm_momentum = 0.02
 
     # Deformable offset loss
     # 'point2point' fitting geometry by penalizing distance from deform point to input points
     # 'point2plane' fitting geometry by penalizing distance from deform point to input point triplet (not implemented)
-    deform_fitting_mode = 'point2point'
-    deform_fitting_power = 1.0              # Multiplier for the fitting/repulsive loss
-    deform_lr_factor = 0.1                  # Multiplier for learning rate applied to the deformations
-    repulse_extent = 1.2                    # Distance of repulsion for deformed kernel points
+    deform_fitting_mode = "point2point"
+    deform_fitting_power = 1.0  # Multiplier for the fitting/repulsive loss
+    deform_lr_factor = 0.1  # Multiplier for learning rate applied to the deformations
+    repulse_extent = 1.2  # Distance of repulsion for deformed kernel points
 
     #####################
     # Training parameters
     #####################
 
@@ -163,150 +166,159 @@
     checkpoint_gap = 50
 
     # Augmentations
     augment_scale_anisotropic = True
     augment_symmetries = [True, False, False]
-    augment_rotation = 'vertical'
+    augment_rotation = "vertical"
     augment_scale_min = 0.9
     augment_scale_max = 1.1
     augment_noise = 0.001
     augment_color = 0.8
 
     # The way we balance segmentation loss
     #   > 'none': Each point in the whole batch has the same contribution.
     #   > 'class': Each class has the same contribution (points are weighted according to class balance)
     #   > 'batch': Each cloud in the batch has the same contribution (points are weighted according cloud sizes)
-    segloss_balance = 'none'
+    segloss_balance = "none"
 
     # Do we nee to save convergence
     saving = False
-    saving_path = ''
+    saving_path = ""
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Main Call
 #       \***************/
 #
 
-if __name__ == '__main__':
+if __name__ == "__main__":
 
     ############################
     # Initialize the environment
     ############################
 
     # Set which gpu is going to be used
-    GPU_ID = '0'
+    GPU_ID = "0"
 
     # Set GPU visible device
-    os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID
+    os.environ["CUDA_VISIBLE_DEVICES"] = GPU_ID
 
     ###############
     # Previous chkp
     ###############
 
     # Choose here if you want to start training from a previous snapshot (None for new training)
     # previous_training_path = 'Log_2020-03-19_19-53-27'
     # previous_training_path = 'KPConv_NPM3d_450'
 
-    previous_training_path = 'KPConv_DALES_210'
+    previous_training_path = "KPConv_DALES_210"
     # Choose index of checkpoint to start from. If None, uses the latest chkp
     chkp_idx = None
     if previous_training_path:
 
         # Find all snapshot in the chosen training folder
-        chkp_path = os.path.join('results', previous_training_path, 'checkpoints')
-        chkps = [f for f in os.listdir(chkp_path) if f[:4] == 'chkp']
+        chkp_path = os.path.join("results", previous_training_path, "checkpoints")
+        chkps = [f for f in os.listdir(chkp_path) if f[:4] == "chkp"]
 
         # Find which snapshot to restore
         if chkp_idx is None:
-            chosen_chkp = 'current_chkp.tar'
+            chosen_chkp = "current_chkp.tar"
         else:
             chosen_chkp = np.sort(chkps)[chkp_idx]
-        chosen_chkp = os.path.join('results', previous_training_path, 'checkpoints', chosen_chkp)
+        chosen_chkp = os.path.join(
+            "results", previous_training_path, "checkpoints", chosen_chkp
+        )
 
     else:
         chosen_chkp = None
 
     ##############
     # Prepare Data
     ##############
 
     print()
-    print('Data Preparation')
-    print('****************')
+    print("Data Preparation")
+    print("****************")
 
     # Initialize configuration class
     config = NPM3DConfig()
     if previous_training_path:
-        config.load(os.path.join('results', previous_training_path))
+        config.load(os.path.join("results", previous_training_path))
         config.saving_path = None
 
     # Get path from argument if given
     if len(sys.argv) > 1:
         config.saving_path = sys.argv[1]
 
     # Initialize datasets
-    training_dataset = NPM3DDataset(config, set='training', use_potentials=True)
-    test_dataset = NPM3DDataset(config, set='validation', use_potentials=True)
+    training_dataset = NPM3DDataset(config, set="training", use_potentials=True)
+    test_dataset = NPM3DDataset(config, set="validation", use_potentials=True)
 
     # Initialize samplers
     training_sampler = NPM3DSampler(training_dataset)
     test_sampler = NPM3DSampler(test_dataset)
 
     # Initialize the dataloader
-    training_loader = DataLoader(training_dataset,
-                                 batch_size=1,
-                                 sampler=training_sampler,
-                                 collate_fn=NPM3DCollate,
-                                 num_workers=config.input_threads,
-                                 pin_memory=True)
-    test_loader = DataLoader(test_dataset,
-                             batch_size=1,
-                             sampler=test_sampler,
-                             collate_fn=NPM3DCollate,
-                             num_workers=config.input_threads,
-                             pin_memory=True)
+    training_loader = DataLoader(
+        training_dataset,
+        batch_size=1,
+        sampler=training_sampler,
+        collate_fn=NPM3DCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
+    test_loader = DataLoader(
+        test_dataset,
+        batch_size=1,
+        sampler=test_sampler,
+        collate_fn=NPM3DCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
 
     # Calibrate samplers
     training_sampler.calibration(training_loader, verbose=True)
     test_sampler.calibration(test_loader, verbose=True)
 
     # Optional debug functions
     # debug_timing(training_dataset, training_loader)
     # debug_timing(test_dataset, test_loader)
     # debug_upsampling(training_dataset, training_loader)
 
-    print('\nModel Preparation')
-    print('*****************')
+    print("\nModel Preparation")
+    print("*****************")
 
     # Define network model
     t1 = time.time()
     net = KPFCNN(config, training_dataset.label_values, training_dataset.ignored_labels)
 
     debug = False
     if debug:
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         print(net)
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         for param in net.parameters():
             if param.requires_grad:
                 print(param.shape)
-        print('\n*************************************\n')
-        print("Model size %i" % sum(param.numel() for param in net.parameters() if param.requires_grad))
-        print('\n*************************************\n')
+        print("\n*************************************\n")
+        print(
+            "Model size %i"
+            % sum(param.numel() for param in net.parameters() if param.requires_grad)
+        )
+        print("\n*************************************\n")
 
     # Define a trainer class
 
-    print('Done in {:.1f}s\n'.format(time.time() - t1))
+    print("Done in {:.1f}s\n".format(time.time() - t1))
     tester = ModelTester(net, chkp_path=chosen_chkp)
 
-    print('\nStart training')
-    print('**************')
+    print("\nStart training")
+    print("**************")
     config.saving = False
     config.validation_size = 1000
     config.batch_num = 10
     # Training
     tester.cloud_segmentation_test(net, test_loader, config, num_votes=3)
 
-    print('Forcing exit now')
+    print("Forcing exit now")
     os.kill(os.getpid(), signal.SIGINT)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/evaluate_NPM3D.py	2024-06-30 22:34:18.118484+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/evaluate_NPM3D.py	2024-07-08 11:53:43.328306+00:00
@@ -39,58 +39,61 @@
 #
 #           Config Class
 #       \******************/
 #
 
+
 class NPM3DConfig(Config):
     """
     Override the parameters you want to modify for this dataset
     """
 
     ####################
     # Dataset parameters
     ####################
 
     # Dataset name
-    dataset = 'NPM3D'
+    dataset = "NPM3D"
 
     # Number of classes in the dataset (This value is overwritten by dataset class when Initializating dataset).
     num_classes = None
 
     # Type of task performed on this dataset (also overwritten)
-    dataset_task = ''
+    dataset_task = ""
 
     # Number of CPU threads for the input pipeline
     input_threads = 10
 
     #########################
     # Architecture definition
     #########################
 
     # # Define layers
-    architecture = ['simple',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary']
+    architecture = [
+        "simple",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+    ]
 
     ###################
     # KPConv parameters
     ###################
 
@@ -111,14 +114,14 @@
 
     # Radius of the area of influence of each kernel point in "number grid cell". (1.0 is the standard value)
     KP_extent = 1.2
 
     # Behavior of convolutions in ('constant', 'linear', 'gaussian')
-    KP_influence = 'linear'
+    KP_influence = "linear"
 
     # Aggregation function of KPConv in ('closest', 'sum')
-    aggregation_mode = 'sum'
+    aggregation_mode = "sum"
 
     # Choice of input features
     first_features_dim = 128
     in_features_dim = 1
 
@@ -130,14 +133,14 @@
     batch_norm_momentum = 0.02
 
     # Deformable offset loss
     # 'point2point' fitting geometry by penalizing distance from deform point to input points
     # 'point2plane' fitting geometry by penalizing distance from deform point to input point triplet (not implemented)
-    deform_fitting_mode = 'point2point'
-    deform_fitting_power = 1.0              # Multiplier for the fitting/repulsive loss
-    deform_lr_factor = 0.1                  # Multiplier for learning rate applied to the deformations
-    repulse_extent = 1.2                    # Distance of repulsion for deformed kernel points
+    deform_fitting_mode = "point2point"
+    deform_fitting_power = 1.0  # Multiplier for the fitting/repulsive loss
+    deform_lr_factor = 0.1  # Multiplier for learning rate applied to the deformations
+    repulse_extent = 1.2  # Distance of repulsion for deformed kernel points
 
     #####################
     # Training parameters
     #####################
 
@@ -163,147 +166,156 @@
     checkpoint_gap = 50
 
     # Augmentations
     augment_scale_anisotropic = True
     augment_symmetries = [True, False, False]
-    augment_rotation = 'vertical'
+    augment_rotation = "vertical"
     augment_scale_min = 0.9
     augment_scale_max = 1.1
     augment_noise = 0.001
     augment_color = 0.8
 
     # The way we balance segmentation loss
     #   > 'none': Each point in the whole batch has the same contribution.
     #   > 'class': Each class has the same contribution (points are weighted according to class balance)
     #   > 'batch': Each cloud in the batch has the same contribution (points are weighted according cloud sizes)
-    segloss_balance = 'none'
+    segloss_balance = "none"
 
     # Do we nee to save convergence
     saving = False
-    saving_path = ''
+    saving_path = ""
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Main Call
 #       \***************/
 #
 
-if __name__ == '__main__':
+if __name__ == "__main__":
 
     ############################
     # Initialize the environment
     ############################
 
     # Set which gpu is going to be used
-    GPU_ID = '0'
+    GPU_ID = "0"
 
     # Set GPU visible device
-    os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID
+    os.environ["CUDA_VISIBLE_DEVICES"] = GPU_ID
 
     ###############
     # Previous chkp
     ###############
 
     # Choose here if you want to start training from a previous snapshot (None for new training)
     # previous_training_path = 'Log_2020-03-19_19-53-27'
-    previous_training_path = 'KPConv_NPM3d_450'
+    previous_training_path = "KPConv_NPM3d_450"
 
     # Choose index of checkpoint to start from. If None, uses the latest chkp
     chkp_idx = None
     if previous_training_path:
 
         # Find all snapshot in the chosen training folder
-        chkp_path = os.path.join('results', previous_training_path, 'checkpoints')
-        chkps = [f for f in os.listdir(chkp_path) if f[:4] == 'chkp']
+        chkp_path = os.path.join("results", previous_training_path, "checkpoints")
+        chkps = [f for f in os.listdir(chkp_path) if f[:4] == "chkp"]
 
         # Find which snapshot to restore
         if chkp_idx is None:
-            chosen_chkp = 'current_chkp.tar'
+            chosen_chkp = "current_chkp.tar"
         else:
             chosen_chkp = np.sort(chkps)[chkp_idx]
-        chosen_chkp = os.path.join('results', previous_training_path, 'checkpoints', chosen_chkp)
+        chosen_chkp = os.path.join(
+            "results", previous_training_path, "checkpoints", chosen_chkp
+        )
 
     else:
         chosen_chkp = None
 
     ##############
     # Prepare Data
     ##############
 
     print()
-    print('Data Preparation')
-    print('****************')
+    print("Data Preparation")
+    print("****************")
 
     # Initialize configuration class
     config = NPM3DConfig()
     if previous_training_path:
-        config.load(os.path.join('results', previous_training_path))
+        config.load(os.path.join("results", previous_training_path))
         config.saving_path = None
 
     # Get path from argument if given
     if len(sys.argv) > 1:
         config.saving_path = sys.argv[1]
 
     # Initialize datasets
-    training_dataset = NPM3DDataset(config, set='training', use_potentials=True)
-    test_dataset = NPM3DDataset(config, set='validation', use_potentials=True)
+    training_dataset = NPM3DDataset(config, set="training", use_potentials=True)
+    test_dataset = NPM3DDataset(config, set="validation", use_potentials=True)
 
     # Initialize samplers
     training_sampler = NPM3DSampler(training_dataset)
     test_sampler = NPM3DSampler(test_dataset)
 
     # Initialize the dataloader
-    training_loader = DataLoader(training_dataset,
-                                 batch_size=1,
-                                 sampler=training_sampler,
-                                 collate_fn=NPM3DCollate,
-                                 num_workers=config.input_threads,
-                                 pin_memory=True)
-    test_loader = DataLoader(test_dataset,
-                             batch_size=1,
-                             sampler=test_sampler,
-                             collate_fn=NPM3DCollate,
-                             num_workers=config.input_threads,
-                             pin_memory=True)
+    training_loader = DataLoader(
+        training_dataset,
+        batch_size=1,
+        sampler=training_sampler,
+        collate_fn=NPM3DCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
+    test_loader = DataLoader(
+        test_dataset,
+        batch_size=1,
+        sampler=test_sampler,
+        collate_fn=NPM3DCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
 
     # Calibrate samplers
     training_sampler.calibration(training_loader, verbose=True)
     test_sampler.calibration(test_loader, verbose=True)
 
     # Optional debug functions
     # debug_timing(training_dataset, training_loader)
     # debug_timing(test_dataset, test_loader)
     # debug_upsampling(training_dataset, training_loader)
 
-    print('\nModel Preparation')
-    print('*****************')
+    print("\nModel Preparation")
+    print("*****************")
 
     # Define network model
     t1 = time.time()
     net = KPFCNN(config, training_dataset.label_values, training_dataset.ignored_labels)
 
     debug = False
     if debug:
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         print(net)
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         for param in net.parameters():
             if param.requires_grad:
                 print(param.shape)
-        print('\n*************************************\n')
-        print("Model size %i" % sum(param.numel() for param in net.parameters() if param.requires_grad))
-        print('\n*************************************\n')
+        print("\n*************************************\n")
+        print(
+            "Model size %i"
+            % sum(param.numel() for param in net.parameters() if param.requires_grad)
+        )
+        print("\n*************************************\n")
 
     # Define a trainer class
 
-    print('Done in {:.1f}s\n'.format(time.time() - t1))
+    print("Done in {:.1f}s\n".format(time.time() - t1))
     tester = ModelTester(net, chkp_path=chosen_chkp)
 
-    print('\nStart training')
-    print('**************')
+    print("\nStart training")
+    print("**************")
     config.saving = False
     # Training
     tester.cloud_segmentation_test(net, test_loader, config, num_votes=10)
 
-    print('Forcing exit now')
+    print("Forcing exit now")
     os.kill(os.getpid(), signal.SIGINT)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/common.py	2024-06-30 22:34:18.097651+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/common.py	2024-07-08 11:53:43.532553+00:00
@@ -39,10 +39,11 @@
 #
 #           Utility functions
 #       \***********************/
 #
 
+
 def grid_subsampling(points, features=None, labels=None, sampleDl=0.1, verbose=0):
     """
     CPP wrapper for a grid subsampling (method = barycenter for points and features)
     :param points: (N, 3) matrix of input points
     :param features: optional (N, d) matrix of features (floating number)
@@ -51,33 +52,39 @@
     :param verbose: 1 to display
     :return: subsampled points, with features and/or labels depending of the input
     """
 
     if (features is None) and (labels is None):
-        return cpp_subsampling.subsample(points,
-                                         sampleDl=sampleDl,
-                                         verbose=verbose)
-    elif (labels is None):
-        return cpp_subsampling.subsample(points,
-                                         features=features,
-                                         sampleDl=sampleDl,
-                                         verbose=verbose)
-    elif (features is None):
-        return cpp_subsampling.subsample(points,
-                                         classes=labels,
-                                         sampleDl=sampleDl,
-                                         verbose=verbose)
+        return cpp_subsampling.subsample(points, sampleDl=sampleDl, verbose=verbose)
+    elif labels is None:
+        return cpp_subsampling.subsample(
+            points, features=features, sampleDl=sampleDl, verbose=verbose
+        )
+    elif features is None:
+        return cpp_subsampling.subsample(
+            points, classes=labels, sampleDl=sampleDl, verbose=verbose
+        )
     else:
-        return cpp_subsampling.subsample(points,
-                                         features=features,
-                                         classes=labels,
-                                         sampleDl=sampleDl,
-                                         verbose=verbose)
-
-
-def batch_grid_subsampling(points, batches_len, features=None, labels=None,
-                           sampleDl=0.1, max_p=0, verbose=0, random_grid_orient=True):
+        return cpp_subsampling.subsample(
+            points,
+            features=features,
+            classes=labels,
+            sampleDl=sampleDl,
+            verbose=verbose,
+        )
+
+
+def batch_grid_subsampling(
+    points,
+    batches_len,
+    features=None,
+    labels=None,
+    sampleDl=0.1,
+    max_p=0,
+    verbose=0,
+    random_grid_orient=True,
+):
     """
     CPP wrapper for a grid subsampling (method = barycenter for points and features)
     :param points: (N, 3) matrix of input points
     :param features: optional (N, d) matrix of features (floating number)
     :param labels: optional (N,) matrix of integer labels
@@ -97,11 +104,13 @@
         # Choose two random angles for the first vector in polar coordinates
         theta = np.random.rand(B) * 2 * np.pi
         phi = (np.random.rand(B) - 0.5) * np.pi
 
         # Create the first vector in carthesian coordinates
-        u = np.vstack([np.cos(theta) * np.cos(phi), np.sin(theta) * np.cos(phi), np.sin(phi)])
+        u = np.vstack(
+            [np.cos(theta) * np.cos(phi), np.sin(theta) * np.cos(phi), np.sin(phi)]
+        )
 
         # Choose a random rotation angle
         alpha = np.random.rand(B) * 2 * np.pi
 
         # Create the rotation matrix with this vector and angle
@@ -113,73 +122,87 @@
 
         i0 = 0
         points = points.copy()
         for bi, length in enumerate(batches_len):
             # Apply the rotation
-            points[i0:i0 + length, :] = np.sum(np.expand_dims(points[i0:i0 + length, :], 2) * R[bi], axis=1)
+            points[i0 : i0 + length, :] = np.sum(
+                np.expand_dims(points[i0 : i0 + length, :], 2) * R[bi], axis=1
+            )
             i0 += length
 
     #######################
     # Sunsample and realign
     #######################
 
     if (features is None) and (labels is None):
-        s_points, s_len = cpp_subsampling.subsample_batch(points,
-                                                          batches_len,
-                                                          sampleDl=sampleDl,
-                                                          max_p=max_p,
-                                                          verbose=verbose)
+        s_points, s_len = cpp_subsampling.subsample_batch(
+            points, batches_len, sampleDl=sampleDl, max_p=max_p, verbose=verbose
+        )
         if random_grid_orient:
             i0 = 0
             for bi, length in enumerate(s_len):
-                s_points[i0:i0 + length, :] = np.sum(np.expand_dims(s_points[i0:i0 + length, :], 2) * R[bi].T, axis=1)
+                s_points[i0 : i0 + length, :] = np.sum(
+                    np.expand_dims(s_points[i0 : i0 + length, :], 2) * R[bi].T, axis=1
+                )
                 i0 += length
         return s_points, s_len
 
-    elif (labels is None):
-        s_points, s_len, s_features = cpp_subsampling.subsample_batch(points,
-                                                                      batches_len,
-                                                                      features=features,
-                                                                      sampleDl=sampleDl,
-                                                                      max_p=max_p,
-                                                                      verbose=verbose)
+    elif labels is None:
+        s_points, s_len, s_features = cpp_subsampling.subsample_batch(
+            points,
+            batches_len,
+            features=features,
+            sampleDl=sampleDl,
+            max_p=max_p,
+            verbose=verbose,
+        )
         if random_grid_orient:
             i0 = 0
             for bi, length in enumerate(s_len):
                 # Apply the rotation
-                s_points[i0:i0 + length, :] = np.sum(np.expand_dims(s_points[i0:i0 + length, :], 2) * R[bi].T, axis=1)
+                s_points[i0 : i0 + length, :] = np.sum(
+                    np.expand_dims(s_points[i0 : i0 + length, :], 2) * R[bi].T, axis=1
+                )
                 i0 += length
         return s_points, s_len, s_features
 
-    elif (features is None):
-        s_points, s_len, s_labels = cpp_subsampling.subsample_batch(points,
-                                                                    batches_len,
-                                                                    classes=labels,
-                                                                    sampleDl=sampleDl,
-                                                                    max_p=max_p,
-                                                                    verbose=verbose)
+    elif features is None:
+        s_points, s_len, s_labels = cpp_subsampling.subsample_batch(
+            points,
+            batches_len,
+            classes=labels,
+            sampleDl=sampleDl,
+            max_p=max_p,
+            verbose=verbose,
+        )
         if random_grid_orient:
             i0 = 0
             for bi, length in enumerate(s_len):
                 # Apply the rotation
-                s_points[i0:i0 + length, :] = np.sum(np.expand_dims(s_points[i0:i0 + length, :], 2) * R[bi].T, axis=1)
+                s_points[i0 : i0 + length, :] = np.sum(
+                    np.expand_dims(s_points[i0 : i0 + length, :], 2) * R[bi].T, axis=1
+                )
                 i0 += length
         return s_points, s_len, s_labels
 
     else:
-        s_points, s_len, s_features, s_labels = cpp_subsampling.subsample_batch(points,
-                                                                              batches_len,
-                                                                              features=features,
-                                                                              classes=labels,
-                                                                              sampleDl=sampleDl,
-                                                                              max_p=max_p,
-                                                                              verbose=verbose)
+        s_points, s_len, s_features, s_labels = cpp_subsampling.subsample_batch(
+            points,
+            batches_len,
+            features=features,
+            classes=labels,
+            sampleDl=sampleDl,
+            max_p=max_p,
+            verbose=verbose,
+        )
         if random_grid_orient:
             i0 = 0
             for bi, length in enumerate(s_len):
                 # Apply the rotation
-                s_points[i0:i0 + length, :] = np.sum(np.expand_dims(s_points[i0:i0 + length, :], 2) * R[bi].T, axis=1)
+                s_points[i0 : i0 + length, :] = np.sum(
+                    np.expand_dims(s_points[i0 : i0 + length, :], 2) * R[bi].T, axis=1
+                )
                 i0 += length
         return s_points, s_len, s_features, s_labels
 
 
 def batch_neighbors(queries, supports, q_batches, s_batches, radius):
@@ -191,11 +214,13 @@
     :param s_batches: (B)the list of lengths of batch elements in supports
     :param radius: float32
     :return: neighbors indices
     """
 
-    return cpp_neighbors.batch_query(queries, supports, q_batches, s_batches, radius=radius)
+    return cpp_neighbors.batch_query(
+        queries, supports, q_batches, s_batches, radius=radius
+    )
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Class definition
@@ -209,11 +234,11 @@
         """
         Initialize parameters of the dataset here.
         """
 
         self.name = name
-        self.path = ''
+        self.path = ""
         self.label_to_names = {}
         self.num_classes = 0
         self.label_values = np.zeros((0,), dtype=np.int32)
         self.label_names = []
         self.label_to_idx = {}
@@ -254,31 +279,39 @@
 
         # Initialize rotation matrix
         R = np.eye(points.shape[1])
 
         if points.shape[1] == 3:
-            if self.config.augment_rotation == 'vertical':
+            if self.config.augment_rotation == "vertical":
 
                 # Create random rotations
                 theta = np.random.rand() * 2 * np.pi
                 c, s = np.cos(theta), np.sin(theta)
                 R = np.array([[c, -s, 0], [s, c, 0], [0, 0, 1]], dtype=np.float32)
 
-            elif self.config.augment_rotation == 'all':
+            elif self.config.augment_rotation == "all":
 
                 # Choose two random angles for the first vector in polar coordinates
                 theta = np.random.rand() * 2 * np.pi
                 phi = (np.random.rand() - 0.5) * np.pi
 
                 # Create the first vector in carthesian coordinates
-                u = np.array([np.cos(theta) * np.cos(phi), np.sin(theta) * np.cos(phi), np.sin(phi)])
+                u = np.array(
+                    [
+                        np.cos(theta) * np.cos(phi),
+                        np.sin(theta) * np.cos(phi),
+                        np.sin(phi),
+                    ]
+                )
 
                 # Choose a random rotation angle
                 alpha = np.random.rand() * 2 * np.pi
 
                 # Create the rotation matrix with this vector and angle
-                R = create_3D_rotations(np.reshape(u, (1, -1)), np.reshape(alpha, (1, -1)))[0]
+                R = create_3D_rotations(
+                    np.reshape(u, (1, -1)), np.reshape(alpha, (1, -1))
+                )[0]
 
         R = R.astype(np.float32)
 
         #######
         # Scale
@@ -299,34 +332,38 @@
 
         #######
         # Noise
         #######
 
-        noise = (np.random.randn(points.shape[0], points.shape[1]) * self.config.augment_noise).astype(np.float32)
+        noise = (
+            np.random.randn(points.shape[0], points.shape[1])
+            * self.config.augment_noise
+        ).astype(np.float32)
 
         ##################
         # Apply transforms
         ##################
 
         # Do not use np.dot because it is multi-threaded
-        #augmented_points = np.dot(points, R) * scale + noise
+        # augmented_points = np.dot(points, R) * scale + noise
         augmented_points = np.sum(np.expand_dims(points, 2) * R, axis=1) * scale + noise
-
 
         if normals is None:
             return augmented_points, scale, R
         else:
             # Anisotropic scale of the normals thanks to cross product formula
             normal_scale = scale[[1, 2, 0]] * scale[[2, 0, 1]]
             augmented_normals = np.dot(normals, R) * normal_scale
             # Renormalise
-            augmented_normals *= 1 / (np.linalg.norm(augmented_normals, axis=1, keepdims=True) + 1e-6)
+            augmented_normals *= 1 / (
+                np.linalg.norm(augmented_normals, axis=1, keepdims=True) + 1e-6
+            )
 
             if verbose:
                 test_p = [np.vstack([points, augmented_points])]
                 test_n = [np.vstack([normals, augmented_normals])]
-                test_l = [np.hstack([points[:, 2]*0, augmented_points[:, 2]*0+1])]
+                test_l = [np.hstack([points[:, 2] * 0, augmented_points[:, 2] * 0 + 1])]
                 show_ModelNet_examples(test_p, test_n, test_l)
 
             return augmented_points, augmented_normals, scale, R
 
     def big_neighborhood_filter(self, neighbors, layer):
@@ -335,19 +372,17 @@
         Limit is computed at initialization
         """
 
         # crop neighbors matrix
         if len(self.neighborhood_limits) > 0:
-            return neighbors[:, :self.neighborhood_limits[layer]]
+            return neighbors[:, : self.neighborhood_limits[layer]]
         else:
             return neighbors
 
-    def classification_inputs(self,
-                              stacked_points,
-                              stacked_features,
-                              labels,
-                              stack_lengths):
+    def classification_inputs(
+        self, stacked_points, stacked_features, labels, stack_lengths
+    ):
 
         # Starting radius of convolutions
         r_normal = self.config.first_subsampling_dl * self.config.conv_radius
 
         # Starting layer
@@ -367,52 +402,63 @@
         arch = self.config.architecture
 
         for block_i, block in enumerate(arch):
 
             # Get all blocks of the layer
-            if not ('pool' in block or 'strided' in block or 'global' in block or 'upsample' in block):
+            if not (
+                "pool" in block
+                or "strided" in block
+                or "global" in block
+                or "upsample" in block
+            ):
                 layer_blocks += [block]
                 continue
 
             # Convolution neighbors indices
             # *****************************
 
             deform_layer = False
             if layer_blocks:
                 # Convolutions are done in this layer, compute the neighbors with the good radius
-                if np.any(['deformable' in blck for blck in layer_blocks]):
+                if np.any(["deformable" in blck for blck in layer_blocks]):
                     r = r_normal * self.config.deform_radius / self.config.conv_radius
                     deform_layer = True
                 else:
                     r = r_normal
-                conv_i = batch_neighbors(stacked_points, stacked_points, stack_lengths, stack_lengths, r)
+                conv_i = batch_neighbors(
+                    stacked_points, stacked_points, stack_lengths, stack_lengths, r
+                )
 
             else:
                 # This layer only perform pooling, no neighbors required
                 conv_i = np.zeros((0, 1), dtype=np.int32)
 
             # Pooling neighbors indices
             # *************************
 
             # If end of layer is a pooling operation
-            if 'pool' in block or 'strided' in block:
+            if "pool" in block or "strided" in block:
 
                 # New subsampling length
                 dl = 2 * r_normal / self.config.conv_radius
 
                 # Subsampled points
-                pool_p, pool_b = batch_grid_subsampling(stacked_points, stack_lengths, sampleDl=dl)
+                pool_p, pool_b = batch_grid_subsampling(
+                    stacked_points, stack_lengths, sampleDl=dl
+                )
 
                 # Radius of pooled neighbors
-                if 'deformable' in block:
+                if "deformable" in block:
                     r = r_normal * self.config.deform_radius / self.config.conv_radius
                     deform_layer = True
                 else:
                     r = r_normal
 
                 # Subsample indices
-                pool_i = batch_neighbors(pool_p, stacked_points, pool_b, stack_lengths, r)
+                pool_i = batch_neighbors(
+                    pool_p, stacked_points, pool_b, stack_lengths, r
+                )
 
             else:
                 # No pooling in the end of this layer, no pooling indices required
                 pool_i = np.zeros((0, 1), dtype=np.int32)
                 pool_p = np.zeros((0, 1), dtype=np.float32)
@@ -436,11 +482,11 @@
             # Update radius and reset blocks
             r_normal *= 2
             layer_blocks = []
 
             # Stop when meeting a global pooling or upsampling
-            if 'global' in block or 'upsample' in block:
+            if "global" in block or "upsample" in block:
                 break
 
         ###############
         # Return inputs
         ###############
@@ -451,16 +497,13 @@
         li = input_points + input_neighbors + input_pools + input_stack_lengths
         li += [stacked_features, labels]
 
         return li
 
-
-    def segmentation_inputs(self,
-                            stacked_points,
-                            stacked_features,
-                            labels,
-                            stack_lengths):
+    def segmentation_inputs(
+        self, stacked_points, stacked_features, labels, stack_lengths
+    ):
 
         # Starting radius of convolutions
         r_normal = self.config.first_subsampling_dl * self.config.conv_radius
 
         # Starting layer
@@ -481,55 +524,68 @@
         arch = self.config.architecture
 
         for block_i, block in enumerate(arch):
 
             # Get all blocks of the layer
-            if not ('pool' in block or 'strided' in block or 'global' in block or 'upsample' in block):
+            if not (
+                "pool" in block
+                or "strided" in block
+                or "global" in block
+                or "upsample" in block
+            ):
                 layer_blocks += [block]
                 continue
 
             # Convolution neighbors indices
             # *****************************
 
             deform_layer = False
             if layer_blocks:
                 # Convolutions are done in this layer, compute the neighbors with the good radius
-                if np.any(['deformable' in blck for blck in layer_blocks]):
+                if np.any(["deformable" in blck for blck in layer_blocks]):
                     r = r_normal * self.config.deform_radius / self.config.conv_radius
                     deform_layer = True
                 else:
                     r = r_normal
-                conv_i = batch_neighbors(stacked_points, stacked_points, stack_lengths, stack_lengths, r)
+                conv_i = batch_neighbors(
+                    stacked_points, stacked_points, stack_lengths, stack_lengths, r
+                )
 
             else:
                 # This layer only perform pooling, no neighbors required
                 conv_i = np.zeros((0, 1), dtype=np.int32)
 
             # Pooling neighbors indices
             # *************************
 
             # If end of layer is a pooling operation
-            if 'pool' in block or 'strided' in block:
+            if "pool" in block or "strided" in block:
 
                 # New subsampling length
                 dl = 2 * r_normal / self.config.conv_radius
 
                 # Subsampled points
-                pool_p, pool_b = batch_grid_subsampling(stacked_points, stack_lengths, sampleDl=dl)
+                pool_p, pool_b = batch_grid_subsampling(
+                    stacked_points, stack_lengths, sampleDl=dl
+                )
 
                 # Radius of pooled neighbors
-                if 'deformable' in block:
+                if "deformable" in block:
                     r = r_normal * self.config.deform_radius / self.config.conv_radius
                     deform_layer = True
                 else:
                     r = r_normal
 
                 # Subsample indices
-                pool_i = batch_neighbors(pool_p, stacked_points, pool_b, stack_lengths, r)
+                pool_i = batch_neighbors(
+                    pool_p, stacked_points, pool_b, stack_lengths, r
+                )
 
                 # Upsample indices (with the radius of the next layer to keep wanted density)
-                up_i = batch_neighbors(stacked_points, pool_p, stack_lengths, pool_b, 2 * r)
+                up_i = batch_neighbors(
+                    stacked_points, pool_p, stack_lengths, pool_b, 2 * r
+                )
 
             else:
                 # No pooling in the end of this layer, no pooling indices required
                 pool_i = np.zeros((0, 1), dtype=np.int32)
                 pool_p = np.zeros((0, 3), dtype=np.float32)
@@ -538,11 +594,11 @@
 
             # Reduce size of neighbors matrices by eliminating furthest point
             conv_i = self.big_neighborhood_filter(conv_i, len(input_points))
             pool_i = self.big_neighborhood_filter(pool_i, len(input_points))
             if up_i.shape[0] > 0:
-                up_i = self.big_neighborhood_filter(up_i, len(input_points)+1)
+                up_i = self.big_neighborhood_filter(up_i, len(input_points) + 1)
 
             # Updating input lists
             input_points += [stacked_points]
             input_neighbors += [conv_i.astype(np.int64)]
             input_pools += [pool_i.astype(np.int64)]
@@ -557,30 +613,23 @@
             # Update radius and reset blocks
             r_normal *= 2
             layer_blocks = []
 
             # Stop when meeting a global pooling or upsampling
-            if 'global' in block or 'upsample' in block:
+            if "global" in block or "upsample" in block:
                 break
 
         ###############
         # Return inputs
         ###############
 
         # list of network inputs
-        li = input_points + input_neighbors + input_pools + input_upsamples + input_stack_lengths
+        li = (
+            input_points
+            + input_neighbors
+            + input_pools
+            + input_upsamples
+            + input_stack_lengths
+        )
         li += [stacked_features, labels]
 
         return li
-
-
-
-
-
-
-
-
-
-
-
-
-
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/evaluate_Semantickitti.py	2024-06-30 22:34:18.134112+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/evaluate_Semantickitti.py	2024-07-08 11:53:43.550485+00:00
@@ -36,16 +36,16 @@
 from utils.trainer import ModelTrainer
 from models.architectures import KPFCNN
 from utils.evaluate_extended_kitti import ModelTester
 
 
-
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Config Class
 #       \******************/
 #
+
 
 class SemanticKittiConfig(Config):
     """
     Override the parameters you want to modify for this dataset
     """
@@ -53,47 +53,49 @@
     ####################
     # Dataset parameters
     ####################
 
     # Dataset name
-    dataset = 'SemanticKitti'
+    dataset = "SemanticKitti"
 
     # Number of classes in the dataset (This value is overwritten by dataset class when Initializating dataset).
     num_classes = None
 
     # Type of task performed on this dataset (also overwritten)
-    dataset_task = ''
+    dataset_task = ""
 
     # Number of CPU threads for the input pipeline
     input_threads = 10
 
     #########################
     # Architecture definition
     #########################
 
     # Define layers
-    architecture = ['simple',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary']
+    architecture = [
+        "simple",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+    ]
 
     ###################
     # KPConv parameters
     ###################
 
@@ -122,14 +124,14 @@
 
     # Radius of the area of influence of each kernel point in "number grid cell". (1.0 is the standard value)
     KP_extent = 1.2
 
     # Behavior of convolutions in ('constant', 'linear', 'gaussian')
-    KP_influence = 'linear'
+    KP_influence = "linear"
 
     # Aggregation function of KPConv in ('closest', 'sum')
-    aggregation_mode = 'sum'
+    aggregation_mode = "sum"
 
     # Choice of input features
     first_features_dim = 128
     in_features_dim = 2
 
@@ -141,14 +143,14 @@
     batch_norm_momentum = 0.02
 
     # Deformable offset loss
     # 'point2point' fitting geometry by penalizing distance from deform point to input points
     # 'point2plane' fitting geometry by penalizing distance from deform point to input point triplet (not implemented)
-    deform_fitting_mode = 'point2point'
-    deform_fitting_power = 1.0              # Multiplier for the fitting/repulsive loss
-    deform_lr_factor = 0.1                  # Multiplier for learning rate applied to the deformations
-    repulse_extent = 1.2                    # Distance of repulsion for deformed kernel points
+    deform_fitting_mode = "point2point"
+    deform_fitting_power = 1.0  # Multiplier for the fitting/repulsive loss
+    deform_lr_factor = 0.1  # Multiplier for learning rate applied to the deformations
+    repulse_extent = 1.2  # Distance of repulsion for deformed kernel points
 
     #####################
     # Training parameters
     #####################
 
@@ -171,11 +173,11 @@
     checkpoint_gap = 50
 
     # Augmentations
     augment_scale_anisotropic = True
     augment_symmetries = [True, False, False]
-    augment_rotation = 'vertical'
+    augment_rotation = "vertical"
     augment_scale_min = 0.8
     augment_scale_max = 1.2
     augment_noise = 0.001
     augment_color = 0.8
 
@@ -193,98 +195,104 @@
     # class_w = [1.430, 5.000, 5.000, 4.226, 5.000, 5.000, 5.000, 5.000, 0.719, 2.377,
     #            0.886, 3.863, 0.869, 1.209, 0.594, 3.780, 1.129, 5.000, 5.000]
 
     # Do we nee to save convergence
     saving = True
-    saving_path = ''
+    saving_path = ""
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Main Call
 #       \***************/
 #
 
-if __name__ == '__main__':
+if __name__ == "__main__":
 
     ############################
     # Initialize the environment
     ############################
 
     # Set which gpu is going to be used
-    GPU_ID = '0'
+    GPU_ID = "0"
 
     # Set GPU visible device
-    os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID
+    os.environ["CUDA_VISIBLE_DEVICES"] = GPU_ID
 
     ###############
     # Previous chkp
     ###############
 
     # Choose here if you want to start training from a previous snapshot (None for new training)
     # previous_training_path = 'Log_2020-03-19_19-53-27'
-    previous_training_path = 'KPConv_Semantickitti_411'
+    previous_training_path = "KPConv_Semantickitti_411"
 
     # Choose index of checkpoint to start from. If None, uses the latest chkp
     chkp_idx = None
     if previous_training_path:
 
         # Find all snapshot in the chosen training folder
-        chkp_path = os.path.join('results', previous_training_path, 'checkpoints')
-        chkps = [f for f in os.listdir(chkp_path) if f[:4] == 'chkp']
+        chkp_path = os.path.join("results", previous_training_path, "checkpoints")
+        chkps = [f for f in os.listdir(chkp_path) if f[:4] == "chkp"]
 
         # Find which snapshot to restore
         if chkp_idx is None:
-            chosen_chkp = 'current_chkp.tar'
+            chosen_chkp = "current_chkp.tar"
         else:
             chosen_chkp = np.sort(chkps)[chkp_idx]
-        chosen_chkp = os.path.join('results', previous_training_path, 'checkpoints', chosen_chkp)
+        chosen_chkp = os.path.join(
+            "results", previous_training_path, "checkpoints", chosen_chkp
+        )
 
     else:
         chosen_chkp = None
 
     ##############
     # Prepare Data
     ##############
 
     print()
-    print('Data Preparation')
-    print('****************')
+    print("Data Preparation")
+    print("****************")
 
     # Initialize configuration class
     config = SemanticKittiConfig()
     if previous_training_path:
-        config.load(os.path.join('results', previous_training_path))
+        config.load(os.path.join("results", previous_training_path))
         config.saving_path = None
 
     # Get path from argument if given
     if len(sys.argv) > 1:
         config.saving_path = sys.argv[1]
 
     # Initialize datasets
-    training_dataset = SemanticKittiDataset(config, set='training',
-                                            balance_classes=True)
-    test_dataset = SemanticKittiDataset(config, set='validation',
-                                        balance_classes=False)
+    training_dataset = SemanticKittiDataset(
+        config, set="training", balance_classes=True
+    )
+    test_dataset = SemanticKittiDataset(config, set="validation", balance_classes=False)
 
     # Initialize samplers
     training_sampler = SemanticKittiSampler(training_dataset)
     test_sampler = SemanticKittiSampler(test_dataset)
 
     # Initialize the dataloader
-    training_loader = DataLoader(training_dataset,
-                                 batch_size=1,
-                                 sampler=training_sampler,
-                                 collate_fn=SemanticKittiCollate,
-                                 num_workers=config.input_threads,
-                                 pin_memory=True)
-    test_loader = DataLoader(test_dataset,
-                             batch_size=1,
-                             sampler=test_sampler,
-                             collate_fn=SemanticKittiCollate,
-                             num_workers=config.input_threads,
-                             pin_memory=True)
+    training_loader = DataLoader(
+        training_dataset,
+        batch_size=1,
+        sampler=training_sampler,
+        collate_fn=SemanticKittiCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
+    test_loader = DataLoader(
+        test_dataset,
+        batch_size=1,
+        sampler=test_sampler,
+        collate_fn=SemanticKittiCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
 
     # Calibrate max_in_point value
     training_sampler.calib_max_in(config, training_loader, verbose=True)
     test_sampler.calib_max_in(config, test_loader, verbose=True)
 
@@ -294,38 +302,41 @@
 
     # debug_timing(training_dataset, training_loader)
     # debug_timing(test_dataset, test_loader)
     # debug_class_w(training_dataset, training_loader)
 
-    print('\nModel Preparation')
-    print('*****************')
+    print("\nModel Preparation")
+    print("*****************")
 
     # Define network model
     t1 = time.time()
     net = KPFCNN(config, training_dataset.label_values, training_dataset.ignored_labels)
 
     debug = False
     if debug:
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         print(net)
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         for param in net.parameters():
             if param.requires_grad:
                 print(param.shape)
-        print('\n*************************************\n')
-        print("Model size %i" % sum(param.numel() for param in net.parameters() if param.requires_grad))
-        print('\n*************************************\n')
+        print("\n*************************************\n")
+        print(
+            "Model size %i"
+            % sum(param.numel() for param in net.parameters() if param.requires_grad)
+        )
+        print("\n*************************************\n")
 
     # Define a trainer class
     # trainer = ModelTrainer(net, config, chkp_path=chosen_chkp)
     tester = ModelTester(net, chkp_path=chosen_chkp)
 
-    print('Done in {:.1f}s\n'.format(time.time() - t1))
-
-    print('\nStart training')
-    print('**************')
+    print("Done in {:.1f}s\n".format(time.time() - t1))
+
+    print("\nStart training")
+    print("**************")
 
     # Training
     tester.slam_segmentation_test(net, test_loader, config, num_votes=5)
 
-    print('Forcing exit now')
+    print("Forcing exit now")
     os.kill(os.getpid(), signal.SIGINT)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/models/architectures.py	2024-06-30 22:34:18.164134+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/models/architectures.py	2024-07-08 11:53:44.289108+00:00
@@ -30,11 +30,11 @@
             ##############
             # Fitting loss
             ##############
 
             # Get the distance to closest input point and normalize to be independant from layers
-            KP_min_d2 = m.min_d2 / (m.KP_extent ** 2)
+            KP_min_d2 = m.min_d2 / (m.KP_extent**2)
 
             # Loss will be the square distance to closest input point. We use L1 because dist is already squared
             fitting_loss += net.l1(KP_min_d2, torch.zeros_like(KP_min_d2))
 
             ################
@@ -44,13 +44,19 @@
             # Normalized KP locations
             KP_locs = m.deformed_KP / m.KP_extent
 
             # Point should not be close to each other
             for i in range(net.K):
-                other_KP = torch.cat([KP_locs[:, :i, :], KP_locs[:, i + 1:, :]], dim=1).detach()
-                distances = torch.sqrt(torch.sum((other_KP - KP_locs[:, i:i + 1, :]) ** 2, dim=2))
-                rep_loss = torch.sum(torch.clamp_max(distances - net.repulse_extent, max=0.0) ** 2, dim=1)
+                other_KP = torch.cat(
+                    [KP_locs[:, :i, :], KP_locs[:, i + 1 :, :]], dim=1
+                ).detach()
+                distances = torch.sqrt(
+                    torch.sum((other_KP - KP_locs[:, i : i + 1, :]) ** 2, dim=2)
+                )
+                rep_loss = torch.sum(
+                    torch.clamp_max(distances - net.repulse_extent, max=0.0) ** 2, dim=1
+                )
                 repulsive_loss += net.l1(rep_loss, torch.zeros_like(rep_loss)) / net.K
 
     return net.deform_fitting_power * (2 * fitting_loss + repulsive_loss)
 
 
@@ -79,38 +85,35 @@
         # Loop over consecutive blocks
         block_in_layer = 0
         for block_i, block in enumerate(config.architecture):
 
             # Check equivariance
-            if ('equivariant' in block) and (not out_dim % 3 == 0):
-                raise ValueError('Equivariant block but features dimension is not a factor of 3')
+            if ("equivariant" in block) and (not out_dim % 3 == 0):
+                raise ValueError(
+                    "Equivariant block but features dimension is not a factor of 3"
+                )
 
             # Detect upsampling block to stop
-            if 'upsample' in block:
+            if "upsample" in block:
                 break
 
             # Apply the good block function defining tf ops
-            self.block_ops.append(block_decider(block,
-                                                r,
-                                                in_dim,
-                                                out_dim,
-                                                layer,
-                                                config))
-
+            self.block_ops.append(
+                block_decider(block, r, in_dim, out_dim, layer, config)
+            )
 
             # Index of block in this layer
             block_in_layer += 1
 
             # Update dimension of input from output
-            if 'simple' in block:
+            if "simple" in block:
                 in_dim = out_dim // 2
             else:
                 in_dim = out_dim
 
-
             # Detect change to a subsampled layer
-            if 'pool' in block or 'strided' in block:
+            if "pool" in block or "strided" in block:
                 # Update radius and feature dimension for next layer
                 layer += 1
                 r *= 2
                 out_dim *= 2
                 block_in_layer = 0
@@ -158,16 +161,16 @@
 
         # Cross entropy loss
         self.output_loss = self.criterion(outputs, labels)
 
         # Regularization of deformable offsets
-        if self.deform_fitting_mode == 'point2point':
+        if self.deform_fitting_mode == "point2point":
             self.reg_loss = p2p_fitting_regularizer(self)
-        elif self.deform_fitting_mode == 'point2plane':
-            raise ValueError('point2plane fitting mode not implemented yet.')
+        elif self.deform_fitting_mode == "point2plane":
+            raise ValueError("point2plane fitting mode not implemented yet.")
         else:
-            raise ValueError('Unknown fitting mode: ' + self.deform_fitting_mode)
+            raise ValueError("Unknown fitting mode: " + self.deform_fitting_mode)
 
         # Combined loss
         return self.output_loss + self.reg_loss
 
     @staticmethod
@@ -217,38 +220,39 @@
 
         # Loop over consecutive blocks
         for block_i, block in enumerate(config.architecture):
 
             # Check equivariance
-            if ('equivariant' in block) and (not out_dim % 3 == 0):
-                raise ValueError('Equivariant block but features dimension is not a factor of 3')
+            if ("equivariant" in block) and (not out_dim % 3 == 0):
+                raise ValueError(
+                    "Equivariant block but features dimension is not a factor of 3"
+                )
 
             # Detect change to next layer for skip connection
-            if np.any([tmp in block for tmp in ['pool', 'strided', 'upsample', 'global']]):
+            if np.any(
+                [tmp in block for tmp in ["pool", "strided", "upsample", "global"]]
+            ):
                 self.encoder_skips.append(block_i)
                 self.encoder_skip_dims.append(in_dim)
 
             # Detect upsampling block to stop
-            if 'upsample' in block:
+            if "upsample" in block:
                 break
 
             # Apply the good block function defining tf ops
-            self.encoder_blocks.append(block_decider(block,
-                                                    r,
-                                                    in_dim,
-                                                    out_dim,
-                                                    layer,
-                                                    config))
+            self.encoder_blocks.append(
+                block_decider(block, r, in_dim, out_dim, layer, config)
+            )
 
             # Update dimension of input from output
-            if 'simple' in block:
+            if "simple" in block:
                 in_dim = out_dim // 2
             else:
                 in_dim = out_dim
 
             # Detect change to a subsampled layer
-            if 'pool' in block or 'strided' in block:
+            if "pool" in block or "strided" in block:
                 # Update radius and feature dimension for next layer
                 layer += 1
                 r *= 2
                 out_dim *= 2
 
@@ -261,42 +265,41 @@
         self.decoder_concats = []
 
         # Find first upsampling block
         start_i = 0
         for block_i, block in enumerate(config.architecture):
-            if 'upsample' in block:
+            if "upsample" in block:
                 start_i = block_i
                 break
 
         # Loop over consecutive blocks
         for block_i, block in enumerate(config.architecture[start_i:]):
 
             # Add dimension of skip connection concat
-            if block_i > 0 and 'upsample' in config.architecture[start_i + block_i - 1]:
+            if block_i > 0 and "upsample" in config.architecture[start_i + block_i - 1]:
                 in_dim += self.encoder_skip_dims[layer]
                 self.decoder_concats.append(block_i)
 
             # Apply the good block function defining tf ops
-            self.decoder_blocks.append(block_decider(block,
-                                                    r,
-                                                    in_dim,
-                                                    out_dim,
-                                                    layer,
-                                                    config))
+            self.decoder_blocks.append(
+                block_decider(block, r, in_dim, out_dim, layer, config)
+            )
 
             # Update dimension of input from output
             in_dim = out_dim
 
             # Detect change to a subsampled layer
-            if 'upsample' in block:
+            if "upsample" in block:
                 # Update radius and feature dimension for next layer
                 layer -= 1
                 r *= 0.5
                 out_dim = out_dim // 2
 
         self.head_mlp = UnaryBlock(out_dim, config.first_features_dim, False, 0)
-        self.head_softmax = UnaryBlock(config.first_features_dim, self.C, False, 0, no_relu=True)
+        self.head_softmax = UnaryBlock(
+            config.first_features_dim, self.C, False, 0, no_relu=True
+        )
 
         ################
         # Network Losses
         ################
 
@@ -336,12 +339,10 @@
             x = block_op(x, batch)
             act_hook = x.register_hook(self.activations_hook)
             x.retain_grad()
             self.activation_maps.append(x)
 
-
-
         for block_i, block_op in enumerate(self.decoder_blocks):
             if block_i in self.decoder_concats:
                 x = torch.cat([x, skip_x.pop()], dim=1)
             x = block_op(x, batch)
             act_hook = x.register_hook(self.activations_hook)
@@ -357,11 +358,10 @@
         x = self.head_softmax(x, batch)
         act_hook = x.register_hook(self.activations_hook)
         x.retain_grad()
         self.activation_maps.append(x)
 
-
         return x
 
     def loss(self, outputs, labels):
         """
         Runs the loss on outputs of the model
@@ -369,11 +369,11 @@
         :param labels: labels
         :return: loss
         """
 
         # Set all ignored labels to -1 and correct the other label to be in [0, C-1] range
-        target = - torch.ones_like(labels)
+        target = -torch.ones_like(labels)
         for i, c in enumerate(self.valid_labels):
             target[labels == c] = i
 
         # Reshape to have a minibatch size of 1
         outputs = torch.transpose(outputs, 0, 1)
@@ -382,16 +382,16 @@
 
         # Cross entropy loss
         self.output_loss = self.criterion(outputs, target)
 
         # Regularization of deformable offsets
-        if self.deform_fitting_mode == 'point2point':
+        if self.deform_fitting_mode == "point2point":
             self.reg_loss = p2p_fitting_regularizer(self)
-        elif self.deform_fitting_mode == 'point2plane':
-            raise ValueError('point2plane fitting mode not implemented yet.')
+        elif self.deform_fitting_mode == "point2plane":
+            raise ValueError("point2plane fitting mode not implemented yet.")
         else:
-            raise ValueError('Unknown fitting mode: ' + self.deform_fitting_mode)
+            raise ValueError("Unknown fitting mode: " + self.deform_fitting_mode)
 
         # Combined loss
         return self.output_loss + self.reg_loss
 
     def accuracy(self, outputs, labels):
@@ -401,35 +401,14 @@
         :param labels: labels
         :return: accuracy value
         """
 
         # Set all ignored labels to -1 and correct the other label to be in [0, C-1] range
-        target = - torch.ones_like(labels)
+        target = -torch.ones_like(labels)
         for i, c in enumerate(self.valid_labels):
             target[labels == c] = i
 
         predicted = torch.argmax(outputs.data, dim=1)
         total = target.size(0)
         correct = (predicted == target).sum().item()
 
         return correct / total
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/ModelNet40.py	2024-06-30 22:34:18.059944+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/ModelNet40.py	2024-07-08 11:53:44.372160+00:00
@@ -53,69 +53,71 @@
 
     def __init__(self, config, train=True, orient_correction=True):
         """
         This dataset is small enough to be stored in-memory, so load all point clouds here
         """
-        PointCloudDataset.__init__(self, 'ModelNet40')
+        PointCloudDataset.__init__(self, "ModelNet40")
 
         ############
         # Parameters
         ############
 
         # Dict from labels to names
-        self.label_to_names = {0: 'airplane',
-                               1: 'bathtub',
-                               2: 'bed',
-                               3: 'bench',
-                               4: 'bookshelf',
-                               5: 'bottle',
-                               6: 'bowl',
-                               7: 'car',
-                               8: 'chair',
-                               9: 'cone',
-                               10: 'cup',
-                               11: 'curtain',
-                               12: 'desk',
-                               13: 'door',
-                               14: 'dresser',
-                               15: 'flower_pot',
-                               16: 'glass_box',
-                               17: 'guitar',
-                               18: 'keyboard',
-                               19: 'lamp',
-                               20: 'laptop',
-                               21: 'mantel',
-                               22: 'monitor',
-                               23: 'night_stand',
-                               24: 'person',
-                               25: 'piano',
-                               26: 'plant',
-                               27: 'radio',
-                               28: 'range_hood',
-                               29: 'sink',
-                               30: 'sofa',
-                               31: 'stairs',
-                               32: 'stool',
-                               33: 'table',
-                               34: 'tent',
-                               35: 'toilet',
-                               36: 'tv_stand',
-                               37: 'vase',
-                               38: 'wardrobe',
-                               39: 'xbox'}
+        self.label_to_names = {
+            0: "airplane",
+            1: "bathtub",
+            2: "bed",
+            3: "bench",
+            4: "bookshelf",
+            5: "bottle",
+            6: "bowl",
+            7: "car",
+            8: "chair",
+            9: "cone",
+            10: "cup",
+            11: "curtain",
+            12: "desk",
+            13: "door",
+            14: "dresser",
+            15: "flower_pot",
+            16: "glass_box",
+            17: "guitar",
+            18: "keyboard",
+            19: "lamp",
+            20: "laptop",
+            21: "mantel",
+            22: "monitor",
+            23: "night_stand",
+            24: "person",
+            25: "piano",
+            26: "plant",
+            27: "radio",
+            28: "range_hood",
+            29: "sink",
+            30: "sofa",
+            31: "stairs",
+            32: "stool",
+            33: "table",
+            34: "tent",
+            35: "toilet",
+            36: "tv_stand",
+            37: "vase",
+            38: "wardrobe",
+            39: "xbox",
+        }
 
         # Initialize a bunch of variables concerning class labels
         self.init_labels()
 
         # List of classes ignored during training (can be empty)
         self.ignored_labels = np.array([])
 
         # Dataset folder
-        self.path = '../../Data/ModelNet40'
+        self.path = "../../Data/ModelNet40"
 
         # Type of task conducted on this dataset
-        self.dataset_task = 'classification'
+        self.dataset_task = "classification"
 
         # Update number of class and data task in configuration
         config.num_classes = self.num_classes
         config.dataset_task = self.dataset_task
 
@@ -126,26 +128,33 @@
         self.train = train
 
         # Number of models and models used per epoch
         if self.train:
             self.num_models = 9843
-            if config.epoch_steps and config.epoch_steps * config.batch_num < self.num_models:
+            if (
+                config.epoch_steps
+                and config.epoch_steps * config.batch_num < self.num_models
+            ):
                 self.epoch_n = config.epoch_steps * config.batch_num
             else:
                 self.epoch_n = self.num_models
         else:
             self.num_models = 2468
-            self.epoch_n = min(self.num_models, config.validation_size * config.batch_num)
+            self.epoch_n = min(
+                self.num_models, config.validation_size * config.batch_num
+            )
 
         #############
         # Load models
         #############
 
         if 0 < self.config.first_subsampling_dl <= 0.01:
-            raise ValueError('subsampling_parameter too low (should be over 1 cm')
-
-        self.input_points, self.input_normals, self.input_labels = self.load_subsampled_clouds(orient_correction)
+            raise ValueError("subsampling_parameter too low (should be over 1 cm")
+
+        self.input_points, self.input_normals, self.input_labels = (
+            self.load_subsampled_clouds(orient_correction)
+        )
 
         return
 
     def __len__(self):
         """
@@ -190,11 +199,11 @@
 
         ###################
         # Concatenate batch
         ###################
 
-        #show_ModelNet_examples(tp_list, cloud_normals=tn_list)
+        # show_ModelNet_examples(tp_list, cloud_normals=tn_list)
 
         stacked_points = np.concatenate(tp_list, axis=0)
         stacked_normals = np.concatenate(tn_list, axis=0)
         labels = np.array(tl_list, dtype=np.int64)
         model_inds = np.array(ti_list, dtype=np.int32)
@@ -207,24 +216,25 @@
         if self.config.in_features_dim == 1:
             pass
         elif self.config.in_features_dim == 4:
             stacked_features = np.hstack((stacked_features, stacked_normals))
         else:
-            raise ValueError('Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)')
+            raise ValueError(
+                "Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)"
+            )
 
         #######################
         # Create network inputs
         #######################
         #
         #   Points, neighbors, pooling indices for each layers
         #
 
         # Get the whole input list
-        input_list = self.classification_inputs(stacked_points,
-                                                stacked_features,
-                                                labels,
-                                                stack_lengths)
+        input_list = self.classification_inputs(
+            stacked_points, stacked_features, labels, stack_lengths
+        )
 
         # Add scale and rotation for testing
         input_list += [scales, rots, model_inds]
 
         return input_list
@@ -234,97 +244,115 @@
         # Restart timer
         t0 = time.time()
 
         # Load wanted points if possible
         if self.train:
-            split ='training'
+            split = "training"
         else:
-            split = 'test'
-
-        print('\nLoading {:s} points subsampled at {:.3f}'.format(split, self.config.first_subsampling_dl))
-        filename = join(self.path, '{:s}_{:.3f}_record.pkl'.format(split, self.config.first_subsampling_dl))
+            split = "test"
+
+        print(
+            "\nLoading {:s} points subsampled at {:.3f}".format(
+                split, self.config.first_subsampling_dl
+            )
+        )
+        filename = join(
+            self.path,
+            "{:s}_{:.3f}_record.pkl".format(split, self.config.first_subsampling_dl),
+        )
 
         if exists(filename):
-            with open(filename, 'rb') as file:
+            with open(filename, "rb") as file:
                 input_points, input_normals, input_labels = pickle.load(file)
 
         # Else compute them from original points
         else:
 
             # Collect training file names
             if self.train:
-                names = np.loadtxt(join(self.path, 'modelnet40_train.txt'), dtype=np.str)
+                names = np.loadtxt(
+                    join(self.path, "modelnet40_train.txt"), dtype=np.str
+                )
             else:
-                names = np.loadtxt(join(self.path, 'modelnet40_test.txt'), dtype=np.str)
+                names = np.loadtxt(join(self.path, "modelnet40_test.txt"), dtype=np.str)
 
             # Initialize containers
             input_points = []
             input_normals = []
 
             # Advanced display
             N = len(names)
             progress_n = 30
-            fmt_str = '[{:<' + str(progress_n) + '}] {:5.1f}%'
+            fmt_str = "[{:<" + str(progress_n) + "}] {:5.1f}%"
 
             # Collect point clouds
             for i, cloud_name in enumerate(names):
 
                 # Read points
-                class_folder = '_'.join(cloud_name.split('_')[:-1])
-                txt_file = join(self.path, class_folder, cloud_name) + '.txt'
-                data = np.loadtxt(txt_file, delimiter=',', dtype=np.float32)
+                class_folder = "_".join(cloud_name.split("_")[:-1])
+                txt_file = join(self.path, class_folder, cloud_name) + ".txt"
+                data = np.loadtxt(txt_file, delimiter=",", dtype=np.float32)
 
                 # Subsample them
                 if self.config.first_subsampling_dl > 0:
-                    points, normals = grid_subsampling(data[:, :3],
-                                                       features=data[:, 3:],
-                                                       sampleDl=self.config.first_subsampling_dl)
+                    points, normals = grid_subsampling(
+                        data[:, :3],
+                        features=data[:, 3:],
+                        sampleDl=self.config.first_subsampling_dl,
+                    )
                 else:
                     points = data[:, :3]
                     normals = data[:, 3:]
 
-                print('', end='\r')
-                print(fmt_str.format('#' * ((i * progress_n) // N), 100 * i / N), end='', flush=True)
+                print("", end="\r")
+                print(
+                    fmt_str.format("#" * ((i * progress_n) // N), 100 * i / N),
+                    end="",
+                    flush=True,
+                )
 
                 # Add to list
                 input_points += [points]
                 input_normals += [normals]
 
-            print('', end='\r')
-            print(fmt_str.format('#' * progress_n, 100), end='', flush=True)
+            print("", end="\r")
+            print(fmt_str.format("#" * progress_n, 100), end="", flush=True)
             print()
 
             # Get labels
-            label_names = ['_'.join(name.split('_')[:-1]) for name in names]
+            label_names = ["_".join(name.split("_")[:-1]) for name in names]
             input_labels = np.array([self.name_to_label[name] for name in label_names])
 
             # Save for later use
-            with open(filename, 'wb') as file:
-                pickle.dump((input_points,
-                             input_normals,
-                             input_labels), file)
+            with open(filename, "wb") as file:
+                pickle.dump((input_points, input_normals, input_labels), file)
 
         lengths = [p.shape[0] for p in input_points]
         sizes = [l * 4 * 6 for l in lengths]
-        print('{:.1f} MB loaded in {:.1f}s'.format(np.sum(sizes) * 1e-6, time.time() - t0))
+        print(
+            "{:.1f} MB loaded in {:.1f}s".format(np.sum(sizes) * 1e-6, time.time() - t0)
+        )
 
         if orient_correction:
             input_points = [pp[:, [0, 2, 1]] for pp in input_points]
             input_normals = [nn[:, [0, 2, 1]] for nn in input_normals]
 
         return input_points, input_normals, input_labels
 
+
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Utility classes definition
 #       \********************************/
 
 
 class ModelNet40Sampler(Sampler):
     """Sampler for ModelNet40"""
 
-    def __init__(self, dataset: ModelNet40Dataset, use_potential=True, balance_labels=False):
+    def __init__(
+        self, dataset: ModelNet40Dataset, use_potential=True, balance_labels=False
+    ):
         Sampler.__init__(self, dataset)
 
         # Does the sampler use potential for regular sampling
         self.use_potential = use_potential
 
@@ -365,11 +393,13 @@
                     label_inds = np.where(np.equal(self.dataset.input_labels, l))[0]
                     class_potentials = self.potentials[label_inds]
 
                     # Get the indices to generate thanks to potentials
                     if pick_n < class_potentials.shape[0]:
-                        pick_indices = np.argpartition(class_potentials, pick_n)[:pick_n]
+                        pick_indices = np.argpartition(class_potentials, pick_n)[
+                            :pick_n
+                        ]
                     else:
                         pick_indices = np.random.permutation(class_potentials.shape[0])
                     class_indices = label_inds[pick_indices]
                     gen_indices.append(class_indices)
 
@@ -378,18 +408,22 @@
 
             else:
 
                 # Get indices with the minimum potential
                 if self.dataset.epoch_n < self.potentials.shape[0]:
-                    gen_indices = np.argpartition(self.potentials, self.dataset.epoch_n)[:self.dataset.epoch_n]
+                    gen_indices = np.argpartition(
+                        self.potentials, self.dataset.epoch_n
+                    )[: self.dataset.epoch_n]
                 else:
                     gen_indices = np.random.permutation(self.potentials.shape[0])
                 gen_indices = np.random.permutation(gen_indices)
 
             # Update potentials (Change the order for the next epoch)
             self.potentials[gen_indices] = np.ceil(self.potentials[gen_indices])
-            self.potentials[gen_indices] += np.random.rand(gen_indices.shape[0]) * 0.1 + 0.1
+            self.potentials[gen_indices] += (
+                np.random.rand(gen_indices.shape[0]) * 0.1 + 0.1
+            )
 
         else:
             if self.balance_labels:
                 pick_n = self.dataset.epoch_n // self.dataset.num_classes + 1
                 gen_indices = []
@@ -397,11 +431,13 @@
                     label_inds = np.where(np.equal(self.dataset.input_labels, l))[0]
                     rand_inds = np.random.choice(label_inds, size=pick_n, replace=True)
                     gen_indices += [rand_inds]
                 gen_indices = np.random.permutation(np.hstack(gen_indices))
             else:
-                gen_indices = np.random.permutation(self.dataset.num_models)[:self.dataset.epoch_n]
+                gen_indices = np.random.permutation(self.dataset.num_models)[
+                    : self.dataset.epoch_n
+                ]
 
         ################
         # Generator loop
         ################
 
@@ -448,52 +484,53 @@
 
         ##############################
         # Previously saved calibration
         ##############################
 
-        print('\nStarting Calibration (use verbose=True for more details)')
+        print("\nStarting Calibration (use verbose=True for more details)")
         t0 = time.time()
 
         redo = False
 
         # Batch limit
         # ***********
 
         # Load batch_limit dictionary
-        batch_lim_file = join(self.dataset.path, 'batch_limits.pkl')
+        batch_lim_file = join(self.dataset.path, "batch_limits.pkl")
         if exists(batch_lim_file):
-            with open(batch_lim_file, 'rb') as file:
+            with open(batch_lim_file, "rb") as file:
                 batch_lim_dict = pickle.load(file)
         else:
             batch_lim_dict = {}
 
         # Check if the batch limit associated with current parameters exists
-        key = '{:.3f}_{:d}'.format(self.dataset.config.first_subsampling_dl,
-                                   self.dataset.config.batch_num)
+        key = "{:.3f}_{:d}".format(
+            self.dataset.config.first_subsampling_dl, self.dataset.config.batch_num
+        )
         if key in batch_lim_dict:
             self.batch_limit = batch_lim_dict[key]
         else:
             redo = True
 
         if verbose:
-            print('\nPrevious calibration found:')
-            print('Check batch limit dictionary')
+            print("\nPrevious calibration found:")
+            print("Check batch limit dictionary")
             if key in batch_lim_dict:
                 color = bcolors.OKGREEN
                 v = str(int(batch_lim_dict[key]))
             else:
                 color = bcolors.FAIL
-                v = '?'
-            print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                v = "?"
+            print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         # Neighbors limit
         # ***************
 
         # Load neighb_limits dictionary
-        neighb_lim_file = join(self.dataset.path, 'neighbors_limits.pkl')
+        neighb_lim_file = join(self.dataset.path, "neighbors_limits.pkl")
         if exists(neighb_lim_file):
-            with open(neighb_lim_file, 'rb') as file:
+            with open(neighb_lim_file, "rb") as file:
                 neighb_lim_dict = pickle.load(file)
         else:
             neighb_lim_dict = {}
 
         # Check if the limit associated with current parameters exists (for each layer)
@@ -504,48 +541,52 @@
             if self.dataset.config.deform_layers[layer_ind]:
                 r = dl * self.dataset.config.deform_radius
             else:
                 r = dl * self.dataset.config.conv_radius
 
-            key = '{:.3f}_{:.3f}'.format(dl, r)
+            key = "{:.3f}_{:.3f}".format(dl, r)
             if key in neighb_lim_dict:
                 neighb_limits += [neighb_lim_dict[key]]
 
         if len(neighb_limits) == self.dataset.config.num_layers:
             self.dataset.neighborhood_limits = neighb_limits
         else:
             redo = True
 
         if verbose:
-            print('Check neighbors limit dictionary')
+            print("Check neighbors limit dictionary")
             for layer_ind in range(self.dataset.config.num_layers):
                 dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
                 if self.dataset.config.deform_layers[layer_ind]:
                     r = dl * self.dataset.config.deform_radius
                 else:
                     r = dl * self.dataset.config.conv_radius
-                key = '{:.3f}_{:.3f}'.format(dl, r)
+                key = "{:.3f}_{:.3f}".format(dl, r)
 
                 if key in neighb_lim_dict:
                     color = bcolors.OKGREEN
                     v = str(neighb_lim_dict[key])
                 else:
                     color = bcolors.FAIL
-                    v = '?'
-                print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                    v = "?"
+                print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         if redo:
 
             ############################
             # Neighbors calib parameters
             ############################
 
             # From config parameter, compute higher bound of neighbors number in a neighborhood
-            hist_n = int(np.ceil(4 / 3 * np.pi * (self.dataset.config.conv_radius + 1) ** 3))
+            hist_n = int(
+                np.ceil(4 / 3 * np.pi * (self.dataset.config.conv_radius + 1) ** 3)
+            )
 
             # Histogram of neighborhood sizes
-            neighb_hists = np.zeros((self.dataset.config.num_layers, hist_n), dtype=np.int32)
+            neighb_hists = np.zeros(
+                (self.dataset.config.num_layers, hist_n), dtype=np.int32
+            )
 
             ########################
             # Batch calib parameters
             ########################
 
@@ -573,11 +614,14 @@
 
             for epoch in range(10):
                 for batch_i, batch in enumerate(dataloader):
 
                     # Update neighborhood histogram
-                    counts = [np.sum(neighb_mat.numpy() < neighb_mat.shape[0], axis=1) for neighb_mat in batch.neighbors]
+                    counts = [
+                        np.sum(neighb_mat.numpy() < neighb_mat.shape[0], axis=1)
+                        for neighb_mat in batch.neighbors
+                    ]
                     hists = [np.bincount(c, minlength=hist_n)[:hist_n] for c in counts]
                     neighb_hists += np.vstack(hists)
 
                     # batch length
                     b = len(batch.labels)
@@ -610,73 +654,73 @@
                     t = time.time()
 
                     # Console display (only one per second)
                     if verbose and (t - last_display) > 1.0:
                         last_display = t
-                        message = 'Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d}'
-                        print(message.format(i,
-                                             estim_b,
-                                             int(self.batch_limit)))
+                        message = "Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d}"
+                        print(message.format(i, estim_b, int(self.batch_limit)))
 
                 if breaking:
                     break
 
             # Use collected neighbor histogram to get neighbors limit
             cumsum = np.cumsum(neighb_hists.T, axis=0)
-            percentiles = np.sum(cumsum < (untouched_ratio * cumsum[hist_n - 1, :]), axis=0)
+            percentiles = np.sum(
+                cumsum < (untouched_ratio * cumsum[hist_n - 1, :]), axis=0
+            )
             self.dataset.neighborhood_limits = percentiles
 
             if verbose:
 
                 # Crop histogram
                 while np.sum(neighb_hists[:, -1]) == 0:
                     neighb_hists = neighb_hists[:, :-1]
                 hist_n = neighb_hists.shape[1]
 
-                print('\n**************************************************\n')
-                line0 = 'neighbors_num '
+                print("\n**************************************************\n")
+                line0 = "neighbors_num "
                 for layer in range(neighb_hists.shape[0]):
-                    line0 += '|  layer {:2d}  '.format(layer)
+                    line0 += "|  layer {:2d}  ".format(layer)
                 print(line0)
                 for neighb_size in range(hist_n):
-                    line0 = '     {:4d}     '.format(neighb_size)
+                    line0 = "     {:4d}     ".format(neighb_size)
                     for layer in range(neighb_hists.shape[0]):
                         if neighb_size > percentiles[layer]:
                             color = bcolors.FAIL
                         else:
                             color = bcolors.OKGREEN
-                        line0 += '|{:}{:10d}{:}  '.format(color,
-                                                         neighb_hists[layer, neighb_size],
-                                                         bcolors.ENDC)
+                        line0 += "|{:}{:10d}{:}  ".format(
+                            color, neighb_hists[layer, neighb_size], bcolors.ENDC
+                        )
 
                     print(line0)
 
-                print('\n**************************************************\n')
-                print('\nchosen neighbors limits: ', percentiles)
+                print("\n**************************************************\n")
+                print("\nchosen neighbors limits: ", percentiles)
                 print()
 
             # Save batch_limit dictionary
-            key = '{:.3f}_{:d}'.format(self.dataset.config.first_subsampling_dl,
-                                       self.dataset.config.batch_num)
+            key = "{:.3f}_{:d}".format(
+                self.dataset.config.first_subsampling_dl, self.dataset.config.batch_num
+            )
             batch_lim_dict[key] = self.batch_limit
-            with open(batch_lim_file, 'wb') as file:
+            with open(batch_lim_file, "wb") as file:
                 pickle.dump(batch_lim_dict, file)
 
             # Save neighb_limit dictionary
             for layer_ind in range(self.dataset.config.num_layers):
-                dl = self.dataset.config.first_subsampling_dl * (2 ** layer_ind)
+                dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
                 if self.dataset.config.deform_layers[layer_ind]:
                     r = dl * self.dataset.config.deform_radius
                 else:
                     r = dl * self.dataset.config.conv_radius
-                key = '{:.3f}_{:.3f}'.format(dl, r)
+                key = "{:.3f}_{:.3f}".format(dl, r)
                 neighb_lim_dict[key] = self.dataset.neighborhood_limits[layer_ind]
-            with open(neighb_lim_file, 'wb') as file:
+            with open(neighb_lim_file, "wb") as file:
                 pickle.dump(neighb_lim_dict, file)
 
-
-        print('Calibration done in {:.1f}s\n'.format(time.time() - t0))
+        print("Calibration done in {:.1f}s\n".format(time.time() - t0))
         return
 
 
 class ModelNet40CustomBatch:
     """Custom batch definition with memory pinning for ModelNet40"""
@@ -689,17 +733,25 @@
         # Number of layers
         L = (len(input_list) - 5) // 4
 
         # Extract input tensors from the list of numpy array
         ind = 0
-        self.points = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.points = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.neighbors = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.neighbors = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.pools = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.pools = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.lengths = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.lengths = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
         self.features = torch.from_numpy(input_list[ind])
         ind += 1
         self.labels = torch.from_numpy(input_list[ind])
         ind += 1
@@ -742,54 +794,54 @@
 
         return self
 
     def unstack_points(self, layer=None):
         """Unstack the points"""
-        return self.unstack_elements('points', layer)
+        return self.unstack_elements("points", layer)
 
     def unstack_neighbors(self, layer=None):
         """Unstack the neighbors indices"""
-        return self.unstack_elements('neighbors', layer)
+        return self.unstack_elements("neighbors", layer)
 
     def unstack_pools(self, layer=None):
         """Unstack the pooling indices"""
-        return self.unstack_elements('pools', layer)
+        return self.unstack_elements("pools", layer)
 
     def unstack_elements(self, element_name, layer=None, to_numpy=True):
         """
         Return a list of the stacked elements in the batch at a certain layer. If no layer is given, then return all
         layers
         """
 
-        if element_name == 'points':
+        if element_name == "points":
             elements = self.points
-        elif element_name == 'neighbors':
+        elif element_name == "neighbors":
             elements = self.neighbors
-        elif element_name == 'pools':
+        elif element_name == "pools":
             elements = self.pools[:-1]
         else:
-            raise ValueError('Unknown element name: {:s}'.format(element_name))
+            raise ValueError("Unknown element name: {:s}".format(element_name))
 
         all_p_list = []
         for layer_i, layer_elems in enumerate(elements):
 
             if layer is None or layer == layer_i:
 
                 i0 = 0
                 p_list = []
-                if element_name == 'pools':
-                    lengths = self.lengths[layer_i+1]
+                if element_name == "pools":
+                    lengths = self.lengths[layer_i + 1]
                 else:
                     lengths = self.lengths[layer_i]
 
                 for b_i, length in enumerate(lengths):
 
-                    elem = layer_elems[i0:i0 + length]
-                    if element_name == 'neighbors':
+                    elem = layer_elems[i0 : i0 + length]
+                    if element_name == "neighbors":
                         elem[elem >= self.points[layer_i].shape[0]] = -1
                         elem[elem >= 0] -= i0
-                    elif element_name == 'pools':
+                    elif element_name == "pools":
                         elem[elem >= self.points[layer_i].shape[0]] = -1
                         elem[elem >= 0] -= torch.sum(self.lengths[layer_i][:b_i])
                     i0 += length
 
                     if to_numpy:
@@ -823,14 +875,14 @@
         for batch_i, (points, normals, labels, indices, in_sizes) in enumerate(loader):
             # print(batch_i, tuple(points.shape),  tuple(normals.shape), labels, indices, in_sizes)
 
             label_sum += np.bincount(labels.numpy(), minlength=dataset.num_classes)
             print(label_sum)
-            #print(sampler.potentials[:6])
-
-            print('******************')
-        print('*******************************************')
+            # print(sampler.potentials[:6])
+
+            print("******************")
+        print("*******************************************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -862,24 +914,24 @@
             mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Console display (only one per second)
             if (t[-1] - last_display) > -1.0:
                 last_display = t[-1]
-                message = 'Step {:08d} -> (ms/batch) {:8.2f} {:8.2f} / batch = {:.2f}'
-                print(message.format(batch_i,
-                                     1000 * mean_dt[0],
-                                     1000 * mean_dt[1],
-                                     estim_b))
-
-        print('************* Epoch ended *************')
+                message = "Step {:08d} -> (ms/batch) {:8.2f} {:8.2f} / batch = {:.2f}"
+                print(
+                    message.format(
+                        batch_i, 1000 * mean_dt[0], 1000 * mean_dt[1], estim_b
+                    )
+                )
+
+        print("************* Epoch ended *************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
 def debug_show_clouds(dataset, sampler, loader):
-
 
     for epoch in range(10):
 
         clouds = []
         cloud_normals = []
@@ -888,34 +940,34 @@
         L = dataset.config.num_layers
 
         for batch_i, batch in enumerate(loader):
 
             # Print characteristics of input tensors
-            print('\nPoints tensors')
+            print("\nPoints tensors")
             for i in range(L):
                 print(batch.points[i].dtype, batch.points[i].shape)
-            print('\nNeigbors tensors')
+            print("\nNeigbors tensors")
             for i in range(L):
                 print(batch.neighbors[i].dtype, batch.neighbors[i].shape)
-            print('\nPools tensors')
+            print("\nPools tensors")
             for i in range(L):
                 print(batch.pools[i].dtype, batch.pools[i].shape)
-            print('\nStack lengths')
+            print("\nStack lengths")
             for i in range(L):
                 print(batch.lengths[i].dtype, batch.lengths[i].shape)
-            print('\nFeatures')
+            print("\nFeatures")
             print(batch.features.dtype, batch.features.shape)
-            print('\nLabels')
+            print("\nLabels")
             print(batch.labels.dtype, batch.labels.shape)
-            print('\nAugment Scales')
+            print("\nAugment Scales")
             print(batch.scales.dtype, batch.scales.shape)
-            print('\nAugment Rotations')
+            print("\nAugment Rotations")
             print(batch.rots.dtype, batch.rots.shape)
-            print('\nModel indices')
+            print("\nModel indices")
             print(batch.model_inds.dtype, batch.model_inds.shape)
 
-            print('\nAre input tensors pinned')
+            print("\nAre input tensors pinned")
             print(batch.neighbors[0].is_pinned())
             print(batch.neighbors[-1].is_pinned())
             print(batch.points[0].is_pinned())
             print(batch.points[-1].is_pinned())
             print(batch.labels.is_pinned())
@@ -923,11 +975,11 @@
             print(batch.rots.is_pinned())
             print(batch.model_inds.is_pinned())
 
             show_input_batch(batch)
 
-        print('*******************************************')
+        print("*******************************************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -955,16 +1007,14 @@
             mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Console display (only one per second)
             if (t[-1] - last_display) > 1.0:
                 last_display = t[-1]
-                message = 'Step {:08d} -> Average timings (ms/batch) {:8.2f} {:8.2f} '
-                print(message.format(batch_i,
-                                     1000 * mean_dt[0],
-                                     1000 * mean_dt[1]))
-
-        print('************* Epoch ended *************')
+                message = "Step {:08d} -> Average timings (ms/batch) {:8.2f} {:8.2f} "
+                print(message.format(batch_i, 1000 * mean_dt[0], 1000 * mean_dt[1]))
+
+        print("************* Epoch ended *************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -983,13 +1033,12 @@
 
         # Get associated dataset
         dataset = worker_info.dataset  # the dataset copy in this worker process
 
         # In windows, each worker has its own copy of the dataset. In Linux, this is shared in memory
-        print(dataset.input_labels.__array_interface__['data'])
-        print(worker_info.dataset.input_labels.__array_interface__['data'])
-        print(self.dataset.input_labels.__array_interface__['data'])
+        print(dataset.input_labels.__array_interface__["data"])
+        print(worker_info.dataset.input_labels.__array_interface__["data"])
+        print(self.dataset.input_labels.__array_interface__["data"])
 
         # configure the dataset to only process the split workload
 
         return
-
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/kernels/kernel_points.py	2024-06-30 22:34:18.154986+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/kernels/kernel_points.py	2024-07-08 11:53:44.638621+00:00
@@ -38,10 +38,11 @@
 #
 #           Functions
 #       \***************/
 #
 #
+
 
 def create_3D_rotations(axis, angle):
     """
     Create rotation matrices from a list of axes and angles. Code from wikipedia on quaternions
     :param axis: float32[N, 3]
@@ -60,25 +61,39 @@
     t12 = t8 * axis[:, 1]
     t15 = axis[:, 1] * axis[:, 1]
     t19 = t2 * axis[:, 1] * axis[:, 2]
     t20 = t8 * axis[:, 0]
     t24 = axis[:, 2] * axis[:, 2]
-    R = np.stack([t1 + t2 * t3,
-                  t7 - t9,
-                  t11 + t12,
-                  t7 + t9,
-                  t1 + t2 * t15,
-                  t19 - t20,
-                  t11 - t12,
-                  t19 + t20,
-                  t1 + t2 * t24], axis=1)
+    R = np.stack(
+        [
+            t1 + t2 * t3,
+            t7 - t9,
+            t11 + t12,
+            t7 + t9,
+            t1 + t2 * t15,
+            t19 - t20,
+            t11 - t12,
+            t19 + t20,
+            t1 + t2 * t24,
+        ],
+        axis=1,
+    )
 
     return np.reshape(R, (-1, 3, 3))
 
 
-def spherical_Lloyd(radius, num_cells, dimension=3, fixed='center', approximation='monte-carlo',
-                    approx_n=5000, max_iter=500, momentum=0.9, verbose=0):
+def spherical_Lloyd(
+    radius,
+    num_cells,
+    dimension=3,
+    fixed="center",
+    approximation="monte-carlo",
+    approx_n=5000,
+    max_iter=500,
+    momentum=0.9,
+    verbose=0,
+):
     """
     Creation of kernel point via Lloyd algorithm. We use an approximation of the algorithm, and compute the Voronoi
     cell centers with discretization  of space. The exact formula is not trivial with part of the sphere as sides.
     :param radius: Radius of the kernels
     :param num_cells: Number of cell (kernel points) in the Voronoi diagram.
@@ -107,17 +122,19 @@
     kernel_points = np.zeros((0, dimension))
     while kernel_points.shape[0] < num_cells:
         new_points = np.random.rand(num_cells, dimension) * 2 * radius0 - radius0
         kernel_points = np.vstack((kernel_points, new_points))
         d2 = np.sum(np.power(kernel_points, 2), axis=1)
-        kernel_points = kernel_points[np.logical_and(d2 < radius0 ** 2, (0.9 * radius0) ** 2 < d2), :]
+        kernel_points = kernel_points[
+            np.logical_and(d2 < radius0**2, (0.9 * radius0) ** 2 < d2), :
+        ]
     kernel_points = kernel_points[:num_cells, :].reshape((num_cells, -1))
 
     # Optional fixing
-    if fixed == 'center':
+    if fixed == "center":
         kernel_points[0, :] *= 0
-    if fixed == 'verticals':
+    if fixed == "verticals":
         kernel_points[:3, :] *= 0
         kernel_points[1, -1] += 2 * radius0 / 3
         kernel_points[2, -1] -= 2 * radius0 / 3
 
     ##############################
@@ -127,29 +144,31 @@
     # Initialize figure
     if verbose > 1:
         fig = plt.figure()
 
     # Initialize discretization in this method is chosen
-    if approximation == 'discretization':
-        side_n = int(np.floor(approx_n ** (1. / dimension)))
+    if approximation == "discretization":
+        side_n = int(np.floor(approx_n ** (1.0 / dimension)))
         dl = 2 * radius0 / side_n
-        coords = np.arange(-radius0 + dl/2, radius0, dl)
+        coords = np.arange(-radius0 + dl / 2, radius0, dl)
         if dimension == 2:
             x, y = np.meshgrid(coords, coords)
             X = np.vstack((np.ravel(x), np.ravel(y))).T
         elif dimension == 3:
             x, y, z = np.meshgrid(coords, coords, coords)
             X = np.vstack((np.ravel(x), np.ravel(y), np.ravel(z))).T
         elif dimension == 4:
             x, y, z, t = np.meshgrid(coords, coords, coords, coords)
             X = np.vstack((np.ravel(x), np.ravel(y), np.ravel(z), np.ravel(t))).T
         else:
-            raise ValueError('Unsupported dimension (max is 4)')
-    elif approximation == 'monte-carlo':
+            raise ValueError("Unsupported dimension (max is 4)")
+    elif approximation == "monte-carlo":
         X = np.zeros((0, dimension))
     else:
-        raise ValueError('Wrong approximation method chosen: "{:s}"'.format(approximation))
+        raise ValueError(
+            'Wrong approximation method chosen: "{:s}"'.format(approximation)
+        )
 
     # Only points inside the sphere are used
     d2 = np.sum(np.power(X, 2), axis=1)
     X = X[d2 < radius0 * radius0, :]
 
@@ -164,11 +183,11 @@
     max_moves = np.zeros((0,))
 
     for iter in range(max_iter):
 
         # In the case of monte-carlo, renew the sampled points
-        if approximation == 'monte-carlo':
+        if approximation == "monte-carlo":
             X = np.random.rand(approx_n, dimension) * 2 * radius0 - radius0
             d2 = np.sum(np.power(X, 2), axis=1)
             X = X[d2 < radius0 * radius0, :]
 
         # Get the distances matrix [n_approx, K, dim]
@@ -177,11 +196,11 @@
 
         # Compute cell centers
         cell_inds = np.argmin(sq_distances, axis=1)
         centers = []
         for c in range(num_cells):
-            bool_c = (cell_inds == c)
+            bool_c = cell_inds == c
             num_c = np.sum(bool_c.astype(np.int32))
             if num_c > 0:
                 centers.append(np.sum(X[bool_c, :], axis=0) / num_c)
             else:
                 warning = True
@@ -194,32 +213,46 @@
 
         # Check moves for convergence
         max_moves = np.append(max_moves, np.max(np.linalg.norm(moves, axis=1)))
 
         # Optional fixing
-        if fixed == 'center':
+        if fixed == "center":
             kernel_points[0, :] *= 0
-        if fixed == 'verticals':
+        if fixed == "verticals":
             kernel_points[0, :] *= 0
             kernel_points[:3, :-1] *= 0
 
         if verbose:
-            print('iter {:5d} / max move = {:f}'.format(iter, np.max(np.linalg.norm(moves, axis=1))))
+            print(
+                "iter {:5d} / max move = {:f}".format(
+                    iter, np.max(np.linalg.norm(moves, axis=1))
+                )
+            )
             if warning:
-                print('{:}WARNING: at least one point has no cell{:}'.format(bcolors.WARNING, bcolors.ENDC))
+                print(
+                    "{:}WARNING: at least one point has no cell{:}".format(
+                        bcolors.WARNING, bcolors.ENDC
+                    )
+                )
         if verbose > 1:
             plt.clf()
-            plt.scatter(X[:, 0], X[:, 1], c=cell_inds, s=20.0,
-                        marker='.', cmap=plt.get_cmap('tab20'))
-            #plt.scatter(kernel_points[:, 0], kernel_points[:, 1], c=np.arange(num_cells), s=100.0,
+            plt.scatter(
+                X[:, 0],
+                X[:, 1],
+                c=cell_inds,
+                s=20.0,
+                marker=".",
+                cmap=plt.get_cmap("tab20"),
+            )
+            # plt.scatter(kernel_points[:, 0], kernel_points[:, 1], c=np.arange(num_cells), s=100.0,
             #            marker='+', cmap=plt.get_cmap('tab20'))
-            plt.plot(kernel_points[:, 0], kernel_points[:, 1], 'k+')
-            circle = plt.Circle((0, 0), radius0, color='r', fill=False)
+            plt.plot(kernel_points[:, 0], kernel_points[:, 1], "k+")
+            circle = plt.Circle((0, 0), radius0, color="r", fill=False)
             fig.axes[0].add_artist(circle)
             fig.axes[0].set_xlim((-radius0 * 1.1, radius0 * 1.1))
             fig.axes[0].set_ylim((-radius0 * 1.1, radius0 * 1.1))
-            fig.axes[0].set_aspect('equal')
+            fig.axes[0].set_aspect("equal")
             plt.draw()
             plt.pause(0.001)
             plt.show(block=False)
 
     ###################
@@ -229,36 +262,49 @@
     # Show the convergence to ask user if this kernel is correct
     if verbose:
         if dimension == 2:
             fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[10.4, 4.8])
             ax1.plot(max_moves)
-            ax2.scatter(X[:, 0], X[:, 1], c=cell_inds, s=20.0,
-                        marker='.', cmap=plt.get_cmap('tab20'))
+            ax2.scatter(
+                X[:, 0],
+                X[:, 1],
+                c=cell_inds,
+                s=20.0,
+                marker=".",
+                cmap=plt.get_cmap("tab20"),
+            )
             # plt.scatter(kernel_points[:, 0], kernel_points[:, 1], c=np.arange(num_cells), s=100.0,
             #            marker='+', cmap=plt.get_cmap('tab20'))
-            ax2.plot(kernel_points[:, 0], kernel_points[:, 1], 'k+')
-            circle = plt.Circle((0, 0), radius0, color='r', fill=False)
+            ax2.plot(kernel_points[:, 0], kernel_points[:, 1], "k+")
+            circle = plt.Circle((0, 0), radius0, color="r", fill=False)
             ax2.add_artist(circle)
             ax2.set_xlim((-radius0 * 1.1, radius0 * 1.1))
             ax2.set_ylim((-radius0 * 1.1, radius0 * 1.1))
-            ax2.set_aspect('equal')
-            plt.title('Check if kernel is correct.')
+            ax2.set_aspect("equal")
+            plt.title("Check if kernel is correct.")
             plt.draw()
             plt.show()
 
         if dimension > 2:
             plt.figure()
             plt.plot(max_moves)
-            plt.title('Check if kernel is correct.')
+            plt.title("Check if kernel is correct.")
             plt.show()
 
     # Rescale kernels with real radius
     return kernel_points * radius
 
 
-def kernel_point_optimization_debug(radius, num_points, num_kernels=1, dimension=3,
-                                    fixed='center', ratio=0.66, verbose=0):
+def kernel_point_optimization_debug(
+    radius,
+    num_points,
+    num_kernels=1,
+    dimension=3,
+    fixed="center",
+    ratio=0.66,
+    verbose=0,
+):
     """
     Creation of kernel point via optimization of potentials.
     :param radius: Radius of the kernels
     :param num_points: points composing kernels
     :param num_kernels: number of wanted kernels
@@ -290,32 +336,39 @@
     #######################
     # Kernel initialization
     #######################
 
     # Random kernel points
-    kernel_points = np.random.rand(num_kernels * num_points - 1, dimension) * diameter0 - radius0
-    while (kernel_points.shape[0] < num_kernels * num_points):
-        new_points = np.random.rand(num_kernels * num_points - 1, dimension) * diameter0 - radius0
+    kernel_points = (
+        np.random.rand(num_kernels * num_points - 1, dimension) * diameter0 - radius0
+    )
+    while kernel_points.shape[0] < num_kernels * num_points:
+        new_points = (
+            np.random.rand(num_kernels * num_points - 1, dimension) * diameter0
+            - radius0
+        )
         kernel_points = np.vstack((kernel_points, new_points))
         d2 = np.sum(np.power(kernel_points, 2), axis=1)
         kernel_points = kernel_points[d2 < 0.5 * radius0 * radius0, :]
-    kernel_points = kernel_points[:num_kernels * num_points, :].reshape((num_kernels, num_points, -1))
+    kernel_points = kernel_points[: num_kernels * num_points, :].reshape(
+        (num_kernels, num_points, -1)
+    )
 
     # Optionnal fixing
-    if fixed == 'center':
+    if fixed == "center":
         kernel_points[:, 0, :] *= 0
-    if fixed == 'verticals':
+    if fixed == "verticals":
         kernel_points[:, :3, :] *= 0
         kernel_points[:, 1, -1] += 2 * radius0 / 3
         kernel_points[:, 2, -1] -= 2 * radius0 / 3
 
     #####################
     # Kernel optimization
     #####################
 
     # Initialize figure
-    if verbose>1:
+    if verbose > 1:
         fig = plt.figure()
 
     saved_gradient_norms = np.zeros((10000, num_kernels))
     old_gradient_norms = np.zeros((num_kernels, num_points))
     step = -1
@@ -329,20 +382,20 @@
 
         # Derivative of the sum of potentials of all points
         A = np.expand_dims(kernel_points, axis=2)
         B = np.expand_dims(kernel_points, axis=1)
         interd2 = np.sum(np.power(A - B, 2), axis=-1)
-        inter_grads = (A - B) / (np.power(np.expand_dims(interd2, -1), 3/2) + 1e-6)
+        inter_grads = (A - B) / (np.power(np.expand_dims(interd2, -1), 3 / 2) + 1e-6)
         inter_grads = np.sum(inter_grads, axis=1)
 
         # Derivative of the radius potential
-        circle_grads = 10*kernel_points
+        circle_grads = 10 * kernel_points
 
         # All gradients
         gradients = inter_grads + circle_grads
 
-        if fixed == 'verticals':
+        if fixed == "verticals":
             gradients[:, 1:3, :-1] = 0
 
         # Stop condition
         # **************
 
@@ -350,13 +403,21 @@
         gradients_norms = np.sqrt(np.sum(np.power(gradients, 2), axis=-1))
         saved_gradient_norms[step, :] = np.max(gradients_norms, axis=1)
 
         # Stop if all moving points are gradients fixed (low gradients diff)
 
-        if fixed == 'center' and np.max(np.abs(old_gradient_norms[:, 1:] - gradients_norms[:, 1:])) < thresh:
+        if (
+            fixed == "center"
+            and np.max(np.abs(old_gradient_norms[:, 1:] - gradients_norms[:, 1:]))
+            < thresh
+        ):
             break
-        elif fixed == 'verticals' and np.max(np.abs(old_gradient_norms[:, 3:] - gradients_norms[:, 3:])) < thresh:
+        elif (
+            fixed == "verticals"
+            and np.max(np.abs(old_gradient_norms[:, 3:] - gradients_norms[:, 3:]))
+            < thresh
+        ):
             break
         elif np.max(np.abs(old_gradient_norms - gradients_norms)) < thresh:
             break
         old_gradient_norms = gradients_norms
 
@@ -365,39 +426,47 @@
 
         # Clip gradient to get moving dists
         moving_dists = np.minimum(moving_factor * gradients_norms, clip)
 
         # Fix central point
-        if fixed == 'center':
+        if fixed == "center":
             moving_dists[:, 0] = 0
-        if fixed == 'verticals':
+        if fixed == "verticals":
             moving_dists[:, 0] = 0
 
         # Move points
-        kernel_points -= np.expand_dims(moving_dists, -1) * gradients / np.expand_dims(gradients_norms + 1e-6, -1)
+        kernel_points -= (
+            np.expand_dims(moving_dists, -1)
+            * gradients
+            / np.expand_dims(gradients_norms + 1e-6, -1)
+        )
 
         if verbose:
-            print('step {:5d} / max grad = {:f}'.format(step, np.max(gradients_norms[:, 3:])))
+            print(
+                "step {:5d} / max grad = {:f}".format(
+                    step, np.max(gradients_norms[:, 3:])
+                )
+            )
         if verbose > 1:
             plt.clf()
-            plt.plot(kernel_points[0, :, 0], kernel_points[0, :, 1], '.')
-            circle = plt.Circle((0, 0), radius, color='r', fill=False)
+            plt.plot(kernel_points[0, :, 0], kernel_points[0, :, 1], ".")
+            circle = plt.Circle((0, 0), radius, color="r", fill=False)
             fig.axes[0].add_artist(circle)
-            fig.axes[0].set_xlim((-radius*1.1, radius*1.1))
-            fig.axes[0].set_ylim((-radius*1.1, radius*1.1))
-            fig.axes[0].set_aspect('equal')
+            fig.axes[0].set_xlim((-radius * 1.1, radius * 1.1))
+            fig.axes[0].set_ylim((-radius * 1.1, radius * 1.1))
+            fig.axes[0].set_aspect("equal")
             plt.draw()
             plt.pause(0.001)
             plt.show(block=False)
             print(moving_factor)
 
         # moving factor decay
         moving_factor *= continuous_moving_decay
 
     # Remove unused lines in the saved gradients
     if step < 10000:
-        saved_gradient_norms = saved_gradient_norms[:step+1, :]
+        saved_gradient_norms = saved_gradient_norms[: step + 1, :]
 
     # Rescale radius to fit the wanted ratio of radius
     r = np.sqrt(np.sum(np.power(kernel_points, 2), axis=-1))
     kernel_points *= ratio / np.mean(r[:, 1:])
 
@@ -406,85 +475,93 @@
 
 
 def load_kernels(radius, num_kpoints, dimension, fixed, lloyd=False):
 
     # Kernel directory
-    kernel_dir = 'kernels/dispositions'
+    kernel_dir = "kernels/dispositions"
     if not exists(kernel_dir):
         makedirs(kernel_dir)
 
     # To many points switch to Lloyds
     if num_kpoints > 30:
         lloyd = True
 
     # Kernel_file
-    kernel_file = join(kernel_dir, 'k_{:03d}_{:s}_{:d}D.ply'.format(num_kpoints, fixed, dimension))
+    kernel_file = join(
+        kernel_dir, "k_{:03d}_{:s}_{:d}D.ply".format(num_kpoints, fixed, dimension)
+    )
 
     # Check if already done
     if not exists(kernel_file):
         if lloyd:
             # Create kernels
-            kernel_points = spherical_Lloyd(1.0,
-                                            num_kpoints,
-                                            dimension=dimension,
-                                            fixed=fixed,
-                                            verbose=0)
+            kernel_points = spherical_Lloyd(
+                1.0, num_kpoints, dimension=dimension, fixed=fixed, verbose=0
+            )
 
         else:
             # Create kernels
-            kernel_points, grad_norms = kernel_point_optimization_debug(1.0,
-                                                                        num_kpoints,
-                                                                        num_kernels=100,
-                                                                        dimension=dimension,
-                                                                        fixed=fixed,
-                                                                        verbose=0)
+            kernel_points, grad_norms = kernel_point_optimization_debug(
+                1.0,
+                num_kpoints,
+                num_kernels=100,
+                dimension=dimension,
+                fixed=fixed,
+                verbose=0,
+            )
 
             # Find best candidate
             best_k = np.argmin(grad_norms[-1, :])
 
             # Save points
             kernel_points = kernel_points[best_k, :, :]
 
-        write_ply(kernel_file, kernel_points, ['x', 'y', 'z'])
+        write_ply(kernel_file, kernel_points, ["x", "y", "z"])
 
     else:
         data = read_ply(kernel_file)
-        kernel_points = np.vstack((data['x'], data['y'], data['z'])).T
+        kernel_points = np.vstack((data["x"], data["y"], data["z"])).T
 
     # Random roations for the kernel
     # N.B. 4D random rotations not supported yet
     R = np.eye(dimension)
     theta = np.random.rand() * 2 * np.pi
     if dimension == 2:
-        if fixed != 'vertical':
+        if fixed != "vertical":
             c, s = np.cos(theta), np.sin(theta)
             R = np.array([[c, -s], [s, c]], dtype=np.float32)
 
     elif dimension == 3:
-        if fixed != 'vertical':
+        if fixed != "vertical":
             c, s = np.cos(theta), np.sin(theta)
             R = np.array([[c, -s, 0], [s, c, 0], [0, 0, 1]], dtype=np.float32)
 
         else:
             phi = (np.random.rand() - 0.5) * np.pi
 
             # Create the first vector in carthesian coordinates
-            u = np.array([np.cos(theta) * np.cos(phi), np.sin(theta) * np.cos(phi), np.sin(phi)])
+            u = np.array(
+                [np.cos(theta) * np.cos(phi), np.sin(theta) * np.cos(phi), np.sin(phi)]
+            )
 
             # Choose a random rotation angle
             alpha = np.random.rand() * 2 * np.pi
 
             # Create the rotation matrix with this vector and angle
-            R = create_3D_rotations(np.reshape(u, (1, -1)), np.reshape(alpha, (1, -1)))[0]
+            R = create_3D_rotations(np.reshape(u, (1, -1)), np.reshape(alpha, (1, -1)))[
+                0
+            ]
 
             R = R.astype(np.float32)
 
     # Add a small noise
-    kernel_points = kernel_points + np.random.normal(scale=0.01, size=kernel_points.shape)
+    kernel_points = kernel_points + np.random.normal(
+        scale=0.01, size=kernel_points.shape
+    )
 
     # Scale kernels
     kernel_points = radius * kernel_points
 
     # Rotate kernels
     kernel_points = np.matmul(kernel_points, R)
 
-    return kernel_points.astype(np.float32)
\ No newline at end of file
+    return kernel_points.astype(np.float32)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/pointDrop.py	2024-06-30 22:34:18.180997+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/pointDrop.py	2024-07-08 11:53:44.706825+00:00
@@ -18,64 +18,66 @@
 from datasets.NPM3D import NPM3DDataset, NPM3DSampler, NPM3DCollate
 from torch.utils.data import DataLoader
 
 
 def PointDrop(file_path=None, model=None, dataset=None, cls=None):
-        if not file_path:
-            raise ValueError("No file_path specified.")
-        if not model in ['kpconv', 'randlanet']:
-            raise ValueError("Unknown model type specified.")
-        if not dataset in ['npm3d', 'semantickitti', 'dales']:
-            raise ValueError("Unknown dataset type specified.")
+    if not file_path:
+        raise ValueError("No file_path specified.")
+    if not model in ["kpconv", "randlanet"]:
+        raise ValueError("Unknown model type specified.")
+    if not dataset in ["npm3d", "semantickitti", "dales"]:
+        raise ValueError("Unknown dataset type specified.")
 
-        if dataset == 'npm3d':
-            label_values = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).astype(np.int64)
-            ignored_labels = np.array([0]).astype(np.int64)
-            
-        cloud = read_ply(file_path)
-        
-        points = cloud[['x', 'y', 'z']]
-        labels = cloud['class']
-        preds = cloud['preds']
-        pgscam = cloud['pgscam']
-        
-        # No. of points
-        N = pgscam.shape[0]
-        
-        # Sorted heatmap indices in descending order
-        desc_idx = np.argsort(pgscam)[::-1]
+    if dataset == "npm3d":
+        label_values = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).astype(np.int64)
+        ignored_labels = np.array([0]).astype(np.int64)
 
-        desc_pgscam = pgscam[desc_idx]
+    cloud = read_ply(file_path)
 
-        # Percentage wise mIoU drop
-        drop_list = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]
+    points = cloud[["x", "y", "z"]]
+    labels = cloud["class"]
+    preds = cloud["preds"]
+    pgscam = cloud["pgscam"]
 
-        for drop in drop_list:
-            num_drop = int((drop * N)/100)
-            left_idx = desc_idx[num_drop:]
-            left_labels = labels[left_idx]
-            left_preds = preds[left_idx]
+    # No. of points
+    N = pgscam.shape[0]
 
-            Confs = [fast_confusion(left_labels, left_preds, label_values)]
+    # Sorted heatmap indices in descending order
+    desc_idx = np.argsort(pgscam)[::-1]
 
-            C = np.sum(np.stack(Confs), axis=0).astype(np.float32)
+    desc_pgscam = pgscam[desc_idx]
 
-            # Remove ignored labels from confusions
-            for l_ind, label_value in reversed(list(enumerate(label_values))):
-                if label_value in ignored_labels:
-                    C = np.delete(C, l_ind, axis=0)
-                    C = np.delete(C, l_ind, axis=1)
+    # Percentage wise mIoU drop
+    drop_list = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]
 
-            IoUs = IoU_from_confusions(C)
-            mIoU = np.mean(IoUs)
-            s = '{:5.2f} | '.format(100 * mIoU)
-            for IoU in IoUs:
-                s += '{:5.2f} '.format(100 * IoU)
-            print(s + '\n')
+    for drop in drop_list:
+        num_drop = int((drop * N) / 100)
+        left_idx = desc_idx[num_drop:]
+        left_labels = labels[left_idx]
+        left_preds = preds[left_idx]
 
-            continue
+        Confs = [fast_confusion(left_labels, left_preds, label_values)]
 
-        return
-        
-        
+        C = np.sum(np.stack(Confs), axis=0).astype(np.float32)
+
+        # Remove ignored labels from confusions
+        for l_ind, label_value in reversed(list(enumerate(label_values))):
+            if label_value in ignored_labels:
+                C = np.delete(C, l_ind, axis=0)
+                C = np.delete(C, l_ind, axis=1)
+
+        IoUs = IoU_from_confusions(C)
+        mIoU = np.mean(IoUs)
+        s = "{:5.2f} | ".format(100 * mIoU)
+        for IoU in IoUs:
+            s += "{:5.2f} ".format(100 * IoU)
+        print(s + "\n")
+
+        continue
+
+    return
+
+
 if __name__ == "__main__":
-    pd = PointDrop(file_path='./pgscam_results/0_cloud.ply', model='kpconv', dataset='npm3d', cls=7)
\ No newline at end of file
+    pd = PointDrop(
+        file_path="./pgscam_results/0_cloud.ply", model="kpconv", dataset="npm3d", cls=7
+    )
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/test_models.py	2024-06-30 22:34:18.639270+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/test_models.py	2024-07-08 11:53:44.975992+00:00
@@ -43,61 +43,68 @@
 #
 #           Main Call
 #       \***************/
 #
 
+
 def model_choice(chosen_log):
 
     ###########################
     # Call the test initializer
     ###########################
 
     # Automatically retrieve the last trained model
-    if chosen_log in ['last_ModelNet40', 'last_ShapeNetPart', 'last_S3DIS']:
+    if chosen_log in ["last_ModelNet40", "last_ShapeNetPart", "last_S3DIS"]:
 
         # Dataset name
-        test_dataset = '_'.join(chosen_log.split('_')[1:])
+        test_dataset = "_".join(chosen_log.split("_")[1:])
 
         # List all training logs
-        logs = np.sort([os.path.join('results', f) for f in os.listdir('results') if f.startswith('Log')])
+        logs = np.sort(
+            [
+                os.path.join("results", f)
+                for f in os.listdir("results")
+                if f.startswith("Log")
+            ]
+        )
 
         # Find the last log of asked dataset
         for log in logs[::-1]:
             log_config = Config()
             log_config.load(log)
             if log_config.dataset.startswith(test_dataset):
                 chosen_log = log
                 break
 
-        if chosen_log in ['last_ModelNet40', 'last_ShapeNetPart', 'last_S3DIS']:
+        if chosen_log in ["last_ModelNet40", "last_ShapeNetPart", "last_S3DIS"]:
             raise ValueError('No log of the dataset "' + test_dataset + '" found')
 
     # Check if log exists
     if not os.path.exists(chosen_log):
-        raise ValueError('The given log does not exists: ' + chosen_log)
+        raise ValueError("The given log does not exists: " + chosen_log)
 
     return chosen_log
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Main Call
 #       \***************/
 #
 
-if __name__ == '__main__':
+if __name__ == "__main__":
 
     ###############################
     # Choose the model to visualize
     ###############################
 
     #   Here you can choose which model you want to test with the variable test_model. Here are the possible values :
     #
     #       > 'last_XXX': Automatically retrieve the last trained model on dataset XXX
     #       > '(old_)results/Log_YYYY-MM-DD_HH-MM-SS': Directly provide the path of a trained model
 
-    chosen_log = 'results/Light_KPFCNN'
+    chosen_log = "results/Light_KPFCNN"
 
     # Choose the index of the checkpoint to load OR None if you want to load the current checkpoint
     chkp_idx = -1
 
     # Choose to test on validation or test split
@@ -109,29 +116,29 @@
     ############################
     # Initialize the environment
     ############################
 
     # Set which gpu is going to be used
-    GPU_ID = '0'
+    GPU_ID = "0"
 
     # Set GPU visible device
-    os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID
+    os.environ["CUDA_VISIBLE_DEVICES"] = GPU_ID
 
     ###############
     # Previous chkp
     ###############
 
     # Find all checkpoints in the chosen training folder
-    chkp_path = os.path.join(chosen_log, 'checkpoints')
-    chkps = [f for f in os.listdir(chkp_path) if f[:4] == 'chkp']
+    chkp_path = os.path.join(chosen_log, "checkpoints")
+    chkps = [f for f in os.listdir(chkp_path) if f[:4] == "chkp"]
 
     # Find which snapshot to restore
     if chkp_idx is None:
-        chosen_chkp = 'current_chkp.tar'
+        chosen_chkp = "current_chkp.tar"
     else:
         chosen_chkp = np.sort(chkps)[chkp_idx]
-    chosen_chkp = os.path.join(chosen_log, 'checkpoints', chosen_chkp)
+    chosen_chkp = os.path.join(chosen_log, "checkpoints", chosen_chkp)
 
     # Initialize configuration class
     config = Config()
     config.load(chosen_log)
 
@@ -139,80 +146,82 @@
     # Change model parameters for test
     ##################################
 
     # Change parameters for the test here. For example, you can stop augmenting the input data.
 
-    #config.augment_noise = 0.0001
-    #config.augment_symmetries = False
-    #config.batch_num = 3
-    #config.in_radius = 4
+    # config.augment_noise = 0.0001
+    # config.augment_symmetries = False
+    # config.batch_num = 3
+    # config.in_radius = 4
     config.validation_size = 200
     config.input_threads = 10
 
     ##############
     # Prepare Data
     ##############
 
     print()
-    print('Data Preparation')
-    print('****************')
+    print("Data Preparation")
+    print("****************")
 
     if on_val:
-        set = 'validation'
-    else:
-        set = 'test'
+        set = "validation"
+    else:
+        set = "test"
 
     # Initiate dataset
-    if config.dataset == 'ModelNet40':
+    if config.dataset == "ModelNet40":
         test_dataset = ModelNet40Dataset(config, train=False)
         test_sampler = ModelNet40Sampler(test_dataset)
         collate_fn = ModelNet40Collate
-    elif config.dataset == 'S3DIS':
-        test_dataset = S3DISDataset(config, set='validation', use_potentials=True)
+    elif config.dataset == "S3DIS":
+        test_dataset = S3DISDataset(config, set="validation", use_potentials=True)
         test_sampler = S3DISSampler(test_dataset)
         collate_fn = S3DISCollate
-    elif config.dataset == 'SemanticKitti':
+    elif config.dataset == "SemanticKitti":
         test_dataset = SemanticKittiDataset(config, set=set, balance_classes=False)
         test_sampler = SemanticKittiSampler(test_dataset)
         collate_fn = SemanticKittiCollate
     else:
-        raise ValueError('Unsupported dataset : ' + config.dataset)
+        raise ValueError("Unsupported dataset : " + config.dataset)
 
     # Data loader
-    test_loader = DataLoader(test_dataset,
-                             batch_size=1,
-                             sampler=test_sampler,
-                             collate_fn=collate_fn,
-                             num_workers=config.input_threads,
-                             pin_memory=True)
+    test_loader = DataLoader(
+        test_dataset,
+        batch_size=1,
+        sampler=test_sampler,
+        collate_fn=collate_fn,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
 
     # Calibrate samplers
     test_sampler.calibration(test_loader, verbose=True)
 
-    print('\nModel Preparation')
-    print('*****************')
+    print("\nModel Preparation")
+    print("*****************")
 
     # Define network model
     t1 = time.time()
-    if config.dataset_task == 'classification':
+    if config.dataset_task == "classification":
         net = KPCNN(config)
-    elif config.dataset_task in ['cloud_segmentation', 'slam_segmentation']:
+    elif config.dataset_task in ["cloud_segmentation", "slam_segmentation"]:
         net = KPFCNN(config, test_dataset.label_values, test_dataset.ignored_labels)
     else:
-        raise ValueError('Unsupported dataset_task for testing: ' + config.dataset_task)
+        raise ValueError("Unsupported dataset_task for testing: " + config.dataset_task)
 
     # Define a visualizer class
     tester = ModelTester(net, chkp_path=chosen_chkp)
-    print('Done in {:.1f}s\n'.format(time.time() - t1))
-
-    print('\nStart test')
-    print('**********\n')
+    print("Done in {:.1f}s\n".format(time.time() - t1))
+
+    print("\nStart test")
+    print("**********\n")
 
     # Training
-    if config.dataset_task == 'classification':
+    if config.dataset_task == "classification":
         tester.classification_test(net, test_loader, config)
-    elif config.dataset_task == 'cloud_segmentation':
+    elif config.dataset_task == "cloud_segmentation":
         tester.cloud_segmentation_test(net, test_loader, config)
-    elif config.dataset_task == 'slam_segmentation':
+    elif config.dataset_task == "slam_segmentation":
         tester.slam_segmentation_test(net, test_loader, config)
     else:
-        raise ValueError('Unsupported dataset_task for testing: ' + config.dataset_task)
\ No newline at end of file
+        raise ValueError("Unsupported dataset_task for testing: " + config.dataset_task)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/models/blocks.py	2024-06-30 22:34:18.176148+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/models/blocks.py	2024-07-08 11:53:45.044203+00:00
@@ -49,23 +49,23 @@
         idx = idx.unsqueeze(2)
         idx = idx.expand((-1, -1, x.shape[-1]))
         return x.gather(0, idx)
     elif method == 2:
         for i, ni in enumerate(idx.size()[1:]):
-            x = x.unsqueeze(i+1)
+            x = x.unsqueeze(i + 1)
             new_s = list(x.size())
-            new_s[i+1] = ni
+            new_s[i + 1] = ni
             x = x.expand(new_s)
         n = len(idx.size())
         for i, di in enumerate(x.size()[n:]):
-            idx = idx.unsqueeze(i+n)
+            idx = idx.unsqueeze(i + n)
             new_s = list(idx.size())
-            new_s[i+n] = di
+            new_s[i + n] = di
             idx = idx.expand(new_s)
         return x.gather(0, idx)
     else:
-        raise ValueError('Unkown method')
+        raise ValueError("Unkown method")
 
 
 def radius_gaussian(sq_r, sig, eps=1e-9):
     """
     Compute a radius gaussian (gaussian of distance)
@@ -122,11 +122,11 @@
     averaged_features = []
     i0 = 0
     for b_i, length in enumerate(batch_lengths):
 
         # Average features for each batch cloud
-        averaged_features.append(torch.mean(x[i0:i0 + length], dim=0))
+        averaged_features.append(torch.mean(x[i0 : i0 + length], dim=0))
 
         # Increment for next cloud
         i0 += length
 
     # Average features in each batch
@@ -140,13 +140,24 @@
 #
 
 
 class KPConv(nn.Module):
 
-    def __init__(self, kernel_size, p_dim, in_channels, out_channels, KP_extent, radius,
-                 fixed_kernel_points='center', KP_influence='linear', aggregation_mode='sum',
-                 deformable=False, modulated=False):
+    def __init__(
+        self,
+        kernel_size,
+        p_dim,
+        in_channels,
+        out_channels,
+        KP_extent,
+        radius,
+        fixed_kernel_points="center",
+        KP_influence="linear",
+        aggregation_mode="sum",
+        deformable=False,
+        modulated=False,
+    ):
         """
         Initialize parameters for KPConvDeformable.
         :param kernel_size: Number of kernel points.
         :param p_dim: dimension of the point space.
         :param in_channels: dimension of input features.
@@ -178,29 +189,35 @@
         self.min_d2 = None
         self.deformed_KP = None
         self.offset_features = None
 
         # Initialize weights
-        self.weights = Parameter(torch.zeros((self.K, in_channels, out_channels), dtype=torch.float32),
-                                 requires_grad=True)
+        self.weights = Parameter(
+            torch.zeros((self.K, in_channels, out_channels), dtype=torch.float32),
+            requires_grad=True,
+        )
 
         # Initiate weights for offsets
         if deformable:
             if modulated:
                 self.offset_dim = (self.p_dim + 1) * self.K
             else:
                 self.offset_dim = self.p_dim * self.K
-            self.offset_conv = KPConv(self.K,
-                                      self.p_dim,
-                                      self.in_channels,
-                                      self.offset_dim,
-                                      KP_extent,
-                                      radius,
-                                      fixed_kernel_points=fixed_kernel_points,
-                                      KP_influence=KP_influence,
-                                      aggregation_mode=aggregation_mode)
-            self.offset_bias = Parameter(torch.zeros(self.offset_dim, dtype=torch.float32), requires_grad=True)
+            self.offset_conv = KPConv(
+                self.K,
+                self.p_dim,
+                self.in_channels,
+                self.offset_dim,
+                KP_extent,
+                radius,
+                fixed_kernel_points=fixed_kernel_points,
+                KP_influence=KP_influence,
+                aggregation_mode=aggregation_mode,
+            )
+            self.offset_bias = Parameter(
+                torch.zeros(self.offset_dim, dtype=torch.float32), requires_grad=True
+            )
 
         else:
             self.offset_dim = None
             self.offset_conv = None
             self.offset_bias = None
@@ -224,37 +241,41 @@
         Initialize the kernel point positions in a sphere
         :return: the tensor of kernel points
         """
 
         # Create one kernel disposition (as numpy array). Choose the KP distance to center thanks to the KP extent
-        K_points_numpy = load_kernels(self.radius,
-                                      self.K,
-                                      dimension=self.p_dim,
-                                      fixed=self.fixed_kernel_points)
-
-        return Parameter(torch.tensor(K_points_numpy, dtype=torch.float32),
-                         requires_grad=False)
+        K_points_numpy = load_kernels(
+            self.radius, self.K, dimension=self.p_dim, fixed=self.fixed_kernel_points
+        )
+
+        return Parameter(
+            torch.tensor(K_points_numpy, dtype=torch.float32), requires_grad=False
+        )
 
     def forward(self, q_pts, s_pts, neighb_inds, x):
 
         ###################
         # Offset generation
         ###################
 
         if self.deformable:
 
             # Get offsets with a KPConv that only takes part of the features
-            self.offset_features = self.offset_conv(q_pts, s_pts, neighb_inds, x) + self.offset_bias
+            self.offset_features = (
+                self.offset_conv(q_pts, s_pts, neighb_inds, x) + self.offset_bias
+            )
 
             if self.modulated:
 
                 # Get offset (in normalized scale) from features
-                unscaled_offsets = self.offset_features[:, :self.p_dim * self.K]
+                unscaled_offsets = self.offset_features[:, : self.p_dim * self.K]
                 unscaled_offsets = unscaled_offsets.view(-1, self.K, self.p_dim)
 
                 # Get modulations
-                modulations = 2 * torch.sigmoid(self.offset_features[:, self.p_dim * self.K:])
+                modulations = 2 * torch.sigmoid(
+                    self.offset_features[:, self.p_dim * self.K :]
+                )
 
             else:
 
                 # Get offset (in normalized scale) from features
                 unscaled_offsets = self.offset_features.view(-1, self.K, self.p_dim)
@@ -292,26 +313,30 @@
         # Get all difference matrices [n_points, n_neighbors, n_kpoints, dim]
         neighbors.unsqueeze_(2)
         differences = neighbors - deformed_K_points
 
         # Get the square distances [n_points, n_neighbors, n_kpoints]
-        sq_distances = torch.sum(differences ** 2, dim=3)
+        sq_distances = torch.sum(differences**2, dim=3)
 
         # Optimization by ignoring points outside a deformed KP range
         if self.deformable:
 
             # Save distances for loss
             self.min_d2, _ = torch.min(sq_distances, dim=1)
 
             # Boolean of the neighbors in range of a kernel point [n_points, n_neighbors]
-            in_range = torch.any(sq_distances < self.KP_extent ** 2, dim=2).type(torch.int32)
+            in_range = torch.any(sq_distances < self.KP_extent**2, dim=2).type(
+                torch.int32
+            )
 
             # New value of max neighbors
             new_max_neighb = torch.max(torch.sum(in_range, dim=1))
 
             # For each row of neighbors, indices of the ones that are in range [n_points, new_max_neighb]
-            neighb_row_bool, neighb_row_inds = torch.topk(in_range, new_max_neighb.item(), dim=1)
+            neighb_row_bool, neighb_row_inds = torch.topk(
+                in_range, new_max_neighb.item(), dim=1
+            )
 
             # Gather new neighbor indices [n_points, new_max_neighb]
             new_neighb_inds = neighb_inds.gather(1, neighb_row_inds, sparse_grad=False)
 
             # Gather new distances to KP [n_points, new_max_neighb, n_kpoints]
@@ -319,39 +344,45 @@
             neighb_row_inds = neighb_row_inds.expand(-1, -1, self.K)
             sq_distances = sq_distances.gather(1, neighb_row_inds, sparse_grad=False)
 
             # New shadow neighbors have to point to the last shadow point
             new_neighb_inds *= neighb_row_bool
-            new_neighb_inds -= (neighb_row_bool.type(torch.int64) - 1) * int(s_pts.shape[0] - 1)
+            new_neighb_inds -= (neighb_row_bool.type(torch.int64) - 1) * int(
+                s_pts.shape[0] - 1
+            )
         else:
             new_neighb_inds = neighb_inds
 
         # Get Kernel point influences [n_points, n_kpoints, n_neighbors]
-        if self.KP_influence == 'constant':
+        if self.KP_influence == "constant":
             # Every point get an influence of 1.
             all_weights = torch.ones_like(sq_distances)
             all_weights = torch.transpose(all_weights, 1, 2)
 
-        elif self.KP_influence == 'linear':
+        elif self.KP_influence == "linear":
             # Influence decrease linearly with the distance, and get to zero when d = KP_extent.
-            all_weights = torch.clamp(1 - torch.sqrt(sq_distances) / self.KP_extent, min=0.0)
+            all_weights = torch.clamp(
+                1 - torch.sqrt(sq_distances) / self.KP_extent, min=0.0
+            )
             all_weights = torch.transpose(all_weights, 1, 2)
 
-        elif self.KP_influence == 'gaussian':
+        elif self.KP_influence == "gaussian":
             # Influence in gaussian of the distance.
             sigma = self.KP_extent * 0.3
             all_weights = radius_gaussian(sq_distances, sigma)
             all_weights = torch.transpose(all_weights, 1, 2)
         else:
-            raise ValueError('Unknown influence function type (config.KP_influence)')
+            raise ValueError("Unknown influence function type (config.KP_influence)")
 
         # In case of closest mode, only the closest KP can influence each point
-        if self.aggregation_mode == 'closest':
+        if self.aggregation_mode == "closest":
             neighbors_1nn = torch.argmin(sq_distances, dim=2)
-            all_weights *= torch.transpose(nn.functional.one_hot(neighbors_1nn, self.K), 1, 2)
-
-        elif self.aggregation_mode != 'sum':
+            all_weights *= torch.transpose(
+                nn.functional.one_hot(neighbors_1nn, self.K), 1, 2
+            )
+
+        elif self.aggregation_mode != "sum":
             raise ValueError("Unknown convolution mode. Should be 'closest' or 'sum'")
 
         # Add a zero feature for shadow neighbors
         x = torch.cat((x, torch.zeros_like(x[:1, :])), 0)
 
@@ -371,61 +402,68 @@
 
         # Convolution sum [n_points, out_fdim]
         return torch.sum(kernel_outputs, dim=0)
 
     def __repr__(self):
-        return 'KPConv(radius: {:.2f}, in_feat: {:d}, out_feat: {:d})'.format(self.radius,
-                                                                              self.in_channels,
-                                                                              self.out_channels)
+        return "KPConv(radius: {:.2f}, in_feat: {:d}, out_feat: {:d})".format(
+            self.radius, self.in_channels, self.out_channels
+        )
+
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Complex blocks
 #       \********************/
 #
 
-def block_decider(block_name,
-                  radius,
-                  in_dim,
-                  out_dim,
-                  layer_ind,
-                  config):
-
-    if block_name == 'unary':
-        return UnaryBlock(in_dim, out_dim, config.use_batch_norm, config.batch_norm_momentum)
-
-    elif block_name in ['simple',
-                        'simple_deformable',
-                        'simple_invariant',
-                        'simple_equivariant',
-                        'simple_strided',
-                        'simple_deformable_strided',
-                        'simple_invariant_strided',
-                        'simple_equivariant_strided']:
+
+def block_decider(block_name, radius, in_dim, out_dim, layer_ind, config):
+
+    if block_name == "unary":
+        return UnaryBlock(
+            in_dim, out_dim, config.use_batch_norm, config.batch_norm_momentum
+        )
+
+    elif block_name in [
+        "simple",
+        "simple_deformable",
+        "simple_invariant",
+        "simple_equivariant",
+        "simple_strided",
+        "simple_deformable_strided",
+        "simple_invariant_strided",
+        "simple_equivariant_strided",
+    ]:
         return SimpleBlock(block_name, in_dim, out_dim, radius, layer_ind, config)
 
-    elif block_name in ['resnetb',
-                        'resnetb_invariant',
-                        'resnetb_equivariant',
-                        'resnetb_deformable',
-                        'resnetb_strided',
-                        'resnetb_deformable_strided',
-                        'resnetb_equivariant_strided',
-                        'resnetb_invariant_strided']:
-        return ResnetBottleneckBlock(block_name, in_dim, out_dim, radius, layer_ind, config)
-
-    elif block_name == 'max_pool' or block_name == 'max_pool_wide':
+    elif block_name in [
+        "resnetb",
+        "resnetb_invariant",
+        "resnetb_equivariant",
+        "resnetb_deformable",
+        "resnetb_strided",
+        "resnetb_deformable_strided",
+        "resnetb_equivariant_strided",
+        "resnetb_invariant_strided",
+    ]:
+        return ResnetBottleneckBlock(
+            block_name, in_dim, out_dim, radius, layer_ind, config
+        )
+
+    elif block_name == "max_pool" or block_name == "max_pool_wide":
         return MaxPoolBlock(layer_ind)
 
-    elif block_name == 'global_average':
+    elif block_name == "global_average":
         return GlobalAverageBlock()
 
-    elif block_name == 'nearest_upsample':
+    elif block_name == "nearest_upsample":
         return NearestUpsampleBlock(layer_ind)
 
     else:
-        raise ValueError('Unknown block name in the architecture definition : ' + block_name)
+        raise ValueError(
+            "Unknown block name in the architecture definition : " + block_name
+        )
 
 
 class BatchNormBlock(nn.Module):
 
     def __init__(self, in_dim, use_bn, bn_momentum):
@@ -439,13 +477,15 @@
         self.bn_momentum = bn_momentum
         self.use_bn = use_bn
         self.in_dim = in_dim
         if self.use_bn:
             self.batch_norm = nn.BatchNorm1d(in_dim, momentum=bn_momentum)
-            #self.batch_norm = nn.InstanceNorm1d(in_dim, momentum=bn_momentum)
-        else:
-            self.bias = Parameter(torch.zeros(in_dim, dtype=torch.float32), requires_grad=True)
+            # self.batch_norm = nn.InstanceNorm1d(in_dim, momentum=bn_momentum)
+        else:
+            self.bias = Parameter(
+                torch.zeros(in_dim, dtype=torch.float32), requires_grad=True
+            )
         return
 
     def reset_parameters(self):
         nn.init.zeros_(self.bias)
 
@@ -459,13 +499,15 @@
             return x.squeeze()
         else:
             return x + self.bias
 
     def __repr__(self):
-        return 'BatchNormBlock(in_feat: {:d}, momentum: {:.3f}, only_bias: {:s})'.format(self.in_dim,
-                                                                                         self.bn_momentum,
-                                                                                         str(not self.use_bn))
+        return (
+            "BatchNormBlock(in_feat: {:d}, momentum: {:.3f}, only_bias: {:s})".format(
+                self.in_dim, self.bn_momentum, str(not self.use_bn)
+            )
+        )
 
 
 class UnaryBlock(nn.Module):
 
     def __init__(self, in_dim, out_dim, use_bn, bn_momentum, no_relu=False):
@@ -495,14 +537,13 @@
         if not self.no_relu:
             x = self.leaky_relu(x)
         return x
 
     def __repr__(self):
-        return 'UnaryBlock(in_feat: {:d}, out_feat: {:d}, BN: {:s}, ReLU: {:s})'.format(self.in_dim,
-                                                                                        self.out_dim,
-                                                                                        str(self.use_bn),
-                                                                                        str(not self.no_relu))
+        return "UnaryBlock(in_feat: {:d}, out_feat: {:d}, BN: {:s}, ReLU: {:s})".format(
+            self.in_dim, self.out_dim, str(self.use_bn), str(not self.no_relu)
+        )
 
 
 class SimpleBlock(nn.Module):
 
     def __init__(self, block_name, in_dim, out_dim, radius, layer_ind, config):
@@ -525,31 +566,33 @@
         self.block_name = block_name
         self.in_dim = in_dim
         self.out_dim = out_dim
 
         # Define the KPConv class
-        self.KPConv = KPConv(config.num_kernel_points,
-                             config.in_points_dim,
-                             in_dim,
-                             out_dim // 2,
-                             current_extent,
-                             radius,
-                             fixed_kernel_points=config.fixed_kernel_points,
-                             KP_influence=config.KP_influence,
-                             aggregation_mode=config.aggregation_mode,
-                             deformable='deform' in block_name,
-                             modulated=config.modulated)
+        self.KPConv = KPConv(
+            config.num_kernel_points,
+            config.in_points_dim,
+            in_dim,
+            out_dim // 2,
+            current_extent,
+            radius,
+            fixed_kernel_points=config.fixed_kernel_points,
+            KP_influence=config.KP_influence,
+            aggregation_mode=config.aggregation_mode,
+            deformable="deform" in block_name,
+            modulated=config.modulated,
+        )
 
         # Other opperations
         self.batch_norm = BatchNormBlock(out_dim // 2, self.use_bn, self.bn_momentum)
         self.leaky_relu = nn.LeakyReLU(0.1)
 
         return
 
     def forward(self, x, batch):
 
-        if 'strided' in self.block_name:
+        if "strided" in self.block_name:
             q_pts = batch.points[self.layer_ind + 1]
             s_pts = batch.points[self.layer_ind]
             neighb_inds = batch.pools[self.layer_ind]
         else:
             q_pts = batch.points[self.layer_ind]
@@ -583,45 +626,55 @@
         self.in_dim = in_dim
         self.out_dim = out_dim
 
         # First downscaling mlp
         if in_dim != out_dim // 4:
-            self.unary1 = UnaryBlock(in_dim, out_dim // 4, self.use_bn, self.bn_momentum)
+            self.unary1 = UnaryBlock(
+                in_dim, out_dim // 4, self.use_bn, self.bn_momentum
+            )
         else:
             self.unary1 = nn.Identity()
 
         # KPConv block
-        self.KPConv = KPConv(config.num_kernel_points,
-                             config.in_points_dim,
-                             out_dim // 4,
-                             out_dim // 4,
-                             current_extent,
-                             radius,
-                             fixed_kernel_points=config.fixed_kernel_points,
-                             KP_influence=config.KP_influence,
-                             aggregation_mode=config.aggregation_mode,
-                             deformable='deform' in block_name,
-                             modulated=config.modulated)
-        self.batch_norm_conv = BatchNormBlock(out_dim // 4, self.use_bn, self.bn_momentum)
+        self.KPConv = KPConv(
+            config.num_kernel_points,
+            config.in_points_dim,
+            out_dim // 4,
+            out_dim // 4,
+            current_extent,
+            radius,
+            fixed_kernel_points=config.fixed_kernel_points,
+            KP_influence=config.KP_influence,
+            aggregation_mode=config.aggregation_mode,
+            deformable="deform" in block_name,
+            modulated=config.modulated,
+        )
+        self.batch_norm_conv = BatchNormBlock(
+            out_dim // 4, self.use_bn, self.bn_momentum
+        )
 
         # Second upscaling mlp
-        self.unary2 = UnaryBlock(out_dim // 4, out_dim, self.use_bn, self.bn_momentum, no_relu=True)
+        self.unary2 = UnaryBlock(
+            out_dim // 4, out_dim, self.use_bn, self.bn_momentum, no_relu=True
+        )
 
         # Shortcut optional mpl
         if in_dim != out_dim:
-            self.unary_shortcut = UnaryBlock(in_dim, out_dim, self.use_bn, self.bn_momentum, no_relu=True)
+            self.unary_shortcut = UnaryBlock(
+                in_dim, out_dim, self.use_bn, self.bn_momentum, no_relu=True
+            )
         else:
             self.unary_shortcut = nn.Identity()
 
         # Other operations
         self.leaky_relu = nn.LeakyReLU(0.1)
 
         return
 
     def forward(self, features, batch):
 
-        if 'strided' in self.block_name:
+        if "strided" in self.block_name:
             q_pts = batch.points[self.layer_ind + 1]
             s_pts = batch.points[self.layer_ind]
             neighb_inds = batch.pools[self.layer_ind]
         else:
             q_pts = batch.points[self.layer_ind]
@@ -637,11 +690,11 @@
 
         # Second upscaling mlp
         x = self.unary2(x)
 
         # Shortcut
-        if 'strided' in self.block_name:
+        if "strided" in self.block_name:
             shortcut = max_pool(features, neighb_inds)
         else:
             shortcut = features
         shortcut = self.unary_shortcut(shortcut)
 
@@ -673,12 +726,13 @@
 
     def forward(self, x, batch):
         return closest_pool(x, batch.upsamples[self.layer_ind - 1])
 
     def __repr__(self):
-        return 'NearestUpsampleBlock(layer: {:d} -> {:d})'.format(self.layer_ind,
-                                                                  self.layer_ind - 1)
+        return "NearestUpsampleBlock(layer: {:d} -> {:d})".format(
+            self.layer_ind, self.layer_ind - 1
+        )
 
 
 class MaxPoolBlock(nn.Module):
 
     def __init__(self, layer_ind):
@@ -689,6 +743,5 @@
         self.layer_ind = layer_ind
         return
 
     def forward(self, x, batch):
         return max_pool(x, batch.pools[self.layer_ind + 1])
-
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/train_DALES.py	2024-06-30 22:34:18.654903+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/train_DALES.py	2024-07-08 11:53:45.116511+00:00
@@ -37,10 +37,11 @@
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Config Class
 #       \******************/
 #
+
 
 class NPM3DConfig(Config):
     """
     Override the parameters you want to modify for this dataset
     """
@@ -48,48 +49,50 @@
     ####################
     # Dataset parameters
     ####################
 
     # Dataset name
-    dataset = 'NPM3D'
+    dataset = "NPM3D"
 
     # Number of classes in the dataset (This value is overwritten by dataset class when Initializating dataset).
     num_classes = None
 
     # Type of task performed on this dataset (also overwritten)
-    dataset_task = ''
+    dataset_task = ""
 
     # Number of CPU threads for the input pipeline
     input_threads = 10
 
     #########################
     # Architecture definition
     #########################
 
     # # Define layers
-    architecture = ['simple',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary']
+    architecture = [
+        "simple",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+    ]
 
     ###################
     # KPConv parameters
     ###################
 
@@ -110,14 +113,14 @@
 
     # Radius of the area of influence of each kernel point in "number grid cell". (1.0 is the standard value)
     KP_extent = 1.2
 
     # Behavior of convolutions in ('constant', 'linear', 'gaussian')
-    KP_influence = 'linear'
+    KP_influence = "linear"
 
     # Aggregation function of KPConv in ('closest', 'sum')
-    aggregation_mode = 'sum'
+    aggregation_mode = "sum"
 
     # Choice of input features
     first_features_dim = 128
     in_features_dim = 1
 
@@ -129,14 +132,14 @@
     batch_norm_momentum = 0.02
 
     # Deformable offset loss
     # 'point2point' fitting geometry by penalizing distance from deform point to input points
     # 'point2plane' fitting geometry by penalizing distance from deform point to input point triplet (not implemented)
-    deform_fitting_mode = 'point2point'
-    deform_fitting_power = 1.0              # Multiplier for the fitting/repulsive loss
-    deform_lr_factor = 0.1                  # Multiplier for learning rate applied to the deformations
-    repulse_extent = 1.2                    # Distance of repulsion for deformed kernel points
+    deform_fitting_mode = "point2point"
+    deform_fitting_power = 1.0  # Multiplier for the fitting/repulsive loss
+    deform_lr_factor = 0.1  # Multiplier for learning rate applied to the deformations
+    repulse_extent = 1.2  # Distance of repulsion for deformed kernel points
 
     #####################
     # Training parameters
     #####################
 
@@ -162,21 +165,21 @@
     checkpoint_gap = 50
 
     # Augmentations
     augment_scale_anisotropic = True
     augment_symmetries = [True, False, False]
-    augment_rotation = 'vertical'
+    augment_rotation = "vertical"
     augment_scale_min = 0.9
     augment_scale_max = 1.1
     augment_noise = 0.001
     augment_color = 0.8
 
     # The way we balance segmentation loss
     #   > 'none': Each point in the whole batch has the same contribution.
     #   > 'class': Each class has the same contribution (points are weighted according to class balance)
     #   > 'batch': Each cloud in the batch has the same contribution (points are weighted according cloud sizes)
-    segloss_balance = 'none'
+    segloss_balance = "none"
 
     # Do we nee to save convergence
     saving = True
     saving_path = None
 
@@ -185,125 +188,133 @@
 #
 #           Main Call
 #       \***************/
 #
 
-if __name__ == '__main__':
+if __name__ == "__main__":
 
     ############################
     # Initialize the environment
     ############################
 
     # Set which gpu is going to be used
-    GPU_ID = '0'
+    GPU_ID = "0"
 
     # Set GPU visible device
-    os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID
+    os.environ["CUDA_VISIBLE_DEVICES"] = GPU_ID
 
     ###############
     # Previous chkp
     ###############
 
     # Choose here if you want to start training from a previous snapshot (None for new training)
     # previous_training_path = 'Log_2020-03-19_19-53-27'
-#     previous_training_path = 'Log_2023-03-28_10-08-39'
-    previous_training_path = 'Log_2023-04-23_07-23-33'
+    #     previous_training_path = 'Log_2023-03-28_10-08-39'
+    previous_training_path = "Log_2023-04-23_07-23-33"
 
     # Choose index of checkpoint to start from. If None, uses the latest chkp
     chkp_idx = None
     if previous_training_path:
 
         # Find all snapshot in the chosen training folder
-        chkp_path = os.path.join('results', previous_training_path, 'checkpoints')
-        chkps = [f for f in os.listdir(chkp_path) if f[:4] == 'chkp']
+        chkp_path = os.path.join("results", previous_training_path, "checkpoints")
+        chkps = [f for f in os.listdir(chkp_path) if f[:4] == "chkp"]
 
         # Find which snapshot to restore
         if chkp_idx is None:
-            chosen_chkp = 'current_chkp.tar'
+            chosen_chkp = "current_chkp.tar"
         else:
             chosen_chkp = np.sort(chkps)[chkp_idx]
-        chosen_chkp = os.path.join('results', previous_training_path, 'checkpoints', chosen_chkp)
+        chosen_chkp = os.path.join(
+            "results", previous_training_path, "checkpoints", chosen_chkp
+        )
 
     else:
         chosen_chkp = None
-
 
     ##############
     # Prepare Data
     ##############
 
     print()
-    print('Data Preparation')
-    print('****************')
+    print("Data Preparation")
+    print("****************")
 
     # Initialize configuration class
     config = NPM3DConfig()
     if previous_training_path:
-        config.load(os.path.join('results', previous_training_path))
+        config.load(os.path.join("results", previous_training_path))
         config.saving_path = None
 
     # Get path from argument if given
     if len(sys.argv) > 1:
         config.saving_path = sys.argv[1]
 
     # Initialize datasets
-    training_dataset = NPM3DDataset(config, set='training', use_potentials=True)
-    test_dataset = NPM3DDataset(config, set='validation', use_potentials=True)
+    training_dataset = NPM3DDataset(config, set="training", use_potentials=True)
+    test_dataset = NPM3DDataset(config, set="validation", use_potentials=True)
 
     # Initialize samplers
     training_sampler = NPM3DSampler(training_dataset)
     test_sampler = NPM3DSampler(test_dataset)
 
     # Initialize the dataloader
-    training_loader = DataLoader(training_dataset,
-                                 batch_size=1,
-                                 sampler=training_sampler,
-                                 collate_fn=NPM3DCollate,
-                                 num_workers=config.input_threads,
-                                 pin_memory=True)
-    test_loader = DataLoader(test_dataset,
-                             batch_size=1,
-                             sampler=test_sampler,
-                             collate_fn=NPM3DCollate,
-                             num_workers=config.input_threads,
-                             pin_memory=True)
+    training_loader = DataLoader(
+        training_dataset,
+        batch_size=1,
+        sampler=training_sampler,
+        collate_fn=NPM3DCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
+    test_loader = DataLoader(
+        test_dataset,
+        batch_size=1,
+        sampler=test_sampler,
+        collate_fn=NPM3DCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
 
     # Calibrate samplers
     training_sampler.calibration(training_loader, verbose=True)
     test_sampler.calibration(test_loader, verbose=True)
 
     # Optional debug functions
     # debug_timing(training_dataset, training_loader)
     # debug_timing(test_dataset, test_loader)
     # debug_upsampling(training_dataset, training_loader)
 
-    print('\nModel Preparation')
-    print('*****************')
+    print("\nModel Preparation")
+    print("*****************")
 
     # Define network model
     t1 = time.time()
     net = KPFCNN(config, training_dataset.label_values, training_dataset.ignored_labels)
 
     debug = False
     if debug:
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         print(net)
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         for param in net.parameters():
             if param.requires_grad:
                 print(param.shape)
-        print('\n*************************************\n')
-        print("Model size %i" % sum(param.numel() for param in net.parameters() if param.requires_grad))
-        print('\n*************************************\n')
+        print("\n*************************************\n")
+        print(
+            "Model size %i"
+            % sum(param.numel() for param in net.parameters() if param.requires_grad)
+        )
+        print("\n*************************************\n")
 
     # Define a trainer class
     trainer = ModelTrainer(net, config, chkp_path=chosen_chkp)
-    print('Done in {:.1f}s\n'.format(time.time() - t1))
-
-    print('\nStart training')
-    print('**************')
+    print("Done in {:.1f}s\n".format(time.time() - t1))
+
+    print("\nStart training")
+    print("**************")
 
     # Training
     trainer.train(net, training_loader, test_loader, config)
 
-    print('Forcing exit now')
+    print("Forcing exit now")
     os.kill(os.getpid(), signal.SIGINT)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/train_NPM3D.py	2024-06-30 22:34:18.660200+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/train_NPM3D.py	2024-07-08 11:53:45.366660+00:00
@@ -37,10 +37,11 @@
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Config Class
 #       \******************/
 #
+
 
 class NPM3DConfig(Config):
     """
     Override the parameters you want to modify for this dataset
     """
@@ -48,48 +49,50 @@
     ####################
     # Dataset parameters
     ####################
 
     # Dataset name
-    dataset = 'NPM3D'
+    dataset = "NPM3D"
 
     # Number of classes in the dataset (This value is overwritten by dataset class when Initializating dataset).
     num_classes = None
 
     # Type of task performed on this dataset (also overwritten)
-    dataset_task = ''
+    dataset_task = ""
 
     # Number of CPU threads for the input pipeline
     input_threads = 10
 
     #########################
     # Architecture definition
     #########################
 
     # # Define layers
-    architecture = ['simple',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary']
+    architecture = [
+        "simple",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+    ]
 
     ###################
     # KPConv parameters
     ###################
 
@@ -110,14 +113,14 @@
 
     # Radius of the area of influence of each kernel point in "number grid cell". (1.0 is the standard value)
     KP_extent = 1.2
 
     # Behavior of convolutions in ('constant', 'linear', 'gaussian')
-    KP_influence = 'linear'
+    KP_influence = "linear"
 
     # Aggregation function of KPConv in ('closest', 'sum')
-    aggregation_mode = 'sum'
+    aggregation_mode = "sum"
 
     # Choice of input features
     first_features_dim = 128
     in_features_dim = 1
 
@@ -129,14 +132,14 @@
     batch_norm_momentum = 0.02
 
     # Deformable offset loss
     # 'point2point' fitting geometry by penalizing distance from deform point to input points
     # 'point2plane' fitting geometry by penalizing distance from deform point to input point triplet (not implemented)
-    deform_fitting_mode = 'point2point'
-    deform_fitting_power = 1.0              # Multiplier for the fitting/repulsive loss
-    deform_lr_factor = 0.1                  # Multiplier for learning rate applied to the deformations
-    repulse_extent = 1.2                    # Distance of repulsion for deformed kernel points
+    deform_fitting_mode = "point2point"
+    deform_fitting_power = 1.0  # Multiplier for the fitting/repulsive loss
+    deform_lr_factor = 0.1  # Multiplier for learning rate applied to the deformations
+    repulse_extent = 1.2  # Distance of repulsion for deformed kernel points
 
     #####################
     # Training parameters
     #####################
 
@@ -162,21 +165,21 @@
     checkpoint_gap = 50
 
     # Augmentations
     augment_scale_anisotropic = True
     augment_symmetries = [True, False, False]
-    augment_rotation = 'vertical'
+    augment_rotation = "vertical"
     augment_scale_min = 0.9
     augment_scale_max = 1.1
     augment_noise = 0.001
     augment_color = 0.8
 
     # The way we balance segmentation loss
     #   > 'none': Each point in the whole batch has the same contribution.
     #   > 'class': Each class has the same contribution (points are weighted according to class balance)
     #   > 'batch': Each cloud in the batch has the same contribution (points are weighted according cloud sizes)
-    segloss_balance = 'none'
+    segloss_balance = "none"
 
     # Do we nee to save convergence
     saving = True
     saving_path = None
 
@@ -185,124 +188,132 @@
 #
 #           Main Call
 #       \***************/
 #
 
-if __name__ == '__main__':
+if __name__ == "__main__":
 
     ############################
     # Initialize the environment
     ############################
 
     # Set which gpu is going to be used
-    GPU_ID = '0'
+    GPU_ID = "0"
 
     # Set GPU visible device
-    os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID
+    os.environ["CUDA_VISIBLE_DEVICES"] = GPU_ID
 
     ###############
     # Previous chkp
     ###############
 
     # Choose here if you want to start training from a previous snapshot (None for new training)
     # previous_training_path = 'Log_2020-03-19_19-53-27'
-    previous_training_path = 'Log_2023-03-28_10-08-39'
+    previous_training_path = "Log_2023-03-28_10-08-39"
 
     # Choose index of checkpoint to start from. If None, uses the latest chkp
     chkp_idx = None
     if previous_training_path:
 
         # Find all snapshot in the chosen training folder
-        chkp_path = os.path.join('results', previous_training_path, 'checkpoints')
-        chkps = [f for f in os.listdir(chkp_path) if f[:4] == 'chkp']
+        chkp_path = os.path.join("results", previous_training_path, "checkpoints")
+        chkps = [f for f in os.listdir(chkp_path) if f[:4] == "chkp"]
 
         # Find which snapshot to restore
         if chkp_idx is None:
-            chosen_chkp = 'current_chkp.tar'
+            chosen_chkp = "current_chkp.tar"
         else:
             chosen_chkp = np.sort(chkps)[chkp_idx]
-        chosen_chkp = os.path.join('results', previous_training_path, 'checkpoints', chosen_chkp)
+        chosen_chkp = os.path.join(
+            "results", previous_training_path, "checkpoints", chosen_chkp
+        )
 
     else:
         chosen_chkp = None
-
 
     ##############
     # Prepare Data
     ##############
 
     print()
-    print('Data Preparation')
-    print('****************')
+    print("Data Preparation")
+    print("****************")
 
     # Initialize configuration class
     config = NPM3DConfig()
     if previous_training_path:
-        config.load(os.path.join('results', previous_training_path))
+        config.load(os.path.join("results", previous_training_path))
         config.saving_path = None
 
     # Get path from argument if given
     if len(sys.argv) > 1:
         config.saving_path = sys.argv[1]
 
     # Initialize datasets
-    training_dataset = NPM3DDataset(config, set='training', use_potentials=True)
-    test_dataset = NPM3DDataset(config, set='validation', use_potentials=True)
+    training_dataset = NPM3DDataset(config, set="training", use_potentials=True)
+    test_dataset = NPM3DDataset(config, set="validation", use_potentials=True)
 
     # Initialize samplers
     training_sampler = NPM3DSampler(training_dataset)
     test_sampler = NPM3DSampler(test_dataset)
 
     # Initialize the dataloader
-    training_loader = DataLoader(training_dataset,
-                                 batch_size=1,
-                                 sampler=training_sampler,
-                                 collate_fn=NPM3DCollate,
-                                 num_workers=config.input_threads,
-                                 pin_memory=True)
-    test_loader = DataLoader(test_dataset,
-                             batch_size=1,
-                             sampler=test_sampler,
-                             collate_fn=NPM3DCollate,
-                             num_workers=config.input_threads,
-                             pin_memory=True)
+    training_loader = DataLoader(
+        training_dataset,
+        batch_size=1,
+        sampler=training_sampler,
+        collate_fn=NPM3DCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
+    test_loader = DataLoader(
+        test_dataset,
+        batch_size=1,
+        sampler=test_sampler,
+        collate_fn=NPM3DCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
 
     # Calibrate samplers
     training_sampler.calibration(training_loader, verbose=True)
     test_sampler.calibration(test_loader, verbose=True)
 
     # Optional debug functions
     # debug_timing(training_dataset, training_loader)
     # debug_timing(test_dataset, test_loader)
     # debug_upsampling(training_dataset, training_loader)
 
-    print('\nModel Preparation')
-    print('*****************')
+    print("\nModel Preparation")
+    print("*****************")
 
     # Define network model
     t1 = time.time()
     net = KPFCNN(config, training_dataset.label_values, training_dataset.ignored_labels)
 
     debug = False
     if debug:
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         print(net)
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         for param in net.parameters():
             if param.requires_grad:
                 print(param.shape)
-        print('\n*************************************\n')
-        print("Model size %i" % sum(param.numel() for param in net.parameters() if param.requires_grad))
-        print('\n*************************************\n')
+        print("\n*************************************\n")
+        print(
+            "Model size %i"
+            % sum(param.numel() for param in net.parameters() if param.requires_grad)
+        )
+        print("\n*************************************\n")
 
     # Define a trainer class
     trainer = ModelTrainer(net, config, chkp_path=chosen_chkp)
-    print('Done in {:.1f}s\n'.format(time.time() - t1))
-
-    print('\nStart training')
-    print('**************')
+    print("Done in {:.1f}s\n".format(time.time() - t1))
+
+    print("\nStart training")
+    print("**************")
 
     # Training
     trainer.train(net, training_loader, test_loader, config)
 
-    print('Forcing exit now')
+    print("Forcing exit now")
     os.kill(os.getpid(), signal.SIGINT)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/train_SemanticKitti.py	2024-06-30 22:34:18.664734+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/train_SemanticKitti.py	2024-07-08 11:53:45.458588+00:00
@@ -41,57 +41,60 @@
 #
 #           Config Class
 #       \******************/
 #
 
+
 class SemanticKittiConfig(Config):
     """
     Override the parameters you want to modify for this dataset
     """
 
     ####################
     # Dataset parameters
     ####################
 
     # Dataset name
-    dataset = 'SemanticKitti'
+    dataset = "SemanticKitti"
 
     # Number of classes in the dataset (This value is overwritten by dataset class when Initializating dataset).
     num_classes = None
 
     # Type of task performed on this dataset (also overwritten)
-    dataset_task = ''
+    dataset_task = ""
 
     # Number of CPU threads for the input pipeline
     input_threads = 10
 
     #########################
     # Architecture definition
     #########################
 
     # Define layers
-    architecture = ['simple',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'resnetb',
-                    'resnetb_strided',
-                    'resnetb',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary',
-                    'nearest_upsample',
-                    'unary']
+    architecture = [
+        "simple",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "resnetb",
+        "resnetb_strided",
+        "resnetb",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+        "nearest_upsample",
+        "unary",
+    ]
 
     ###################
     # KPConv parameters
     ###################
 
@@ -120,14 +123,14 @@
 
     # Radius of the area of influence of each kernel point in "number grid cell". (1.0 is the standard value)
     KP_extent = 1.2
 
     # Behavior of convolutions in ('constant', 'linear', 'gaussian')
-    KP_influence = 'linear'
+    KP_influence = "linear"
 
     # Aggregation function of KPConv in ('closest', 'sum')
-    aggregation_mode = 'sum'
+    aggregation_mode = "sum"
 
     # Choice of input features
     first_features_dim = 128
     in_features_dim = 2
 
@@ -139,14 +142,14 @@
     batch_norm_momentum = 0.02
 
     # Deformable offset loss
     # 'point2point' fitting geometry by penalizing distance from deform point to input points
     # 'point2plane' fitting geometry by penalizing distance from deform point to input point triplet (not implemented)
-    deform_fitting_mode = 'point2point'
-    deform_fitting_power = 1.0              # Multiplier for the fitting/repulsive loss
-    deform_lr_factor = 0.1                  # Multiplier for learning rate applied to the deformations
-    repulse_extent = 1.2                    # Distance of repulsion for deformed kernel points
+    deform_fitting_mode = "point2point"
+    deform_fitting_power = 1.0  # Multiplier for the fitting/repulsive loss
+    deform_lr_factor = 0.1  # Multiplier for learning rate applied to the deformations
+    repulse_extent = 1.2  # Distance of repulsion for deformed kernel points
 
     #####################
     # Training parameters
     #####################
 
@@ -169,11 +172,11 @@
     checkpoint_gap = 50
 
     # Augmentations
     augment_scale_anisotropic = True
     augment_symmetries = [True, False, False]
-    augment_rotation = 'vertical'
+    augment_rotation = "vertical"
     augment_scale_min = 0.8
     augment_scale_max = 1.2
     augment_noise = 0.001
     augment_color = 0.8
 
@@ -200,89 +203,95 @@
 #
 #           Main Call
 #       \***************/
 #
 
-if __name__ == '__main__':
+if __name__ == "__main__":
 
     ############################
     # Initialize the environment
     ############################
 
     # Set which gpu is going to be used
-    GPU_ID = '0'
+    GPU_ID = "0"
 
     # Set GPU visible device
-    os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID
+    os.environ["CUDA_VISIBLE_DEVICES"] = GPU_ID
 
     ###############
     # Previous chkp
     ###############
 
     # Choose here if you want to start training from a previous snapshot (None for new training)
     # previous_training_path = 'Log_2020-03-19_19-53-27'
-    previous_training_path = ''
+    previous_training_path = ""
 
     # Choose index of checkpoint to start from. If None, uses the latest chkp
     chkp_idx = None
     if previous_training_path:
 
         # Find all snapshot in the chosen training folder
-        chkp_path = os.path.join('results', previous_training_path, 'checkpoints')
-        chkps = [f for f in os.listdir(chkp_path) if f[:4] == 'chkp']
+        chkp_path = os.path.join("results", previous_training_path, "checkpoints")
+        chkps = [f for f in os.listdir(chkp_path) if f[:4] == "chkp"]
 
         # Find which snapshot to restore
         if chkp_idx is None:
-            chosen_chkp = 'current_chkp.tar'
+            chosen_chkp = "current_chkp.tar"
         else:
             chosen_chkp = np.sort(chkps)[chkp_idx]
-        chosen_chkp = os.path.join('results', previous_training_path, 'checkpoints', chosen_chkp)
+        chosen_chkp = os.path.join(
+            "results", previous_training_path, "checkpoints", chosen_chkp
+        )
 
     else:
         chosen_chkp = None
 
     ##############
     # Prepare Data
     ##############
 
     print()
-    print('Data Preparation')
-    print('****************')
+    print("Data Preparation")
+    print("****************")
 
     # Initialize configuration class
     config = SemanticKittiConfig()
     if previous_training_path:
-        config.load(os.path.join('results', previous_training_path))
+        config.load(os.path.join("results", previous_training_path))
         config.saving_path = None
 
     # Get path from argument if given
     if len(sys.argv) > 1:
         config.saving_path = sys.argv[1]
 
     # Initialize datasets
-    training_dataset = SemanticKittiDataset(config, set='training',
-                                            balance_classes=True)
-    test_dataset = SemanticKittiDataset(config, set='validation',
-                                        balance_classes=False)
+    training_dataset = SemanticKittiDataset(
+        config, set="training", balance_classes=True
+    )
+    test_dataset = SemanticKittiDataset(config, set="validation", balance_classes=False)
 
     # Initialize samplers
     training_sampler = SemanticKittiSampler(training_dataset)
     test_sampler = SemanticKittiSampler(test_dataset)
 
     # Initialize the dataloader
-    training_loader = DataLoader(training_dataset,
-                                 batch_size=1,
-                                 sampler=training_sampler,
-                                 collate_fn=SemanticKittiCollate,
-                                 num_workers=config.input_threads,
-                                 pin_memory=True)
-    test_loader = DataLoader(test_dataset,
-                             batch_size=1,
-                             sampler=test_sampler,
-                             collate_fn=SemanticKittiCollate,
-                             num_workers=config.input_threads,
-                             pin_memory=True)
+    training_loader = DataLoader(
+        training_dataset,
+        batch_size=1,
+        sampler=training_sampler,
+        collate_fn=SemanticKittiCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
+    test_loader = DataLoader(
+        test_dataset,
+        batch_size=1,
+        sampler=test_sampler,
+        collate_fn=SemanticKittiCollate,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
 
     # Calibrate max_in_point value
     training_sampler.calib_max_in(config, training_loader, verbose=True)
     test_sampler.calib_max_in(config, test_loader, verbose=True)
 
@@ -292,36 +301,39 @@
 
     # debug_timing(training_dataset, training_loader)
     # debug_timing(test_dataset, test_loader)
     # debug_class_w(training_dataset, training_loader)
 
-    print('\nModel Preparation')
-    print('*****************')
+    print("\nModel Preparation")
+    print("*****************")
 
     # Define network model
     t1 = time.time()
     net = KPFCNN(config, training_dataset.label_values, training_dataset.ignored_labels)
 
     debug = False
     if debug:
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         print(net)
-        print('\n*************************************\n')
+        print("\n*************************************\n")
         for param in net.parameters():
             if param.requires_grad:
                 print(param.shape)
-        print('\n*************************************\n')
-        print("Model size %i" % sum(param.numel() for param in net.parameters() if param.requires_grad))
-        print('\n*************************************\n')
+        print("\n*************************************\n")
+        print(
+            "Model size %i"
+            % sum(param.numel() for param in net.parameters() if param.requires_grad)
+        )
+        print("\n*************************************\n")
 
     # Define a trainer class
     trainer = ModelTrainer(net, config, chkp_path=chosen_chkp)
-    print('Done in {:.1f}s\n'.format(time.time() - t1))
-
-    print('\nStart training')
-    print('**************')
+    print("Done in {:.1f}s\n".format(time.time() - t1))
+
+    print("\nStart training")
+    print("**************")
 
     # Training
     trainer.train(net, training_loader, test_loader, config)
 
-    print('Forcing exit now')
+    print("Forcing exit now")
     os.kill(os.getpid(), signal.SIGINT)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/config.py	2024-06-30 22:34:18.722734+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/config.py	2024-07-08 11:53:45.916405+00:00
@@ -19,18 +19,18 @@
 import numpy as np
 
 
 # Colors for printing
 class bcolors:
-    HEADER = '\033[95m'
-    OKBLUE = '\033[94m'
-    OKGREEN = '\033[92m'
-    WARNING = '\033[93m'
-    FAIL = '\033[91m'
-    ENDC = '\033[0m'
-    BOLD = '\033[1m'
-    UNDERLINE = '\033[4m'
+    HEADER = "\033[95m"
+    OKBLUE = "\033[94m"
+    OKGREEN = "\033[92m"
+    WARNING = "\033[93m"
+    FAIL = "\033[91m"
+    ENDC = "\033[0m"
+    BOLD = "\033[1m"
+    UNDERLINE = "\033[4m"
 
 
 class Config:
     """
     Class containing the parameters you want to modify for this dataset
@@ -39,14 +39,14 @@
     ##################
     # Input parameters
     ##################
 
     # Dataset name
-    dataset = ''
+    dataset = ""
 
     # Type of network model
-    dataset_task = ''
+    dataset_task = ""
 
     # Number of classes in the dataset
     num_classes = 0
 
     # Dimension of input points
@@ -67,12 +67,12 @@
 
     # Architecture definition. List of blocks
     architecture = []
 
     # Decide the mode of equivariance and invariance
-    equivar_mode = ''
-    invar_mode = ''
+    equivar_mode = ""
+    invar_mode = ""
 
     # Dimension of the first feature maps
     first_features_dim = 64
 
     # Batch normalization parameters
@@ -100,18 +100,18 @@
 
     # Kernel point influence radius
     KP_extent = 1.0
 
     # Influence function when d < KP_extent. ('constant', 'linear', 'gaussian') When d > KP_extent, always zero
-    KP_influence = 'linear'
+    KP_influence = "linear"
 
     # Aggregation function of KPConv in ('closest', 'sum')
     # Decide if you sum all kernel point influences, or if you only take the influence of the closest KP
-    aggregation_mode = 'sum'
+    aggregation_mode = "sum"
 
     # Fixed points in the kernel : 'none', 'center' or 'verticals'
-    fixed_kernel_points = 'center'
+    fixed_kernel_points = "center"
 
     # Use modulateion in deformable convolutions
     modulated = False
 
     # For SLAM datasets like SemanticKitti number of frames used (minimum one)
@@ -139,35 +139,35 @@
     # Augmentation parameters
     augment_scale_anisotropic = True
     augment_scale_min = 0.9
     augment_scale_max = 1.1
     augment_symmetries = [False, False, False]
-    augment_rotation = 'vertical'
+    augment_rotation = "vertical"
     augment_noise = 0.005
     augment_color = 0.7
 
     # Augment with occlusions (not implemented yet)
-    augment_occlusion = 'none'
+    augment_occlusion = "none"
     augment_occlusion_ratio = 0.2
     augment_occlusion_num = 1
 
     # Regularization loss importance
     weight_decay = 1e-3
 
     # The way we balance segmentation loss DEPRECATED
-    segloss_balance = 'none'
+    segloss_balance = "none"
 
     # Choose weights for class (used in segmentation loss). Empty list for no weights
     class_w = []
 
     # Deformable offset loss
     # 'point2point' fitting geometry by penalizing distance from deform point to input points
     # 'point2plane' fitting geometry by penalizing distance from deform point to input point triplet (not implemented)
-    deform_fitting_mode = 'point2point'
-    deform_fitting_power = 1.0              # Multiplier for the fitting/repulsive loss
-    deform_lr_factor = 0.1                  # Multiplier for learning rate applied to the deformations
-    repulse_extent = 1.0                    # Distance of repulsion for deformed kernel points
+    deform_fitting_mode = "point2point"
+    deform_fitting_power = 1.0  # Multiplier for the fitting/repulsive loss
+    deform_lr_factor = 0.1  # Multiplier for learning rate applied to the deformations
+    repulse_extent = 1.0  # Distance of repulsion for deformed kernel points
 
     # Number of batch
     batch_num = 10
     val_batch_num = 10
 
@@ -191,11 +191,20 @@
         """
         Class Initialyser
         """
 
         # Number of layers
-        self.num_layers = len([block for block in self.architecture if 'pool' in block or 'strided' in block]) + 1
+        self.num_layers = (
+            len(
+                [
+                    block
+                    for block in self.architecture
+                    if "pool" in block or "strided" in block
+                ]
+            )
+            + 1
+        )
 
         ###################
         # Deform layer list
         ###################
         #
@@ -206,63 +215,71 @@
         self.deform_layers = []
         arch = self.architecture
         for block_i, block in enumerate(arch):
 
             # Get all blocks of the layer
-            if not ('pool' in block or 'strided' in block or 'global' in block or 'upsample' in block):
+            if not (
+                "pool" in block
+                or "strided" in block
+                or "global" in block
+                or "upsample" in block
+            ):
                 layer_blocks += [block]
                 continue
 
             # Convolution neighbors indices
             # *****************************
 
             deform_layer = False
             if layer_blocks:
-                if np.any(['deformable' in blck for blck in layer_blocks]):
+                if np.any(["deformable" in blck for blck in layer_blocks]):
                     deform_layer = True
 
-            if 'pool' in block or 'strided' in block:
-                if 'deformable' in block:
+            if "pool" in block or "strided" in block:
+                if "deformable" in block:
                     deform_layer = True
 
             self.deform_layers += [deform_layer]
             layer_blocks = []
 
             # Stop when meeting a global pooling or upsampling
-            if 'global' in block or 'upsample' in block:
+            if "global" in block or "upsample" in block:
                 break
 
     def load(self, path):
 
-        filename = join(path, 'parameters.txt')
-        with open(filename, 'r') as f:
+        filename = join(path, "parameters.txt")
+        with open(filename, "r") as f:
             lines = f.readlines()
 
         # Class variable dictionary
         for line in lines:
             line_info = line.split()
-            if len(line_info) > 2 and line_info[0] != '#':
-
-                if line_info[2] == 'None':
+            if len(line_info) > 2 and line_info[0] != "#":
+
+                if line_info[2] == "None":
                     setattr(self, line_info[0], None)
 
-                elif line_info[0] == 'lr_decay_epochs':
-                    self.lr_decays = {int(b.split(':')[0]): float(b.split(':')[1]) for b in line_info[2:]}
-
-                elif line_info[0] == 'architecture':
+                elif line_info[0] == "lr_decay_epochs":
+                    self.lr_decays = {
+                        int(b.split(":")[0]): float(b.split(":")[1])
+                        for b in line_info[2:]
+                    }
+
+                elif line_info[0] == "architecture":
                     self.architecture = [b for b in line_info[2:]]
 
-                elif line_info[0] == 'augment_symmetries':
+                elif line_info[0] == "augment_symmetries":
                     self.augment_symmetries = [bool(int(b)) for b in line_info[2:]]
 
-                elif line_info[0] == 'num_classes':
+                elif line_info[0] == "num_classes":
                     if len(line_info) > 3:
                         self.num_classes = [int(c) for c in line_info[2:]]
                     else:
                         self.num_classes = int(line_info[2])
 
-                elif line_info[0] == 'class_w':
+                elif line_info[0] == "class_w":
                     self.class_w = [float(w) for w in line_info[2:]]
 
                 elif hasattr(self, line_info[0]):
                     attr_type = type(getattr(self, line_info[0]))
                     if attr_type == bool:
@@ -274,109 +291,135 @@
         self.saving_path = path
         self.__init__()
 
     def save(self):
 
-        with open(join(self.saving_path, 'parameters.txt'), "w") as text_file:
-
-            text_file.write('# -----------------------------------#\n')
-            text_file.write('# Parameters of the training session #\n')
-            text_file.write('# -----------------------------------#\n\n')
+        with open(join(self.saving_path, "parameters.txt"), "w") as text_file:
+
+            text_file.write("# -----------------------------------#\n")
+            text_file.write("# Parameters of the training session #\n")
+            text_file.write("# -----------------------------------#\n\n")
 
             # Input parameters
-            text_file.write('# Input parameters\n')
-            text_file.write('# ****************\n\n')
-            text_file.write('dataset = {:s}\n'.format(self.dataset))
-            text_file.write('dataset_task = {:s}\n'.format(self.dataset_task))
+            text_file.write("# Input parameters\n")
+            text_file.write("# ****************\n\n")
+            text_file.write("dataset = {:s}\n".format(self.dataset))
+            text_file.write("dataset_task = {:s}\n".format(self.dataset_task))
             if type(self.num_classes) is list:
-                text_file.write('num_classes =')
+                text_file.write("num_classes =")
                 for n in self.num_classes:
-                    text_file.write(' {:d}'.format(n))
-                text_file.write('\n')
+                    text_file.write(" {:d}".format(n))
+                text_file.write("\n")
             else:
-                text_file.write('num_classes = {:d}\n'.format(self.num_classes))
-            text_file.write('in_points_dim = {:d}\n'.format(self.in_points_dim))
-            text_file.write('in_features_dim = {:d}\n'.format(self.in_features_dim))
-            text_file.write('in_radius = {:.6f}\n'.format(self.in_radius))
-            text_file.write('input_threads = {:d}\n\n'.format(self.input_threads))
+                text_file.write("num_classes = {:d}\n".format(self.num_classes))
+            text_file.write("in_points_dim = {:d}\n".format(self.in_points_dim))
+            text_file.write("in_features_dim = {:d}\n".format(self.in_features_dim))
+            text_file.write("in_radius = {:.6f}\n".format(self.in_radius))
+            text_file.write("input_threads = {:d}\n\n".format(self.input_threads))
 
             # Model parameters
-            text_file.write('# Model parameters\n')
-            text_file.write('# ****************\n\n')
-
-            text_file.write('architecture =')
+            text_file.write("# Model parameters\n")
+            text_file.write("# ****************\n\n")
+
+            text_file.write("architecture =")
             for a in self.architecture:
-                text_file.write(' {:s}'.format(a))
-            text_file.write('\n')
-            text_file.write('equivar_mode = {:s}\n'.format(self.equivar_mode))
-            text_file.write('invar_mode = {:s}\n'.format(self.invar_mode))
-            text_file.write('num_layers = {:d}\n'.format(self.num_layers))
-            text_file.write('first_features_dim = {:d}\n'.format(self.first_features_dim))
-            text_file.write('use_batch_norm = {:d}\n'.format(int(self.use_batch_norm)))
-            text_file.write('batch_norm_momentum = {:.6f}\n\n'.format(self.batch_norm_momentum))
-            text_file.write('segmentation_ratio = {:.6f}\n\n'.format(self.segmentation_ratio))
+                text_file.write(" {:s}".format(a))
+            text_file.write("\n")
+            text_file.write("equivar_mode = {:s}\n".format(self.equivar_mode))
+            text_file.write("invar_mode = {:s}\n".format(self.invar_mode))
+            text_file.write("num_layers = {:d}\n".format(self.num_layers))
+            text_file.write(
+                "first_features_dim = {:d}\n".format(self.first_features_dim)
+            )
+            text_file.write("use_batch_norm = {:d}\n".format(int(self.use_batch_norm)))
+            text_file.write(
+                "batch_norm_momentum = {:.6f}\n\n".format(self.batch_norm_momentum)
+            )
+            text_file.write(
+                "segmentation_ratio = {:.6f}\n\n".format(self.segmentation_ratio)
+            )
 
             # KPConv parameters
-            text_file.write('# KPConv parameters\n')
-            text_file.write('# *****************\n\n')
-
-            text_file.write('first_subsampling_dl = {:.6f}\n'.format(self.first_subsampling_dl))
-            text_file.write('num_kernel_points = {:d}\n'.format(self.num_kernel_points))
-            text_file.write('conv_radius = {:.6f}\n'.format(self.conv_radius))
-            text_file.write('deform_radius = {:.6f}\n'.format(self.deform_radius))
-            text_file.write('fixed_kernel_points = {:s}\n'.format(self.fixed_kernel_points))
-            text_file.write('KP_extent = {:.6f}\n'.format(self.KP_extent))
-            text_file.write('KP_influence = {:s}\n'.format(self.KP_influence))
-            text_file.write('aggregation_mode = {:s}\n'.format(self.aggregation_mode))
-            text_file.write('modulated = {:d}\n'.format(int(self.modulated)))
-            text_file.write('n_frames = {:d}\n'.format(self.n_frames))
-            text_file.write('max_in_points = {:d}\n\n'.format(self.max_in_points))
-            text_file.write('max_val_points = {:d}\n\n'.format(self.max_val_points))
-            text_file.write('val_radius = {:.6f}\n\n'.format(self.val_radius))
+            text_file.write("# KPConv parameters\n")
+            text_file.write("# *****************\n\n")
+
+            text_file.write(
+                "first_subsampling_dl = {:.6f}\n".format(self.first_subsampling_dl)
+            )
+            text_file.write("num_kernel_points = {:d}\n".format(self.num_kernel_points))
+            text_file.write("conv_radius = {:.6f}\n".format(self.conv_radius))
+            text_file.write("deform_radius = {:.6f}\n".format(self.deform_radius))
+            text_file.write(
+                "fixed_kernel_points = {:s}\n".format(self.fixed_kernel_points)
+            )
+            text_file.write("KP_extent = {:.6f}\n".format(self.KP_extent))
+            text_file.write("KP_influence = {:s}\n".format(self.KP_influence))
+            text_file.write("aggregation_mode = {:s}\n".format(self.aggregation_mode))
+            text_file.write("modulated = {:d}\n".format(int(self.modulated)))
+            text_file.write("n_frames = {:d}\n".format(self.n_frames))
+            text_file.write("max_in_points = {:d}\n\n".format(self.max_in_points))
+            text_file.write("max_val_points = {:d}\n\n".format(self.max_val_points))
+            text_file.write("val_radius = {:.6f}\n\n".format(self.val_radius))
 
             # Training parameters
-            text_file.write('# Training parameters\n')
-            text_file.write('# *******************\n\n')
-
-            text_file.write('learning_rate = {:f}\n'.format(self.learning_rate))
-            text_file.write('momentum = {:f}\n'.format(self.momentum))
-            text_file.write('lr_decay_epochs =')
+            text_file.write("# Training parameters\n")
+            text_file.write("# *******************\n\n")
+
+            text_file.write("learning_rate = {:f}\n".format(self.learning_rate))
+            text_file.write("momentum = {:f}\n".format(self.momentum))
+            text_file.write("lr_decay_epochs =")
             for e, d in self.lr_decays.items():
-                text_file.write(' {:d}:{:f}'.format(e, d))
-            text_file.write('\n')
-            text_file.write('grad_clip_norm = {:f}\n\n'.format(self.grad_clip_norm))
-
-
-            text_file.write('augment_symmetries =')
+                text_file.write(" {:d}:{:f}".format(e, d))
+            text_file.write("\n")
+            text_file.write("grad_clip_norm = {:f}\n\n".format(self.grad_clip_norm))
+
+            text_file.write("augment_symmetries =")
             for a in self.augment_symmetries:
-                text_file.write(' {:d}'.format(int(a)))
-            text_file.write('\n')
-            text_file.write('augment_rotation = {:s}\n'.format(self.augment_rotation))
-            text_file.write('augment_noise = {:f}\n'.format(self.augment_noise))
-            text_file.write('augment_occlusion = {:s}\n'.format(self.augment_occlusion))
-            text_file.write('augment_occlusion_ratio = {:.6f}\n'.format(self.augment_occlusion_ratio))
-            text_file.write('augment_occlusion_num = {:d}\n'.format(self.augment_occlusion_num))
-            text_file.write('augment_scale_anisotropic = {:d}\n'.format(int(self.augment_scale_anisotropic)))
-            text_file.write('augment_scale_min = {:.6f}\n'.format(self.augment_scale_min))
-            text_file.write('augment_scale_max = {:.6f}\n'.format(self.augment_scale_max))
-            text_file.write('augment_color = {:.6f}\n\n'.format(self.augment_color))
-
-            text_file.write('weight_decay = {:f}\n'.format(self.weight_decay))
-            text_file.write('segloss_balance = {:s}\n'.format(self.segloss_balance))
-            text_file.write('class_w =')
+                text_file.write(" {:d}".format(int(a)))
+            text_file.write("\n")
+            text_file.write("augment_rotation = {:s}\n".format(self.augment_rotation))
+            text_file.write("augment_noise = {:f}\n".format(self.augment_noise))
+            text_file.write("augment_occlusion = {:s}\n".format(self.augment_occlusion))
+            text_file.write(
+                "augment_occlusion_ratio = {:.6f}\n".format(
+                    self.augment_occlusion_ratio
+                )
+            )
+            text_file.write(
+                "augment_occlusion_num = {:d}\n".format(self.augment_occlusion_num)
+            )
+            text_file.write(
+                "augment_scale_anisotropic = {:d}\n".format(
+                    int(self.augment_scale_anisotropic)
+                )
+            )
+            text_file.write(
+                "augment_scale_min = {:.6f}\n".format(self.augment_scale_min)
+            )
+            text_file.write(
+                "augment_scale_max = {:.6f}\n".format(self.augment_scale_max)
+            )
+            text_file.write("augment_color = {:.6f}\n\n".format(self.augment_color))
+
+            text_file.write("weight_decay = {:f}\n".format(self.weight_decay))
+            text_file.write("segloss_balance = {:s}\n".format(self.segloss_balance))
+            text_file.write("class_w =")
             for a in self.class_w:
-                text_file.write(' {:.6f}'.format(a))
-            text_file.write('\n')
-            text_file.write('deform_fitting_mode = {:s}\n'.format(self.deform_fitting_mode))
-            text_file.write('deform_fitting_power = {:.6f}\n'.format(self.deform_fitting_power))
-            text_file.write('deform_lr_factor = {:.6f}\n'.format(self.deform_lr_factor))
-            text_file.write('repulse_extent = {:.6f}\n'.format(self.repulse_extent))
-            text_file.write('batch_num = {:d}\n'.format(self.batch_num))
-            text_file.write('val_batch_num = {:d}\n'.format(self.val_batch_num))
-            text_file.write('max_epoch = {:d}\n'.format(self.max_epoch))
+                text_file.write(" {:.6f}".format(a))
+            text_file.write("\n")
+            text_file.write(
+                "deform_fitting_mode = {:s}\n".format(self.deform_fitting_mode)
+            )
+            text_file.write(
+                "deform_fitting_power = {:.6f}\n".format(self.deform_fitting_power)
+            )
+            text_file.write("deform_lr_factor = {:.6f}\n".format(self.deform_lr_factor))
+            text_file.write("repulse_extent = {:.6f}\n".format(self.repulse_extent))
+            text_file.write("batch_num = {:d}\n".format(self.batch_num))
+            text_file.write("val_batch_num = {:d}\n".format(self.val_batch_num))
+            text_file.write("max_epoch = {:d}\n".format(self.max_epoch))
             if self.epoch_steps is None:
-                text_file.write('epoch_steps = None\n')
+                text_file.write("epoch_steps = None\n")
             else:
-                text_file.write('epoch_steps = {:d}\n'.format(self.epoch_steps))
-            text_file.write('validation_size = {:d}\n'.format(self.validation_size))
-            text_file.write('checkpoint_gap = {:d}\n'.format(self.checkpoint_gap))
-
+                text_file.write("epoch_steps = {:d}\n".format(self.epoch_steps))
+            text_file.write("validation_size = {:d}\n".format(self.validation_size))
+            text_file.write("checkpoint_gap = {:d}\n".format(self.checkpoint_gap))
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/SemanticKitti.py	2024-06-30 22:34:18.064096+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/SemanticKitti.py	2024-07-08 11:53:46.195811+00:00
@@ -52,65 +52,71 @@
 
 
 class SemanticKittiDataset(PointCloudDataset):
     """Class to handle SemanticKitti dataset."""
 
-    def __init__(self, config, set='training', balance_classes=True):
-        PointCloudDataset.__init__(self, 'SemanticKitti')
+    def __init__(self, config, set="training", balance_classes=True):
+        PointCloudDataset.__init__(self, "SemanticKitti")
 
         ##########################
         # Parameters for the files
         ##########################
 
         # Dataset folder
-        self.path = '../../SemanticKitti/unzipped/dataset'
+        self.path = "../../SemanticKitti/unzipped/dataset"
 
         # Type of task conducted on this dataset
-        self.dataset_task = 'slam_segmentation'
+        self.dataset_task = "slam_segmentation"
 
         # Training or test set
         self.set = set
 
         # Get a list of sequences
-        if self.set == 'training':
-            self.sequences = ['{:02d}'.format(i) for i in range(11) if i != 8]
-        elif self.set == 'validation':
-            self.sequences = ['{:02d}'.format(i) for i in range(23) if i == 22]
-        elif self.set == 'test':
-            self.sequences = ['{:02d}'.format(i) for i in range(11, 22)]
+        if self.set == "training":
+            self.sequences = ["{:02d}".format(i) for i in range(11) if i != 8]
+        elif self.set == "validation":
+            self.sequences = ["{:02d}".format(i) for i in range(23) if i == 22]
+        elif self.set == "test":
+            self.sequences = ["{:02d}".format(i) for i in range(11, 22)]
         else:
-            raise ValueError('Unknown set for SemanticKitti data: ', self.set)
+            raise ValueError("Unknown set for SemanticKitti data: ", self.set)
 
         # List all files in each sequence
         self.frames = []
         for seq in self.sequences:
-            velo_path = join(self.path, 'sequences', seq, 'velodyne')
-            frames = np.sort([vf[:-4] for vf in listdir(velo_path) if vf.endswith('.bin')])
+            velo_path = join(self.path, "sequences", seq, "velodyne")
+            frames = np.sort(
+                [vf[:-4] for vf in listdir(velo_path) if vf.endswith(".bin")]
+            )
             self.frames.append(frames)
 
         ###########################
         # Object classes parameters
         ###########################
 
         # Read labels
         if config.n_frames == 1:
-            config_file = join(self.path, 'semantic-kitti.yaml')
+            config_file = join(self.path, "semantic-kitti.yaml")
         elif config.n_frames > 1:
-            config_file = join(self.path, 'semantic-kitti-all.yaml')
+            config_file = join(self.path, "semantic-kitti-all.yaml")
         else:
-            raise ValueError('number of frames has to be >= 1')
-
-        with open(config_file, 'r') as stream:
+            raise ValueError("number of frames has to be >= 1")
+
+        with open(config_file, "r") as stream:
             doc = yaml.safe_load(stream)
-            all_labels = doc['labels']
-            learning_map_inv = doc['learning_map_inv']
-            learning_map = doc['learning_map']
-            self.learning_map = np.zeros((np.max([k for k in learning_map.keys()]) + 1), dtype=np.int32)
+            all_labels = doc["labels"]
+            learning_map_inv = doc["learning_map_inv"]
+            learning_map = doc["learning_map"]
+            self.learning_map = np.zeros(
+                (np.max([k for k in learning_map.keys()]) + 1), dtype=np.int32
+            )
             for k, v in learning_map.items():
                 self.learning_map[k] = v
 
-            self.learning_map_inv = np.zeros((np.max([k for k in learning_map_inv.keys()]) + 1), dtype=np.int32)
+            self.learning_map_inv = np.zeros(
+                (np.max([k for k in learning_map_inv.keys()]) + 1), dtype=np.int32
+            )
             for k, v in learning_map_inv.items():
                 self.learning_map_inv[k] = v
 
         # Dict from labels to names
         self.label_to_names = {k: all_labels[v] for k, v in learning_map_inv.items()}
@@ -155,39 +161,43 @@
         # Initialize value for batch limit (max number of points per batch).
         self.batch_limit = torch.tensor([1], dtype=torch.float32)
         self.batch_limit.share_memory_()
 
         # Initialize frame potentials
-        self.potentials = torch.from_numpy(np.random.rand(self.all_inds.shape[0]) * 0.1 + 0.1)
+        self.potentials = torch.from_numpy(
+            np.random.rand(self.all_inds.shape[0]) * 0.1 + 0.1
+        )
         self.potentials.share_memory_()
 
         # If true, the same amount of frames is picked per class
         self.balance_classes = balance_classes
 
         # Choose batch_num in_R and max_in_p depending on validation or training
-        if self.set == 'training':
+        if self.set == "training":
             self.batch_num = config.batch_num
             self.max_in_p = config.max_in_points
             self.in_R = config.in_radius
         else:
             self.batch_num = config.val_batch_num
             self.max_in_p = config.max_val_points
             self.in_R = config.val_radius
 
         # shared epoch indices and classes (in case we want class balanced sampler)
-        if set == 'training':
+        if set == "training":
             N = int(np.ceil(config.epoch_steps * self.batch_num * 1.1))
         else:
             N = int(np.ceil(config.validation_size * self.batch_num * 1.1))
         self.epoch_i = torch.from_numpy(np.zeros((1,), dtype=np.int64))
         self.epoch_inds = torch.from_numpy(np.zeros((N,), dtype=np.int64))
         self.epoch_labels = torch.from_numpy(np.zeros((N,), dtype=np.int32))
         self.epoch_i.share_memory_()
         self.epoch_inds.share_memory_()
         self.epoch_labels.share_memory_()
 
-        self.worker_waiting = torch.tensor([0 for _ in range(config.input_threads)], dtype=torch.int32)
+        self.worker_waiting = torch.tensor(
+            [0 for _ in range(config.input_threads)], dtype=torch.int32
+        )
         self.worker_waiting.share_memory_()
         self.worker_lock = Lock()
 
         return
 
@@ -271,51 +281,57 @@
                     if num_merged > 0 and np.linalg.norm(diff) < num_merged * X:
                         f_inc += 1
                         continue
 
                 # Path of points and labels
-                seq_path = join(self.path, 'sequences', self.sequences[s_ind])
-                velo_file = join(seq_path, 'velodyne', self.frames[s_ind][f_ind - f_inc] + '.bin')
-                if self.set == 'test':
+                seq_path = join(self.path, "sequences", self.sequences[s_ind])
+                velo_file = join(
+                    seq_path, "velodyne", self.frames[s_ind][f_ind - f_inc] + ".bin"
+                )
+                if self.set == "test":
                     label_file = None
                 else:
-                    label_file = join(seq_path, 'labels', self.frames[s_ind][f_ind - f_inc] + '.label')
+                    label_file = join(
+                        seq_path, "labels", self.frames[s_ind][f_ind - f_inc] + ".label"
+                    )
 
                 # Read points
                 frame_points = np.fromfile(velo_file, dtype=np.float32)
                 points = frame_points.reshape((-1, 4))
 
-                if self.set == 'test':
+                if self.set == "test":
                     # Fake labels
                     sem_labels = np.zeros((frame_points.shape[0],), dtype=np.int32)
                 else:
                     # Read labels
                     frame_labels = np.fromfile(label_file, dtype=np.int32)
                     sem_labels = frame_labels & 0xFFFF  # semantic label in lower half
                     sem_labels = self.learning_map[sem_labels]
 
                 # Apply pose (without np.dot to avoid multi-threading)
                 hpoints = np.hstack((points[:, :3], np.ones_like(points[:, :1])))
-                #new_points = hpoints.dot(pose.T)
+                # new_points = hpoints.dot(pose.T)
                 new_points = np.sum(np.expand_dims(hpoints, 2) * pose.T, axis=1)
-                #new_points[:, 3:] = points[:, 3:]
+                # new_points[:, 3:] = points[:, 3:]
 
                 # In case of validation, keep the original points in memory
-                if self.set in ['validation', 'test'] and f_inc == 0:
+                if self.set in ["validation", "test"] and f_inc == 0:
                     o_pts = new_points[:, :3].astype(np.float32)
                     o_labels = sem_labels.astype(np.int32)
 
                 # In case radius smaller than 50m, chose new center on a point of the wanted class or not
                 if self.in_R < 50.0 and f_inc == 0:
                     if self.balance_classes:
-                        wanted_ind = np.random.choice(np.where(sem_labels == wanted_label)[0])
+                        wanted_ind = np.random.choice(
+                            np.where(sem_labels == wanted_label)[0]
+                        )
                     else:
                         wanted_ind = np.random.choice(new_points.shape[0])
                     p0 = new_points[wanted_ind, :3]
 
                 # Eliminate points further than config.in_radius
-                mask = np.sum(np.square(new_points[:, :3] - p0), axis=1) < self.in_R ** 2
+                mask = np.sum(np.square(new_points[:, :3] - p0), axis=1) < self.in_R**2
                 mask_inds = np.where(mask)[0].astype(np.int32)
 
                 # Shuffle points
                 rand_order = np.random.permutation(mask_inds)
                 new_points = new_points[rand_order, :3]
@@ -326,11 +342,13 @@
                     new_coords = points[rand_order, :]
                 else:
                     # We have to project in the first frame coordinates
                     new_coords = new_points - pose0[:3, 3]
                     # new_coords = new_coords.dot(pose0[:3, :3])
-                    new_coords = np.sum(np.expand_dims(new_coords, 2) * pose0[:3, :3], axis=1)
+                    new_coords = np.sum(
+                        np.expand_dims(new_coords, 2) * pose0[:3, :3], axis=1
+                    )
                     new_coords = np.hstack((new_coords, points[rand_order, 3:]))
 
                 # Increment merge count
                 merged_points = np.vstack((merged_points, new_points))
                 merged_labels = np.hstack((merged_labels, sem_labels))
@@ -343,14 +361,16 @@
             #########################
             # Merge n_frames together
             #########################
 
             # Subsample merged frames
-            in_pts, in_fts, in_lbls = grid_subsampling(merged_points,
-                                                       features=merged_coords,
-                                                       labels=merged_labels,
-                                                       sampleDl=self.config.first_subsampling_dl)
+            in_pts, in_fts, in_lbls = grid_subsampling(
+                merged_points,
+                features=merged_coords,
+                labels=merged_labels,
+                sampleDl=self.config.first_subsampling_dl,
+            )
 
             t += [time.time()]
 
             # Number collected
             n = in_pts.shape[0]
@@ -368,19 +388,21 @@
                 n = input_inds.shape[0]
 
             t += [time.time()]
 
             # Before augmenting, compute reprojection inds (only for validation and test)
-            if self.set in ['validation', 'test']:
+            if self.set in ["validation", "test"]:
 
                 # get val_points that are in range
                 radiuses = np.sum(np.square(o_pts - p0), axis=1)
                 reproj_mask = radiuses < (0.99 * self.in_R) ** 2
 
                 # Project predictions on the frame points
                 search_tree = KDTree(in_pts, leaf_size=50)
-                proj_inds = search_tree.query(o_pts[reproj_mask, :], return_distance=False)
+                proj_inds = search_tree.query(
+                    o_pts[reproj_mask, :], return_distance=False
+                )
                 proj_inds = np.squeeze(proj_inds).astype(np.int32)
             else:
                 proj_inds = np.zeros((0,))
                 reproj_mask = np.zeros((0,))
 
@@ -444,11 +466,13 @@
             stacked_features = np.hstack((stacked_features, features[:3]))
         elif self.config.in_features_dim == 5:
             # Use all coordinates + reflectance
             stacked_features = np.hstack((stacked_features, features))
         else:
-            raise ValueError('Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)')
+            raise ValueError(
+                "Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)"
+            )
 
         t += [time.time()]
 
         #######################
         # Create network inputs
@@ -456,90 +480,124 @@
         #
         #   Points, neighbors, pooling indices for each layers
         #
 
         # Get the whole input list
-        input_list = self.segmentation_inputs(stacked_points,
-                                              stacked_features,
-                                              labels.astype(np.int64),
-                                              stack_lengths)
+        input_list = self.segmentation_inputs(
+            stacked_points, stacked_features, labels.astype(np.int64), stack_lengths
+        )
 
         t += [time.time()]
 
         # Add scale and rotation for testing
-        input_list += [scales, rots, frame_inds, frame_centers, r_inds_list, r_mask_list, val_labels_list]
+        input_list += [
+            scales,
+            rots,
+            frame_inds,
+            frame_centers,
+            r_inds_list,
+            r_mask_list,
+            val_labels_list,
+        ]
 
         t += [time.time()]
 
         # Display timings
         debugT = False
         if debugT:
-            print('\n************************\n')
-            print('Timings:')
+            print("\n************************\n")
+            print("Timings:")
             ti = 0
             N = 9
-            mess = 'Init ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Init ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Lock ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Lock ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Init ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Init ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Load ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Load ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Subs ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Subs ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Drop ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Drop ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Reproj .... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Reproj .... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Augment ... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Augment ... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Stack ..... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Stack ..... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += N * (len(stack_lengths) - 1) + 1
-            print('concat .... {:5.1f}ms'.format(1000 * (t[ti+1] - t[ti])))
+            print("concat .... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('input ..... {:5.1f}ms'.format(1000 * (t[ti+1] - t[ti])))
+            print("input ..... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('stack ..... {:5.1f}ms'.format(1000 * (t[ti+1] - t[ti])))
+            print("stack ..... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('\n************************\n')
+            print("\n************************\n")
 
         return [self.config.num_layers] + input_list
 
     def load_calib_poses(self):
         """
@@ -554,89 +612,109 @@
         self.times = []
         self.poses = []
 
         for seq in self.sequences:
 
-            seq_folder = join(self.path, 'sequences', seq)
+            seq_folder = join(self.path, "sequences", seq)
 
             # Read Calib
-            self.calibrations.append(self.parse_calibration(join(seq_folder, "calib.txt")))
+            self.calibrations.append(
+                self.parse_calibration(join(seq_folder, "calib.txt"))
+            )
 
             # Read times
-            self.times.append(np.loadtxt(join(seq_folder, 'times.txt'), dtype=np.float32))
+            self.times.append(
+                np.loadtxt(join(seq_folder, "times.txt"), dtype=np.float32)
+            )
 
             # Read poses
-            poses_f64 = self.parse_poses(join(seq_folder, 'poses.txt'), self.calibrations[-1])
+            poses_f64 = self.parse_poses(
+                join(seq_folder, "poses.txt"), self.calibrations[-1]
+            )
             self.poses.append([pose.astype(np.float32) for pose in poses_f64])
 
         ###################################
         # Prepare the indices of all frames
         ###################################
 
-        seq_inds = np.hstack([np.ones(len(_), dtype=np.int32) * i for i, _ in enumerate(self.frames)])
+        seq_inds = np.hstack(
+            [np.ones(len(_), dtype=np.int32) * i for i, _ in enumerate(self.frames)]
+        )
         frame_inds = np.hstack([np.arange(len(_), dtype=np.int32) for _ in self.frames])
         self.all_inds = np.vstack((seq_inds, frame_inds)).T
 
         ################################################
         # For each class list the frames containing them
         ################################################
 
-        if self.set in ['training', 'validation']:
+        if self.set in ["training", "validation"]:
 
             class_frames_bool = np.zeros((0, self.num_classes), dtype=np.bool)
             self.class_proportions = np.zeros((self.num_classes,), dtype=np.int32)
 
             for s_ind, (seq, seq_frames) in enumerate(zip(self.sequences, self.frames)):
 
-                frame_mode = 'single'
+                frame_mode = "single"
                 if self.config.n_frames > 1:
-                    frame_mode = 'multi'
-                seq_stat_file = join(self.path, 'sequences', seq, 'stats_{:s}.pkl'.format(frame_mode))
+                    frame_mode = "multi"
+                seq_stat_file = join(
+                    self.path, "sequences", seq, "stats_{:s}.pkl".format(frame_mode)
+                )
 
                 # Check if inputs have already been computed
                 if exists(seq_stat_file):
                     # Read pkl
-                    with open(seq_stat_file, 'rb') as f:
+                    with open(seq_stat_file, "rb") as f:
                         seq_class_frames, seq_proportions = pickle.load(f)
 
                 else:
 
                     # Initiate dict
-                    print('Preparing seq {:s} class frames. (Long but one time only)'.format(seq))
+                    print(
+                        "Preparing seq {:s} class frames. (Long but one time only)".format(
+                            seq
+                        )
+                    )
 
                     # Class frames as a boolean mask
-                    seq_class_frames = np.zeros((len(seq_frames), self.num_classes), dtype=np.bool)
+                    seq_class_frames = np.zeros(
+                        (len(seq_frames), self.num_classes), dtype=np.bool
+                    )
 
                     # Proportion of each class
                     seq_proportions = np.zeros((self.num_classes,), dtype=np.int32)
 
                     # Sequence path
-                    seq_path = join(self.path, 'sequences', seq)
+                    seq_path = join(self.path, "sequences", seq)
 
                     # Read all frames
                     for f_ind, frame_name in enumerate(seq_frames):
 
                         # Path of points and labels
-                        label_file = join(seq_path, 'labels', frame_name + '.label')
+                        label_file = join(seq_path, "labels", frame_name + ".label")
 
                         # Read labels
                         frame_labels = np.fromfile(label_file, dtype=np.int32)
-                        sem_labels = frame_labels & 0xFFFF  # semantic label in lower half
+                        sem_labels = (
+                            frame_labels & 0xFFFF
+                        )  # semantic label in lower half
                         sem_labels = self.learning_map[sem_labels]
 
                         # Get present labels and there frequency
                         unique, counts = np.unique(sem_labels, return_counts=True)
 
                         # Add this frame to the frame lists of all class present
-                        frame_labels = np.array([self.label_to_idx[l] for l in unique], dtype=np.int32)
+                        frame_labels = np.array(
+                            [self.label_to_idx[l] for l in unique], dtype=np.int32
+                        )
                         seq_class_frames[f_ind, frame_labels] = True
 
                         # Add proportions
                         seq_proportions[frame_labels] += counts
 
                     # Save pickle
-                    with open(seq_stat_file, 'wb') as f:
+                    with open(seq_stat_file, "wb") as f:
                         pickle.dump([seq_class_frames, seq_proportions], f)
 
                 class_frames_bool = np.vstack((class_frames_bool, seq_class_frames))
                 self.class_proportions += seq_proportions
 
@@ -645,30 +723,34 @@
             for i, c in enumerate(self.label_values):
                 if c in self.ignored_labels:
                     self.class_frames.append(torch.zeros((0,), dtype=torch.int64))
                 else:
                     integer_inds = np.where(class_frames_bool[:, i])[0]
-                    self.class_frames.append(torch.from_numpy(integer_inds.astype(np.int64)))
+                    self.class_frames.append(
+                        torch.from_numpy(integer_inds.astype(np.int64))
+                    )
 
         # Add variables for validation
-        if self.set == 'validation':
+        if self.set == "validation":
             self.val_points = []
             self.val_labels = []
             self.val_confs = []
 
             for s_ind, seq_frames in enumerate(self.frames):
-                self.val_confs.append(np.zeros((len(seq_frames), self.num_classes, self.num_classes)))
+                self.val_confs.append(
+                    np.zeros((len(seq_frames), self.num_classes, self.num_classes))
+                )
 
         return
 
     def parse_calibration(self, filename):
-        """ read calibration file with given filename
-
-            Returns
-            -------
-            dict
-                Calibration matrices as 4x4 numpy arrays.
+        """read calibration file with given filename
+
+        Returns
+        -------
+        dict
+            Calibration matrices as 4x4 numpy arrays.
         """
         calib = {}
 
         calib_file = open(filename)
         for line in calib_file:
@@ -686,16 +768,16 @@
         calib_file.close()
 
         return calib
 
     def parse_poses(self, filename, calibration):
-        """ read poses file with per-scan poses from given filename
-
-            Returns
-            -------
-            list
-                list of poses as 4x4 numpy arrays.
+        """read poses file with per-scan poses from given filename
+
+        Returns
+        -------
+        list
+            list of poses as 4x4 numpy arrays.
         """
         file = open(filename)
 
         poses = []
 
@@ -730,11 +812,11 @@
 
         # Dataset used by the sampler (no copy is made in memory)
         self.dataset = dataset
 
         # Number of step per epoch
-        if dataset.set == 'training':
+        if dataset.set == "training":
             self.N = dataset.config.epoch_steps
         else:
             self.N = dataset.config.validation_size
 
         return
@@ -760,44 +842,62 @@
             gen_classes = []
             for i, c in enumerate(self.dataset.label_values):
                 if c not in self.dataset.ignored_labels:
 
                     # Get the potentials of the frames containing this class
-                    class_potentials = self.dataset.potentials[self.dataset.class_frames[i]]
-
+                    class_potentials = self.dataset.potentials[
+                        self.dataset.class_frames[i]
+                    ]
 
                     if class_potentials.shape[0] > 0:
 
                         # Get the indices to generate thanks to potentials
-                        used_classes = self.dataset.num_classes - len(self.dataset.ignored_labels)
+                        used_classes = self.dataset.num_classes - len(
+                            self.dataset.ignored_labels
+                        )
                         class_n = num_centers // used_classes + 1
                         if class_n < class_potentials.shape[0]:
-                            _, class_indices = torch.topk(class_potentials, class_n, largest=False)
+                            _, class_indices = torch.topk(
+                                class_potentials, class_n, largest=False
+                            )
                         else:
                             class_indices = torch.zeros((0,), dtype=torch.int64)
                             while class_indices.shape[0] < class_n:
-                                new_class_inds = torch.randperm(class_potentials.shape[0]).type(torch.int64)
-                                class_indices = torch.cat((class_indices, new_class_inds), dim=0)
+                                new_class_inds = torch.randperm(
+                                    class_potentials.shape[0]
+                                ).type(torch.int64)
+                                class_indices = torch.cat(
+                                    (class_indices, new_class_inds), dim=0
+                                )
                             class_indices = class_indices[:class_n]
                         class_indices = self.dataset.class_frames[i][class_indices]
 
                         # Add the indices to the generated ones
                         gen_indices.append(class_indices)
                         gen_classes.append(class_indices * 0 + c)
 
                         # Update potentials
                         update_inds = torch.unique(class_indices)
-                        self.dataset.potentials[update_inds] = torch.ceil(self.dataset.potentials[update_inds])
-                        self.dataset.potentials[update_inds] += torch.from_numpy(np.random.rand(update_inds.shape[0]) * 0.1 + 0.1)
+                        self.dataset.potentials[update_inds] = torch.ceil(
+                            self.dataset.potentials[update_inds]
+                        )
+                        self.dataset.potentials[update_inds] += torch.from_numpy(
+                            np.random.rand(update_inds.shape[0]) * 0.1 + 0.1
+                        )
 
                     else:
-                        error_message = '\nIt seems there is a problem with the class statistics of your dataset, saved in the variable dataset.class_frames.\n'
-                        error_message += 'Here are the current statistics:\n'
-                        error_message += '{:>15s} {:>15s}\n'.format('Class', '# of frames')
+                        error_message = "\nIt seems there is a problem with the class statistics of your dataset, saved in the variable dataset.class_frames.\n"
+                        error_message += "Here are the current statistics:\n"
+                        error_message += "{:>15s} {:>15s}\n".format(
+                            "Class", "# of frames"
+                        )
                         for iii, ccc in enumerate(self.dataset.label_values):
-                            error_message += '{:>15s} {:>15d}\n'.format(self.dataset.label_names[iii], len(self.dataset.class_frames[iii]))
-                        error_message += '\nThis error is raised if one of the classes is not ignored and does not appear in any of the frames of the dataset.\n'
+                            error_message += "{:>15s} {:>15d}\n".format(
+                                self.dataset.label_names[iii],
+                                len(self.dataset.class_frames[iii]),
+                            )
+                        error_message += "\nThis error is raised if one of the classes is not ignored and does not appear in any of the frames of the dataset.\n"
                         raise ValueError(error_message)
 
             # Stack the chosen indices of all classes
             gen_indices = torch.cat(gen_indices, dim=0)
             gen_classes = torch.cat(gen_classes, dim=0)
@@ -806,12 +906,12 @@
             rand_order = torch.randperm(gen_indices.shape[0])[:num_centers]
             gen_indices = gen_indices[rand_order]
             gen_classes = gen_classes[rand_order]
 
             # Update potentials (Change the order for the next epoch)
-            #self.dataset.potentials[gen_indices] = torch.ceil(self.dataset.potentials[gen_indices])
-            #self.dataset.potentials[gen_indices] += torch.from_numpy(np.random.rand(gen_indices.shape[0]) * 0.1 + 0.1)
+            # self.dataset.potentials[gen_indices] = torch.ceil(self.dataset.potentials[gen_indices])
+            # self.dataset.potentials[gen_indices] += torch.from_numpy(np.random.rand(gen_indices.shape[0]) * 0.1 + 0.1)
 
             # Update epoch inds
             self.dataset.epoch_inds += gen_indices
             self.dataset.epoch_labels += gen_classes.type(torch.int32)
 
@@ -825,21 +925,29 @@
             # Number of sphere centers taken per class in each cloud
             num_centers = self.dataset.epoch_inds.shape[0]
 
             # Get the list of indices to generate thanks to potentials
             if num_centers < self.dataset.potentials.shape[0]:
-                _, gen_indices = torch.topk(self.dataset.potentials, num_centers, largest=False, sorted=True)
+                _, gen_indices = torch.topk(
+                    self.dataset.potentials, num_centers, largest=False, sorted=True
+                )
             else:
                 gen_indices = torch.randperm(self.dataset.potentials.shape[0])
                 while gen_indices.shape[0] < num_centers:
-                    new_gen_indices = torch.randperm(self.dataset.potentials.shape[0]).type(torch.int32)
+                    new_gen_indices = torch.randperm(
+                        self.dataset.potentials.shape[0]
+                    ).type(torch.int32)
                     gen_indices = torch.cat((gen_indices, new_gen_indices), dim=0)
                 gen_indices = gen_indices[:num_centers]
 
             # Update potentials (Change the order for the next epoch)
-            self.dataset.potentials[gen_indices] = torch.ceil(self.dataset.potentials[gen_indices])
-            self.dataset.potentials[gen_indices] += torch.from_numpy(np.random.rand(gen_indices.shape[0]) * 0.1 + 0.1)
+            self.dataset.potentials[gen_indices] = torch.ceil(
+                self.dataset.potentials[gen_indices]
+            )
+            self.dataset.potentials[gen_indices] += torch.from_numpy(
+                np.random.rand(gen_indices.shape[0]) * 0.1 + 0.1
+            )
 
             # Update epoch inds
             self.dataset.epoch_inds += gen_indices
 
         # Generator loop
@@ -850,11 +958,13 @@
         """
         The number of yielded samples is variable
         """
         return self.N
 
-    def calib_max_in(self, config, dataloader, untouched_ratio=0.8, verbose=True, force_redo=False):
+    def calib_max_in(
+        self, config, dataloader, untouched_ratio=0.8, verbose=True, force_redo=False
+    ):
         """
         Method performing batch and neighbors calibration.
             Batch calibration: Set "batch_limit" (the maximum number of points allowed in every batch) so that the
                                average batch size (number of stacked pointclouds) is the one asked.
         Neighbors calibration: Set the "neighborhood_limits" (the maximum number of neighbors allowed in convolutions)
@@ -863,49 +973,51 @@
 
         ##############################
         # Previously saved calibration
         ##############################
 
-        print('\nStarting Calibration of max_in_points value (use verbose=True for more details)')
+        print(
+            "\nStarting Calibration of max_in_points value (use verbose=True for more details)"
+        )
         t0 = time.time()
 
         redo = force_redo
 
         # Batch limit
         # ***********
 
         # Load max_in_limit dictionary
-        max_in_lim_file = join(self.dataset.path, 'max_in_limits.pkl')
+        max_in_lim_file = join(self.dataset.path, "max_in_limits.pkl")
         if exists(max_in_lim_file):
-            with open(max_in_lim_file, 'rb') as file:
+            with open(max_in_lim_file, "rb") as file:
                 max_in_lim_dict = pickle.load(file)
         else:
             max_in_lim_dict = {}
 
         # Check if the max_in limit associated with current parameters exists
         if self.dataset.balance_classes:
-            sampler_method = 'balanced'
+            sampler_method = "balanced"
         else:
-            sampler_method = 'random'
-        key = '{:s}_{:.3f}_{:.3f}'.format(sampler_method,
-                                          self.dataset.in_R,
-                                          self.dataset.config.first_subsampling_dl)
+            sampler_method = "random"
+        key = "{:s}_{:.3f}_{:.3f}".format(
+            sampler_method, self.dataset.in_R, self.dataset.config.first_subsampling_dl
+        )
         if not redo and key in max_in_lim_dict:
             self.dataset.max_in_p = max_in_lim_dict[key]
         else:
             redo = True
 
         if verbose:
-            print('\nPrevious calibration found:')
-            print('Check max_in limit dictionary')
+            print("\nPrevious calibration found:")
+            print("Check max_in limit dictionary")
             if key in max_in_lim_dict:
                 color = bcolors.OKGREEN
                 v = str(int(max_in_lim_dict[key]))
             else:
                 color = bcolors.FAIL
-                v = '?'
-            print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                v = "?"
+            print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         if redo:
 
             ########################
             # Batch calib parameters
@@ -938,40 +1050,43 @@
                     t = time.time()
 
                     # Console display (only one per second)
                     if t - last_display > 1.0:
                         last_display = t
-                        message = 'Collecting {:d} in_points: {:5.1f}%'
-                        print(message.format(N,
-                                             100 * len(all_lengths) / N))
+                        message = "Collecting {:d} in_points: {:5.1f}%"
+                        print(message.format(N, 100 * len(all_lengths) / N))
 
                 if breaking:
                     break
 
-            self.dataset.max_in_p = int(np.percentile(all_lengths, 100*untouched_ratio))
+            self.dataset.max_in_p = int(
+                np.percentile(all_lengths, 100 * untouched_ratio)
+            )
 
             if verbose:
 
                 # Create histogram
                 a = 1
 
             # Save max_in_limit dictionary
-            print('New max_in_p = ', self.dataset.max_in_p)
+            print("New max_in_p = ", self.dataset.max_in_p)
             max_in_lim_dict[key] = self.dataset.max_in_p
-            with open(max_in_lim_file, 'wb') as file:
+            with open(max_in_lim_file, "wb") as file:
                 pickle.dump(max_in_lim_dict, file)
 
         # Update value in config
-        if self.dataset.set == 'training':
+        if self.dataset.set == "training":
             config.max_in_points = self.dataset.max_in_p
         else:
             config.max_val_points = self.dataset.max_in_p
 
-        print('Calibration done in {:.1f}s\n'.format(time.time() - t0))
+        print("Calibration done in {:.1f}s\n".format(time.time() - t0))
         return
 
-    def calibration(self, dataloader, untouched_ratio=0.9, verbose=False, force_redo=False):
+    def calibration(
+        self, dataloader, untouched_ratio=0.9, verbose=False, force_redo=False
+    ):
         """
         Method performing batch and neighbors calibration.
             Batch calibration: Set "batch_limit" (the maximum number of points allowed in every batch) so that the
                                average batch size (number of stacked pointclouds) is the one asked.
         Neighbors calibration: Set the "neighborhood_limits" (the maximum number of neighbors allowed in convolutions)
@@ -980,59 +1095,61 @@
 
         ##############################
         # Previously saved calibration
         ##############################
 
-        print('\nStarting Calibration (use verbose=True for more details)')
+        print("\nStarting Calibration (use verbose=True for more details)")
         t0 = time.time()
 
         redo = force_redo
 
         # Batch limit
         # ***********
 
         # Load batch_limit dictionary
-        batch_lim_file = join(self.dataset.path, 'batch_limits.pkl')
+        batch_lim_file = join(self.dataset.path, "batch_limits.pkl")
         if exists(batch_lim_file):
-            with open(batch_lim_file, 'rb') as file:
+            with open(batch_lim_file, "rb") as file:
                 batch_lim_dict = pickle.load(file)
         else:
             batch_lim_dict = {}
 
         # Check if the batch limit associated with current parameters exists
         if self.dataset.balance_classes:
-            sampler_method = 'balanced'
+            sampler_method = "balanced"
         else:
-            sampler_method = 'random'
-        key = '{:s}_{:.3f}_{:.3f}_{:d}_{:d}'.format(sampler_method,
-                                                    self.dataset.in_R,
-                                                    self.dataset.config.first_subsampling_dl,
-                                                    self.dataset.batch_num,
-                                                    self.dataset.max_in_p)
+            sampler_method = "random"
+        key = "{:s}_{:.3f}_{:.3f}_{:d}_{:d}".format(
+            sampler_method,
+            self.dataset.in_R,
+            self.dataset.config.first_subsampling_dl,
+            self.dataset.batch_num,
+            self.dataset.max_in_p,
+        )
         if not redo and key in batch_lim_dict:
             self.dataset.batch_limit[0] = batch_lim_dict[key]
         else:
             redo = True
 
         if verbose:
-            print('\nPrevious calibration found:')
-            print('Check batch limit dictionary')
+            print("\nPrevious calibration found:")
+            print("Check batch limit dictionary")
             if key in batch_lim_dict:
                 color = bcolors.OKGREEN
                 v = str(int(batch_lim_dict[key]))
             else:
                 color = bcolors.FAIL
-                v = '?'
-            print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                v = "?"
+            print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         # Neighbors limit
         # ***************
 
         # Load neighb_limits dictionary
-        neighb_lim_file = join(self.dataset.path, 'neighbors_limits.pkl')
+        neighb_lim_file = join(self.dataset.path, "neighbors_limits.pkl")
         if exists(neighb_lim_file):
-            with open(neighb_lim_file, 'rb') as file:
+            with open(neighb_lim_file, "rb") as file:
                 neighb_lim_dict = pickle.load(file)
         else:
             neighb_lim_dict = {}
 
         # Check if the limit associated with current parameters exists (for each layer)
@@ -1043,48 +1160,56 @@
             if self.dataset.config.deform_layers[layer_ind]:
                 r = dl * self.dataset.config.deform_radius
             else:
                 r = dl * self.dataset.config.conv_radius
 
-            key = '{:s}_{:d}_{:.3f}_{:.3f}'.format(sampler_method, self.dataset.max_in_p, dl, r)
+            key = "{:s}_{:d}_{:.3f}_{:.3f}".format(
+                sampler_method, self.dataset.max_in_p, dl, r
+            )
             if key in neighb_lim_dict:
                 neighb_limits += [neighb_lim_dict[key]]
 
         if not redo and len(neighb_limits) == self.dataset.config.num_layers:
             self.dataset.neighborhood_limits = neighb_limits
         else:
             redo = True
 
         if verbose:
-            print('Check neighbors limit dictionary')
+            print("Check neighbors limit dictionary")
             for layer_ind in range(self.dataset.config.num_layers):
                 dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
                 if self.dataset.config.deform_layers[layer_ind]:
                     r = dl * self.dataset.config.deform_radius
                 else:
                     r = dl * self.dataset.config.conv_radius
-                key = '{:s}_{:d}_{:.3f}_{:.3f}'.format(sampler_method, self.dataset.max_in_p, dl, r)
+                key = "{:s}_{:d}_{:.3f}_{:.3f}".format(
+                    sampler_method, self.dataset.max_in_p, dl, r
+                )
 
                 if key in neighb_lim_dict:
                     color = bcolors.OKGREEN
                     v = str(neighb_lim_dict[key])
                 else:
                     color = bcolors.FAIL
-                    v = '?'
-                print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                    v = "?"
+                print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         if redo:
 
             ############################
             # Neighbors calib parameters
             ############################
 
             # From config parameter, compute higher bound of neighbors number in a neighborhood
-            hist_n = int(np.ceil(4 / 3 * np.pi * (self.dataset.config.deform_radius + 1) ** 3))
+            hist_n = int(
+                np.ceil(4 / 3 * np.pi * (self.dataset.config.deform_radius + 1) ** 3)
+            )
 
             # Histogram of neighborhood sizes
-            neighb_hists = np.zeros((self.dataset.config.num_layers, hist_n), dtype=np.int32)
+            neighb_hists = np.zeros(
+                (self.dataset.config.num_layers, hist_n), dtype=np.int32
+            )
 
             ########################
             # Batch calib parameters
             ########################
 
@@ -1112,22 +1237,25 @@
 
             #####################
             # Perform calibration
             #####################
 
-            #self.dataset.batch_limit[0] = self.dataset.max_in_p * (self.dataset.batch_num - 1)
+            # self.dataset.batch_limit[0] = self.dataset.max_in_p * (self.dataset.batch_num - 1)
 
             for epoch in range(10):
                 for batch_i, batch in enumerate(dataloader):
 
                     # Control max_in_points value
                     are_cropped = batch.lengths[0] > self.dataset.max_in_p - 1
                     cropped_n += torch.sum(are_cropped.type(torch.int32)).item()
                     all_n += int(batch.lengths[0].shape[0])
 
                     # Update neighborhood histogram
-                    counts = [np.sum(neighb_mat.numpy() < neighb_mat.shape[0], axis=1) for neighb_mat in batch.neighbors]
+                    counts = [
+                        np.sum(neighb_mat.numpy() < neighb_mat.shape[0], axis=1)
+                        for neighb_mat in batch.neighbors
+                    ]
                     hists = [np.bincount(c, minlength=hist_n)[:hist_n] for c in counts]
                     neighb_hists += np.vstack(hists)
 
                     # batch length
                     b = len(batch.frame_inds)
@@ -1160,89 +1288,102 @@
                     t = time.time()
 
                     # Console display (only one per second)
                     if verbose and (t - last_display) > 1.0:
                         last_display = t
-                        message = 'Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d}'
-                        print(message.format(i,
-                                             estim_b,
-                                             int(self.dataset.batch_limit[0])))
+                        message = "Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d}"
+                        print(
+                            message.format(i, estim_b, int(self.dataset.batch_limit[0]))
+                        )
 
                 if breaking:
                     break
 
             # Use collected neighbor histogram to get neighbors limit
             cumsum = np.cumsum(neighb_hists.T, axis=0)
-            percentiles = np.sum(cumsum < (untouched_ratio * cumsum[hist_n - 1, :]), axis=0)
+            percentiles = np.sum(
+                cumsum < (untouched_ratio * cumsum[hist_n - 1, :]), axis=0
+            )
             self.dataset.neighborhood_limits = percentiles
 
             if verbose:
 
                 # Crop histogram
                 while np.sum(neighb_hists[:, -1]) == 0:
                     neighb_hists = neighb_hists[:, :-1]
                 hist_n = neighb_hists.shape[1]
 
-                print('\n**************************************************\n')
-                line0 = 'neighbors_num '
+                print("\n**************************************************\n")
+                line0 = "neighbors_num "
                 for layer in range(neighb_hists.shape[0]):
-                    line0 += '|  layer {:2d}  '.format(layer)
+                    line0 += "|  layer {:2d}  ".format(layer)
                 print(line0)
                 for neighb_size in range(hist_n):
-                    line0 = '     {:4d}     '.format(neighb_size)
+                    line0 = "     {:4d}     ".format(neighb_size)
                     for layer in range(neighb_hists.shape[0]):
                         if neighb_size > percentiles[layer]:
                             color = bcolors.FAIL
                         else:
                             color = bcolors.OKGREEN
-                        line0 += '|{:}{:10d}{:}  '.format(color,
-                                                         neighb_hists[layer, neighb_size],
-                                                         bcolors.ENDC)
+                        line0 += "|{:}{:10d}{:}  ".format(
+                            color, neighb_hists[layer, neighb_size], bcolors.ENDC
+                        )
 
                     print(line0)
 
-                print('\n**************************************************\n')
-                print('\nchosen neighbors limits: ', percentiles)
+                print("\n**************************************************\n")
+                print("\nchosen neighbors limits: ", percentiles)
                 print()
 
             # Control max_in_points value
-            print('\n**************************************************\n')
+            print("\n**************************************************\n")
             if cropped_n > 0.3 * all_n:
                 color = bcolors.FAIL
             else:
                 color = bcolors.OKGREEN
-            print('Current value of max_in_points {:d}'.format(self.dataset.max_in_p))
-            print('  > {:}{:.1f}% inputs are cropped{:}'.format(color, 100 * cropped_n / all_n, bcolors.ENDC))
+            print("Current value of max_in_points {:d}".format(self.dataset.max_in_p))
+            print(
+                "  > {:}{:.1f}% inputs are cropped{:}".format(
+                    color, 100 * cropped_n / all_n, bcolors.ENDC
+                )
+            )
             if cropped_n > 0.3 * all_n:
-                print('\nTry a higher max_in_points value\n'.format(100 * cropped_n / all_n))
-                #raise ValueError('Value of max_in_points too low')
-            print('\n**************************************************\n')
+                print(
+                    "\nTry a higher max_in_points value\n".format(
+                        100 * cropped_n / all_n
+                    )
+                )
+                # raise ValueError('Value of max_in_points too low')
+            print("\n**************************************************\n")
 
             # Save batch_limit dictionary
-            key = '{:s}_{:.3f}_{:.3f}_{:d}_{:d}'.format(sampler_method,
-                                                        self.dataset.in_R,
-                                                        self.dataset.config.first_subsampling_dl,
-                                                        self.dataset.batch_num,
-                                                        self.dataset.max_in_p)
+            key = "{:s}_{:.3f}_{:.3f}_{:d}_{:d}".format(
+                sampler_method,
+                self.dataset.in_R,
+                self.dataset.config.first_subsampling_dl,
+                self.dataset.batch_num,
+                self.dataset.max_in_p,
+            )
             batch_lim_dict[key] = float(self.dataset.batch_limit[0])
-            with open(batch_lim_file, 'wb') as file:
+            with open(batch_lim_file, "wb") as file:
                 pickle.dump(batch_lim_dict, file)
 
             # Save neighb_limit dictionary
             for layer_ind in range(self.dataset.config.num_layers):
-                dl = self.dataset.config.first_subsampling_dl * (2 ** layer_ind)
+                dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
                 if self.dataset.config.deform_layers[layer_ind]:
                     r = dl * self.dataset.config.deform_radius
                 else:
                     r = dl * self.dataset.config.conv_radius
-                key = '{:s}_{:d}_{:.3f}_{:.3f}'.format(sampler_method, self.dataset.max_in_p, dl, r)
+                key = "{:s}_{:d}_{:.3f}_{:.3f}".format(
+                    sampler_method, self.dataset.max_in_p, dl, r
+                )
                 neighb_lim_dict[key] = self.dataset.neighborhood_limits[layer_ind]
-            with open(neighb_lim_file, 'wb') as file:
+            with open(neighb_lim_file, "wb") as file:
                 pickle.dump(neighb_lim_dict, file)
 
-
-        print('Calibration done in {:.1f}s\n'.format(time.time() - t0))
+        print("Calibration done in {:.1f}s\n".format(time.time() - t0))
         return
 
 
 class SemanticKittiCustomBatch:
     """Custom batch definition with memory pinning for SemanticKitti"""
@@ -1255,19 +1396,29 @@
         # Number of layers
         L = int(input_list[0])
 
         # Extract input tensors from the list of numpy array
         ind = 1
-        self.points = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.points = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.neighbors = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.neighbors = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.pools = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.pools = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.upsamples = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.upsamples = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.lengths = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.lengths = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
         self.features = torch.from_numpy(input_list[ind])
         ind += 1
         self.labels = torch.from_numpy(input_list[ind])
         ind += 1
@@ -1322,54 +1473,54 @@
 
         return self
 
     def unstack_points(self, layer=None):
         """Unstack the points"""
-        return self.unstack_elements('points', layer)
+        return self.unstack_elements("points", layer)
 
     def unstack_neighbors(self, layer=None):
         """Unstack the neighbors indices"""
-        return self.unstack_elements('neighbors', layer)
+        return self.unstack_elements("neighbors", layer)
 
     def unstack_pools(self, layer=None):
         """Unstack the pooling indices"""
-        return self.unstack_elements('pools', layer)
+        return self.unstack_elements("pools", layer)
 
     def unstack_elements(self, element_name, layer=None, to_numpy=True):
         """
         Return a list of the stacked elements in the batch at a certain layer. If no layer is given, then return all
         layers
         """
 
-        if element_name == 'points':
+        if element_name == "points":
             elements = self.points
-        elif element_name == 'neighbors':
+        elif element_name == "neighbors":
             elements = self.neighbors
-        elif element_name == 'pools':
+        elif element_name == "pools":
             elements = self.pools[:-1]
         else:
-            raise ValueError('Unknown element name: {:s}'.format(element_name))
+            raise ValueError("Unknown element name: {:s}".format(element_name))
 
         all_p_list = []
         for layer_i, layer_elems in enumerate(elements):
 
             if layer is None or layer == layer_i:
 
                 i0 = 0
                 p_list = []
-                if element_name == 'pools':
-                    lengths = self.lengths[layer_i+1]
+                if element_name == "pools":
+                    lengths = self.lengths[layer_i + 1]
                 else:
                     lengths = self.lengths[layer_i]
 
                 for b_i, length in enumerate(lengths):
 
-                    elem = layer_elems[i0:i0 + length]
-                    if element_name == 'neighbors':
+                    elem = layer_elems[i0 : i0 + length]
+                    if element_name == "neighbors":
                         elem[elem >= self.points[layer_i].shape[0]] = -1
                         elem[elem >= 0] -= i0
-                    elif element_name == 'pools':
+                    elif element_name == "pools":
                         elem[elem >= self.points[layer_i].shape[0]] = -1
                         elem[elem >= 0] -= torch.sum(self.lengths[layer_i][:b_i])
                     i0 += length
 
                     if to_numpy:
@@ -1425,18 +1576,18 @@
             mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Console display (only one per second)
             if (t[-1] - last_display) > -1.0:
                 last_display = t[-1]
-                message = 'Step {:08d} -> (ms/batch) {:8.2f} {:8.2f} / batch = {:.2f} - {:.0f}'
-                print(message.format(batch_i,
-                                     1000 * mean_dt[0],
-                                     1000 * mean_dt[1],
-                                     estim_b,
-                                     estim_N))
-
-        print('************* Epoch ended *************')
+                message = "Step {:08d} -> (ms/batch) {:8.2f} {:8.2f} / batch = {:.2f} - {:.0f}"
+                print(
+                    message.format(
+                        batch_i, 1000 * mean_dt[0], 1000 * mean_dt[1], estim_b, estim_N
+                    )
+                )
+
+        print("************* Epoch ended *************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -1445,29 +1596,28 @@
 
     i = 0
 
     counts = np.zeros((dataset.num_classes,), dtype=np.int64)
 
-    s = '{:^6}|'.format('step')
+    s = "{:^6}|".format("step")
     for c in dataset.label_names:
-        s += '{:^6}'.format(c[:4])
+        s += "{:^6}".format(c[:4])
     print(s)
-    print(6*'-' + '|' + 6*dataset.num_classes*'-')
+    print(6 * "-" + "|" + 6 * dataset.num_classes * "-")
 
     for epoch in range(10):
         for batch_i, batch in enumerate(loader):
             # print(batch_i, tuple(points.shape),  tuple(normals.shape), labels, indices, in_sizes)
 
             # count labels
             new_counts = np.bincount(batch.labels)
 
-            counts[:new_counts.shape[0]] += new_counts.astype(np.int64)
+            counts[: new_counts.shape[0]] += new_counts.astype(np.int64)
 
             # Update proportions
             proportions = 1000 * counts / np.sum(counts)
 
-            s = '{:^6d}|'.format(i)
+            s = "{:^6d}|".format(i)
             for pp in proportions:
-                s += '{:^6.1f}'.format(pp)
+                s += "{:^6.1f}".format(pp)
             print(s)
             i += 1
-
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/evaluate.py	2024-06-30 22:34:18.722734+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/evaluate.py	2024-07-08 11:53:46.258734+00:00
@@ -21,68 +21,73 @@
         if on_gpu and torch.cuda.is_available():
             self.device = torch.device("cuda:0")
         else:
             self.device = torch.device("cpu")
         net.to(self.device)
-        
+
         # Load checkpoint
         checkpoint = torch.load(chkp_path)
-        net.load_state_dict(checkpoint['model_state_dict'])
-        self.epoch = checkpoint['epoch']
+        net.load_state_dict(checkpoint["model_state_dict"])
+        self.epoch = checkpoint["epoch"]
         net.eval()
         print("Model and training state restored.")
-        
-        
-        
-    def cloud_segmentation_test(self, net, test_loader, config, num_votes=100, debug=False):
+
+    def cloud_segmentation_test(
+        self, net, test_loader, config, num_votes=100, debug=False
+    ):
         # Choose test smoothing parameter (0 for no smothing, 0.99 for big smoothing)
         test_smooth = 0.95
         test_radius_ratio = 0.7
         softmax = torch.nn.Softmax(1)
         self.cls = 7
         self.act = 6
 
-
         # Number of classes including ignored labels
         nc_tot = test_loader.dataset.num_classes
 
         # Number of classes predicted by the model
         nc_model = config.num_classes
 
         # Initiate global prediction on test/validation cloud. Dim: (M, 3) (Remember this is subsampled one so not original cloud)
-        self.test_probs = [np.zeros((l.shape[0], nc_model)) for l in test_loader.dataset.input_labels]
-        self.test_heatmap = [np.zeros((l.shape[0],)) for l in test_loader.dataset.input_labels]
-        
+        self.test_probs = [
+            np.zeros((l.shape[0], nc_model)) for l in test_loader.dataset.input_labels
+        ]
+        self.test_heatmap = [
+            np.zeros((l.shape[0],)) for l in test_loader.dataset.input_labels
+        ]
+
         self.test_loader = test_loader
 
-
-            
         # For validation, label proportions. (used as weights in criterion)
-        if test_loader.dataset.set == 'validation':
+        if test_loader.dataset.set == "validation":
             val_proportions = np.zeros(nc_model, dtype=np.float32)
             i = 0
             for label_value in test_loader.dataset.label_values:
                 if label_value not in test_loader.dataset.ignored_labels:
-                    val_proportions[i] = np.sum([np.sum(labels == label_value)
-                                                 for labels in test_loader.dataset.validation_labels])
+                    val_proportions[i] = np.sum(
+                        [
+                            np.sum(labels == label_value)
+                            for labels in test_loader.dataset.validation_labels
+                        ]
+                    )
                     i += 1
         else:
             val_proportions = None
-            
+
         self.val_proportions = val_proportions
-            
+
         # Network predictions
         test_epoch = 0
         last_min = -0.5
-        
+
         # Start test loop
         while True:
             print("Initialize workers.")
             for i, batch in enumerate(test_loader):
-                if 'cuda' in self.device.type:
+                if "cuda" in self.device.type:
                     batch.to(self.device)
-                    
+
                     # Forward pass
                     outputs = net(batch, config)
 
                     stacked_probs = softmax(outputs)
                     logits = stacked_probs[:, self.cls]
@@ -104,11 +109,13 @@
                     alpha = torch.sum(grads, axis=0, keepdim=True)
 
                     stacked_heatmap = torch.matmul(last_act, alpha.T).squeeze()
 
                     # Apply ReLU
-                    stacked_heatmap = torch.maximum(stacked_heatmap, torch.zeros_like(stacked_heatmap))
+                    stacked_heatmap = torch.maximum(
+                        stacked_heatmap, torch.zeros_like(stacked_heatmap)
+                    )
 
                     # Normalize
                     max_val = torch.max(stacked_heatmap, dim=-1, keepdim=True)[0]
                     min_val = torch.min(stacked_heatmap, dim=-1, keepdim=True)[0]
                     stacked_heatmap = (stacked_heatmap - min_val) / (max_val - min_val)
@@ -121,11 +128,13 @@
                         for pt in batch.points:
                             if stacked_heatmap.shape[0] == pt.shape[0]:
                                 # Build tree using pt
                                 pt = pt.cpu().numpy()
                                 tree = KDTree(pt, leaf_size=40)
-                                reproj_idx = tree.query(s_points, k=1, return_distance=False)
+                                reproj_idx = tree.query(
+                                    s_points, k=1, return_distance=False
+                                )
                                 reproj_idx = reproj_idx.squeeze()
 
                                 # Reprojected stacked_heatmap (of same dimension as batch.points[0])
                                 stacked_heatmap = stacked_heatmap[reproj_idx]
                                 break
@@ -135,59 +144,65 @@
                     lengths = batch.lengths[0].cpu().numpy()
                     in_inds = batch.input_inds.cpu().numpy()
                     cloud_inds = batch.cloud_inds.cpu().numpy()
                     torch.cuda.synchronize(self.device)
 
-
-                    
                     # Get predictions and labels per instance
                     # Also update test_probs for each instance.
                     i0 = 0
                     for b_i, length in enumerate(lengths):
                         # Get prediction
-                        points = s_points[i0:i0 + length]
-                        probs = stacked_probs[i0:i0 + length]
-                        inds = in_inds[i0:i0 + length]
-                        heatmap = stacked_heatmap[i0:i0 + length]
+                        points = s_points[i0 : i0 + length]
+                        probs = stacked_probs[i0 : i0 + length]
+                        inds = in_inds[i0 : i0 + length]
+                        heatmap = stacked_heatmap[i0 : i0 + length]
                         c_i = cloud_inds[b_i]
 
                         if 0 < test_radius_ratio < 1:
-                            mask = np.sum(points ** 2, axis=1) < (test_radius_ratio * config.in_radius) ** 2
+                            mask = (
+                                np.sum(points**2, axis=1)
+                                < (test_radius_ratio * config.in_radius) ** 2
+                            )
                             inds = inds[mask]
                             probs = probs[mask]
                             heatmap = heatmap[mask]
 
                         # Update current probs in subsampled cloud
-                        self.test_probs[c_i][inds] = test_smooth * self.test_probs[c_i][inds] + (1 - test_smooth) * probs
-                        self.test_heatmap[c_i][inds] = test_smooth * self.test_heatmap[c_i][inds] + (1 - test_smooth) * heatmap
+                        self.test_probs[c_i][inds] = (
+                            test_smooth * self.test_probs[c_i][inds]
+                            + (1 - test_smooth) * probs
+                        )
+                        self.test_heatmap[c_i][inds] = (
+                            test_smooth * self.test_heatmap[c_i][inds]
+                            + (1 - test_smooth) * heatmap
+                        )
                         i0 += length
-                    
-                    if i%20 == 0:
-                        message = 'e{:03d}-i{:04d}'
+
+                    if i % 20 == 0:
+                        message = "e{:03d}-i{:04d}"
                         print(message.format(test_epoch, i))
-
-
 
             # Update min potentials
             new_min = torch.min(test_loader.dataset.min_potentials)
-            print('Test epoch {:d}, end. Min potential = {:.1f}'.format(test_epoch, new_min))
-
+            print(
+                "Test epoch {:d}, end. Min potential = {:.1f}".format(
+                    test_epoch, new_min
+                )
+            )
 
             # Compute confusion for subsampled clouds
             if last_min + 1 < new_min:
                 # Update last min
                 last_min += 1
 
-                            
             if last_min > num_votes:
                 break
 
         # Voting results on subsampled clouds (NOT ORIGINAL CLOUD)
         self.compute_on_sub_cloud(save=True)
         self.compute_on_full_cloud()
-        
-        
+
     def compute_on_sub_cloud(self, save=False):
         print("\nConfusion on subsampled clouds...")
         Confs = []
         for i, file_path in enumerate(self.test_loader.dataset.files):
             # Insert false columns for ignored labels
@@ -195,95 +210,105 @@
             for l_ind, label_value in enumerate(self.test_loader.dataset.label_values):
                 if label_value in self.test_loader.dataset.ignored_labels:
                     probs = np.insert(probs, l_ind, 0, axis=1)
 
             # Predicted labels
-            preds = self.test_loader.dataset.label_values[np.argmax(probs, axis=1)].astype(np.int32)
+            preds = self.test_loader.dataset.label_values[
+                np.argmax(probs, axis=1)
+            ].astype(np.int32)
 
             # Targets
             targets = self.test_loader.dataset.input_labels[i]
 
             # pGS-CAM heatmap
             pgscam = self.test_heatmap[i]
-            
+
             pgscam = np.nan_to_num(pgscam, nan=0.0)
 
             sub_points = self.test_loader.dataset.input_trees[i].data.base
 
             if save:
-                write_ply(f'./pgscam_results/KPConv_NPM3d_cls_{self.cls}_act_{self.act}.ply', [sub_points, preds, targets, pgscam], ['x', 'y', 'z', 'preds', 'class', 'pgscam'])
+                write_ply(
+                    f"./pgscam_results/KPConv_NPM3d_cls_{self.cls}_act_{self.act}.ply",
+                    [sub_points, preds, targets, pgscam],
+                    ["x", "y", "z", "preds", "class", "pgscam"],
+                )
 
             # Confs
-            Confs += [fast_confusion(targets, preds, self.test_loader.dataset.label_values)]
+            Confs += [
+                fast_confusion(targets, preds, self.test_loader.dataset.label_values)
+            ]
 
         # Regroup confusions
         C = np.sum(np.stack(Confs), axis=0).astype(np.float32)
 
         # Remove ignored labels from confusions
-        for l_ind, label_value in reversed(list(enumerate(self.test_loader.dataset.label_values))):
+        for l_ind, label_value in reversed(
+            list(enumerate(self.test_loader.dataset.label_values))
+        ):
             if label_value in self.test_loader.dataset.ignored_labels:
                 C = np.delete(C, l_ind, axis=0)
                 C = np.delete(C, l_ind, axis=1)
 
-
         # Rescale with the right number of point per class
         C *= np.expand_dims(self.val_proportions / (np.sum(C, axis=1) + 1e-6), 1)
 
         # Compute IoUs
         IoUs = IoU_from_confusions(C)
         mIoU = np.mean(IoUs)
-        s = '{:5.2f} | '.format(100 * mIoU)
+        s = "{:5.2f} | ".format(100 * mIoU)
         for IoU in IoUs:
-            s += '{:5.2f} '.format(100 * IoU)
-        print(s + '\n')
-        
-        
+            s += "{:5.2f} ".format(100 * IoU)
+        print(s + "\n")
+
     def compute_on_full_cloud(self):
         print("Reprojection for full cloud (KNN with 1 neighbor)")
         # REPROJECTION to compute for full cloud (Uses KNN with 1 neighbor for compute for entire cloud from subsampled cloud)
         proj_probs = []
-        
+
         for i, file_path in enumerate(self.test_loader.dataset.files):
             probs = self.test_probs[i][self.test_loader.dataset.test_proj[i], :]
             proj_probs += [probs]
-            
+
             for l_ind, label_value in enumerate(self.test_loader.dataset.label_values):
                 if label_value in self.test_loader.dataset.ignored_labels:
                     proj_probs[i] = np.insert(proj_probs[i], l_ind, 0, axis=1)
-                    
-                    
+
         # PROJECTION ON FULL CLOUDS
         print("Confusion on full clouds...")
         Confs = []
         for i, file_path in enumerate(self.test_loader.dataset.files):
             # Get the predicted labels
-            preds = self.test_loader.dataset.label_values[np.argmax(proj_probs[i], axis=1)].astype(np.int32)
-            
+            preds = self.test_loader.dataset.label_values[
+                np.argmax(proj_probs[i], axis=1)
+            ].astype(np.int32)
+
             if self.save_labels:
-                print("You have the preds for full cloud. Save label anywhere you want...")
+                print(
+                    "You have the preds for full cloud. Save label anywhere you want..."
+                )
 
             # Confusion
             targets = self.test_loader.dataset.validation_labels[i]
-            Confs += [fast_confusion(targets, preds, self.test_loader.dataset.label_values)]
-                
+            Confs += [
+                fast_confusion(targets, preds, self.test_loader.dataset.label_values)
+            ]
+
         # Regroup confusions
         C = np.sum(np.stack(Confs), axis=0)
 
         # Remove ignored labels from confusions
-        for l_ind, label_value in reversed(list(enumerate(self.test_loader.dataset.label_values))):
+        for l_ind, label_value in reversed(
+            list(enumerate(self.test_loader.dataset.label_values))
+        ):
             if label_value in self.test_loader.dataset.ignored_labels:
                 C = np.delete(C, l_ind, axis=0)
                 C = np.delete(C, l_ind, axis=1)
 
         IoUs = IoU_from_confusions(C)
         mIoU = np.mean(IoUs)
-        s = '{:5.2f} | '.format(100 * mIoU)
+        s = "{:5.2f} | ".format(100 * mIoU)
         for IoU in IoUs:
-            s += '{:5.2f} '.format(100 * IoU)
-        print('-' * len(s))
+            s += "{:5.2f} ".format(100 * IoU)
+        print("-" * len(s))
         print(s)
-        print('-' * len(s) + '\n')
-        
-
-        
-            
-            
\ No newline at end of file
+        print("-" * len(s) + "\n")
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/plot_convergence.py	2024-06-30 22:34:18.180997+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/plot_convergence.py	2024-07-08 11:53:46.324043+00:00
@@ -45,10 +45,11 @@
 #
 #           Utility functions
 #       \***********************/
 #
 
+
 def listdir_str(path):
 
     # listdir can return binary string instead od decoded string sometimes.
     # This function ensures a steady behavior
 
@@ -61,40 +62,39 @@
         f_list.append(f)
 
     return f_list
 
 
-
 def running_mean(signal, n, axis=0, stride=1):
     signal = np.array(signal)
-    torch_conv = torch.nn.Conv1d(1, 1, kernel_size=2*n+1, stride=stride, bias=False)
+    torch_conv = torch.nn.Conv1d(1, 1, kernel_size=2 * n + 1, stride=stride, bias=False)
     torch_conv.weight.requires_grad_(False)
     torch_conv.weight *= 0
-    torch_conv.weight += 1 / (2*n+1)
+    torch_conv.weight += 1 / (2 * n + 1)
     if signal.ndim == 1:
         torch_signal = torch.from_numpy(signal.reshape([1, 1, -1]).astype(np.float32))
         return torch_conv(torch_signal).squeeze().numpy()
 
     elif signal.ndim == 2:
-        print('TODO implement with torch and stride here')
+        print("TODO implement with torch and stride here")
         smoothed = np.empty(signal.shape)
         if axis == 0:
             for i, sig in enumerate(signal):
-                sig_sum = np.convolve(sig, np.ones((2*n+1,)), mode='same')
-                sig_num = np.convolve(sig*0+1, np.ones((2*n+1,)), mode='same')
+                sig_sum = np.convolve(sig, np.ones((2 * n + 1,)), mode="same")
+                sig_num = np.convolve(sig * 0 + 1, np.ones((2 * n + 1,)), mode="same")
                 smoothed[i, :] = sig_sum / sig_num
         elif axis == 1:
             for i, sig in enumerate(signal.T):
-                sig_sum = np.convolve(sig, np.ones((2*n+1,)), mode='same')
-                sig_num = np.convolve(sig*0+1, np.ones((2*n+1,)), mode='same')
+                sig_sum = np.convolve(sig, np.ones((2 * n + 1,)), mode="same")
+                sig_num = np.convolve(sig * 0 + 1, np.ones((2 * n + 1,)), mode="same")
                 smoothed[:, i] = sig_sum / sig_num
         else:
-            print('wrong axis')
+            print("wrong axis")
         return smoothed
 
     else:
-        print('wrong dimensions')
+        print("wrong dimensions")
         return None
 
 
 def IoU_class_metrics(all_IoUs, smooth_n):
 
@@ -110,11 +110,11 @@
     return smoothed_IoUs, smoothed_mIoUs
 
 
 def load_confusions(filename, n_class):
 
-    with open(filename, 'r') as f:
+    with open(filename, "r") as f:
         lines = f.readlines()
 
     confs = np.zeros((len(lines), n_class, n_class))
     for i, line in enumerate(lines):
         C = np.array([int(value) for value in line.split()])
@@ -123,23 +123,23 @@
     return confs
 
 
 def load_training_results(path):
 
-    filename = join(path, 'training.txt')
-    with open(filename, 'r') as f:
+    filename = join(path, "training.txt")
+    with open(filename, "r") as f:
         lines = f.readlines()
 
     epochs = []
     steps = []
     L_out = []
     L_p = []
     acc = []
     t = []
     for line in lines[1:]:
         line_info = line.split()
-        if (len(line) > 0):
+        if len(line) > 0:
             epochs += [int(line_info[0])]
             steps += [int(line_info[1])]
             L_out += [float(line_info[2])]
             L_p += [float(line_info[3])]
             acc += [float(line_info[4])]
@@ -150,11 +150,11 @@
     return epochs, steps, L_out, L_p, acc, t
 
 
 def load_single_IoU(filename, n_parts):
 
-    with open(filename, 'r') as f:
+    with open(filename, "r") as f:
         lines = f.readlines()
 
     # Load all IoUs
     all_IoUs = []
     for i, line in enumerate(lines):
@@ -162,40 +162,46 @@
     return all_IoUs
 
 
 def load_snap_clouds(path, dataset, only_last=False):
 
-    cloud_folders = np.array([join(path, f) for f in listdir_str(path) if f.startswith('val_preds')])
-    cloud_epochs = np.array([int(f.split('_')[-1]) for f in cloud_folders])
+    cloud_folders = np.array(
+        [join(path, f) for f in listdir_str(path) if f.startswith("val_preds")]
+    )
+    cloud_epochs = np.array([int(f.split("_")[-1]) for f in cloud_folders])
     epoch_order = np.argsort(cloud_epochs)
     cloud_epochs = cloud_epochs[epoch_order]
     cloud_folders = cloud_folders[epoch_order]
 
-    Confs = np.zeros((len(cloud_epochs), dataset.num_classes, dataset.num_classes), dtype=np.int32)
+    Confs = np.zeros(
+        (len(cloud_epochs), dataset.num_classes, dataset.num_classes), dtype=np.int32
+    )
     for c_i, cloud_folder in enumerate(cloud_folders):
         if only_last and c_i < len(cloud_epochs) - 1:
             continue
 
         # Load confusion if previously saved
-        conf_file = join(cloud_folder, 'conf.txt')
+        conf_file = join(cloud_folder, "conf.txt")
         if isfile(conf_file):
             Confs[c_i] += np.loadtxt(conf_file, dtype=np.int32)
 
         else:
             for f in listdir_str(cloud_folder):
-                if f.endswith('.ply') and not f.endswith('sub.ply'):
+                if f.endswith(".ply") and not f.endswith("sub.ply"):
                     data = read_ply(join(cloud_folder, f))
-                    labels = data['class']
-                    preds = data['preds']
-                    Confs[c_i] += fast_confusion(labels, preds, dataset.label_values).astype(np.int32)
-
-            np.savetxt(conf_file, Confs[c_i], '%12d')
+                    labels = data["class"]
+                    preds = data["preds"]
+                    Confs[c_i] += fast_confusion(
+                        labels, preds, dataset.label_values
+                    ).astype(np.int32)
+
+            np.savetxt(conf_file, Confs[c_i], "%12d")
 
         # Erase ply to save disk memory
         if c_i < len(cloud_folders) - 1:
             for f in listdir_str(cloud_folder):
-                if f.endswith('.ply'):
+                if f.endswith(".ply"):
                     remove(join(cloud_folder, f))
 
     # Remove ignored labels from confusions
     for l_ind, label_value in reversed(list(enumerate(dataset.label_values))):
         if label_value in dataset.ignored_labels:
@@ -235,11 +241,13 @@
 
     for path in list_of_paths:
 
         print(path)
 
-        if ('val_IoUs.txt' in [f for f in listdir_str(path)]) or ('val_confs.txt' in [f for f in listdir_str(path)]):
+        if ("val_IoUs.txt" in [f for f in listdir_str(path)]) or (
+            "val_confs.txt" in [f for f in listdir_str(path)]
+        ):
             config = Config()
             config.load(path)
         else:
             continue
 
@@ -276,71 +284,70 @@
             all_lr += [lr[np.floor(all_epochs[-1]).astype(np.int32)]]
 
     # Plots learning rate
     # *******************
 
-
     if plot_lr:
         # Figure
-        fig = plt.figure('lr')
+        fig = plt.figure("lr")
         for i, label in enumerate(list_of_labels):
             plt.plot(all_epochs[i], all_lr[i], linewidth=1, label=label)
 
         # Set names for axes
-        plt.xlabel('epochs')
-        plt.ylabel('lr')
-        plt.yscale('log')
+        plt.xlabel("epochs")
+        plt.ylabel("lr")
+        plt.yscale("log")
 
         # Display legends and title
         plt.legend(loc=1)
 
         # Customize the graph
         ax = fig.gca()
-        ax.grid(linestyle='-.', which='both')
+        ax.grid(linestyle="-.", which="both")
         # ax.set_yticks(np.arange(0.8, 1.02, 0.02))
 
     # Plots loss
     # **********
 
     # Figure
-    fig = plt.figure('loss')
+    fig = plt.figure("loss")
     for i, label in enumerate(list_of_labels):
         plt.plot(all_epochs[i], all_loss[i], linewidth=1, label=label)
 
     # Set names for axes
-    plt.xlabel('epochs')
-    plt.ylabel('loss')
-    plt.yscale('log')
+    plt.xlabel("epochs")
+    plt.ylabel("loss")
+    plt.yscale("log")
 
     # Display legends and title
     plt.legend(loc=1)
-    plt.title('Losses compare')
+    plt.title("Losses compare")
 
     # Customize the graph
     ax = fig.gca()
-    ax.grid(linestyle='-.', which='both')
+    ax.grid(linestyle="-.", which="both")
     # ax.set_yticks(np.arange(0.8, 1.02, 0.02))
 
     # Plot Times
     # **********
 
     # Figure
-    fig = plt.figure('time')
+    fig = plt.figure("time")
     for i, label in enumerate(list_of_labels):
         plt.plot(all_epochs[i], np.array(all_times[i]) / 3600, linewidth=1, label=label)
 
     # Set names for axes
-    plt.xlabel('epochs')
-    plt.ylabel('time')
+    plt.xlabel("epochs")
+    plt.ylabel("time")
     # plt.yscale('log')
 
     # Display legends and title
     plt.legend(loc=0)
 
     # Customize the graph
     ax = fig.gca()
-    ax.grid(linestyle='-.', which='both')
+    ax.grid(linestyle="-.", which="both")
     # ax.set_yticks(np.arange(0.8, 1.02, 0.02))
 
     # Show all
     plt.show()
 
@@ -366,98 +373,111 @@
 
     # Load parameters
     config = Config()
     config.load(list_of_paths[0])
 
-    class_list = [dataset.label_to_names[label] for label in dataset.label_values
-                  if label not in dataset.ignored_labels]
-
-    s = '{:^10}|'.format('mean')
+    class_list = [
+        dataset.label_to_names[label]
+        for label in dataset.label_values
+        if label not in dataset.ignored_labels
+    ]
+
+    s = "{:^10}|".format("mean")
     for c in class_list:
-        s += '{:^10}'.format(c)
+        s += "{:^10}".format(c)
     print(s)
-    print(10*'-' + '|' + 10*config.num_classes*'-')
+    print(10 * "-" + "|" + 10 * config.num_classes * "-")
     for path in list_of_paths:
 
         # Get validation IoUs
-        file = join(path, 'val_IoUs.txt')
+        file = join(path, "val_IoUs.txt")
         val_IoUs = load_single_IoU(file, config.num_classes)
 
         # Get mean IoU
         class_IoUs, mIoUs = IoU_class_metrics(val_IoUs, smooth_n)
 
         # Aggregate results
         all_pred_epochs += [np.array([i for i in range(len(val_IoUs))])]
         all_mIoUs += [mIoUs]
         all_class_IoUs += [class_IoUs]
 
-        s = '{:^10.1f}|'.format(100*mIoUs[-1])
+        s = "{:^10.1f}|".format(100 * mIoUs[-1])
         for IoU in class_IoUs[-1]:
-            s += '{:^10.1f}'.format(100*IoU)
+            s += "{:^10.1f}".format(100 * IoU)
         print(s)
 
         # Get optional full validation on clouds
         snap_epochs, snap_IoUs = load_snap_clouds(path, dataset)
         all_snap_epochs += [snap_epochs]
         all_snap_IoUs += [snap_IoUs]
 
-    print(10*'-' + '|' + 10*config.num_classes*'-')
+    print(10 * "-" + "|" + 10 * config.num_classes * "-")
     for snap_IoUs in all_snap_IoUs:
         if len(snap_IoUs) > 0:
-            s = '{:^10.1f}|'.format(100*np.mean(snap_IoUs[-1]))
+            s = "{:^10.1f}|".format(100 * np.mean(snap_IoUs[-1]))
             for IoU in snap_IoUs[-1]:
-                s += '{:^10.1f}'.format(100*IoU)
+                s += "{:^10.1f}".format(100 * IoU)
         else:
-            s = '{:^10s}'.format('-')
+            s = "{:^10s}".format("-")
             for _ in range(config.num_classes):
-                s += '{:^10s}'.format('-')
+                s += "{:^10s}".format("-")
         print(s)
 
     # Plots
     # *****
 
     # Figure
-    fig = plt.figure('mIoUs')
+    fig = plt.figure("mIoUs")
     for i, name in enumerate(list_of_names):
-        p = plt.plot(all_pred_epochs[i], all_mIoUs[i], '--', linewidth=1, label=name)
-        plt.plot(all_snap_epochs[i], np.mean(all_snap_IoUs[i], axis=1), linewidth=1, color=p[-1].get_color())
-    plt.xlabel('epochs')
-    plt.ylabel('IoU')
+        p = plt.plot(all_pred_epochs[i], all_mIoUs[i], "--", linewidth=1, label=name)
+        plt.plot(
+            all_snap_epochs[i],
+            np.mean(all_snap_IoUs[i], axis=1),
+            linewidth=1,
+            color=p[-1].get_color(),
+        )
+    plt.xlabel("epochs")
+    plt.ylabel("IoU")
 
     # Set limits for y axis
-    #plt.ylim(0.55, 0.95)
+    # plt.ylim(0.55, 0.95)
 
     # Display legends and title
     plt.legend(loc=4)
 
     # Customize the graph
     ax = fig.gca()
-    ax.grid(linestyle='-.', which='both')
-    #ax.set_yticks(np.arange(0.8, 1.02, 0.02))
+    ax.grid(linestyle="-.", which="both")
+    # ax.set_yticks(np.arange(0.8, 1.02, 0.02))
 
     displayed_classes = [0, 1, 2, 3, 4, 5, 6, 7]
     displayed_classes = []
     for c_i, c_name in enumerate(class_list):
         if c_i in displayed_classes:
 
             # Figure
-            fig = plt.figure(c_name + ' IoU')
+            fig = plt.figure(c_name + " IoU")
             for i, name in enumerate(list_of_names):
-                plt.plot(all_pred_epochs[i], all_class_IoUs[i][:, c_i], linewidth=1, label=name)
-            plt.xlabel('epochs')
-            plt.ylabel('IoU')
+                plt.plot(
+                    all_pred_epochs[i],
+                    all_class_IoUs[i][:, c_i],
+                    linewidth=1,
+                    label=name,
+                )
+            plt.xlabel("epochs")
+            plt.ylabel("IoU")
 
             # Set limits for y axis
-            #plt.ylim(0.8, 1)
+            # plt.ylim(0.8, 1)
 
             # Display legends and title
             plt.legend(loc=4)
 
             # Customize the graph
             ax = fig.gca()
-            ax.grid(linestyle='-.', which='both')
-            #ax.set_yticks(np.arange(0.8, 1.02, 0.02))
+            ax.grid(linestyle="-.", which="both")
+            # ax.set_yticks(np.arange(0.8, 1.02, 0.02))
 
     # Show all
     plt.show()
 
 
@@ -479,11 +499,10 @@
     all_val_OA = []
     all_train_OA = []
     all_vote_OA = []
     all_vote_confs = []
 
-
     for path in list_of_paths:
 
         # Load parameters
         config = Config()
         config.load(list_of_paths[0])
@@ -494,25 +513,35 @@
         # Load epochs
         epochs, _, _, _, _, _ = load_training_results(path)
         first_e = np.min(epochs)
 
         # Get validation confusions
-        file = join(path, 'val_confs.txt')
+        file = join(path, "val_confs.txt")
         val_C1 = load_confusions(file, n_class)
-        val_PRE, val_REC, val_F1, val_IoU, val_ACC = smooth_metrics(val_C1, smooth_n=smooth_n)
+        val_PRE, val_REC, val_F1, val_IoU, val_ACC = smooth_metrics(
+            val_C1, smooth_n=smooth_n
+        )
 
         # Get vote confusions
-        file = join(path, 'vote_confs.txt')
+        file = join(path, "vote_confs.txt")
         if exists(file):
             vote_C2 = load_confusions(file, n_class)
-            vote_PRE, vote_REC, vote_F1, vote_IoU, vote_ACC = smooth_metrics(vote_C2, smooth_n=2)
+            vote_PRE, vote_REC, vote_F1, vote_IoU, vote_ACC = smooth_metrics(
+                vote_C2, smooth_n=2
+            )
         else:
             vote_C2 = val_C1
-            vote_PRE, vote_REC, vote_F1, vote_IoU, vote_ACC = (val_PRE, val_REC, val_F1, val_IoU, val_ACC)
+            vote_PRE, vote_REC, vote_F1, vote_IoU, vote_ACC = (
+                val_PRE,
+                val_REC,
+                val_F1,
+                val_IoU,
+                val_ACC,
+            )
 
         # Aggregate results
-        all_pred_epochs += [np.array([i+first_e for i in range(len(val_ACC))])]
+        all_pred_epochs += [np.array([i + first_e for i in range(len(val_ACC))])]
         all_val_OA += [val_ACC]
         all_vote_OA += [vote_ACC]
         all_vote_confs += [vote_C2]
 
     print()
@@ -520,15 +549,19 @@
     # Best scores
     # ***********
 
     for i, label in enumerate(list_of_labels):
 
-        print('\n' + label + '\n' + '*' * len(label) + '\n')
+        print("\n" + label + "\n" + "*" * len(label) + "\n")
         print(list_of_paths[i])
 
         best_epoch = np.argmax(all_vote_OA[i])
-        print('Best Accuracy : {:.1f} % (epoch {:d})'.format(100 * all_vote_OA[i][best_epoch], best_epoch))
+        print(
+            "Best Accuracy : {:.1f} % (epoch {:d})".format(
+                100 * all_vote_OA[i][best_epoch], best_epoch
+            )
+        )
 
         confs = all_vote_confs[i]
 
         """
         s = ''
@@ -542,36 +575,36 @@
         TP_plus_FN = np.sum(confs, axis=-1, keepdims=True)
         class_avg_confs = confs.astype(np.float32) / TP_plus_FN.astype(np.float32)
         diags = np.diagonal(class_avg_confs, axis1=-2, axis2=-1)
         class_avg_ACC = np.sum(diags, axis=-1) / np.sum(class_avg_confs, axis=(-1, -2))
 
-        print('Corresponding mAcc : {:.1f} %'.format(100 * class_avg_ACC[best_epoch]))
+        print("Corresponding mAcc : {:.1f} %".format(100 * class_avg_ACC[best_epoch]))
 
     # Plots
     # *****
 
-    for fig_name, OA in zip(['Validation', 'Vote'], [all_val_OA, all_vote_OA]):
+    for fig_name, OA in zip(["Validation", "Vote"], [all_val_OA, all_vote_OA]):
 
         # Figure
         fig = plt.figure(fig_name)
         for i, label in enumerate(list_of_labels):
             plt.plot(all_pred_epochs[i], OA[i], linewidth=1, label=label)
-        plt.xlabel('epochs')
-        plt.ylabel(fig_name + ' Accuracy')
+        plt.xlabel("epochs")
+        plt.ylabel(fig_name + " Accuracy")
 
         # Set limits for y axis
-        #plt.ylim(0.55, 0.95)
+        # plt.ylim(0.55, 0.95)
 
         # Display legends and title
         plt.legend(loc=4)
 
         # Customize the graph
         ax = fig.gca()
-        ax.grid(linestyle='-.', which='both')
-        #ax.set_yticks(np.arange(0.8, 1.02, 0.02))
-
-    #for i, label in enumerate(list_of_labels):
+        ax.grid(linestyle="-.", which="both")
+        # ax.set_yticks(np.arange(0.8, 1.02, 0.02))
+
+    # for i, label in enumerate(list_of_labels):
     #    print(label, np.max(all_train_OA[i]), np.max(all_val_OA[i]))
 
     # Show all
     plt.show()
 
@@ -597,27 +630,30 @@
 
     # Load parameters
     config = Config()
     config.load(list_of_paths[0])
 
-    class_list = [dataset.label_to_names[label] for label in dataset.label_values
-                  if label not in dataset.ignored_labels]
-
-    s = '{:^6}|'.format('mean')
+    class_list = [
+        dataset.label_to_names[label]
+        for label in dataset.label_values
+        if label not in dataset.ignored_labels
+    ]
+
+    s = "{:^6}|".format("mean")
     for c in class_list:
-        s += '{:^6}'.format(c[:4])
+        s += "{:^6}".format(c[:4])
     print(s)
-    print(6*'-' + '|' + 6*config.num_classes*'-')
+    print(6 * "-" + "|" + 6 * config.num_classes * "-")
     for path in list_of_paths:
 
         # Get validation IoUs
         nc_model = dataset.num_classes - len(dataset.ignored_labels)
-        file = join(path, 'val_IoUs.txt')
+        file = join(path, "val_IoUs.txt")
         val_IoUs = load_single_IoU(file, nc_model)
 
         # Get Subpart IoUs
-        file = join(path, 'subpart_IoUs.txt')
+        file = join(path, "subpart_IoUs.txt")
         subpart_IoUs = load_single_IoU(file, nc_model)
 
         # Get mean IoU
         val_class_IoUs, val_mIoUs = IoU_class_metrics(val_IoUs, smooth_n)
         subpart_class_IoUs, subpart_mIoUs = IoU_class_metrics(subpart_IoUs, smooth_n)
@@ -627,73 +663,80 @@
         all_val_mIoUs += [val_mIoUs]
         all_val_class_IoUs += [val_class_IoUs]
         all_subpart_mIoUs += [subpart_mIoUs]
         all_subpart_class_IoUs += [subpart_class_IoUs]
 
-        s = '{:^6.1f}|'.format(100*subpart_mIoUs[-1])
+        s = "{:^6.1f}|".format(100 * subpart_mIoUs[-1])
         for IoU in subpart_class_IoUs[-1]:
-            s += '{:^6.1f}'.format(100*IoU)
+            s += "{:^6.1f}".format(100 * IoU)
         print(s)
 
-    print(6*'-' + '|' + 6*config.num_classes*'-')
+    print(6 * "-" + "|" + 6 * config.num_classes * "-")
     for snap_IoUs in all_val_class_IoUs:
         if len(snap_IoUs) > 0:
-            s = '{:^6.1f}|'.format(100*np.mean(snap_IoUs[-1]))
+            s = "{:^6.1f}|".format(100 * np.mean(snap_IoUs[-1]))
             for IoU in snap_IoUs[-1]:
-                s += '{:^6.1f}'.format(100*IoU)
+                s += "{:^6.1f}".format(100 * IoU)
         else:
-            s = '{:^6s}'.format('-')
+            s = "{:^6s}".format("-")
             for _ in range(config.num_classes):
-                s += '{:^6s}'.format('-')
+                s += "{:^6s}".format("-")
         print(s)
 
     # Plots
     # *****
 
     # Figure
-    fig = plt.figure('mIoUs')
+    fig = plt.figure("mIoUs")
     for i, name in enumerate(list_of_names):
-        p = plt.plot(all_pred_epochs[i], all_subpart_mIoUs[i], '--', linewidth=1, label=name)
-        plt.plot(all_pred_epochs[i], all_val_mIoUs[i], linewidth=1, color=p[-1].get_color())
-    plt.xlabel('epochs')
-    plt.ylabel('IoU')
+        p = plt.plot(
+            all_pred_epochs[i], all_subpart_mIoUs[i], "--", linewidth=1, label=name
+        )
+        plt.plot(
+            all_pred_epochs[i], all_val_mIoUs[i], linewidth=1, color=p[-1].get_color()
+        )
+    plt.xlabel("epochs")
+    plt.ylabel("IoU")
 
     # Set limits for y axis
-    #plt.ylim(0.55, 0.95)
+    # plt.ylim(0.55, 0.95)
 
     # Display legends and title
     plt.legend(loc=4)
 
     # Customize the graph
     ax = fig.gca()
-    ax.grid(linestyle='-.', which='both')
-    #ax.set_yticks(np.arange(0.8, 1.02, 0.02))
+    ax.grid(linestyle="-.", which="both")
+    # ax.set_yticks(np.arange(0.8, 1.02, 0.02))
 
     displayed_classes = [0, 1, 2, 3, 4, 5, 6, 7]
-    #displayed_classes = []
+    # displayed_classes = []
     for c_i, c_name in enumerate(class_list):
         if c_i in displayed_classes:
 
             # Figure
-            fig = plt.figure(c_name + ' IoU')
+            fig = plt.figure(c_name + " IoU")
             for i, name in enumerate(list_of_names):
-                plt.plot(all_pred_epochs[i], all_val_class_IoUs[i][:, c_i], linewidth=1, label=name)
-            plt.xlabel('epochs')
-            plt.ylabel('IoU')
+                plt.plot(
+                    all_pred_epochs[i],
+                    all_val_class_IoUs[i][:, c_i],
+                    linewidth=1,
+                    label=name,
+                )
+            plt.xlabel("epochs")
+            plt.ylabel("IoU")
 
             # Set limits for y axis
-            #plt.ylim(0.8, 1)
+            # plt.ylim(0.8, 1)
 
             # Display legends and title
             plt.legend(loc=4)
 
             # Customize the graph
             ax = fig.gca()
-            ax.grid(linestyle='-.', which='both')
-            #ax.set_yticks(np.arange(0.8, 1.02, 0.02))
-
-
+            ax.grid(linestyle="-.", which="both")
+            # ax.set_yticks(np.arange(0.8, 1.02, 0.02))
 
     # Show all
     plt.show()
 
 
@@ -711,27 +754,26 @@
     of these logs.
     Below an example of how to automatically gather all logs between two dates, and name them.
     """
 
     # Using the dates of the logs, you can easily gather consecutive ones. All logs should be of the same dataset.
-    start = 'Log_2020-04-22_11-52-58'
-    end = 'Log_2023-07-29_12-40-27'
+    start = "Log_2020-04-22_11-52-58"
+    end = "Log_2023-07-29_12-40-27"
 
     # Name of the result path
-    res_path = 'results'
+    res_path = "results"
 
     # Gather logs and sort by date
-    logs = np.sort([join(res_path, l) for l in listdir_str(res_path) if start <= l <= end])
+    logs = np.sort(
+        [join(res_path, l) for l in listdir_str(res_path) if start <= l <= end]
+    )
 
     # Give names to the logs (for plot legends)
-    logs_names = ['name_log_1',
-                  'name_log_2',
-                  'name_log_3',
-                  'name_log_4']
+    logs_names = ["name_log_1", "name_log_2", "name_log_3", "name_log_4"]
 
     # safe check log names
-    logs_names = np.array(logs_names[:len(logs)])
+    logs_names = np.array(logs_names[: len(logs)])
 
     return logs, logs_names
 
 
 def experiment_name_2():
@@ -741,42 +783,41 @@
     of these logs.
     Below an example of how to automatically gather all logs between two dates, and name them.
     """
 
     # Using the dates of the logs, you can easily gather consecutive ones. All logs should be of the same dataset.
-    start = 'Log_2020-04-22_11-52-58'
-    end = 'Log_2020-05-22_11-52-58'
+    start = "Log_2020-04-22_11-52-58"
+    end = "Log_2020-05-22_11-52-58"
 
     # Name of the result path
-    res_path = 'results'
+    res_path = "results"
 
     # Gather logs and sort by date
-    logs = np.sort([join(res_path, l) for l in listdir_str(res_path) if start <= l <= end])
+    logs = np.sort(
+        [join(res_path, l) for l in listdir_str(res_path) if start <= l <= end]
+    )
 
     # Optionally add a specific log at a specific place in the log list
-    logs = logs.astype('<U50')
-    logs = np.insert(logs, 0, 'results/Log_2020-04-04_10-04-42')
+    logs = logs.astype("<U50")
+    logs = np.insert(logs, 0, "results/Log_2020-04-04_10-04-42")
 
     # Give names to the logs (for plot legends)
-    logs_names = ['name_log_inserted',
-                  'name_log_1',
-                  'name_log_2',
-                  'name_log_3']
+    logs_names = ["name_log_inserted", "name_log_1", "name_log_2", "name_log_3"]
 
     # safe check log names
-    logs_names = np.array(logs_names[:len(logs)])
+    logs_names = np.array(logs_names[: len(logs)])
 
     return logs, logs_names
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Main Call
 #       \***************/
 #
 
-if __name__ == '__main__':
+if __name__ == "__main__":
 
     ######################################################
     # Choose a list of log to plot together for comparison
     ######################################################
 
@@ -791,37 +832,33 @@
     plot_dataset = None
     config = None
     for log in logs:
         config = Config()
         config.load(log)
-        if 'ShapeNetPart' in config.dataset:
-            this_dataset = 'ShapeNetPart'
+        if "ShapeNetPart" in config.dataset:
+            this_dataset = "ShapeNetPart"
         else:
             this_dataset = config.dataset
         if plot_dataset:
             if plot_dataset == this_dataset:
                 continue
             else:
-                raise ValueError('All logs must share the same dataset to be compared')
+                raise ValueError("All logs must share the same dataset to be compared")
         else:
             plot_dataset = this_dataset
 
     # Plot the training loss and accuracy
     compare_trainings(logs, logs_names)
 
     # Plot the validation
-    if config.dataset_task == 'classification':
+    if config.dataset_task == "classification":
         compare_convergences_classif(logs, logs_names)
-    elif config.dataset_task == 'cloud_segmentation':
-        if config.dataset.startswith('S3DIS'):
+    elif config.dataset_task == "cloud_segmentation":
+        if config.dataset.startswith("S3DIS"):
             dataset = S3DISDataset(config, load_data=False)
             compare_convergences_segment(dataset, logs, logs_names)
-    elif config.dataset_task == 'slam_segmentation':
-        if config.dataset.startswith('SemanticKitti'):
+    elif config.dataset_task == "slam_segmentation":
+        if config.dataset.startswith("SemanticKitti"):
             dataset = SemanticKittiDataset(config)
             compare_convergences_SLAM(dataset, logs, logs_names)
     else:
-        raise ValueError('Unsupported dataset : ' + plot_dataset)
-
-
-
-
+        raise ValueError("Unsupported dataset : " + plot_dataset)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/evaluate_extended_DALES.py	2024-06-30 22:34:18.722734+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/evaluate_extended_DALES.py	2024-07-08 11:53:46.475721+00:00
@@ -24,18 +24,18 @@
             self.device = torch.device("cpu")
         net.to(self.device)
 
         # Load checkpoint
         checkpoint = torch.load(chkp_path)
-        net.load_state_dict(checkpoint['model_state_dict'])
-        self.epoch = checkpoint['epoch']
+        net.load_state_dict(checkpoint["model_state_dict"])
+        self.epoch = checkpoint["epoch"]
         net.eval()
         print("Model and training state restored.")
 
-
-
-    def cloud_segmentation_test(self, net, test_loader, config, num_votes=100, debug=False):
+    def cloud_segmentation_test(
+        self, net, test_loader, config, num_votes=100, debug=False
+    ):
         test_smooth = 0.95
         test_radius_ratio = 0.7
         softmax = torch.nn.Softmax(1)
         self.cls = 7
         self.act_list = np.arange(0, 22)
@@ -45,23 +45,37 @@
 
         # Number of classes predicted by the model
         nc_model = config.num_classes
 
         # Initiate global prediction on test/validation cloud. Dim: (M, 3) (Remember this is subsampled one so not original cloud)
-        self.test_probs = [np.zeros((l.shape[0], nc_model)) for l in test_loader.dataset.input_labels]
-        self.test_heatmap = [np.zeros((self.act_list.shape[0], l.shape[0],)) for l in test_loader.dataset.input_labels]
+        self.test_probs = [
+            np.zeros((l.shape[0], nc_model)) for l in test_loader.dataset.input_labels
+        ]
+        self.test_heatmap = [
+            np.zeros(
+                (
+                    self.act_list.shape[0],
+                    l.shape[0],
+                )
+            )
+            for l in test_loader.dataset.input_labels
+        ]
 
         self.test_loader = test_loader
 
         # For validation, label proportions. (used as weights in criterion)
-        if test_loader.dataset.set == 'validation':
+        if test_loader.dataset.set == "validation":
             val_proportions = np.zeros(nc_model, dtype=np.float32)
             i = 0
             for label_value in test_loader.dataset.label_values:
                 if label_value not in test_loader.dataset.ignored_labels:
-                    val_proportions[i] = np.sum([np.sum(labels == label_value)
-                                                 for labels in test_loader.dataset.validation_labels])
+                    val_proportions[i] = np.sum(
+                        [
+                            np.sum(labels == label_value)
+                            for labels in test_loader.dataset.validation_labels
+                        ]
+                    )
                     i += 1
         else:
             val_proportions = None
 
         self.val_proportions = val_proportions
@@ -72,11 +86,11 @@
 
         while True:
             print("Initialize workers.")
             for i, batch in enumerate(test_loader):
                 ti = time.time()
-                if 'cuda' in self.device.type:
+                if "cuda" in self.device.type:
                     batch.to(self.device)
 
                 # Forward pass
                 outputs = net(batch, config)
 
@@ -110,23 +124,28 @@
                 # Also update test_probs for each instance.
                 t0 = time.time()
                 i0 = 0
                 for b_i, length in enumerate(lengths):
                     # Get prediction
-                    points = s_points[i0:i0 + length]
-                    probs = stacked_probs[i0:i0 + length]
-                    inds = in_inds[i0:i0 + length]
+                    points = s_points[i0 : i0 + length]
+                    probs = stacked_probs[i0 : i0 + length]
+                    inds = in_inds[i0 : i0 + length]
                     c_i = cloud_inds[b_i]
 
                     if 0 < test_radius_ratio < 1:
-                        mask = np.sum(points ** 2, axis=1) < (test_radius_ratio * config.in_radius) ** 2
+                        mask = (
+                            np.sum(points**2, axis=1)
+                            < (test_radius_ratio * config.in_radius) ** 2
+                        )
                         inds = inds[mask]
                         probs = probs[mask]
 
                     # Update current probs in subsampled cloud
-                    self.test_probs[c_i][inds] = test_smooth * self.test_probs[c_i][inds] + (
-                            1 - test_smooth) * probs
+                    self.test_probs[c_i][inds] = (
+                        test_smooth * self.test_probs[c_i][inds]
+                        + (1 - test_smooth) * probs
+                    )
                     i0 += length
 
                 t1 = time.time()
 
                 for act in self.act_list:
@@ -141,11 +160,13 @@
                     alpha = torch.sum(grads, axis=0, keepdim=True)
 
                     stacked_heatmap = torch.matmul(cur_act, alpha.T).squeeze()
 
                     # Apply ReLU
-                    stacked_heatmap = torch.maximum(stacked_heatmap, torch.zeros_like(stacked_heatmap))
+                    stacked_heatmap = torch.maximum(
+                        stacked_heatmap, torch.zeros_like(stacked_heatmap)
+                    )
 
                     # Normalize
                     max_val = torch.max(stacked_heatmap, dim=-1, keepdim=True)[0]
                     min_val = torch.min(stacked_heatmap, dim=-1, keepdim=True)[0]
                     stacked_heatmap = (stacked_heatmap - min_val) / (max_val - min_val)
@@ -160,37 +181,46 @@
 
                     t7 = time.time()
 
                     i0 = 0
                     for b_i, length in enumerate(lengths):
-                        points = s_points[i0:i0 + length]
-                        heatmap = stacked_heatmap[i0:i0 + length]
+                        points = s_points[i0 : i0 + length]
+                        heatmap = stacked_heatmap[i0 : i0 + length]
                         c_i = cloud_inds[b_i]
-                        inds = in_inds[i0:i0 + length]
+                        inds = in_inds[i0 : i0 + length]
 
                         if 0 < test_radius_ratio < 1:
-                            mask = np.sum(points ** 2, axis=1) < (test_radius_ratio * config.in_radius) ** 2
+                            mask = (
+                                np.sum(points**2, axis=1)
+                                < (test_radius_ratio * config.in_radius) ** 2
+                            )
                             inds = inds[mask]
                             heatmap = heatmap[mask]
 
                         # Update current heatmap in subsampled cloud
-                        self.test_heatmap[c_i][act][inds] = test_smooth * self.test_heatmap[c_i][act][inds] + (
-                                    1 - test_smooth) * heatmap
+                        self.test_heatmap[c_i][act][inds] = (
+                            test_smooth * self.test_heatmap[c_i][act][inds]
+                            + (1 - test_smooth) * heatmap
+                        )
                         i0 += length
 
                     t8 = time.time()
 
                 t9 = time.time()
 
                 if i % 20 == 0:
-                    message = 'e{:03d}-i{:04d}'
+                    message = "e{:03d}-i{:04d}"
                     print(message.format(test_epoch, i))
 
             # Update min potentials
 
             new_min = torch.min(test_loader.dataset.min_potentials)
-            print('Test epoch {:d}, end. Min potential = {:.1f}'.format(test_epoch, new_min))
+            print(
+                "Test epoch {:d}, end. Min potential = {:.1f}".format(
+                    test_epoch, new_min
+                )
+            )
 
             # Compute confusion for subsampled clouds
             if last_min + 1 < new_min:
                 # Update last min
                 last_min += 1
@@ -199,11 +229,10 @@
                 break
 
         # Voting results on subsampled clouds (NOT ORIGINAL CLOUD)
         self.compute_on_sub_cloud(save=True)
         self.compute_on_full_cloud()
-
 
     def compute_on_sub_cloud(self, save=False):
         print("\nConfusion on subsampled clouds...")
         Confs = []
         for i, file_path in enumerate(self.test_loader.dataset.files):
@@ -212,11 +241,13 @@
             for l_ind, label_value in enumerate(self.test_loader.dataset.label_values):
                 if label_value in self.test_loader.dataset.ignored_labels:
                     probs = np.insert(probs, l_ind, 0, axis=1)
 
             # Predicted labels
-            preds = self.test_loader.dataset.label_values[np.argmax(probs, axis=1)].astype(np.int32)
+            preds = self.test_loader.dataset.label_values[
+                np.argmax(probs, axis=1)
+            ].astype(np.int32)
 
             # Targets
             targets = self.test_loader.dataset.input_labels[i]
 
             # Subsampled points
@@ -227,35 +258,42 @@
                 pgscam = self.test_heatmap[i][act, :]
 
                 pgscam = np.nan_to_num(pgscam, nan=0.0)
 
                 if save:
-                    write_ply(f'./pgscam_results/KPConv_DALES_cls_{self.cls}_act_{act+1}.ply',
-                              [sub_points, preds, targets, pgscam], ['x', 'y', 'z', 'preds', 'class', 'pgscam'])
+                    write_ply(
+                        f"./pgscam_results/KPConv_DALES_cls_{self.cls}_act_{act+1}.ply",
+                        [sub_points, preds, targets, pgscam],
+                        ["x", "y", "z", "preds", "class", "pgscam"],
+                    )
 
             # Confs
-            Confs += [fast_confusion(targets, preds, self.test_loader.dataset.label_values)]
+            Confs += [
+                fast_confusion(targets, preds, self.test_loader.dataset.label_values)
+            ]
 
         # Regroup confusions
         C = np.sum(np.stack(Confs), axis=0).astype(np.float32)
 
         # Remove ignored labels from confusions
-        for l_ind, label_value in reversed(list(enumerate(self.test_loader.dataset.label_values))):
+        for l_ind, label_value in reversed(
+            list(enumerate(self.test_loader.dataset.label_values))
+        ):
             if label_value in self.test_loader.dataset.ignored_labels:
                 C = np.delete(C, l_ind, axis=0)
                 C = np.delete(C, l_ind, axis=1)
 
         # Rescale with the right number of point per class
         C *= np.expand_dims(self.val_proportions / (np.sum(C, axis=1) + 1e-6), 1)
 
         # Compute IoUs
         IoUs = IoU_from_confusions(C)
         mIoU = np.mean(IoUs)
-        s = '{:5.2f} | '.format(100 * mIoU)
+        s = "{:5.2f} | ".format(100 * mIoU)
         for IoU in IoUs:
-            s += '{:5.2f} '.format(100 * IoU)
-        print(s + '\n')
+            s += "{:5.2f} ".format(100 * IoU)
+        print(s + "\n")
 
     def compute_on_full_cloud(self):
         print("Reprojection for full cloud (KNN with 1 neighbor)")
         # REPROJECTION to compute for full cloud (Uses KNN with 1 neighbor for compute for entire cloud from subsampled cloud)
         proj_probs = []
@@ -271,35 +309,39 @@
         # PROJECTION ON FULL CLOUDS
         print("Confusion on full clouds...")
         Confs = []
         for i, file_path in enumerate(self.test_loader.dataset.files):
             # Get the predicted labels
-            preds = self.test_loader.dataset.label_values[np.argmax(proj_probs[i], axis=1)].astype(np.int32)
+            preds = self.test_loader.dataset.label_values[
+                np.argmax(proj_probs[i], axis=1)
+            ].astype(np.int32)
 
             if self.save_labels:
-                print("You have the preds for full cloud. Save label anywhere you want...")
+                print(
+                    "You have the preds for full cloud. Save label anywhere you want..."
+                )
 
             # Confusion
             targets = self.test_loader.dataset.validation_labels[i]
-            Confs += [fast_confusion(targets, preds, self.test_loader.dataset.label_values)]
+            Confs += [
+                fast_confusion(targets, preds, self.test_loader.dataset.label_values)
+            ]
 
         # Regroup confusions
         C = np.sum(np.stack(Confs), axis=0)
 
         # Remove ignored labels from confusions
-        for l_ind, label_value in reversed(list(enumerate(self.test_loader.dataset.label_values))):
+        for l_ind, label_value in reversed(
+            list(enumerate(self.test_loader.dataset.label_values))
+        ):
             if label_value in self.test_loader.dataset.ignored_labels:
                 C = np.delete(C, l_ind, axis=0)
                 C = np.delete(C, l_ind, axis=1)
 
         IoUs = IoU_from_confusions(C)
         mIoU = np.mean(IoUs)
-        s = '{:5.2f} | '.format(100 * mIoU)
+        s = "{:5.2f} | ".format(100 * mIoU)
         for IoU in IoUs:
-            s += '{:5.2f} '.format(100 * IoU)
-        print('-' * len(s))
+            s += "{:5.2f} ".format(100 * IoU)
+        print("-" * len(s))
         print(s)
-        print('-' * len(s) + '\n')
-
-
-
-
+        print("-" * len(s) + "\n")
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/DALES.py	2024-06-30 22:34:18.050725+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/DALES.py	2024-07-08 11:53:46.448023+00:00
@@ -51,42 +51,44 @@
 
 
 class NPM3DDataset(PointCloudDataset):
     """Class to handle NPM3D dataset."""
 
-    def __init__(self, config, set='training', use_potentials=True, load_data=True):
+    def __init__(self, config, set="training", use_potentials=True, load_data=True):
         """
         This dataset is small enough to be stored in-memory, so load all point clouds here
         """
-        PointCloudDataset.__init__(self, 'NPM3D')
+        PointCloudDataset.__init__(self, "NPM3D")
 
         ############
         # Parameters
         ############
 
         # Dict from labels to names
-        self.label_to_names = {0: 'unknown',
-                               1: 'Ground',
-                               2: 'Vegetation',
-                               3: 'Cars',
-                               4: 'Trucks',
-                               5: 'Power lines',
-                               6: 'Fences',
-                               7: 'Poles',
-                               8: 'Buildings'}
+        self.label_to_names = {
+            0: "unknown",
+            1: "Ground",
+            2: "Vegetation",
+            3: "Cars",
+            4: "Trucks",
+            5: "Power lines",
+            6: "Fences",
+            7: "Poles",
+            8: "Buildings",
+        }
 
         # Initialize a bunch of variables concerning class labels
         self.init_labels()
 
         # List of classes ignored during training (can be empty)
         self.ignored_labels = np.array([0])
 
         # Dataset folder
-        self.path = '../../dales_ply_bin'
+        self.path = "../../dales_ply_bin"
 
         # Type of task conducted on this dataset
-        self.dataset_task = 'cloud_segmentation'
+        self.dataset_task = "cloud_segmentation"
 
         # Update number of class and data task in configuration
         config.num_classes = self.num_classes - len(self.ignored_labels)
         config.dataset_task = self.dataset_task
 
@@ -99,32 +101,47 @@
         # Using potential or random epoch generation
         self.use_potentials = use_potentials
 
         # Path of the training files
         # self.train_path = 'original_ply'
-        self.train_path = 'train'
-        self.original_ply_path = 'original_ply'
+        self.train_path = "train"
+        self.original_ply_path = "original_ply"
 
         # List of files to process
         ply_path = join(self.path, self.train_path)
 
         # Proportion of validation scenes
-#         self.cloud_names = ['Lille1_1', 'Lille1_2', 'Lille2', 'Paris', 'ajaccio_2', 'ajaccio_57', 'dijon_9']
-        self.cloud_names = ['5080_54435', '5085_54320', '5095_54440', '5095_54455' , '5100_54495', '5105_54405', '5105_54460', '5110_54320', '5110_54475', '5110_54495', '5115_54480', '5130_54355', '5135_54495', '5140_54445']
+        #         self.cloud_names = ['Lille1_1', 'Lille1_2', 'Lille2', 'Paris', 'ajaccio_2', 'ajaccio_57', 'dijon_9']
+        self.cloud_names = [
+            "5080_54435",
+            "5085_54320",
+            "5095_54440",
+            "5095_54455",
+            "5100_54495",
+            "5105_54405",
+            "5105_54460",
+            "5110_54320",
+            "5110_54475",
+            "5110_54495",
+            "5115_54480",
+            "5130_54355",
+            "5135_54495",
+            "5140_54445",
+        ]
         self.all_splits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
         self.validation_split = 1
         # self.test_cloud_names = ['ajaccio_2', 'ajaccio_57', 'dijon_9']
         self.test_splits = [5]
         self.train_splits = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
 
         # Number of models used per epoch
-        if self.set == 'training':
+        if self.set == "training":
             self.epoch_n = config.epoch_steps * config.batch_num
-        elif self.set in ['validation', 'test', 'ERF']:
+        elif self.set in ["validation", "test", "ERF"]:
             self.epoch_n = config.validation_size * config.batch_num
         else:
-            raise ValueError('Unknown set for NPM3D data: ', self.set)
+            raise ValueError("Unknown set for NPM3D data: ", self.set)
 
         # Stop data is not needed
         if not load_data:
             return
 
@@ -139,36 +156,45 @@
         ################
 
         # List of training files
         self.files = []
         for i, f in enumerate(self.cloud_names):
-            if self.set == 'training':
+            if self.set == "training":
                 if self.all_splits[i] in self.train_splits:
-                    self.files += [join(ply_path, f + '.ply')]
-            elif self.set in ['validation', 'ERF']:
+                    self.files += [join(ply_path, f + ".ply")]
+            elif self.set in ["validation", "ERF"]:
                 if self.all_splits[i] == self.validation_split:
-                    self.files += [join(ply_path, f + '.ply')]
-            elif self.set == 'test':
+                    self.files += [join(ply_path, f + ".ply")]
+            elif self.set == "test":
                 if self.all_splits[i] in self.test_splits:
-                    self.files += [join(ply_path, f + '.ply')]
+                    self.files += [join(ply_path, f + ".ply")]
             else:
-                raise ValueError('Unknown set for NPM3D data: ', self.set)
-        print('The set is ' + str(self.set))
-
-        if self.set == 'training':
-            self.cloud_names = [f for i, f in enumerate(self.cloud_names)
-                                if self.all_splits[i] in self.train_splits]
-        elif self.set in ['validation', 'ERF']:
-            self.cloud_names = [f for i, f in enumerate(self.cloud_names)
-                                if self.all_splits[i] == self.validation_split]
-        elif self.set == 'test':
-            self.cloud_names = [f for i, f in enumerate(self.cloud_names)
-                                if self.all_splits[i] in self.test_splits]
-        print('The files are ' + str(self.cloud_names))
+                raise ValueError("Unknown set for NPM3D data: ", self.set)
+        print("The set is " + str(self.set))
+
+        if self.set == "training":
+            self.cloud_names = [
+                f
+                for i, f in enumerate(self.cloud_names)
+                if self.all_splits[i] in self.train_splits
+            ]
+        elif self.set in ["validation", "ERF"]:
+            self.cloud_names = [
+                f
+                for i, f in enumerate(self.cloud_names)
+                if self.all_splits[i] == self.validation_split
+            ]
+        elif self.set == "test":
+            self.cloud_names = [
+                f
+                for i, f in enumerate(self.cloud_names)
+                if self.all_splits[i] in self.test_splits
+            ]
+        print("The files are " + str(self.cloud_names))
 
         if 0 < self.config.first_subsampling_dl <= 0.01:
-            raise ValueError('subsampling_parameter too low (should be over 1 cm')
+            raise ValueError("subsampling_parameter too low (should be over 1 cm")
 
         # Initiate containers
         self.input_trees = []
         self.input_colors = []
         self.input_labels = []
@@ -192,41 +218,51 @@
         if use_potentials:
             self.potentials = []
             self.min_potentials = []
             self.argmin_potentials = []
             for i, tree in enumerate(self.pot_trees):
-                self.potentials += [torch.from_numpy(np.random.rand(tree.data.shape[0]) * 1e-3)]
+                self.potentials += [
+                    torch.from_numpy(np.random.rand(tree.data.shape[0]) * 1e-3)
+                ]
                 min_ind = int(torch.argmin(self.potentials[-1]))
                 self.argmin_potentials += [min_ind]
                 self.min_potentials += [float(self.potentials[-1][min_ind])]
 
             # Share potential memory
-            self.argmin_potentials = torch.from_numpy(np.array(self.argmin_potentials, dtype=np.int64))
-            self.min_potentials = torch.from_numpy(np.array(self.min_potentials, dtype=np.float64))
+            self.argmin_potentials = torch.from_numpy(
+                np.array(self.argmin_potentials, dtype=np.int64)
+            )
+            self.min_potentials = torch.from_numpy(
+                np.array(self.min_potentials, dtype=np.float64)
+            )
             self.argmin_potentials.share_memory_()
             self.min_potentials.share_memory_()
             for i, _ in enumerate(self.pot_trees):
                 self.potentials[i].share_memory_()
 
-            self.worker_waiting = torch.tensor([0 for _ in range(config.input_threads)], dtype=torch.int32)
+            self.worker_waiting = torch.tensor(
+                [0 for _ in range(config.input_threads)], dtype=torch.int32
+            )
             self.worker_waiting.share_memory_()
             self.epoch_inds = None
             self.epoch_i = 0
 
         else:
             self.potentials = None
             self.min_potentials = None
             self.argmin_potentials = None
-            self.epoch_inds = torch.from_numpy(np.zeros((2, self.epoch_n), dtype=np.int64))
+            self.epoch_inds = torch.from_numpy(
+                np.zeros((2, self.epoch_n), dtype=np.int64)
+            )
             self.epoch_i = torch.from_numpy(np.zeros((1,), dtype=np.int64))
             self.epoch_i.share_memory_()
             self.epoch_inds.share_memory_()
 
         self.worker_lock = Lock()
 
         # For ERF visualization, we want only one cloud per batch and no randomness
-        if self.set == 'ERF':
+        if self.set == "ERF":
             self.batch_limit = torch.tensor([1], dtype=torch.float32)
             self.batch_limit.share_memory_()
             np.random.seed(42)
 
         return
@@ -273,36 +309,36 @@
         while True:
 
             t += [time.time()]
 
             if debug_workers:
-                message = ''
+                message = ""
                 for wi in range(info.num_workers):
                     if wi == wid:
-                        message += ' {:}X{:} '.format(bcolors.FAIL, bcolors.ENDC)
+                        message += " {:}X{:} ".format(bcolors.FAIL, bcolors.ENDC)
                     elif self.worker_waiting[wi] == 0:
-                        message += '   '
+                        message += "   "
                     elif self.worker_waiting[wi] == 1:
-                        message += ' | '
+                        message += " | "
                     elif self.worker_waiting[wi] == 2:
-                        message += ' o '
+                        message += " o "
                 print(message)
                 self.worker_waiting[wid] = 0
 
             with self.worker_lock:
 
                 if debug_workers:
-                    message = ''
+                    message = ""
                     for wi in range(info.num_workers):
                         if wi == wid:
-                            message += ' {:}v{:} '.format(bcolors.OKGREEN, bcolors.ENDC)
+                            message += " {:}v{:} ".format(bcolors.OKGREEN, bcolors.ENDC)
                         elif self.worker_waiting[wi] == 0:
-                            message += '   '
+                            message += "   "
                         elif self.worker_waiting[wi] == 1:
-                            message += ' | '
+                            message += " | "
                         elif self.worker_waiting[wi] == 2:
-                            message += ' o '
+                            message += " o "
                     print(message)
                     self.worker_waiting[wid] = 1
 
                 # Get potential minimum
                 cloud_ind = int(torch.argmin(self.min_potentials))
@@ -313,57 +349,64 @@
 
                 # Center point of input region
                 center_point = pot_points[point_ind, :].reshape(1, -1)
 
                 # Add a small noise to center point
-                if self.set != 'ERF':
-                    center_point += np.random.normal(scale=self.config.in_radius / 10, size=center_point.shape)
+                if self.set != "ERF":
+                    center_point += np.random.normal(
+                        scale=self.config.in_radius / 10, size=center_point.shape
+                    )
 
                 # Indices of points in input region
-                pot_inds, dists = self.pot_trees[cloud_ind].query_radius(center_point,
-                                                                         r=self.config.in_radius,
-                                                                         return_distance=True)
+                pot_inds, dists = self.pot_trees[cloud_ind].query_radius(
+                    center_point, r=self.config.in_radius, return_distance=True
+                )
 
                 d2s = np.square(dists[0])
                 pot_inds = pot_inds[0]
 
                 # Update potentials (Tukey weights)
-                if self.set != 'ERF':
+                if self.set != "ERF":
                     tukeys = np.square(1 - d2s / np.square(self.config.in_radius))
                     tukeys[d2s > np.square(self.config.in_radius)] = 0
                     self.potentials[cloud_ind][pot_inds] += tukeys
                     min_ind = torch.argmin(self.potentials[cloud_ind])
-                    self.min_potentials[[cloud_ind]] = self.potentials[cloud_ind][min_ind]
+                    self.min_potentials[[cloud_ind]] = self.potentials[cloud_ind][
+                        min_ind
+                    ]
                     self.argmin_potentials[[cloud_ind]] = min_ind
 
             t += [time.time()]
 
             # Get points from tree structure
             points = np.array(self.input_trees[cloud_ind].data, copy=False)
 
             # Indices of points in input region
-            input_inds = self.input_trees[cloud_ind].query_radius(center_point,
-                                                                  r=self.config.in_radius)[0]
+            input_inds = self.input_trees[cloud_ind].query_radius(
+                center_point, r=self.config.in_radius
+            )[0]
 
             t += [time.time()]
 
             # Number collected
             n = input_inds.shape[0]
 
             # Safe check for empty spheres
             if n < 2:
                 failed_attempts += 1
                 if failed_attempts > 100 * self.config.batch_num:
-                    raise ValueError('It seems this dataset only containes empty input spheres')
+                    raise ValueError(
+                        "It seems this dataset only containes empty input spheres"
+                    )
                 t += [time.time()]
                 t += [time.time()]
                 continue
 
             # Collect labels and colors
             input_points = (points[input_inds] - center_point).astype(np.float32)
             # input_colors = self.input_colors[cloud_ind][input_inds]
-            if self.set in ['test', 'ERF']:
+            if self.set in ["test", "ERF"]:
                 input_labels = np.zeros(input_points.shape[0])
             else:
                 input_labels = self.input_labels[cloud_ind][input_inds]
                 input_labels = np.array([self.label_to_idx[l] for l in input_labels])
 
@@ -376,11 +419,13 @@
             # if np.random.rand() > self.config.augment_color:
             #    input_colors *= 0
 
             # Get original height as additional feature
             # input_features = np.hstack((input_colors, input_points[:, 2:] + center_point[:, 2:])).astype(np.float32)
-            input_features = np.hstack((input_points[:, 2:] + center_point[:, 2:])).astype(np.float32)
+            input_features = np.hstack(
+                (input_points[:, 2:] + center_point[:, 2:])
+            ).astype(np.float32)
 
             t += [time.time()]
 
             # Stack batch
             p_list += [input_points]
@@ -425,11 +470,13 @@
         elif self.config.in_features_dim == 4:
             stacked_features = np.hstack((stacked_features, features[:, :3]))
         elif self.config.in_features_dim == 5:
             stacked_features = np.hstack((stacked_features, features))
         else:
-            raise ValueError('Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)')
+            raise ValueError(
+                "Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)"
+            )
 
         #######################
         # Create network inputs
         #######################
         #
@@ -437,80 +484,94 @@
         #
 
         t += [time.time()]
 
         # Get the whole input list
-        input_list = self.segmentation_inputs(stacked_points,
-                                              stacked_features,
-                                              labels,
-                                              stack_lengths)
+        input_list = self.segmentation_inputs(
+            stacked_points, stacked_features, labels, stack_lengths
+        )
 
         t += [time.time()]
 
         # Add scale and rotation for testing
         input_list += [scales, rots, cloud_inds, point_inds, input_inds]
 
         if debug_workers:
-            message = ''
+            message = ""
             for wi in range(info.num_workers):
                 if wi == wid:
-                    message += ' {:}0{:} '.format(bcolors.OKBLUE, bcolors.ENDC)
+                    message += " {:}0{:} ".format(bcolors.OKBLUE, bcolors.ENDC)
                 elif self.worker_waiting[wi] == 0:
-                    message += '   '
+                    message += "   "
                 elif self.worker_waiting[wi] == 1:
-                    message += ' | '
+                    message += " | "
                 elif self.worker_waiting[wi] == 2:
-                    message += ' o '
+                    message += " o "
             print(message)
             self.worker_waiting[wid] = 2
 
         t += [time.time()]
 
         # Display timings
         debugT = False
         if debugT:
-            print('\n************************\n')
-            print('Timings:')
+            print("\n************************\n")
+            print("Timings:")
             ti = 0
             N = 5
-            mess = 'Init ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Init ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Pots ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Pots ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Sphere .... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Sphere .... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Collect ... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Collect ... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Augment ... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Augment ... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += N * (len(stack_lengths) - 1) + 1
-            print('concat .... {:5.1f}ms'.format(1000 * (t[ti + 1] - t[ti])))
+            print("concat .... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('input ..... {:5.1f}ms'.format(1000 * (t[ti + 1] - t[ti])))
+            print("input ..... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('stack ..... {:5.1f}ms'.format(1000 * (t[ti + 1] - t[ti])))
+            print("stack ..... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('\n************************\n')
+            print("\n************************\n")
         return input_list
 
     def random_item(self, batch_i):
 
         # Initiate concatanation lists
@@ -543,31 +604,36 @@
 
             # Center point of input region
             center_point = points[point_ind, :].reshape(1, -1)
 
             # Add a small noise to center point
-            if self.set != 'ERF':
-                center_point += np.random.normal(scale=self.config.in_radius / 10, size=center_point.shape)
+            if self.set != "ERF":
+                center_point += np.random.normal(
+                    scale=self.config.in_radius / 10, size=center_point.shape
+                )
 
             # Indices of points in input region
-            input_inds = self.input_trees[cloud_ind].query_radius(center_point,
-                                                                  r=self.config.in_radius)[0]
+            input_inds = self.input_trees[cloud_ind].query_radius(
+                center_point, r=self.config.in_radius
+            )[0]
 
             # Number collected
             n = input_inds.shape[0]
 
             # Safe check for empty spheres
             if n < 2:
                 failed_attempts += 1
                 if failed_attempts > 100 * self.config.batch_num:
-                    raise ValueError('It seems this dataset only containes empty input spheres')
+                    raise ValueError(
+                        "It seems this dataset only containes empty input spheres"
+                    )
                 continue
 
             # Collect labels and colors
             input_points = (points[input_inds] - center_point).astype(np.float32)
             # input_colors = self.input_colors[cloud_ind][input_inds]
-            if self.set in ['test', 'ERF']:
+            if self.set in ["test", "ERF"]:
                 input_labels = np.zeros(input_points.shape[0])
             else:
                 input_labels = self.input_labels[cloud_ind][input_inds]
                 input_labels = np.array([self.label_to_idx[l] for l in input_labels])
 
@@ -577,11 +643,13 @@
             # Color augmentation
             # if np.random.rand() > self.config.augment_color:
             #   input_colors *= 0
 
             # Get original height as additional feature
-            input_features = np.hstack((input_colors, input_points[:, 2:] + center_point[:, 2:])).astype(np.float32)
+            input_features = np.hstack(
+                (input_colors, input_points[:, 2:] + center_point[:, 2:])
+            ).astype(np.float32)
 
             # Stack batch
             p_list += [input_points]
             f_list += [input_features]
             l_list += [input_labels]
@@ -624,53 +692,56 @@
         elif self.config.in_features_dim == 4:
             stacked_features = np.hstack((stacked_features, features[:, :3]))
         elif self.config.in_features_dim == 5:
             stacked_features = np.hstack((stacked_features, features))
         else:
-            raise ValueError('Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)')
+            raise ValueError(
+                "Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)"
+            )
 
         #######################
         # Create network inputs
         #######################
         #
         #   Points, neighbors, pooling indices for each layers
         #
 
         # Get the whole input list
-        input_list = self.segmentation_inputs(stacked_points,
-                                              stacked_features,
-                                              labels,
-                                              stack_lengths)
+        input_list = self.segmentation_inputs(
+            stacked_points, stacked_features, labels, stack_lengths
+        )
 
         # Add scale and rotation for testing
         input_list += [scales, rots, cloud_inds, point_inds, input_inds]
 
         return input_list
 
     def prepare_NPM3D_ply(self):
 
-        print('\nPreparing ply files')
+        print("\nPreparing ply files")
         t0 = time.time()
 
         # Folder for the ply files
         ply_path = join(self.path, self.train_path)
         if not exists(ply_path):
             makedirs(ply_path)
 
         for cloud_name in self.cloud_names:
 
             # Pass if the cloud has already been computed
-            cloud_file = join(ply_path, cloud_name + '.ply')
+            cloud_file = join(ply_path, cloud_name + ".ply")
             if exists(cloud_file):
                 continue
 
-            original_ply = read_ply(join(self.path, self.original_ply_path, cloud_name + '.ply'))
+            original_ply = read_ply(
+                join(self.path, self.original_ply_path, cloud_name + ".ply")
+            )
 
             # Initiate containers
-            cloud_x = original_ply['x']
-            cloud_y = original_ply['y']
-            cloud_z = original_ply['z']
+            cloud_x = original_ply["x"]
+            cloud_y = original_ply["y"]
+            cloud_z = original_ply["z"]
             cloud_x = cloud_x - (cloud_x.min())
             cloud_y = cloud_y - (cloud_y.min())
             cloud_z = cloud_z - (cloud_z.min())
 
             # Reshape
@@ -685,34 +756,40 @@
 
             # Stack
             cloud_points = np.hstack((cloud_x, cloud_y, cloud_z))
 
             # Labels
-            if cloud_name in ['ajaccio_2', 'ajaccio_57', 'dijon_9']:
-
-                field_names = ['x', 'y', 'z']
-                write_ply(join(ply_path, cloud_name + '.ply'), cloud_points, field_names)
+            if cloud_name in ["ajaccio_2", "ajaccio_57", "dijon_9"]:
+
+                field_names = ["x", "y", "z"]
+                write_ply(
+                    join(ply_path, cloud_name + ".ply"), cloud_points, field_names
+                )
 
             else:
-                labels = original_ply['class']
+                labels = original_ply["class"]
                 labels = labels.astype(np.int32)
                 labels = labels.reshape(len(labels), 1)
 
                 # Save as ply
-                field_names = ['x', 'y', 'z', 'class']
-                write_ply(join(ply_path, cloud_name + '.ply'), [cloud_points, labels], field_names)
-
-        print('Done in {:.1f}s'.format(time.time() - t0))
+                field_names = ["x", "y", "z", "class"]
+                write_ply(
+                    join(ply_path, cloud_name + ".ply"),
+                    [cloud_points, labels],
+                    field_names,
+                )
+
+        print("Done in {:.1f}s".format(time.time() - t0))
         return
 
     def load_subsampled_clouds(self):
 
         # Parameter
         dl = self.config.first_subsampling_dl
 
         # Create path for files
-        tree_path = join(self.path, 'input_{:.3f}'.format(dl))
+        tree_path = join(self.path, "input_{:.3f}".format(dl))
         if not exists(tree_path):
             makedirs(tree_path)
 
         ##############
         # Load KDTrees
@@ -725,44 +802,52 @@
 
             # Get cloud name
             cloud_name = self.cloud_names[i]
 
             # Name of the input files
-            KDTree_file = join(tree_path, '{:s}_KDTree.pkl'.format(cloud_name))
-            sub_ply_file = join(tree_path, '{:s}.ply'.format(cloud_name))
+            KDTree_file = join(tree_path, "{:s}_KDTree.pkl".format(cloud_name))
+            sub_ply_file = join(tree_path, "{:s}.ply".format(cloud_name))
 
             # Check if inputs have already been computed
             if exists(KDTree_file):
-                print('\nFound KDTree for cloud {:s}, subsampled at {:.3f}'.format(cloud_name, dl))
+                print(
+                    "\nFound KDTree for cloud {:s}, subsampled at {:.3f}".format(
+                        cloud_name, dl
+                    )
+                )
 
                 # read ply with data
                 data = read_ply(sub_ply_file)
                 # sub_colors = np.vstack((data['red'], data['green'], data['blue'])).T
-                sub_labels = data['class']
+                sub_labels = data["class"]
 
                 # Read pkl with search tree
-                with open(KDTree_file, 'rb') as f:
+                with open(KDTree_file, "rb") as f:
                     search_tree = pickle.load(f)
 
             else:
-                print('\nPreparing KDTree for cloud {:s}, subsampled at {:.3f}'.format(cloud_name, dl))
+                print(
+                    "\nPreparing KDTree for cloud {:s}, subsampled at {:.3f}".format(
+                        cloud_name, dl
+                    )
+                )
 
                 # Read ply file
                 data = read_ply(file_path)
-                points = np.vstack((data['x'], data['y'], data['z'])).T
+                points = np.vstack((data["x"], data["y"], data["z"])).T
                 # colors = np.vstack((data['red'], data['green'], data['blue'])).T
 
                 # Fake labels for test data
-                if self.set == 'test':
+                if self.set == "test":
                     labels = np.zeros((data.shape[0],), dtype=np.int32)
                 else:
-                    labels = data['scalar_class'].astype(np.int32)
+                    labels = data["scalar_class"].astype(np.int32)
 
                 # Subsample cloud
-                sub_points, sub_labels = grid_subsampling(points,
-                                                          labels=labels,
-                                                          sampleDl=dl)
+                sub_points, sub_labels = grid_subsampling(
+                    points, labels=labels, sampleDl=dl
+                )
 
                 # Rescale float color and squeeze label
                 # sub_colors = sub_colors / 255
                 sub_labels = np.squeeze(sub_labels)
 
@@ -770,33 +855,33 @@
                 search_tree = KDTree(sub_points, leaf_size=10)
                 # search_tree = nnfln.KDTree(n_neighbors=1, metric='L2', leaf_size=10)
                 # search_tree.fit(sub_points)
 
                 # Save KDTree
-                with open(KDTree_file, 'wb') as f:
+                with open(KDTree_file, "wb") as f:
                     pickle.dump(search_tree, f)
 
                 # Save ply
-                write_ply(sub_ply_file,
-                          [sub_points, sub_labels],
-                          ['x', 'y', 'z', 'class'])
+                write_ply(
+                    sub_ply_file, [sub_points, sub_labels], ["x", "y", "z", "class"]
+                )
 
             # Fill data containers
             self.input_trees += [search_tree]
             # self.input_colors += [sub_colors]
             self.input_labels += [sub_labels]
 
             size = sub_labels.shape[0] * 4 * 7
-            print('{:.1f} MB loaded in {:.1f}s'.format(size * 1e-6, time.time() - t0))
+            print("{:.1f} MB loaded in {:.1f}s".format(size * 1e-6, time.time() - t0))
 
         ############################
         # Coarse potential locations
         ############################
 
         # Only necessary for validation and test sets
         if self.use_potentials:
-            print('\nPreparing potentials')
+            print("\nPreparing potentials")
 
             # Restart timer
             t0 = time.time()
 
             pot_dl = self.config.in_radius / 10
@@ -806,47 +891,51 @@
 
                 # Get cloud name
                 cloud_name = self.cloud_names[i]
 
                 # Name of the input files
-                coarse_KDTree_file = join(tree_path, '{:s}_coarse_KDTree.pkl'.format(cloud_name))
+                coarse_KDTree_file = join(
+                    tree_path, "{:s}_coarse_KDTree.pkl".format(cloud_name)
+                )
 
                 # Check if inputs have already been computed
                 if exists(coarse_KDTree_file):
                     # Read pkl with search tree
-                    with open(coarse_KDTree_file, 'rb') as f:
+                    with open(coarse_KDTree_file, "rb") as f:
                         search_tree = pickle.load(f)
 
                 else:
                     # Subsample cloud
                     sub_points = np.array(self.input_trees[cloud_ind].data, copy=False)
-                    coarse_points = grid_subsampling(sub_points.astype(np.float32), sampleDl=pot_dl)
+                    coarse_points = grid_subsampling(
+                        sub_points.astype(np.float32), sampleDl=pot_dl
+                    )
 
                     # Get chosen neighborhoods
                     search_tree = KDTree(coarse_points, leaf_size=10)
 
                     # Save KDTree
-                    with open(coarse_KDTree_file, 'wb') as f:
+                    with open(coarse_KDTree_file, "wb") as f:
                         pickle.dump(search_tree, f)
 
                 # Fill data containers
                 self.pot_trees += [search_tree]
                 cloud_ind += 1
 
-            print('Done in {:.1f}s'.format(time.time() - t0))
+            print("Done in {:.1f}s".format(time.time() - t0))
 
         ######################
         # Reprojection indices
         ######################
 
         # Get number of clouds
         self.num_clouds = len(self.input_trees)
 
         # Only necessary for validation and test sets
-        if self.set in ['validation', 'test']:
-
-            print('\nPreparing reprojection indices for testing')
+        if self.set in ["validation", "test"]:
+
+            print("\nPreparing reprojection indices for testing")
 
             # Get validation/test reprojection indices
             for i, file_path in enumerate(self.files):
 
                 # Restart timer
@@ -854,38 +943,38 @@
 
                 # Get info on this cloud
                 cloud_name = self.cloud_names[i]
 
                 # File name for saving
-                proj_file = join(tree_path, '{:s}_proj.pkl'.format(cloud_name))
+                proj_file = join(tree_path, "{:s}_proj.pkl".format(cloud_name))
 
                 # Try to load previous indices
                 if exists(proj_file):
-                    with open(proj_file, 'rb') as f:
+                    with open(proj_file, "rb") as f:
                         proj_inds, labels = pickle.load(f)
                 else:
                     data = read_ply(file_path)
-                    points = np.vstack((data['x'], data['y'], data['z'])).T
+                    points = np.vstack((data["x"], data["y"], data["z"])).T
 
                     # Fake labels
-                    if self.set == 'test':
+                    if self.set == "test":
                         labels = np.zeros((data.shape[0],), dtype=np.int32)
                     else:
-                        labels = data['scalar_class']
+                        labels = data["scalar_class"]
 
                     # Compute projection inds
                     idxs = self.input_trees[i].query(points, return_distance=False)
                     # dists, idxs = self.input_trees[i_cloud].kneighbors(points)
                     proj_inds = np.squeeze(idxs).astype(np.int32)
 
                     # Save
-                    with open(proj_file, 'wb') as f:
+                    with open(proj_file, "wb") as f:
                         pickle.dump([proj_inds, labels], f)
 
                 self.test_proj += [proj_inds]
                 self.validation_labels += [labels]
-                print('{:s} done in {:.1f}s'.format(cloud_name, time.time() - t0))
+                print("{:s} done in {:.1f}s".format(cloud_name, time.time() - t0))
 
         print()
         return
 
     def load_evaluation_points(self, file_path):
@@ -893,11 +982,11 @@
         Load points (from test or validation split) on which the metrics should be evaluated
         """
 
         # Get original points
         data = read_ply(file_path)
-        return np.vstack((data['x'], data['y'], data['z'])).T
+        return np.vstack((data["x"], data["y"], data["z"])).T
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Utility classes definition
@@ -912,11 +1001,11 @@
 
         # Dataset used by the sampler (no copy is made in memory)
         self.dataset = dataset
 
         # Number of step per epoch
-        if dataset.set == 'training':
+        if dataset.set == "training":
             self.N = dataset.config.epoch_steps
         else:
             self.N = dataset.config.validation_size
 
         return
@@ -948,39 +1037,62 @@
                     # Gather indices of the points with this label in all the input clouds
                     all_label_indices = []
                     for cloud_ind, cloud_labels in enumerate(self.dataset.input_labels):
                         label_indices = np.where(np.equal(cloud_labels, label))[0]
                         all_label_indices.append(
-                            np.vstack((np.full(label_indices.shape, cloud_ind, dtype=np.int64), label_indices)))
+                            np.vstack(
+                                (
+                                    np.full(
+                                        label_indices.shape, cloud_ind, dtype=np.int64
+                                    ),
+                                    label_indices,
+                                )
+                            )
+                        )
 
                     # Stack them: [2, N1+N2+...]
                     all_label_indices = np.hstack(all_label_indices)
 
                     # Select a a random number amongst them
                     N_inds = all_label_indices.shape[1]
                     if N_inds < random_pick_n:
                         chosen_label_inds = np.zeros((2, 0), dtype=np.int64)
                         while chosen_label_inds.shape[1] < random_pick_n:
                             chosen_label_inds = np.hstack(
-                                (chosen_label_inds, all_label_indices[:, np.random.permutation(N_inds)]))
-                        warnings.warn('When choosing random epoch indices (use_potentials=False), \
+                                (
+                                    chosen_label_inds,
+                                    all_label_indices[:, np.random.permutation(N_inds)],
+                                )
+                            )
+                        warnings.warn(
+                            "When choosing random epoch indices (use_potentials=False), \
                                        class {:d}: {:s} only had {:d} available points, while we \
-                                       needed {:d}. Repeating indices in the same epoch'.format(label,
-                                                                                                self.dataset.label_names[
-                                                                                                    label_ind],
-                                                                                                N_inds,
-                                                                                                random_pick_n))
+                                       needed {:d}. Repeating indices in the same epoch".format(
+                                label,
+                                self.dataset.label_names[label_ind],
+                                N_inds,
+                                random_pick_n,
+                            )
+                        )
 
                     elif N_inds < 50 * random_pick_n:
-                        rand_inds = np.random.choice(N_inds, size=random_pick_n, replace=False)
+                        rand_inds = np.random.choice(
+                            N_inds, size=random_pick_n, replace=False
+                        )
                         chosen_label_inds = all_label_indices[:, rand_inds]
 
                     else:
                         chosen_label_inds = np.zeros((2, 0), dtype=np.int64)
                         while chosen_label_inds.shape[1] < random_pick_n:
-                            rand_inds = np.unique(np.random.choice(N_inds, size=2 * random_pick_n, replace=True))
-                            chosen_label_inds = np.hstack((chosen_label_inds, all_label_indices[:, rand_inds]))
+                            rand_inds = np.unique(
+                                np.random.choice(
+                                    N_inds, size=2 * random_pick_n, replace=True
+                                )
+                            )
+                            chosen_label_inds = np.hstack(
+                                (chosen_label_inds, all_label_indices[:, rand_inds])
+                            )
                         chosen_label_inds = chosen_label_inds[:, :random_pick_n]
 
                     # Stack for each label
                     all_epoch_inds = np.hstack((all_epoch_inds, chosen_label_inds))
 
@@ -1066,21 +1178,27 @@
                 mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
                 # Console display (only one per second)
                 if (t[-1] - last_display) > 1.0:
                     last_display = t[-1]
-                    message = 'Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d},  //  {:.1f}ms {:.1f}ms'
-                    print(message.format(i,
-                                         estim_b,
-                                         int(self.dataset.batch_limit),
-                                         1000 * mean_dt[0],
-                                         1000 * mean_dt[1]))
+                    message = "Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d},  //  {:.1f}ms {:.1f}ms"
+                    print(
+                        message.format(
+                            i,
+                            estim_b,
+                            int(self.dataset.batch_limit),
+                            1000 * mean_dt[0],
+                            1000 * mean_dt[1],
+                        )
+                    )
 
             if breaking:
                 break
 
-    def calibration(self, dataloader, untouched_ratio=0.9, verbose=False, force_redo=False):
+    def calibration(
+        self, dataloader, untouched_ratio=0.9, verbose=False, force_redo=False
+    ):
         """
         Method performing batch and neighbors calibration.
             Batch calibration: Set "batch_limit" (the maximum number of points allowed in every batch) so that the
                                average batch size (number of stacked pointclouds) is the one asked.
         Neighbors calibration: Set the "neighborhood_limits" (the maximum number of neighbors allowed in convolutions)
@@ -1089,110 +1207,116 @@
 
         ##############################
         # Previously saved calibration
         ##############################
 
-        print('\nStarting Calibration (use verbose=True for more details)')
+        print("\nStarting Calibration (use verbose=True for more details)")
         t0 = time.time()
 
         redo = force_redo
 
         # Batch limit
         # ***********
 
         # Load batch_limit dictionary
-        batch_lim_file = join(self.dataset.path, 'batch_limits.pkl')
+        batch_lim_file = join(self.dataset.path, "batch_limits.pkl")
         if exists(batch_lim_file):
-            with open(batch_lim_file, 'rb') as file:
+            with open(batch_lim_file, "rb") as file:
                 batch_lim_dict = pickle.load(file)
         else:
             batch_lim_dict = {}
 
         # Check if the batch limit associated with current parameters exists
         if self.dataset.use_potentials:
-            sampler_method = 'potentials'
+            sampler_method = "potentials"
         else:
-            sampler_method = 'random'
-        key = '{:s}_{:.3f}_{:.3f}_{:d}'.format(sampler_method,
-                                               self.dataset.config.in_radius,
-                                               self.dataset.config.first_subsampling_dl,
-                                               self.dataset.config.batch_num)
+            sampler_method = "random"
+        key = "{:s}_{:.3f}_{:.3f}_{:d}".format(
+            sampler_method,
+            self.dataset.config.in_radius,
+            self.dataset.config.first_subsampling_dl,
+            self.dataset.config.batch_num,
+        )
         if not redo and key in batch_lim_dict:
             self.dataset.batch_limit[0] = batch_lim_dict[key]
         else:
             redo = True
 
         if verbose:
-            print('\nPrevious calibration found:')
-            print('Check batch limit dictionary')
+            print("\nPrevious calibration found:")
+            print("Check batch limit dictionary")
             if key in batch_lim_dict:
                 color = bcolors.OKGREEN
                 v = str(int(batch_lim_dict[key]))
             else:
                 color = bcolors.FAIL
-                v = '?'
-            print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                v = "?"
+            print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         # Neighbors limit
         # ***************
 
         # Load neighb_limits dictionary
-        neighb_lim_file = join(self.dataset.path, 'neighbors_limits.pkl')
+        neighb_lim_file = join(self.dataset.path, "neighbors_limits.pkl")
         if exists(neighb_lim_file):
-            with open(neighb_lim_file, 'rb') as file:
+            with open(neighb_lim_file, "rb") as file:
                 neighb_lim_dict = pickle.load(file)
         else:
             neighb_lim_dict = {}
 
         # Check if the limit associated with current parameters exists (for each layer)
         neighb_limits = []
         for layer_ind in range(self.dataset.config.num_layers):
 
-            dl = self.dataset.config.first_subsampling_dl * (2 ** layer_ind)
+            dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
             if self.dataset.config.deform_layers[layer_ind]:
                 r = dl * self.dataset.config.deform_radius
             else:
                 r = dl * self.dataset.config.conv_radius
 
-            key = '{:.3f}_{:.3f}'.format(dl, r)
+            key = "{:.3f}_{:.3f}".format(dl, r)
             if key in neighb_lim_dict:
                 neighb_limits += [neighb_lim_dict[key]]
 
         if not redo and len(neighb_limits) == self.dataset.config.num_layers:
             self.dataset.neighborhood_limits = neighb_limits
         else:
             redo = True
 
         if verbose:
-            print('Check neighbors limit dictionary')
+            print("Check neighbors limit dictionary")
             for layer_ind in range(self.dataset.config.num_layers):
-                dl = self.dataset.config.first_subsampling_dl * (2 ** layer_ind)
+                dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
                 if self.dataset.config.deform_layers[layer_ind]:
                     r = dl * self.dataset.config.deform_radius
                 else:
                     r = dl * self.dataset.config.conv_radius
-                key = '{:.3f}_{:.3f}'.format(dl, r)
+                key = "{:.3f}_{:.3f}".format(dl, r)
 
                 if key in neighb_lim_dict:
                     color = bcolors.OKGREEN
                     v = str(neighb_lim_dict[key])
                 else:
                     color = bcolors.FAIL
-                    v = '?'
-                print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                    v = "?"
+                print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         if redo:
 
             ############################
             # Neighbors calib parameters
             ############################
 
             # From config parameter, compute higher bound of neighbors number in a neighborhood
-            hist_n = int(np.ceil(4 / 3 * np.pi * (self.dataset.config.deform_radius + 1) ** 3))
+            hist_n = int(
+                np.ceil(4 / 3 * np.pi * (self.dataset.config.deform_radius + 1) ** 3)
+            )
 
             # Histogram of neighborhood sizes
-            neighb_hists = np.zeros((self.dataset.config.num_layers, hist_n), dtype=np.int32)
+            neighb_hists = np.zeros(
+                (self.dataset.config.num_layers, hist_n), dtype=np.int32
+            )
 
             ########################
             # Batch calib parameters
             ########################
 
@@ -1238,12 +1362,14 @@
             sample_batches = 999
             for epoch in range((sample_batches // self.N) + 1):
                 for batch_i, batch in enumerate(dataloader):
 
                     # Update neighborhood histogram
-                    counts = [np.sum(neighb_mat.numpy() < neighb_mat.shape[0], axis=1) for neighb_mat in
-                              batch.neighbors]
+                    counts = [
+                        np.sum(neighb_mat.numpy() < neighb_mat.shape[0], axis=1)
+                        for neighb_mat in batch.neighbors
+                    ]
                     hists = [np.bincount(c, minlength=hist_n)[:hist_n] for c in counts]
                     neighb_hists += np.vstack(hists)
 
                     # batch length
                     b = len(batch.cloud_inds)
@@ -1286,14 +1412,12 @@
                     t = time.time()
 
                     # Console display (only one per second)
                     if verbose and (t - last_display) > 1.0:
                         last_display = t
-                        message = 'Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d}'
-                        print(message.format(i,
-                                             estim_b,
-                                             int(self.dataset.batch_limit)))
+                        message = "Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d}"
+                        print(message.format(i, estim_b, int(self.dataset.batch_limit)))
 
                     # Debug plots
                     debug_in.append(int(batch.points[0].shape[0]))
                     debug_out.append(int(self.dataset.batch_limit))
                     debug_b.append(b)
@@ -1305,11 +1429,12 @@
             # Plot in case we did not reach convergence
             if not breaking:
                 import matplotlib.pyplot as plt
 
                 print(
-                    "ERROR: It seems that the calibration have not reached convergence. Here are some plot to understand why:")
+                    "ERROR: It seems that the calibration have not reached convergence. Here are some plot to understand why:"
+                )
                 print("If you notice unstability, reduce the expected_N value")
                 print("If convergece is too slow, increase the expected_N value")
 
                 plt.figure()
                 plt.plot(debug_in)
@@ -1323,68 +1448,72 @@
 
                 a = 1 / 0
 
             # Use collected neighbor histogram to get neighbors limit
             cumsum = np.cumsum(neighb_hists.T, axis=0)
-            percentiles = np.sum(cumsum < (untouched_ratio * cumsum[hist_n - 1, :]), axis=0)
+            percentiles = np.sum(
+                cumsum < (untouched_ratio * cumsum[hist_n - 1, :]), axis=0
+            )
             self.dataset.neighborhood_limits = percentiles
 
             if verbose:
 
                 # Crop histogram
                 while np.sum(neighb_hists[:, -1]) == 0:
                     neighb_hists = neighb_hists[:, :-1]
                 hist_n = neighb_hists.shape[1]
 
-                print('\n**************************************************\n')
-                line0 = 'neighbors_num '
+                print("\n**************************************************\n")
+                line0 = "neighbors_num "
                 for layer in range(neighb_hists.shape[0]):
-                    line0 += '|  layer {:2d}  '.format(layer)
+                    line0 += "|  layer {:2d}  ".format(layer)
                 print(line0)
                 for neighb_size in range(hist_n):
-                    line0 = '     {:4d}     '.format(neighb_size)
+                    line0 = "     {:4d}     ".format(neighb_size)
                     for layer in range(neighb_hists.shape[0]):
                         if neighb_size > percentiles[layer]:
                             color = bcolors.FAIL
                         else:
                             color = bcolors.OKGREEN
-                        line0 += '|{:}{:10d}{:}  '.format(color,
-                                                          neighb_hists[layer, neighb_size],
-                                                          bcolors.ENDC)
+                        line0 += "|{:}{:10d}{:}  ".format(
+                            color, neighb_hists[layer, neighb_size], bcolors.ENDC
+                        )
 
                     print(line0)
 
-                print('\n**************************************************\n')
-                print('\nchosen neighbors limits: ', percentiles)
+                print("\n**************************************************\n")
+                print("\nchosen neighbors limits: ", percentiles)
                 print()
 
             # Save batch_limit dictionary
             if self.dataset.use_potentials:
-                sampler_method = 'potentials'
+                sampler_method = "potentials"
             else:
-                sampler_method = 'random'
-            key = '{:s}_{:.3f}_{:.3f}_{:d}'.format(sampler_method,
-                                                   self.dataset.config.in_radius,
-                                                   self.dataset.config.first_subsampling_dl,
-                                                   self.dataset.config.batch_num)
+                sampler_method = "random"
+            key = "{:s}_{:.3f}_{:.3f}_{:d}".format(
+                sampler_method,
+                self.dataset.config.in_radius,
+                self.dataset.config.first_subsampling_dl,
+                self.dataset.config.batch_num,
+            )
             batch_lim_dict[key] = float(self.dataset.batch_limit)
-            with open(batch_lim_file, 'wb') as file:
+            with open(batch_lim_file, "wb") as file:
                 pickle.dump(batch_lim_dict, file)
 
             # Save neighb_limit dictionary
             for layer_ind in range(self.dataset.config.num_layers):
-                dl = self.dataset.config.first_subsampling_dl * (2 ** layer_ind)
+                dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
                 if self.dataset.config.deform_layers[layer_ind]:
                     r = dl * self.dataset.config.deform_radius
                 else:
                     r = dl * self.dataset.config.conv_radius
-                key = '{:.3f}_{:.3f}'.format(dl, r)
+                key = "{:.3f}_{:.3f}".format(dl, r)
                 neighb_lim_dict[key] = self.dataset.neighborhood_limits[layer_ind]
-            with open(neighb_lim_file, 'wb') as file:
+            with open(neighb_lim_file, "wb") as file:
                 pickle.dump(neighb_lim_dict, file)
 
-        print('Calibration done in {:.1f}s\n'.format(time.time() - t0))
+        print("Calibration done in {:.1f}s\n".format(time.time() - t0))
         return
 
 
 class NPM3DCustomBatch:
     """Custom batch definition with memory pinning for NPM3D"""
@@ -1397,19 +1526,29 @@
         # Number of layers
         L = (len(input_list) - 7) // 5
 
         # Extract input tensors from the list of numpy array
         ind = 0
-        self.points = [torch.from_numpy(nparray) for nparray in input_list[ind:ind + L]]
+        self.points = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.neighbors = [torch.from_numpy(nparray) for nparray in input_list[ind:ind + L]]
+        self.neighbors = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.pools = [torch.from_numpy(nparray) for nparray in input_list[ind:ind + L]]
+        self.pools = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.upsamples = [torch.from_numpy(nparray) for nparray in input_list[ind:ind + L]]
+        self.upsamples = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.lengths = [torch.from_numpy(nparray) for nparray in input_list[ind:ind + L]]
+        self.lengths = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
         self.features = torch.from_numpy(input_list[ind])
         ind += 1
         self.labels = torch.from_numpy(input_list[ind])
         ind += 1
@@ -1462,54 +1601,54 @@
 
         return self
 
     def unstack_points(self, layer=None):
         """Unstack the points"""
-        return self.unstack_elements('points', layer)
+        return self.unstack_elements("points", layer)
 
     def unstack_neighbors(self, layer=None):
         """Unstack the neighbors indices"""
-        return self.unstack_elements('neighbors', layer)
+        return self.unstack_elements("neighbors", layer)
 
     def unstack_pools(self, layer=None):
         """Unstack the pooling indices"""
-        return self.unstack_elements('pools', layer)
+        return self.unstack_elements("pools", layer)
 
     def unstack_elements(self, element_name, layer=None, to_numpy=True):
         """
         Return a list of the stacked elements in the batch at a certain layer. If no layer is given, then return all
         layers
         """
 
-        if element_name == 'points':
+        if element_name == "points":
             elements = self.points
-        elif element_name == 'neighbors':
+        elif element_name == "neighbors":
             elements = self.neighbors
-        elif element_name == 'pools':
+        elif element_name == "pools":
             elements = self.pools[:-1]
         else:
-            raise ValueError('Unknown element name: {:s}'.format(element_name))
+            raise ValueError("Unknown element name: {:s}".format(element_name))
 
         all_p_list = []
         for layer_i, layer_elems in enumerate(elements):
 
             if layer is None or layer == layer_i:
 
                 i0 = 0
                 p_list = []
-                if element_name == 'pools':
+                if element_name == "pools":
                     lengths = self.lengths[layer_i + 1]
                 else:
                     lengths = self.lengths[layer_i]
 
                 for b_i, length in enumerate(lengths):
 
-                    elem = layer_elems[i0:i0 + length]
-                    if element_name == 'neighbors':
+                    elem = layer_elems[i0 : i0 + length]
+                    if element_name == "neighbors":
                         elem[elem >= self.points[layer_i].shape[0]] = -1
                         elem[elem >= 0] -= i0
-                    elif element_name == 'pools':
+                    elif element_name == "pools":
                         elem[elem >= self.points[layer_i].shape[0]] = -1
                         elem[elem >= 0] -= torch.sum(self.lengths[layer_i][:b_i])
                     i0 += length
 
                     if to_numpy:
@@ -1543,27 +1682,27 @@
         for batch_i, batch in enumerate(loader):
             pc1 = batch.points[1].numpy()
             pc2 = batch.points[2].numpy()
             up1 = batch.upsamples[1].numpy()
 
-            print(pc1.shape, '=>', pc2.shape)
+            print(pc1.shape, "=>", pc2.shape)
             print(up1.shape, np.max(up1))
 
             pc2 = np.vstack((pc2, np.zeros_like(pc2[:1, :])))
 
             # Get neighbors distance
             p0 = pc1[10, :]
             neighbs0 = up1[10, :]
             neighbs0 = pc2[neighbs0, :] - p0
-            d2 = np.sum(neighbs0 ** 2, axis=1)
+            d2 = np.sum(neighbs0**2, axis=1)
 
             print(neighbs0.shape)
             print(neighbs0[:5])
             print(d2[:5])
 
-            print('******************')
-        print('*******************************************')
+            print("******************")
+        print("*******************************************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -1597,18 +1736,18 @@
             mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Console display (only one per second)
             if (t[-1] - last_display) > -1.0:
                 last_display = t[-1]
-                message = 'Step {:08d} -> (ms/batch) {:8.2f} {:8.2f} / batch = {:.2f} - {:.0f}'
-                print(message.format(batch_i,
-                                     1000 * mean_dt[0],
-                                     1000 * mean_dt[1],
-                                     estim_b,
-                                     estim_N))
-
-        print('************* Epoch ended *************')
+                message = "Step {:08d} -> (ms/batch) {:8.2f} {:8.2f} / batch = {:.2f} - {:.0f}"
+                print(
+                    message.format(
+                        batch_i, 1000 * mean_dt[0], 1000 * mean_dt[1], estim_b, estim_N
+                    )
+                )
+
+        print("************* Epoch ended *************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -1622,34 +1761,34 @@
         L = dataset.config.num_layers
 
         for batch_i, batch in enumerate(loader):
 
             # Print characteristics of input tensors
-            print('\nPoints tensors')
+            print("\nPoints tensors")
             for i in range(L):
                 print(batch.points[i].dtype, batch.points[i].shape)
-            print('\nNeigbors tensors')
+            print("\nNeigbors tensors")
             for i in range(L):
                 print(batch.neighbors[i].dtype, batch.neighbors[i].shape)
-            print('\nPools tensors')
+            print("\nPools tensors")
             for i in range(L):
                 print(batch.pools[i].dtype, batch.pools[i].shape)
-            print('\nStack lengths')
+            print("\nStack lengths")
             for i in range(L):
                 print(batch.lengths[i].dtype, batch.lengths[i].shape)
-            print('\nFeatures')
+            print("\nFeatures")
             print(batch.features.dtype, batch.features.shape)
-            print('\nLabels')
+            print("\nLabels")
             print(batch.labels.dtype, batch.labels.shape)
-            print('\nAugment Scales')
+            print("\nAugment Scales")
             print(batch.scales.dtype, batch.scales.shape)
-            print('\nAugment Rotations')
+            print("\nAugment Rotations")
             print(batch.rots.dtype, batch.rots.shape)
-            print('\nModel indices')
+            print("\nModel indices")
             print(batch.model_inds.dtype, batch.model_inds.shape)
 
-            print('\nAre input tensors pinned')
+            print("\nAre input tensors pinned")
             print(batch.neighbors[0].is_pinned())
             print(batch.neighbors[-1].is_pinned())
             print(batch.points[0].is_pinned())
             print(batch.points[-1].is_pinned())
             print(batch.labels.is_pinned())
@@ -1657,11 +1796,11 @@
             print(batch.rots.is_pinned())
             print(batch.model_inds.is_pinned())
 
             show_input_batch(batch)
 
-        print('*******************************************')
+        print("*******************************************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -1689,14 +1828,12 @@
             mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Console display (only one per second)
             if (t[-1] - last_display) > 1.0:
                 last_display = t[-1]
-                message = 'Step {:08d} -> Average timings (ms/batch) {:8.2f} {:8.2f} '
-                print(message.format(batch_i,
-                                     1000 * mean_dt[0],
-                                     1000 * mean_dt[1]))
-
-        print('************* Epoch ended *************')
+                message = "Step {:08d} -> Average timings (ms/batch) {:8.2f} {:8.2f} "
+                print(message.format(batch_i, 1000 * mean_dt[0], 1000 * mean_dt[1]))
+
+        print("************* Epoch ended *************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/NPM3D.py	2024-06-30 22:34:18.064096+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/NPM3D.py	2024-07-08 11:53:46.523519+00:00
@@ -51,44 +51,45 @@
 
 
 class NPM3DDataset(PointCloudDataset):
     """Class to handle NPM3D dataset."""
 
-    def __init__(self, config, set='training', use_potentials=True, load_data=True):
+    def __init__(self, config, set="training", use_potentials=True, load_data=True):
         """
         This dataset is small enough to be stored in-memory, so load all point clouds here
         """
-        PointCloudDataset.__init__(self, 'NPM3D')
+        PointCloudDataset.__init__(self, "NPM3D")
 
         ############
         # Parameters
         ############
 
         # Dict from labels to names
-        self.label_to_names = {0: 'unclassified',
-                               1: 'ground',
-                               2: 'building',
-                               3: 'pole',       # pole - road sign - traffic light
-                               4: 'bollard',    # bollard - small pole
-                               5: 'trash',      # trash can
-                               6: 'barrier',
-                               7: 'pedestrian',
-                               8: 'car',
-                               9: 'natural'     # natural - vegetation
-                               }
+        self.label_to_names = {
+            0: "unclassified",
+            1: "ground",
+            2: "building",
+            3: "pole",  # pole - road sign - traffic light
+            4: "bollard",  # bollard - small pole
+            5: "trash",  # trash can
+            6: "barrier",
+            7: "pedestrian",
+            8: "car",
+            9: "natural",  # natural - vegetation
+        }
 
         # Initialize a bunch of variables concerning class labels
         self.init_labels()
 
         # List of classes ignored during training (can be empty)
         self.ignored_labels = np.array([0])
 
         # Dataset folder
-        self.path = '../../Paris_lille3d'
+        self.path = "../../Paris_lille3d"
 
         # Type of task conducted on this dataset
-        self.dataset_task = 'cloud_segmentation'
+        self.dataset_task = "cloud_segmentation"
 
         # Update number of class and data task in configuration
         config.num_classes = self.num_classes - len(self.ignored_labels)
         config.dataset_task = self.dataset_task
 
@@ -101,31 +102,39 @@
         # Using potential or random epoch generation
         self.use_potentials = use_potentials
 
         # Path of the training files
         # self.train_path = 'original_ply'
-        self.train_path = 'train'
-        self.original_ply_path = 'original_ply'
+        self.train_path = "train"
+        self.original_ply_path = "original_ply"
 
         # List of files to process
         ply_path = join(self.path, self.train_path)
 
         # Proportion of validation scenes
-        self.cloud_names = ['Lille1_1', 'Lille1_2', 'Lille2', 'Paris', 'ajaccio_2', 'ajaccio_57', 'dijon_9']
+        self.cloud_names = [
+            "Lille1_1",
+            "Lille1_2",
+            "Lille2",
+            "Paris",
+            "ajaccio_2",
+            "ajaccio_57",
+            "dijon_9",
+        ]
         self.all_splits = [0, 1, 2, 3, 4, 5, 6]
         self.validation_split = 1
         # self.test_cloud_names = ['ajaccio_2', 'ajaccio_57', 'dijon_9']
         self.test_splits = [4, 5, 6]
         self.train_splits = [0, 2, 3]
 
         # Number of models used per epoch
-        if self.set == 'training':
+        if self.set == "training":
             self.epoch_n = config.epoch_steps * config.batch_num
-        elif self.set in ['validation', 'test', 'ERF']:
+        elif self.set in ["validation", "test", "ERF"]:
             self.epoch_n = config.validation_size * config.batch_num
         else:
-            raise ValueError('Unknown set for NPM3D data: ', self.set)
+            raise ValueError("Unknown set for NPM3D data: ", self.set)
 
         # Stop data is not needed
         if not load_data:
             return
 
@@ -140,36 +149,45 @@
         ################
 
         # List of training files
         self.files = []
         for i, f in enumerate(self.cloud_names):
-            if self.set == 'training':
+            if self.set == "training":
                 if self.all_splits[i] in self.train_splits:
-                    self.files += [join(ply_path, f + '.ply')]
-            elif self.set in ['validation', 'ERF']:
+                    self.files += [join(ply_path, f + ".ply")]
+            elif self.set in ["validation", "ERF"]:
                 if self.all_splits[i] == self.validation_split:
-                    self.files += [join(ply_path, f + '.ply')]
-            elif self.set == 'test':
+                    self.files += [join(ply_path, f + ".ply")]
+            elif self.set == "test":
                 if self.all_splits[i] in self.test_splits:
-                    self.files += [join(ply_path, f + '.ply')]
+                    self.files += [join(ply_path, f + ".ply")]
             else:
-                raise ValueError('Unknown set for NPM3D data: ', self.set)
-        print('The set is ' + str(self.set))
-
-        if self.set == 'training':
-            self.cloud_names = [f for i, f in enumerate(self.cloud_names)
-                                if self.all_splits[i] in self.train_splits]
-        elif self.set in ['validation', 'ERF']:
-            self.cloud_names = [f for i, f in enumerate(self.cloud_names)
-                                if self.all_splits[i] == self.validation_split]
-        elif self.set == 'test':
-            self.cloud_names = [f for i, f in enumerate(self.cloud_names)
-                                if self.all_splits[i] in self.test_splits]
-        print('The files are ' + str(self.cloud_names))
+                raise ValueError("Unknown set for NPM3D data: ", self.set)
+        print("The set is " + str(self.set))
+
+        if self.set == "training":
+            self.cloud_names = [
+                f
+                for i, f in enumerate(self.cloud_names)
+                if self.all_splits[i] in self.train_splits
+            ]
+        elif self.set in ["validation", "ERF"]:
+            self.cloud_names = [
+                f
+                for i, f in enumerate(self.cloud_names)
+                if self.all_splits[i] == self.validation_split
+            ]
+        elif self.set == "test":
+            self.cloud_names = [
+                f
+                for i, f in enumerate(self.cloud_names)
+                if self.all_splits[i] in self.test_splits
+            ]
+        print("The files are " + str(self.cloud_names))
 
         if 0 < self.config.first_subsampling_dl <= 0.01:
-            raise ValueError('subsampling_parameter too low (should be over 1 cm')
+            raise ValueError("subsampling_parameter too low (should be over 1 cm")
 
         # Initiate containers
         self.input_trees = []
         self.input_colors = []
         self.input_labels = []
@@ -193,41 +211,51 @@
         if use_potentials:
             self.potentials = []
             self.min_potentials = []
             self.argmin_potentials = []
             for i, tree in enumerate(self.pot_trees):
-                self.potentials += [torch.from_numpy(np.random.rand(tree.data.shape[0]) * 1e-3)]
+                self.potentials += [
+                    torch.from_numpy(np.random.rand(tree.data.shape[0]) * 1e-3)
+                ]
                 min_ind = int(torch.argmin(self.potentials[-1]))
                 self.argmin_potentials += [min_ind]
                 self.min_potentials += [float(self.potentials[-1][min_ind])]
 
             # Share potential memory
-            self.argmin_potentials = torch.from_numpy(np.array(self.argmin_potentials, dtype=np.int64))
-            self.min_potentials = torch.from_numpy(np.array(self.min_potentials, dtype=np.float64))
+            self.argmin_potentials = torch.from_numpy(
+                np.array(self.argmin_potentials, dtype=np.int64)
+            )
+            self.min_potentials = torch.from_numpy(
+                np.array(self.min_potentials, dtype=np.float64)
+            )
             self.argmin_potentials.share_memory_()
             self.min_potentials.share_memory_()
             for i, _ in enumerate(self.pot_trees):
                 self.potentials[i].share_memory_()
 
-            self.worker_waiting = torch.tensor([0 for _ in range(config.input_threads)], dtype=torch.int32)
+            self.worker_waiting = torch.tensor(
+                [0 for _ in range(config.input_threads)], dtype=torch.int32
+            )
             self.worker_waiting.share_memory_()
             self.epoch_inds = None
             self.epoch_i = 0
 
         else:
             self.potentials = None
             self.min_potentials = None
             self.argmin_potentials = None
-            self.epoch_inds = torch.from_numpy(np.zeros((2, self.epoch_n), dtype=np.int64))
+            self.epoch_inds = torch.from_numpy(
+                np.zeros((2, self.epoch_n), dtype=np.int64)
+            )
             self.epoch_i = torch.from_numpy(np.zeros((1,), dtype=np.int64))
             self.epoch_i.share_memory_()
             self.epoch_inds.share_memory_()
 
         self.worker_lock = Lock()
 
         # For ERF visualization, we want only one cloud per batch and no randomness
-        if self.set == 'ERF':
+        if self.set == "ERF":
             self.batch_limit = torch.tensor([1], dtype=torch.float32)
             self.batch_limit.share_memory_()
             np.random.seed(42)
 
         return
@@ -274,36 +302,36 @@
         while True:
 
             t += [time.time()]
 
             if debug_workers:
-                message = ''
+                message = ""
                 for wi in range(info.num_workers):
                     if wi == wid:
-                        message += ' {:}X{:} '.format(bcolors.FAIL, bcolors.ENDC)
+                        message += " {:}X{:} ".format(bcolors.FAIL, bcolors.ENDC)
                     elif self.worker_waiting[wi] == 0:
-                        message += '   '
+                        message += "   "
                     elif self.worker_waiting[wi] == 1:
-                        message += ' | '
+                        message += " | "
                     elif self.worker_waiting[wi] == 2:
-                        message += ' o '
+                        message += " o "
                 print(message)
                 self.worker_waiting[wid] = 0
 
             with self.worker_lock:
 
                 if debug_workers:
-                    message = ''
+                    message = ""
                     for wi in range(info.num_workers):
                         if wi == wid:
-                            message += ' {:}v{:} '.format(bcolors.OKGREEN, bcolors.ENDC)
+                            message += " {:}v{:} ".format(bcolors.OKGREEN, bcolors.ENDC)
                         elif self.worker_waiting[wi] == 0:
-                            message += '   '
+                            message += "   "
                         elif self.worker_waiting[wi] == 1:
-                            message += ' | '
+                            message += " | "
                         elif self.worker_waiting[wi] == 2:
-                            message += ' o '
+                            message += " o "
                     print(message)
                     self.worker_waiting[wid] = 1
 
                 # Get potential minimum
                 cloud_ind = int(torch.argmin(self.min_potentials))
@@ -314,57 +342,64 @@
 
                 # Center point of input region
                 center_point = pot_points[point_ind, :].reshape(1, -1)
 
                 # Add a small noise to center point
-                if self.set != 'ERF':
-                    center_point += np.random.normal(scale=self.config.in_radius / 10, size=center_point.shape)
+                if self.set != "ERF":
+                    center_point += np.random.normal(
+                        scale=self.config.in_radius / 10, size=center_point.shape
+                    )
 
                 # Indices of points in input region
-                pot_inds, dists = self.pot_trees[cloud_ind].query_radius(center_point,
-                                                                         r=self.config.in_radius,
-                                                                         return_distance=True)
+                pot_inds, dists = self.pot_trees[cloud_ind].query_radius(
+                    center_point, r=self.config.in_radius, return_distance=True
+                )
 
                 d2s = np.square(dists[0])
                 pot_inds = pot_inds[0]
 
                 # Update potentials (Tukey weights)
-                if self.set != 'ERF':
+                if self.set != "ERF":
                     tukeys = np.square(1 - d2s / np.square(self.config.in_radius))
                     tukeys[d2s > np.square(self.config.in_radius)] = 0
                     self.potentials[cloud_ind][pot_inds] += tukeys
                     min_ind = torch.argmin(self.potentials[cloud_ind])
-                    self.min_potentials[[cloud_ind]] = self.potentials[cloud_ind][min_ind]
+                    self.min_potentials[[cloud_ind]] = self.potentials[cloud_ind][
+                        min_ind
+                    ]
                     self.argmin_potentials[[cloud_ind]] = min_ind
 
             t += [time.time()]
 
             # Get points from tree structure
             points = np.array(self.input_trees[cloud_ind].data, copy=False)
 
             # Indices of points in input region
-            input_inds = self.input_trees[cloud_ind].query_radius(center_point,
-                                                                  r=self.config.in_radius)[0]
+            input_inds = self.input_trees[cloud_ind].query_radius(
+                center_point, r=self.config.in_radius
+            )[0]
 
             t += [time.time()]
 
             # Number collected
             n = input_inds.shape[0]
 
             # Safe check for empty spheres
             if n < 2:
                 failed_attempts += 1
                 if failed_attempts > 100 * self.config.batch_num:
-                    raise ValueError('It seems this dataset only containes empty input spheres')
+                    raise ValueError(
+                        "It seems this dataset only containes empty input spheres"
+                    )
                 t += [time.time()]
                 t += [time.time()]
                 continue
 
             # Collect labels and colors
             input_points = (points[input_inds] - center_point).astype(np.float32)
             # input_colors = self.input_colors[cloud_ind][input_inds]
-            if self.set in ['test', 'ERF']:
+            if self.set in ["test", "ERF"]:
                 input_labels = np.zeros(input_points.shape[0])
             else:
                 input_labels = self.input_labels[cloud_ind][input_inds]
                 input_labels = np.array([self.label_to_idx[l] for l in input_labels])
 
@@ -377,11 +412,13 @@
             # if np.random.rand() > self.config.augment_color:
             #    input_colors *= 0
 
             # Get original height as additional feature
             # input_features = np.hstack((input_colors, input_points[:, 2:] + center_point[:, 2:])).astype(np.float32)
-            input_features = np.hstack((input_points[:, 2:] + center_point[:, 2:])).astype(np.float32)
+            input_features = np.hstack(
+                (input_points[:, 2:] + center_point[:, 2:])
+            ).astype(np.float32)
 
             t += [time.time()]
 
             # Stack batch
             p_list += [input_points]
@@ -426,11 +463,13 @@
         elif self.config.in_features_dim == 4:
             stacked_features = np.hstack((stacked_features, features[:, :3]))
         elif self.config.in_features_dim == 5:
             stacked_features = np.hstack((stacked_features, features))
         else:
-            raise ValueError('Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)')
+            raise ValueError(
+                "Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)"
+            )
 
         #######################
         # Create network inputs
         #######################
         #
@@ -438,80 +477,94 @@
         #
 
         t += [time.time()]
 
         # Get the whole input list
-        input_list = self.segmentation_inputs(stacked_points,
-                                              stacked_features,
-                                              labels,
-                                              stack_lengths)
+        input_list = self.segmentation_inputs(
+            stacked_points, stacked_features, labels, stack_lengths
+        )
 
         t += [time.time()]
 
         # Add scale and rotation for testing
         input_list += [scales, rots, cloud_inds, point_inds, input_inds]
 
         if debug_workers:
-            message = ''
+            message = ""
             for wi in range(info.num_workers):
                 if wi == wid:
-                    message += ' {:}0{:} '.format(bcolors.OKBLUE, bcolors.ENDC)
+                    message += " {:}0{:} ".format(bcolors.OKBLUE, bcolors.ENDC)
                 elif self.worker_waiting[wi] == 0:
-                    message += '   '
+                    message += "   "
                 elif self.worker_waiting[wi] == 1:
-                    message += ' | '
+                    message += " | "
                 elif self.worker_waiting[wi] == 2:
-                    message += ' o '
+                    message += " o "
             print(message)
             self.worker_waiting[wid] = 2
 
         t += [time.time()]
 
         # Display timings
         debugT = False
         if debugT:
-            print('\n************************\n')
-            print('Timings:')
+            print("\n************************\n")
+            print("Timings:")
             ti = 0
             N = 5
-            mess = 'Init ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Init ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Pots ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Pots ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Sphere .... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Sphere .... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Collect ... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Collect ... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Augment ... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Augment ... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += N * (len(stack_lengths) - 1) + 1
-            print('concat .... {:5.1f}ms'.format(1000 * (t[ti + 1] - t[ti])))
+            print("concat .... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('input ..... {:5.1f}ms'.format(1000 * (t[ti + 1] - t[ti])))
+            print("input ..... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('stack ..... {:5.1f}ms'.format(1000 * (t[ti + 1] - t[ti])))
+            print("stack ..... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('\n************************\n')
+            print("\n************************\n")
         return input_list
 
     def random_item(self, batch_i):
 
         # Initiate concatanation lists
@@ -544,31 +597,36 @@
 
             # Center point of input region
             center_point = points[point_ind, :].reshape(1, -1)
 
             # Add a small noise to center point
-            if self.set != 'ERF':
-                center_point += np.random.normal(scale=self.config.in_radius / 10, size=center_point.shape)
+            if self.set != "ERF":
+                center_point += np.random.normal(
+                    scale=self.config.in_radius / 10, size=center_point.shape
+                )
 
             # Indices of points in input region
-            input_inds = self.input_trees[cloud_ind].query_radius(center_point,
-                                                                  r=self.config.in_radius)[0]
+            input_inds = self.input_trees[cloud_ind].query_radius(
+                center_point, r=self.config.in_radius
+            )[0]
 
             # Number collected
             n = input_inds.shape[0]
 
             # Safe check for empty spheres
             if n < 2:
                 failed_attempts += 1
                 if failed_attempts > 100 * self.config.batch_num:
-                    raise ValueError('It seems this dataset only containes empty input spheres')
+                    raise ValueError(
+                        "It seems this dataset only containes empty input spheres"
+                    )
                 continue
 
             # Collect labels and colors
             input_points = (points[input_inds] - center_point).astype(np.float32)
             # input_colors = self.input_colors[cloud_ind][input_inds]
-            if self.set in ['test', 'ERF']:
+            if self.set in ["test", "ERF"]:
                 input_labels = np.zeros(input_points.shape[0])
             else:
                 input_labels = self.input_labels[cloud_ind][input_inds]
                 input_labels = np.array([self.label_to_idx[l] for l in input_labels])
 
@@ -578,11 +636,13 @@
             # Color augmentation
             # if np.random.rand() > self.config.augment_color:
             #   input_colors *= 0
 
             # Get original height as additional feature
-            input_features = np.hstack((input_colors, input_points[:, 2:] + center_point[:, 2:])).astype(np.float32)
+            input_features = np.hstack(
+                (input_colors, input_points[:, 2:] + center_point[:, 2:])
+            ).astype(np.float32)
 
             # Stack batch
             p_list += [input_points]
             f_list += [input_features]
             l_list += [input_labels]
@@ -625,53 +685,56 @@
         elif self.config.in_features_dim == 4:
             stacked_features = np.hstack((stacked_features, features[:, :3]))
         elif self.config.in_features_dim == 5:
             stacked_features = np.hstack((stacked_features, features))
         else:
-            raise ValueError('Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)')
+            raise ValueError(
+                "Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)"
+            )
 
         #######################
         # Create network inputs
         #######################
         #
         #   Points, neighbors, pooling indices for each layers
         #
 
         # Get the whole input list
-        input_list = self.segmentation_inputs(stacked_points,
-                                              stacked_features,
-                                              labels,
-                                              stack_lengths)
+        input_list = self.segmentation_inputs(
+            stacked_points, stacked_features, labels, stack_lengths
+        )
 
         # Add scale and rotation for testing
         input_list += [scales, rots, cloud_inds, point_inds, input_inds]
 
         return input_list
 
     def prepare_NPM3D_ply(self):
 
-        print('\nPreparing ply files')
+        print("\nPreparing ply files")
         t0 = time.time()
 
         # Folder for the ply files
         ply_path = join(self.path, self.train_path)
         if not exists(ply_path):
             makedirs(ply_path)
 
         for cloud_name in self.cloud_names:
 
             # Pass if the cloud has already been computed
-            cloud_file = join(ply_path, cloud_name + '.ply')
+            cloud_file = join(ply_path, cloud_name + ".ply")
             if exists(cloud_file):
                 continue
 
-            original_ply = read_ply(join(self.path, self.original_ply_path, cloud_name + '.ply'))
+            original_ply = read_ply(
+                join(self.path, self.original_ply_path, cloud_name + ".ply")
+            )
 
             # Initiate containers
-            cloud_x = original_ply['x']
-            cloud_y = original_ply['y']
-            cloud_z = original_ply['z']
+            cloud_x = original_ply["x"]
+            cloud_y = original_ply["y"]
+            cloud_z = original_ply["z"]
             cloud_x = cloud_x - (cloud_x.min())
             cloud_y = cloud_y - (cloud_y.min())
             cloud_z = cloud_z - (cloud_z.min())
 
             # Reshape
@@ -686,34 +749,40 @@
 
             # Stack
             cloud_points = np.hstack((cloud_x, cloud_y, cloud_z))
 
             # Labels
-            if cloud_name in ['ajaccio_2', 'ajaccio_57', 'dijon_9']:
-
-                field_names = ['x', 'y', 'z']
-                write_ply(join(ply_path, cloud_name + '.ply'), cloud_points, field_names)
+            if cloud_name in ["ajaccio_2", "ajaccio_57", "dijon_9"]:
+
+                field_names = ["x", "y", "z"]
+                write_ply(
+                    join(ply_path, cloud_name + ".ply"), cloud_points, field_names
+                )
 
             else:
-                labels = original_ply['class']
+                labels = original_ply["class"]
                 labels = labels.astype(np.int32)
                 labels = labels.reshape(len(labels), 1)
 
                 # Save as ply
-                field_names = ['x', 'y', 'z', 'class']
-                write_ply(join(ply_path, cloud_name + '.ply'), [cloud_points, labels], field_names)
-
-        print('Done in {:.1f}s'.format(time.time() - t0))
+                field_names = ["x", "y", "z", "class"]
+                write_ply(
+                    join(ply_path, cloud_name + ".ply"),
+                    [cloud_points, labels],
+                    field_names,
+                )
+
+        print("Done in {:.1f}s".format(time.time() - t0))
         return
 
     def load_subsampled_clouds(self):
 
         # Parameter
         dl = self.config.first_subsampling_dl
 
         # Create path for files
-        tree_path = join(self.path, 'input_{:.3f}'.format(dl))
+        tree_path = join(self.path, "input_{:.3f}".format(dl))
         if not exists(tree_path):
             makedirs(tree_path)
 
         ##############
         # Load KDTrees
@@ -726,44 +795,52 @@
 
             # Get cloud name
             cloud_name = self.cloud_names[i]
 
             # Name of the input files
-            KDTree_file = join(tree_path, '{:s}_KDTree.pkl'.format(cloud_name))
-            sub_ply_file = join(tree_path, '{:s}.ply'.format(cloud_name))
+            KDTree_file = join(tree_path, "{:s}_KDTree.pkl".format(cloud_name))
+            sub_ply_file = join(tree_path, "{:s}.ply".format(cloud_name))
 
             # Check if inputs have already been computed
             if exists(KDTree_file):
-                print('\nFound KDTree for cloud {:s}, subsampled at {:.3f}'.format(cloud_name, dl))
+                print(
+                    "\nFound KDTree for cloud {:s}, subsampled at {:.3f}".format(
+                        cloud_name, dl
+                    )
+                )
 
                 # read ply with data
                 data = read_ply(sub_ply_file)
                 # sub_colors = np.vstack((data['red'], data['green'], data['blue'])).T
-                sub_labels = data['class']
+                sub_labels = data["class"]
 
                 # Read pkl with search tree
-                with open(KDTree_file, 'rb') as f:
+                with open(KDTree_file, "rb") as f:
                     search_tree = pickle.load(f)
 
             else:
-                print('\nPreparing KDTree for cloud {:s}, subsampled at {:.3f}'.format(cloud_name, dl))
+                print(
+                    "\nPreparing KDTree for cloud {:s}, subsampled at {:.3f}".format(
+                        cloud_name, dl
+                    )
+                )
 
                 # Read ply file
                 data = read_ply(file_path)
-                points = np.vstack((data['x'], data['y'], data['z'])).T
+                points = np.vstack((data["x"], data["y"], data["z"])).T
                 # colors = np.vstack((data['red'], data['green'], data['blue'])).T
 
                 # Fake labels for test data
-                if self.set == 'test':
+                if self.set == "test":
                     labels = np.zeros((data.shape[0],), dtype=np.int32)
                 else:
-                    labels = data['class']
+                    labels = data["class"]
 
                 # Subsample cloud
-                sub_points, sub_labels = grid_subsampling(points,
-                                                          labels=labels,
-                                                          sampleDl=dl)
+                sub_points, sub_labels = grid_subsampling(
+                    points, labels=labels, sampleDl=dl
+                )
 
                 # Rescale float color and squeeze label
                 # sub_colors = sub_colors / 255
                 sub_labels = np.squeeze(sub_labels)
 
@@ -771,33 +848,33 @@
                 search_tree = KDTree(sub_points, leaf_size=10)
                 # search_tree = nnfln.KDTree(n_neighbors=1, metric='L2', leaf_size=10)
                 # search_tree.fit(sub_points)
 
                 # Save KDTree
-                with open(KDTree_file, 'wb') as f:
+                with open(KDTree_file, "wb") as f:
                     pickle.dump(search_tree, f)
 
                 # Save ply
-                write_ply(sub_ply_file,
-                          [sub_points, sub_labels],
-                          ['x', 'y', 'z', 'class'])
+                write_ply(
+                    sub_ply_file, [sub_points, sub_labels], ["x", "y", "z", "class"]
+                )
 
             # Fill data containers
             self.input_trees += [search_tree]
             # self.input_colors += [sub_colors]
             self.input_labels += [sub_labels]
 
             size = sub_labels.shape[0] * 4 * 7
-            print('{:.1f} MB loaded in {:.1f}s'.format(size * 1e-6, time.time() - t0))
+            print("{:.1f} MB loaded in {:.1f}s".format(size * 1e-6, time.time() - t0))
 
         ############################
         # Coarse potential locations
         ############################
 
         # Only necessary for validation and test sets
         if self.use_potentials:
-            print('\nPreparing potentials')
+            print("\nPreparing potentials")
 
             # Restart timer
             t0 = time.time()
 
             pot_dl = self.config.in_radius / 10
@@ -807,47 +884,51 @@
 
                 # Get cloud name
                 cloud_name = self.cloud_names[i]
 
                 # Name of the input files
-                coarse_KDTree_file = join(tree_path, '{:s}_coarse_KDTree.pkl'.format(cloud_name))
+                coarse_KDTree_file = join(
+                    tree_path, "{:s}_coarse_KDTree.pkl".format(cloud_name)
+                )
 
                 # Check if inputs have already been computed
                 if exists(coarse_KDTree_file):
                     # Read pkl with search tree
-                    with open(coarse_KDTree_file, 'rb') as f:
+                    with open(coarse_KDTree_file, "rb") as f:
                         search_tree = pickle.load(f)
 
                 else:
                     # Subsample cloud
                     sub_points = np.array(self.input_trees[cloud_ind].data, copy=False)
-                    coarse_points = grid_subsampling(sub_points.astype(np.float32), sampleDl=pot_dl)
+                    coarse_points = grid_subsampling(
+                        sub_points.astype(np.float32), sampleDl=pot_dl
+                    )
 
                     # Get chosen neighborhoods
                     search_tree = KDTree(coarse_points, leaf_size=10)
 
                     # Save KDTree
-                    with open(coarse_KDTree_file, 'wb') as f:
+                    with open(coarse_KDTree_file, "wb") as f:
                         pickle.dump(search_tree, f)
 
                 # Fill data containers
                 self.pot_trees += [search_tree]
                 cloud_ind += 1
 
-            print('Done in {:.1f}s'.format(time.time() - t0))
+            print("Done in {:.1f}s".format(time.time() - t0))
 
         ######################
         # Reprojection indices
         ######################
 
         # Get number of clouds
         self.num_clouds = len(self.input_trees)
 
         # Only necessary for validation and test sets
-        if self.set in ['validation', 'test']:
-
-            print('\nPreparing reprojection indices for testing')
+        if self.set in ["validation", "test"]:
+
+            print("\nPreparing reprojection indices for testing")
 
             # Get validation/test reprojection indices
             for i, file_path in enumerate(self.files):
 
                 # Restart timer
@@ -855,38 +936,38 @@
 
                 # Get info on this cloud
                 cloud_name = self.cloud_names[i]
 
                 # File name for saving
-                proj_file = join(tree_path, '{:s}_proj.pkl'.format(cloud_name))
+                proj_file = join(tree_path, "{:s}_proj.pkl".format(cloud_name))
 
                 # Try to load previous indices
                 if exists(proj_file):
-                    with open(proj_file, 'rb') as f:
+                    with open(proj_file, "rb") as f:
                         proj_inds, labels = pickle.load(f)
                 else:
                     data = read_ply(file_path)
-                    points = np.vstack((data['x'], data['y'], data['z'])).T
+                    points = np.vstack((data["x"], data["y"], data["z"])).T
 
                     # Fake labels
-                    if self.set == 'test':
+                    if self.set == "test":
                         labels = np.zeros((data.shape[0],), dtype=np.int32)
                     else:
-                        labels = data['class']
+                        labels = data["class"]
 
                     # Compute projection inds
                     idxs = self.input_trees[i].query(points, return_distance=False)
                     # dists, idxs = self.input_trees[i_cloud].kneighbors(points)
                     proj_inds = np.squeeze(idxs).astype(np.int32)
 
                     # Save
-                    with open(proj_file, 'wb') as f:
+                    with open(proj_file, "wb") as f:
                         pickle.dump([proj_inds, labels], f)
 
                 self.test_proj += [proj_inds]
                 self.validation_labels += [labels]
-                print('{:s} done in {:.1f}s'.format(cloud_name, time.time() - t0))
+                print("{:s} done in {:.1f}s".format(cloud_name, time.time() - t0))
 
         print()
         return
 
     def load_evaluation_points(self, file_path):
@@ -894,11 +975,11 @@
         Load points (from test or validation split) on which the metrics should be evaluated
         """
 
         # Get original points
         data = read_ply(file_path)
-        return np.vstack((data['x'], data['y'], data['z'])).T
+        return np.vstack((data["x"], data["y"], data["z"])).T
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Utility classes definition
@@ -913,11 +994,11 @@
 
         # Dataset used by the sampler (no copy is made in memory)
         self.dataset = dataset
 
         # Number of step per epoch
-        if dataset.set == 'training':
+        if dataset.set == "training":
             self.N = dataset.config.epoch_steps
         else:
             self.N = dataset.config.validation_size
 
         return
@@ -949,39 +1030,62 @@
                     # Gather indices of the points with this label in all the input clouds
                     all_label_indices = []
                     for cloud_ind, cloud_labels in enumerate(self.dataset.input_labels):
                         label_indices = np.where(np.equal(cloud_labels, label))[0]
                         all_label_indices.append(
-                            np.vstack((np.full(label_indices.shape, cloud_ind, dtype=np.int64), label_indices)))
+                            np.vstack(
+                                (
+                                    np.full(
+                                        label_indices.shape, cloud_ind, dtype=np.int64
+                                    ),
+                                    label_indices,
+                                )
+                            )
+                        )
 
                     # Stack them: [2, N1+N2+...]
                     all_label_indices = np.hstack(all_label_indices)
 
                     # Select a a random number amongst them
                     N_inds = all_label_indices.shape[1]
                     if N_inds < random_pick_n:
                         chosen_label_inds = np.zeros((2, 0), dtype=np.int64)
                         while chosen_label_inds.shape[1] < random_pick_n:
                             chosen_label_inds = np.hstack(
-                                (chosen_label_inds, all_label_indices[:, np.random.permutation(N_inds)]))
-                        warnings.warn('When choosing random epoch indices (use_potentials=False), \
+                                (
+                                    chosen_label_inds,
+                                    all_label_indices[:, np.random.permutation(N_inds)],
+                                )
+                            )
+                        warnings.warn(
+                            "When choosing random epoch indices (use_potentials=False), \
                                        class {:d}: {:s} only had {:d} available points, while we \
-                                       needed {:d}. Repeating indices in the same epoch'.format(label,
-                                                                                                self.dataset.label_names[
-                                                                                                    label_ind],
-                                                                                                N_inds,
-                                                                                                random_pick_n))
+                                       needed {:d}. Repeating indices in the same epoch".format(
+                                label,
+                                self.dataset.label_names[label_ind],
+                                N_inds,
+                                random_pick_n,
+                            )
+                        )
 
                     elif N_inds < 50 * random_pick_n:
-                        rand_inds = np.random.choice(N_inds, size=random_pick_n, replace=False)
+                        rand_inds = np.random.choice(
+                            N_inds, size=random_pick_n, replace=False
+                        )
                         chosen_label_inds = all_label_indices[:, rand_inds]
 
                     else:
                         chosen_label_inds = np.zeros((2, 0), dtype=np.int64)
                         while chosen_label_inds.shape[1] < random_pick_n:
-                            rand_inds = np.unique(np.random.choice(N_inds, size=2 * random_pick_n, replace=True))
-                            chosen_label_inds = np.hstack((chosen_label_inds, all_label_indices[:, rand_inds]))
+                            rand_inds = np.unique(
+                                np.random.choice(
+                                    N_inds, size=2 * random_pick_n, replace=True
+                                )
+                            )
+                            chosen_label_inds = np.hstack(
+                                (chosen_label_inds, all_label_indices[:, rand_inds])
+                            )
                         chosen_label_inds = chosen_label_inds[:, :random_pick_n]
 
                     # Stack for each label
                     all_epoch_inds = np.hstack((all_epoch_inds, chosen_label_inds))
 
@@ -1067,21 +1171,27 @@
                 mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
                 # Console display (only one per second)
                 if (t[-1] - last_display) > 1.0:
                     last_display = t[-1]
-                    message = 'Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d},  //  {:.1f}ms {:.1f}ms'
-                    print(message.format(i,
-                                         estim_b,
-                                         int(self.dataset.batch_limit),
-                                         1000 * mean_dt[0],
-                                         1000 * mean_dt[1]))
+                    message = "Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d},  //  {:.1f}ms {:.1f}ms"
+                    print(
+                        message.format(
+                            i,
+                            estim_b,
+                            int(self.dataset.batch_limit),
+                            1000 * mean_dt[0],
+                            1000 * mean_dt[1],
+                        )
+                    )
 
             if breaking:
                 break
 
-    def calibration(self, dataloader, untouched_ratio=0.9, verbose=False, force_redo=False):
+    def calibration(
+        self, dataloader, untouched_ratio=0.9, verbose=False, force_redo=False
+    ):
         """
         Method performing batch and neighbors calibration.
             Batch calibration: Set "batch_limit" (the maximum number of points allowed in every batch) so that the
                                average batch size (number of stacked pointclouds) is the one asked.
         Neighbors calibration: Set the "neighborhood_limits" (the maximum number of neighbors allowed in convolutions)
@@ -1090,110 +1200,116 @@
 
         ##############################
         # Previously saved calibration
         ##############################
 
-        print('\nStarting Calibration (use verbose=True for more details)')
+        print("\nStarting Calibration (use verbose=True for more details)")
         t0 = time.time()
 
         redo = force_redo
 
         # Batch limit
         # ***********
 
         # Load batch_limit dictionary
-        batch_lim_file = join(self.dataset.path, 'batch_limits.pkl')
+        batch_lim_file = join(self.dataset.path, "batch_limits.pkl")
         if exists(batch_lim_file):
-            with open(batch_lim_file, 'rb') as file:
+            with open(batch_lim_file, "rb") as file:
                 batch_lim_dict = pickle.load(file)
         else:
             batch_lim_dict = {}
 
         # Check if the batch limit associated with current parameters exists
         if self.dataset.use_potentials:
-            sampler_method = 'potentials'
+            sampler_method = "potentials"
         else:
-            sampler_method = 'random'
-        key = '{:s}_{:.3f}_{:.3f}_{:d}'.format(sampler_method,
-                                               self.dataset.config.in_radius,
-                                               self.dataset.config.first_subsampling_dl,
-                                               self.dataset.config.batch_num)
+            sampler_method = "random"
+        key = "{:s}_{:.3f}_{:.3f}_{:d}".format(
+            sampler_method,
+            self.dataset.config.in_radius,
+            self.dataset.config.first_subsampling_dl,
+            self.dataset.config.batch_num,
+        )
         if not redo and key in batch_lim_dict:
             self.dataset.batch_limit[0] = batch_lim_dict[key]
         else:
             redo = True
 
         if verbose:
-            print('\nPrevious calibration found:')
-            print('Check batch limit dictionary')
+            print("\nPrevious calibration found:")
+            print("Check batch limit dictionary")
             if key in batch_lim_dict:
                 color = bcolors.OKGREEN
                 v = str(int(batch_lim_dict[key]))
             else:
                 color = bcolors.FAIL
-                v = '?'
-            print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                v = "?"
+            print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         # Neighbors limit
         # ***************
 
         # Load neighb_limits dictionary
-        neighb_lim_file = join(self.dataset.path, 'neighbors_limits.pkl')
+        neighb_lim_file = join(self.dataset.path, "neighbors_limits.pkl")
         if exists(neighb_lim_file):
-            with open(neighb_lim_file, 'rb') as file:
+            with open(neighb_lim_file, "rb") as file:
                 neighb_lim_dict = pickle.load(file)
         else:
             neighb_lim_dict = {}
 
         # Check if the limit associated with current parameters exists (for each layer)
         neighb_limits = []
         for layer_ind in range(self.dataset.config.num_layers):
 
-            dl = self.dataset.config.first_subsampling_dl * (2 ** layer_ind)
+            dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
             if self.dataset.config.deform_layers[layer_ind]:
                 r = dl * self.dataset.config.deform_radius
             else:
                 r = dl * self.dataset.config.conv_radius
 
-            key = '{:.3f}_{:.3f}'.format(dl, r)
+            key = "{:.3f}_{:.3f}".format(dl, r)
             if key in neighb_lim_dict:
                 neighb_limits += [neighb_lim_dict[key]]
 
         if not redo and len(neighb_limits) == self.dataset.config.num_layers:
             self.dataset.neighborhood_limits = neighb_limits
         else:
             redo = True
 
         if verbose:
-            print('Check neighbors limit dictionary')
+            print("Check neighbors limit dictionary")
             for layer_ind in range(self.dataset.config.num_layers):
-                dl = self.dataset.config.first_subsampling_dl * (2 ** layer_ind)
+                dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
                 if self.dataset.config.deform_layers[layer_ind]:
                     r = dl * self.dataset.config.deform_radius
                 else:
                     r = dl * self.dataset.config.conv_radius
-                key = '{:.3f}_{:.3f}'.format(dl, r)
+                key = "{:.3f}_{:.3f}".format(dl, r)
 
                 if key in neighb_lim_dict:
                     color = bcolors.OKGREEN
                     v = str(neighb_lim_dict[key])
                 else:
                     color = bcolors.FAIL
-                    v = '?'
-                print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                    v = "?"
+                print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         if redo:
 
             ############################
             # Neighbors calib parameters
             ############################
 
             # From config parameter, compute higher bound of neighbors number in a neighborhood
-            hist_n = int(np.ceil(4 / 3 * np.pi * (self.dataset.config.deform_radius + 1) ** 3))
+            hist_n = int(
+                np.ceil(4 / 3 * np.pi * (self.dataset.config.deform_radius + 1) ** 3)
+            )
 
             # Histogram of neighborhood sizes
-            neighb_hists = np.zeros((self.dataset.config.num_layers, hist_n), dtype=np.int32)
+            neighb_hists = np.zeros(
+                (self.dataset.config.num_layers, hist_n), dtype=np.int32
+            )
 
             ########################
             # Batch calib parameters
             ########################
 
@@ -1238,12 +1354,14 @@
             sample_batches = 999
             for epoch in range((sample_batches // self.N) + 1):
                 for batch_i, batch in enumerate(dataloader):
 
                     # Update neighborhood histogram
-                    counts = [np.sum(neighb_mat.numpy() < neighb_mat.shape[0], axis=1) for neighb_mat in
-                              batch.neighbors]
+                    counts = [
+                        np.sum(neighb_mat.numpy() < neighb_mat.shape[0], axis=1)
+                        for neighb_mat in batch.neighbors
+                    ]
                     hists = [np.bincount(c, minlength=hist_n)[:hist_n] for c in counts]
                     neighb_hists += np.vstack(hists)
 
                     # batch length
                     b = len(batch.cloud_inds)
@@ -1286,14 +1404,12 @@
                     t = time.time()
 
                     # Console display (only one per second)
                     if verbose and (t - last_display) > 1.0:
                         last_display = t
-                        message = 'Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d}'
-                        print(message.format(i,
-                                             estim_b,
-                                             int(self.dataset.batch_limit)))
+                        message = "Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d}"
+                        print(message.format(i, estim_b, int(self.dataset.batch_limit)))
 
                     # Debug plots
                     debug_in.append(int(batch.points[0].shape[0]))
                     debug_out.append(int(self.dataset.batch_limit))
                     debug_b.append(b)
@@ -1305,11 +1421,12 @@
             # Plot in case we did not reach convergence
             if not breaking:
                 import matplotlib.pyplot as plt
 
                 print(
-                    "ERROR: It seems that the calibration have not reached convergence. Here are some plot to understand why:")
+                    "ERROR: It seems that the calibration have not reached convergence. Here are some plot to understand why:"
+                )
                 print("If you notice unstability, reduce the expected_N value")
                 print("If convergece is too slow, increase the expected_N value")
 
                 plt.figure()
                 plt.plot(debug_in)
@@ -1323,68 +1440,72 @@
 
                 a = 1 / 0
 
             # Use collected neighbor histogram to get neighbors limit
             cumsum = np.cumsum(neighb_hists.T, axis=0)
-            percentiles = np.sum(cumsum < (untouched_ratio * cumsum[hist_n - 1, :]), axis=0)
+            percentiles = np.sum(
+                cumsum < (untouched_ratio * cumsum[hist_n - 1, :]), axis=0
+            )
             self.dataset.neighborhood_limits = percentiles
 
             if verbose:
 
                 # Crop histogram
                 while np.sum(neighb_hists[:, -1]) == 0:
                     neighb_hists = neighb_hists[:, :-1]
                 hist_n = neighb_hists.shape[1]
 
-                print('\n**************************************************\n')
-                line0 = 'neighbors_num '
+                print("\n**************************************************\n")
+                line0 = "neighbors_num "
                 for layer in range(neighb_hists.shape[0]):
-                    line0 += '|  layer {:2d}  '.format(layer)
+                    line0 += "|  layer {:2d}  ".format(layer)
                 print(line0)
                 for neighb_size in range(hist_n):
-                    line0 = '     {:4d}     '.format(neighb_size)
+                    line0 = "     {:4d}     ".format(neighb_size)
                     for layer in range(neighb_hists.shape[0]):
                         if neighb_size > percentiles[layer]:
                             color = bcolors.FAIL
                         else:
                             color = bcolors.OKGREEN
-                        line0 += '|{:}{:10d}{:}  '.format(color,
-                                                          neighb_hists[layer, neighb_size],
-                                                          bcolors.ENDC)
+                        line0 += "|{:}{:10d}{:}  ".format(
+                            color, neighb_hists[layer, neighb_size], bcolors.ENDC
+                        )
 
                     print(line0)
 
-                print('\n**************************************************\n')
-                print('\nchosen neighbors limits: ', percentiles)
+                print("\n**************************************************\n")
+                print("\nchosen neighbors limits: ", percentiles)
                 print()
 
             # Save batch_limit dictionary
             if self.dataset.use_potentials:
-                sampler_method = 'potentials'
+                sampler_method = "potentials"
             else:
-                sampler_method = 'random'
-            key = '{:s}_{:.3f}_{:.3f}_{:d}'.format(sampler_method,
-                                                   self.dataset.config.in_radius,
-                                                   self.dataset.config.first_subsampling_dl,
-                                                   self.dataset.config.batch_num)
+                sampler_method = "random"
+            key = "{:s}_{:.3f}_{:.3f}_{:d}".format(
+                sampler_method,
+                self.dataset.config.in_radius,
+                self.dataset.config.first_subsampling_dl,
+                self.dataset.config.batch_num,
+            )
             batch_lim_dict[key] = float(self.dataset.batch_limit)
-            with open(batch_lim_file, 'wb') as file:
+            with open(batch_lim_file, "wb") as file:
                 pickle.dump(batch_lim_dict, file)
 
             # Save neighb_limit dictionary
             for layer_ind in range(self.dataset.config.num_layers):
-                dl = self.dataset.config.first_subsampling_dl * (2 ** layer_ind)
+                dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
                 if self.dataset.config.deform_layers[layer_ind]:
                     r = dl * self.dataset.config.deform_radius
                 else:
                     r = dl * self.dataset.config.conv_radius
-                key = '{:.3f}_{:.3f}'.format(dl, r)
+                key = "{:.3f}_{:.3f}".format(dl, r)
                 neighb_lim_dict[key] = self.dataset.neighborhood_limits[layer_ind]
-            with open(neighb_lim_file, 'wb') as file:
+            with open(neighb_lim_file, "wb") as file:
                 pickle.dump(neighb_lim_dict, file)
 
-        print('Calibration done in {:.1f}s\n'.format(time.time() - t0))
+        print("Calibration done in {:.1f}s\n".format(time.time() - t0))
         return
 
 
 class NPM3DCustomBatch:
     """Custom batch definition with memory pinning for NPM3D"""
@@ -1397,19 +1518,29 @@
         # Number of layers
         L = (len(input_list) - 7) // 5
 
         # Extract input tensors from the list of numpy array
         ind = 0
-        self.points = [torch.from_numpy(nparray) for nparray in input_list[ind:ind + L]]
+        self.points = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.neighbors = [torch.from_numpy(nparray) for nparray in input_list[ind:ind + L]]
+        self.neighbors = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.pools = [torch.from_numpy(nparray) for nparray in input_list[ind:ind + L]]
+        self.pools = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.upsamples = [torch.from_numpy(nparray) for nparray in input_list[ind:ind + L]]
+        self.upsamples = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.lengths = [torch.from_numpy(nparray) for nparray in input_list[ind:ind + L]]
+        self.lengths = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
         self.features = torch.from_numpy(input_list[ind])
         ind += 1
         self.labels = torch.from_numpy(input_list[ind])
         ind += 1
@@ -1462,54 +1593,54 @@
 
         return self
 
     def unstack_points(self, layer=None):
         """Unstack the points"""
-        return self.unstack_elements('points', layer)
+        return self.unstack_elements("points", layer)
 
     def unstack_neighbors(self, layer=None):
         """Unstack the neighbors indices"""
-        return self.unstack_elements('neighbors', layer)
+        return self.unstack_elements("neighbors", layer)
 
     def unstack_pools(self, layer=None):
         """Unstack the pooling indices"""
-        return self.unstack_elements('pools', layer)
+        return self.unstack_elements("pools", layer)
 
     def unstack_elements(self, element_name, layer=None, to_numpy=True):
         """
         Return a list of the stacked elements in the batch at a certain layer. If no layer is given, then return all
         layers
         """
 
-        if element_name == 'points':
+        if element_name == "points":
             elements = self.points
-        elif element_name == 'neighbors':
+        elif element_name == "neighbors":
             elements = self.neighbors
-        elif element_name == 'pools':
+        elif element_name == "pools":
             elements = self.pools[:-1]
         else:
-            raise ValueError('Unknown element name: {:s}'.format(element_name))
+            raise ValueError("Unknown element name: {:s}".format(element_name))
 
         all_p_list = []
         for layer_i, layer_elems in enumerate(elements):
 
             if layer is None or layer == layer_i:
 
                 i0 = 0
                 p_list = []
-                if element_name == 'pools':
+                if element_name == "pools":
                     lengths = self.lengths[layer_i + 1]
                 else:
                     lengths = self.lengths[layer_i]
 
                 for b_i, length in enumerate(lengths):
 
-                    elem = layer_elems[i0:i0 + length]
-                    if element_name == 'neighbors':
+                    elem = layer_elems[i0 : i0 + length]
+                    if element_name == "neighbors":
                         elem[elem >= self.points[layer_i].shape[0]] = -1
                         elem[elem >= 0] -= i0
-                    elif element_name == 'pools':
+                    elif element_name == "pools":
                         elem[elem >= self.points[layer_i].shape[0]] = -1
                         elem[elem >= 0] -= torch.sum(self.lengths[layer_i][:b_i])
                     i0 += length
 
                     if to_numpy:
@@ -1543,27 +1674,27 @@
         for batch_i, batch in enumerate(loader):
             pc1 = batch.points[1].numpy()
             pc2 = batch.points[2].numpy()
             up1 = batch.upsamples[1].numpy()
 
-            print(pc1.shape, '=>', pc2.shape)
+            print(pc1.shape, "=>", pc2.shape)
             print(up1.shape, np.max(up1))
 
             pc2 = np.vstack((pc2, np.zeros_like(pc2[:1, :])))
 
             # Get neighbors distance
             p0 = pc1[10, :]
             neighbs0 = up1[10, :]
             neighbs0 = pc2[neighbs0, :] - p0
-            d2 = np.sum(neighbs0 ** 2, axis=1)
+            d2 = np.sum(neighbs0**2, axis=1)
 
             print(neighbs0.shape)
             print(neighbs0[:5])
             print(d2[:5])
 
-            print('******************')
-        print('*******************************************')
+            print("******************")
+        print("*******************************************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -1597,18 +1728,18 @@
             mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Console display (only one per second)
             if (t[-1] - last_display) > -1.0:
                 last_display = t[-1]
-                message = 'Step {:08d} -> (ms/batch) {:8.2f} {:8.2f} / batch = {:.2f} - {:.0f}'
-                print(message.format(batch_i,
-                                     1000 * mean_dt[0],
-                                     1000 * mean_dt[1],
-                                     estim_b,
-                                     estim_N))
-
-        print('************* Epoch ended *************')
+                message = "Step {:08d} -> (ms/batch) {:8.2f} {:8.2f} / batch = {:.2f} - {:.0f}"
+                print(
+                    message.format(
+                        batch_i, 1000 * mean_dt[0], 1000 * mean_dt[1], estim_b, estim_N
+                    )
+                )
+
+        print("************* Epoch ended *************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -1622,34 +1753,34 @@
         L = dataset.config.num_layers
 
         for batch_i, batch in enumerate(loader):
 
             # Print characteristics of input tensors
-            print('\nPoints tensors')
+            print("\nPoints tensors")
             for i in range(L):
                 print(batch.points[i].dtype, batch.points[i].shape)
-            print('\nNeigbors tensors')
+            print("\nNeigbors tensors")
             for i in range(L):
                 print(batch.neighbors[i].dtype, batch.neighbors[i].shape)
-            print('\nPools tensors')
+            print("\nPools tensors")
             for i in range(L):
                 print(batch.pools[i].dtype, batch.pools[i].shape)
-            print('\nStack lengths')
+            print("\nStack lengths")
             for i in range(L):
                 print(batch.lengths[i].dtype, batch.lengths[i].shape)
-            print('\nFeatures')
+            print("\nFeatures")
             print(batch.features.dtype, batch.features.shape)
-            print('\nLabels')
+            print("\nLabels")
             print(batch.labels.dtype, batch.labels.shape)
-            print('\nAugment Scales')
+            print("\nAugment Scales")
             print(batch.scales.dtype, batch.scales.shape)
-            print('\nAugment Rotations')
+            print("\nAugment Rotations")
             print(batch.rots.dtype, batch.rots.shape)
-            print('\nModel indices')
+            print("\nModel indices")
             print(batch.model_inds.dtype, batch.model_inds.shape)
 
-            print('\nAre input tensors pinned')
+            print("\nAre input tensors pinned")
             print(batch.neighbors[0].is_pinned())
             print(batch.neighbors[-1].is_pinned())
             print(batch.points[0].is_pinned())
             print(batch.points[-1].is_pinned())
             print(batch.labels.is_pinned())
@@ -1657,11 +1788,11 @@
             print(batch.rots.is_pinned())
             print(batch.model_inds.is_pinned())
 
             show_input_batch(batch)
 
-        print('*******************************************')
+        print("*******************************************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -1689,14 +1820,12 @@
             mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Console display (only one per second)
             if (t[-1] - last_display) > 1.0:
                 last_display = t[-1]
-                message = 'Step {:08d} -> Average timings (ms/batch) {:8.2f} {:8.2f} '
-                print(message.format(batch_i,
-                                     1000 * mean_dt[0],
-                                     1000 * mean_dt[1]))
-
-        print('************* Epoch ended *************')
+                message = "Step {:08d} -> Average timings (ms/batch) {:8.2f} {:8.2f} "
+                print(message.format(batch_i, 1000 * mean_dt[0], 1000 * mean_dt[1]))
+
+        print("************* Epoch ended *************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/S3DIS.py	2024-06-30 22:34:18.064096+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/datasets/S3DIS.py	2024-07-08 11:53:46.555822+00:00
@@ -52,46 +52,48 @@
 
 
 class S3DISDataset(PointCloudDataset):
     """Class to handle S3DIS dataset."""
 
-    def __init__(self, config, set='training', use_potentials=True, load_data=True):
+    def __init__(self, config, set="training", use_potentials=True, load_data=True):
         """
         This dataset is small enough to be stored in-memory, so load all point clouds here
         """
-        PointCloudDataset.__init__(self, 'S3DIS')
+        PointCloudDataset.__init__(self, "S3DIS")
 
         ############
         # Parameters
         ############
 
         # Dict from labels to names
-        self.label_to_names = {0: 'ceiling',
-                               1: 'floor',
-                               2: 'wall',
-                               3: 'beam',
-                               4: 'column',
-                               5: 'window',
-                               6: 'door',
-                               7: 'chair',
-                               8: 'table',
-                               9: 'bookcase',
-                               10: 'sofa',
-                               11: 'board',
-                               12: 'clutter'}
+        self.label_to_names = {
+            0: "ceiling",
+            1: "floor",
+            2: "wall",
+            3: "beam",
+            4: "column",
+            5: "window",
+            6: "door",
+            7: "chair",
+            8: "table",
+            9: "bookcase",
+            10: "sofa",
+            11: "board",
+            12: "clutter",
+        }
 
         # Initialize a bunch of variables concerning class labels
         self.init_labels()
 
         # List of classes ignored during training (can be empty)
         self.ignored_labels = np.array([])
 
         # Dataset folder
-        self.path = '../../Data/S3DIS'
+        self.path = "../../Data/S3DIS"
 
         # Type of task conducted on this dataset
-        self.dataset_task = 'cloud_segmentation'
+        self.dataset_task = "cloud_segmentation"
 
         # Update number of class and data task in configuration
         config.num_classes = self.num_classes - len(self.ignored_labels)
         config.dataset_task = self.dataset_task
 
@@ -103,27 +105,27 @@
 
         # Using potential or random epoch generation
         self.use_potentials = use_potentials
 
         # Path of the training files
-        self.train_path = 'original_ply'
+        self.train_path = "original_ply"
 
         # List of files to process
         ply_path = join(self.path, self.train_path)
 
         # Proportion of validation scenes
-        self.cloud_names = ['Area_1', 'Area_2', 'Area_3', 'Area_4', 'Area_5', 'Area_6']
+        self.cloud_names = ["Area_1", "Area_2", "Area_3", "Area_4", "Area_5", "Area_6"]
         self.all_splits = [0, 1, 2, 3, 4, 5]
         self.validation_split = 4
 
         # Number of models used per epoch
-        if self.set == 'training':
+        if self.set == "training":
             self.epoch_n = config.epoch_steps * config.batch_num
-        elif self.set in ['validation', 'test', 'ERF']:
+        elif self.set in ["validation", "test", "ERF"]:
             self.epoch_n = config.validation_size * config.batch_num
         else:
-            raise ValueError('Unknown set for S3DIS data: ', self.set)
+            raise ValueError("Unknown set for S3DIS data: ", self.set)
 
         # Stop data is not needed
         if not load_data:
             return
 
@@ -138,28 +140,34 @@
         ################
 
         # List of training files
         self.files = []
         for i, f in enumerate(self.cloud_names):
-            if self.set == 'training':
+            if self.set == "training":
                 if self.all_splits[i] != self.validation_split:
-                    self.files += [join(ply_path, f + '.ply')]
-            elif self.set in ['validation', 'test', 'ERF']:
+                    self.files += [join(ply_path, f + ".ply")]
+            elif self.set in ["validation", "test", "ERF"]:
                 if self.all_splits[i] == self.validation_split:
-                    self.files += [join(ply_path, f + '.ply')]
+                    self.files += [join(ply_path, f + ".ply")]
             else:
-                raise ValueError('Unknown set for S3DIS data: ', self.set)
-
-        if self.set == 'training':
-            self.cloud_names = [f for i, f in enumerate(self.cloud_names)
-                                if self.all_splits[i] != self.validation_split]
-        elif self.set in ['validation', 'test', 'ERF']:
-            self.cloud_names = [f for i, f in enumerate(self.cloud_names)
-                                if self.all_splits[i] == self.validation_split]
+                raise ValueError("Unknown set for S3DIS data: ", self.set)
+
+        if self.set == "training":
+            self.cloud_names = [
+                f
+                for i, f in enumerate(self.cloud_names)
+                if self.all_splits[i] != self.validation_split
+            ]
+        elif self.set in ["validation", "test", "ERF"]:
+            self.cloud_names = [
+                f
+                for i, f in enumerate(self.cloud_names)
+                if self.all_splits[i] == self.validation_split
+            ]
 
         if 0 < self.config.first_subsampling_dl <= 0.01:
-            raise ValueError('subsampling_parameter too low (should be over 1 cm')
+            raise ValueError("subsampling_parameter too low (should be over 1 cm")
 
         # Initiate containers
         self.input_trees = []
         self.input_colors = []
         self.input_labels = []
@@ -183,41 +191,51 @@
         if use_potentials:
             self.potentials = []
             self.min_potentials = []
             self.argmin_potentials = []
             for i, tree in enumerate(self.pot_trees):
-                self.potentials += [torch.from_numpy(np.random.rand(tree.data.shape[0]) * 1e-3)]
+                self.potentials += [
+                    torch.from_numpy(np.random.rand(tree.data.shape[0]) * 1e-3)
+                ]
                 min_ind = int(torch.argmin(self.potentials[-1]))
                 self.argmin_potentials += [min_ind]
                 self.min_potentials += [float(self.potentials[-1][min_ind])]
 
             # Share potential memory
-            self.argmin_potentials = torch.from_numpy(np.array(self.argmin_potentials, dtype=np.int64))
-            self.min_potentials = torch.from_numpy(np.array(self.min_potentials, dtype=np.float64))
+            self.argmin_potentials = torch.from_numpy(
+                np.array(self.argmin_potentials, dtype=np.int64)
+            )
+            self.min_potentials = torch.from_numpy(
+                np.array(self.min_potentials, dtype=np.float64)
+            )
             self.argmin_potentials.share_memory_()
             self.min_potentials.share_memory_()
             for i, _ in enumerate(self.pot_trees):
                 self.potentials[i].share_memory_()
 
-            self.worker_waiting = torch.tensor([0 for _ in range(config.input_threads)], dtype=torch.int32)
+            self.worker_waiting = torch.tensor(
+                [0 for _ in range(config.input_threads)], dtype=torch.int32
+            )
             self.worker_waiting.share_memory_()
             self.epoch_inds = None
             self.epoch_i = 0
 
         else:
             self.potentials = None
             self.min_potentials = None
             self.argmin_potentials = None
-            self.epoch_inds = torch.from_numpy(np.zeros((2, self.epoch_n), dtype=np.int64))
+            self.epoch_inds = torch.from_numpy(
+                np.zeros((2, self.epoch_n), dtype=np.int64)
+            )
             self.epoch_i = torch.from_numpy(np.zeros((1,), dtype=np.int64))
             self.epoch_i.share_memory_()
             self.epoch_inds.share_memory_()
 
         self.worker_lock = Lock()
 
         # For ERF visualization, we want only one cloud per batch and no randomness
-        if self.set == 'ERF':
+        if self.set == "ERF":
             self.batch_limit = torch.tensor([1], dtype=torch.float32)
             self.batch_limit.share_memory_()
             np.random.seed(42)
 
         return
@@ -264,36 +282,36 @@
         while True:
 
             t += [time.time()]
 
             if debug_workers:
-                message = ''
+                message = ""
                 for wi in range(info.num_workers):
                     if wi == wid:
-                        message += ' {:}X{:} '.format(bcolors.FAIL, bcolors.ENDC)
+                        message += " {:}X{:} ".format(bcolors.FAIL, bcolors.ENDC)
                     elif self.worker_waiting[wi] == 0:
-                        message += '   '
+                        message += "   "
                     elif self.worker_waiting[wi] == 1:
-                        message += ' | '
+                        message += " | "
                     elif self.worker_waiting[wi] == 2:
-                        message += ' o '
+                        message += " o "
                 print(message)
                 self.worker_waiting[wid] = 0
 
             with self.worker_lock:
 
                 if debug_workers:
-                    message = ''
+                    message = ""
                     for wi in range(info.num_workers):
                         if wi == wid:
-                            message += ' {:}v{:} '.format(bcolors.OKGREEN, bcolors.ENDC)
+                            message += " {:}v{:} ".format(bcolors.OKGREEN, bcolors.ENDC)
                         elif self.worker_waiting[wi] == 0:
-                            message += '   '
+                            message += "   "
                         elif self.worker_waiting[wi] == 1:
-                            message += ' | '
+                            message += " | "
                         elif self.worker_waiting[wi] == 2:
-                            message += ' o '
+                            message += " o "
                     print(message)
                     self.worker_waiting[wid] = 1
 
                 # Get potential minimum
                 cloud_ind = int(torch.argmin(self.min_potentials))
@@ -304,58 +322,64 @@
 
                 # Center point of input region
                 center_point = pot_points[point_ind, :].reshape(1, -1)
 
                 # Add a small noise to center point
-                if self.set != 'ERF':
-                    center_point += np.random.normal(scale=self.config.in_radius / 10, size=center_point.shape)
+                if self.set != "ERF":
+                    center_point += np.random.normal(
+                        scale=self.config.in_radius / 10, size=center_point.shape
+                    )
 
                 # Indices of points in input region
-                pot_inds, dists = self.pot_trees[cloud_ind].query_radius(center_point,
-                                                                         r=self.config.in_radius,
-                                                                         return_distance=True)
+                pot_inds, dists = self.pot_trees[cloud_ind].query_radius(
+                    center_point, r=self.config.in_radius, return_distance=True
+                )
 
                 d2s = np.square(dists[0])
                 pot_inds = pot_inds[0]
 
                 # Update potentials (Tukey weights)
-                if self.set != 'ERF':
+                if self.set != "ERF":
                     tukeys = np.square(1 - d2s / np.square(self.config.in_radius))
                     tukeys[d2s > np.square(self.config.in_radius)] = 0
                     self.potentials[cloud_ind][pot_inds] += tukeys
                     min_ind = torch.argmin(self.potentials[cloud_ind])
-                    self.min_potentials[[cloud_ind]] = self.potentials[cloud_ind][min_ind]
+                    self.min_potentials[[cloud_ind]] = self.potentials[cloud_ind][
+                        min_ind
+                    ]
                     self.argmin_potentials[[cloud_ind]] = min_ind
 
             t += [time.time()]
 
             # Get points from tree structure
             points = np.array(self.input_trees[cloud_ind].data, copy=False)
 
-
             # Indices of points in input region
-            input_inds = self.input_trees[cloud_ind].query_radius(center_point,
-                                                                  r=self.config.in_radius)[0]
+            input_inds = self.input_trees[cloud_ind].query_radius(
+                center_point, r=self.config.in_radius
+            )[0]
 
             t += [time.time()]
 
             # Number collected
             n = input_inds.shape[0]
 
             # Safe check for empty spheres
             if n < 2:
                 failed_attempts += 1
                 if failed_attempts > 100 * self.config.batch_num:
-                    raise ValueError('It seems this dataset only containes empty input spheres')
+                    raise ValueError(
+                        "It seems this dataset only containes empty input spheres"
+                    )
                 t += [time.time()]
                 t += [time.time()]
                 continue
 
             # Collect labels and colors
             input_points = (points[input_inds] - center_point).astype(np.float32)
             input_colors = self.input_colors[cloud_ind][input_inds]
-            if self.set in ['test', 'ERF']:
+            if self.set in ["test", "ERF"]:
                 input_labels = np.zeros(input_points.shape[0])
             else:
                 input_labels = self.input_labels[cloud_ind][input_inds]
                 input_labels = np.array([self.label_to_idx[l] for l in input_labels])
 
@@ -367,11 +391,13 @@
             # Color augmentation
             if np.random.rand() > self.config.augment_color:
                 input_colors *= 0
 
             # Get original height as additional feature
-            input_features = np.hstack((input_colors, input_points[:, 2:] + center_point[:, 2:])).astype(np.float32)
+            input_features = np.hstack(
+                (input_colors, input_points[:, 2:] + center_point[:, 2:])
+            ).astype(np.float32)
 
             t += [time.time()]
 
             # Stack batch
             p_list += [input_points]
@@ -416,11 +442,13 @@
         elif self.config.in_features_dim == 4:
             stacked_features = np.hstack((stacked_features, features[:, :3]))
         elif self.config.in_features_dim == 5:
             stacked_features = np.hstack((stacked_features, features))
         else:
-            raise ValueError('Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)')
+            raise ValueError(
+                "Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)"
+            )
 
         #######################
         # Create network inputs
         #######################
         #
@@ -428,80 +456,94 @@
         #
 
         t += [time.time()]
 
         # Get the whole input list
-        input_list = self.segmentation_inputs(stacked_points,
-                                              stacked_features,
-                                              labels,
-                                              stack_lengths)
+        input_list = self.segmentation_inputs(
+            stacked_points, stacked_features, labels, stack_lengths
+        )
 
         t += [time.time()]
 
         # Add scale and rotation for testing
         input_list += [scales, rots, cloud_inds, point_inds, input_inds]
 
         if debug_workers:
-            message = ''
+            message = ""
             for wi in range(info.num_workers):
                 if wi == wid:
-                    message += ' {:}0{:} '.format(bcolors.OKBLUE, bcolors.ENDC)
+                    message += " {:}0{:} ".format(bcolors.OKBLUE, bcolors.ENDC)
                 elif self.worker_waiting[wi] == 0:
-                    message += '   '
+                    message += "   "
                 elif self.worker_waiting[wi] == 1:
-                    message += ' | '
+                    message += " | "
                 elif self.worker_waiting[wi] == 2:
-                    message += ' o '
+                    message += " o "
             print(message)
             self.worker_waiting[wid] = 2
 
         t += [time.time()]
 
         # Display timings
         debugT = False
         if debugT:
-            print('\n************************\n')
-            print('Timings:')
+            print("\n************************\n")
+            print("Timings:")
             ti = 0
             N = 5
-            mess = 'Init ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Init ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Pots ...... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Pots ...... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Sphere .... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Sphere .... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Collect ... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Collect ... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += 1
-            mess = 'Augment ... {:5.1f}ms /'
-            loop_times = [1000 * (t[ti + N * i + 1] - t[ti + N * i]) for i in range(len(stack_lengths))]
+            mess = "Augment ... {:5.1f}ms /"
+            loop_times = [
+                1000 * (t[ti + N * i + 1] - t[ti + N * i])
+                for i in range(len(stack_lengths))
+            ]
             for dt in loop_times:
-                mess += ' {:5.1f}'.format(dt)
+                mess += " {:5.1f}".format(dt)
             print(mess.format(np.sum(loop_times)))
             ti += N * (len(stack_lengths) - 1) + 1
-            print('concat .... {:5.1f}ms'.format(1000 * (t[ti+1] - t[ti])))
+            print("concat .... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('input ..... {:5.1f}ms'.format(1000 * (t[ti+1] - t[ti])))
+            print("input ..... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('stack ..... {:5.1f}ms'.format(1000 * (t[ti+1] - t[ti])))
+            print("stack ..... {:5.1f}ms".format(1000 * (t[ti + 1] - t[ti])))
             ti += 1
-            print('\n************************\n')
+            print("\n************************\n")
         return input_list
 
     def random_item(self, batch_i):
 
         # Initiate concatanation lists
@@ -526,40 +568,44 @@
 
                 # Update epoch indice
                 self.epoch_i += 1
                 if self.epoch_i >= int(self.epoch_inds.shape[1]):
                     self.epoch_i -= int(self.epoch_inds.shape[1])
-                
 
             # Get points from tree structure
             points = np.array(self.input_trees[cloud_ind].data, copy=False)
 
             # Center point of input region
             center_point = points[point_ind, :].reshape(1, -1)
 
             # Add a small noise to center point
-            if self.set != 'ERF':
-                center_point += np.random.normal(scale=self.config.in_radius / 10, size=center_point.shape)
+            if self.set != "ERF":
+                center_point += np.random.normal(
+                    scale=self.config.in_radius / 10, size=center_point.shape
+                )
 
             # Indices of points in input region
-            input_inds = self.input_trees[cloud_ind].query_radius(center_point,
-                                                                  r=self.config.in_radius)[0]
+            input_inds = self.input_trees[cloud_ind].query_radius(
+                center_point, r=self.config.in_radius
+            )[0]
 
             # Number collected
             n = input_inds.shape[0]
-            
+
             # Safe check for empty spheres
             if n < 2:
                 failed_attempts += 1
                 if failed_attempts > 100 * self.config.batch_num:
-                    raise ValueError('It seems this dataset only containes empty input spheres')
+                    raise ValueError(
+                        "It seems this dataset only containes empty input spheres"
+                    )
                 continue
 
             # Collect labels and colors
             input_points = (points[input_inds] - center_point).astype(np.float32)
             input_colors = self.input_colors[cloud_ind][input_inds]
-            if self.set in ['test', 'ERF']:
+            if self.set in ["test", "ERF"]:
                 input_labels = np.zeros(input_points.shape[0])
             else:
                 input_labels = self.input_labels[cloud_ind][input_inds]
                 input_labels = np.array([self.label_to_idx[l] for l in input_labels])
 
@@ -569,11 +615,13 @@
             # Color augmentation
             if np.random.rand() > self.config.augment_color:
                 input_colors *= 0
 
             # Get original height as additional feature
-            input_features = np.hstack((input_colors, input_points[:, 2:] + center_point[:, 2:])).astype(np.float32)
+            input_features = np.hstack(
+                (input_colors, input_points[:, 2:] + center_point[:, 2:])
+            ).astype(np.float32)
 
             # Stack batch
             p_list += [input_points]
             f_list += [input_features]
             l_list += [input_labels]
@@ -616,111 +664,129 @@
         elif self.config.in_features_dim == 4:
             stacked_features = np.hstack((stacked_features, features[:, :3]))
         elif self.config.in_features_dim == 5:
             stacked_features = np.hstack((stacked_features, features))
         else:
-            raise ValueError('Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)')
+            raise ValueError(
+                "Only accepted input dimensions are 1, 4 and 7 (without and with XYZ)"
+            )
 
         #######################
         # Create network inputs
         #######################
         #
         #   Points, neighbors, pooling indices for each layers
         #
 
         # Get the whole input list
-        input_list = self.segmentation_inputs(stacked_points,
-                                              stacked_features,
-                                              labels,
-                                              stack_lengths)
+        input_list = self.segmentation_inputs(
+            stacked_points, stacked_features, labels, stack_lengths
+        )
 
         # Add scale and rotation for testing
         input_list += [scales, rots, cloud_inds, point_inds, input_inds]
 
         return input_list
 
     def prepare_S3DIS_ply(self):
 
-        print('\nPreparing ply files')
+        print("\nPreparing ply files")
         t0 = time.time()
 
         # Folder for the ply files
         ply_path = join(self.path, self.train_path)
         if not exists(ply_path):
             makedirs(ply_path)
 
         for cloud_name in self.cloud_names:
 
             # Pass if the cloud has already been computed
-            cloud_file = join(ply_path, cloud_name + '.ply')
+            cloud_file = join(ply_path, cloud_name + ".ply")
             if exists(cloud_file):
                 continue
 
             # Get rooms of the current cloud
             cloud_folder = join(self.path, cloud_name)
-            room_folders = [join(cloud_folder, room) for room in listdir(cloud_folder) if isdir(join(cloud_folder, room))]
+            room_folders = [
+                join(cloud_folder, room)
+                for room in listdir(cloud_folder)
+                if isdir(join(cloud_folder, room))
+            ]
 
             # Initiate containers
             cloud_points = np.empty((0, 3), dtype=np.float32)
             cloud_colors = np.empty((0, 3), dtype=np.uint8)
             cloud_classes = np.empty((0, 1), dtype=np.int32)
 
             # Loop over rooms
             for i, room_folder in enumerate(room_folders):
 
-                print('Cloud %s - Room %d/%d : %s' % (cloud_name, i+1, len(room_folders), room_folder.split('/')[-1]))
-
-                for object_name in listdir(join(room_folder, 'Annotations')):
-
-                    if object_name[-4:] == '.txt':
+                print(
+                    "Cloud %s - Room %d/%d : %s"
+                    % (cloud_name, i + 1, len(room_folders), room_folder.split("/")[-1])
+                )
+
+                for object_name in listdir(join(room_folder, "Annotations")):
+
+                    if object_name[-4:] == ".txt":
 
                         # Text file containing point of the object
-                        object_file = join(room_folder, 'Annotations', object_name)
+                        object_file = join(room_folder, "Annotations", object_name)
 
                         # Object class and ID
-                        tmp = object_name[:-4].split('_')[0]
+                        tmp = object_name[:-4].split("_")[0]
                         if tmp in self.name_to_label:
                             object_class = self.name_to_label[tmp]
-                        elif tmp in ['stairs']:
-                            object_class = self.name_to_label['clutter']
+                        elif tmp in ["stairs"]:
+                            object_class = self.name_to_label["clutter"]
                         else:
-                            raise ValueError('Unknown object name: ' + str(tmp))
+                            raise ValueError("Unknown object name: " + str(tmp))
 
                         # Correct bug in S3DIS dataset
-                        if object_name == 'ceiling_1.txt':
-                            with open(object_file, 'r') as f:
+                        if object_name == "ceiling_1.txt":
+                            with open(object_file, "r") as f:
                                 lines = f.readlines()
                             for l_i, line in enumerate(lines):
-                                if '103.0\x100000' in line:
-                                    lines[l_i] = line.replace('103.0\x100000', '103.000000')
-                            with open(object_file, 'w') as f:
+                                if "103.0\x100000" in line:
+                                    lines[l_i] = line.replace(
+                                        "103.0\x100000", "103.000000"
+                                    )
+                            with open(object_file, "w") as f:
                                 f.writelines(lines)
 
                         # Read object points and colors
                         object_data = np.loadtxt(object_file, dtype=np.float32)
 
                         # Stack all data
-                        cloud_points = np.vstack((cloud_points, object_data[:, 0:3].astype(np.float32)))
-                        cloud_colors = np.vstack((cloud_colors, object_data[:, 3:6].astype(np.uint8)))
-                        object_classes = np.full((object_data.shape[0], 1), object_class, dtype=np.int32)
+                        cloud_points = np.vstack(
+                            (cloud_points, object_data[:, 0:3].astype(np.float32))
+                        )
+                        cloud_colors = np.vstack(
+                            (cloud_colors, object_data[:, 3:6].astype(np.uint8))
+                        )
+                        object_classes = np.full(
+                            (object_data.shape[0], 1), object_class, dtype=np.int32
+                        )
                         cloud_classes = np.vstack((cloud_classes, object_classes))
 
             # Save as ply
-            write_ply(cloud_file,
-                      (cloud_points, cloud_colors, cloud_classes),
-                      ['x', 'y', 'z', 'red', 'green', 'blue', 'class'])
-
-        print('Done in {:.1f}s'.format(time.time() - t0))
+            write_ply(
+                cloud_file,
+                (cloud_points, cloud_colors, cloud_classes),
+                ["x", "y", "z", "red", "green", "blue", "class"],
+            )
+
+        print("Done in {:.1f}s".format(time.time() - t0))
         return
 
     def load_subsampled_clouds(self):
 
         # Parameter
         dl = self.config.first_subsampling_dl
 
         # Create path for files
-        tree_path = join(self.path, 'input_{:.3f}'.format(dl))
+        tree_path = join(self.path, "input_{:.3f}".format(dl))
         if not exists(tree_path):
             makedirs(tree_path)
 
         ##############
         # Load KDTrees
@@ -733,74 +799,83 @@
 
             # Get cloud name
             cloud_name = self.cloud_names[i]
 
             # Name of the input files
-            KDTree_file = join(tree_path, '{:s}_KDTree.pkl'.format(cloud_name))
-            sub_ply_file = join(tree_path, '{:s}.ply'.format(cloud_name))
+            KDTree_file = join(tree_path, "{:s}_KDTree.pkl".format(cloud_name))
+            sub_ply_file = join(tree_path, "{:s}.ply".format(cloud_name))
 
             # Check if inputs have already been computed
             if exists(KDTree_file):
-                print('\nFound KDTree for cloud {:s}, subsampled at {:.3f}'.format(cloud_name, dl))
+                print(
+                    "\nFound KDTree for cloud {:s}, subsampled at {:.3f}".format(
+                        cloud_name, dl
+                    )
+                )
 
                 # read ply with data
                 data = read_ply(sub_ply_file)
-                sub_colors = np.vstack((data['red'], data['green'], data['blue'])).T
-                sub_labels = data['class']
+                sub_colors = np.vstack((data["red"], data["green"], data["blue"])).T
+                sub_labels = data["class"]
 
                 # Read pkl with search tree
-                with open(KDTree_file, 'rb') as f:
+                with open(KDTree_file, "rb") as f:
                     search_tree = pickle.load(f)
 
             else:
-                print('\nPreparing KDTree for cloud {:s}, subsampled at {:.3f}'.format(cloud_name, dl))
+                print(
+                    "\nPreparing KDTree for cloud {:s}, subsampled at {:.3f}".format(
+                        cloud_name, dl
+                    )
+                )
 
                 # Read ply file
                 data = read_ply(file_path)
-                points = np.vstack((data['x'], data['y'], data['z'])).T
-                colors = np.vstack((data['red'], data['green'], data['blue'])).T
-                labels = data['class']
+                points = np.vstack((data["x"], data["y"], data["z"])).T
+                colors = np.vstack((data["red"], data["green"], data["blue"])).T
+                labels = data["class"]
 
                 # Subsample cloud
-                sub_points, sub_colors, sub_labels = grid_subsampling(points,
-                                                                      features=colors,
-                                                                      labels=labels,
-                                                                      sampleDl=dl)
+                sub_points, sub_colors, sub_labels = grid_subsampling(
+                    points, features=colors, labels=labels, sampleDl=dl
+                )
 
                 # Rescale float color and squeeze label
                 sub_colors = sub_colors / 255
                 sub_labels = np.squeeze(sub_labels)
 
                 # Get chosen neighborhoods
                 search_tree = KDTree(sub_points, leaf_size=10)
-                #search_tree = nnfln.KDTree(n_neighbors=1, metric='L2', leaf_size=10)
-                #search_tree.fit(sub_points)
+                # search_tree = nnfln.KDTree(n_neighbors=1, metric='L2', leaf_size=10)
+                # search_tree.fit(sub_points)
 
                 # Save KDTree
-                with open(KDTree_file, 'wb') as f:
+                with open(KDTree_file, "wb") as f:
                     pickle.dump(search_tree, f)
 
                 # Save ply
-                write_ply(sub_ply_file,
-                          [sub_points, sub_colors, sub_labels],
-                          ['x', 'y', 'z', 'red', 'green', 'blue', 'class'])
+                write_ply(
+                    sub_ply_file,
+                    [sub_points, sub_colors, sub_labels],
+                    ["x", "y", "z", "red", "green", "blue", "class"],
+                )
 
             # Fill data containers
             self.input_trees += [search_tree]
             self.input_colors += [sub_colors]
             self.input_labels += [sub_labels]
 
             size = sub_colors.shape[0] * 4 * 7
-            print('{:.1f} MB loaded in {:.1f}s'.format(size * 1e-6, time.time() - t0))
+            print("{:.1f} MB loaded in {:.1f}s".format(size * 1e-6, time.time() - t0))
 
         ############################
         # Coarse potential locations
         ############################
 
         # Only necessary for validation and test sets
         if self.use_potentials:
-            print('\nPreparing potentials')
+            print("\nPreparing potentials")
 
             # Restart timer
             t0 = time.time()
 
             pot_dl = self.config.in_radius / 10
@@ -810,47 +885,51 @@
 
                 # Get cloud name
                 cloud_name = self.cloud_names[i]
 
                 # Name of the input files
-                coarse_KDTree_file = join(tree_path, '{:s}_coarse_KDTree.pkl'.format(cloud_name))
+                coarse_KDTree_file = join(
+                    tree_path, "{:s}_coarse_KDTree.pkl".format(cloud_name)
+                )
 
                 # Check if inputs have already been computed
                 if exists(coarse_KDTree_file):
                     # Read pkl with search tree
-                    with open(coarse_KDTree_file, 'rb') as f:
+                    with open(coarse_KDTree_file, "rb") as f:
                         search_tree = pickle.load(f)
 
                 else:
                     # Subsample cloud
                     sub_points = np.array(self.input_trees[cloud_ind].data, copy=False)
-                    coarse_points = grid_subsampling(sub_points.astype(np.float32), sampleDl=pot_dl)
+                    coarse_points = grid_subsampling(
+                        sub_points.astype(np.float32), sampleDl=pot_dl
+                    )
 
                     # Get chosen neighborhoods
                     search_tree = KDTree(coarse_points, leaf_size=10)
 
                     # Save KDTree
-                    with open(coarse_KDTree_file, 'wb') as f:
+                    with open(coarse_KDTree_file, "wb") as f:
                         pickle.dump(search_tree, f)
 
                 # Fill data containers
                 self.pot_trees += [search_tree]
                 cloud_ind += 1
 
-            print('Done in {:.1f}s'.format(time.time() - t0))
+            print("Done in {:.1f}s".format(time.time() - t0))
 
         ######################
         # Reprojection indices
         ######################
 
         # Get number of clouds
         self.num_clouds = len(self.input_trees)
 
         # Only necessary for validation and test sets
-        if self.set in ['validation', 'test']:
-
-            print('\nPreparing reprojection indices for testing')
+        if self.set in ["validation", "test"]:
+
+            print("\nPreparing reprojection indices for testing")
 
             # Get validation/test reprojection indices
             for i, file_path in enumerate(self.files):
 
                 # Restart timer
@@ -858,33 +937,33 @@
 
                 # Get info on this cloud
                 cloud_name = self.cloud_names[i]
 
                 # File name for saving
-                proj_file = join(tree_path, '{:s}_proj.pkl'.format(cloud_name))
+                proj_file = join(tree_path, "{:s}_proj.pkl".format(cloud_name))
 
                 # Try to load previous indices
                 if exists(proj_file):
-                    with open(proj_file, 'rb') as f:
+                    with open(proj_file, "rb") as f:
                         proj_inds, labels = pickle.load(f)
                 else:
                     data = read_ply(file_path)
-                    points = np.vstack((data['x'], data['y'], data['z'])).T
-                    labels = data['class']
+                    points = np.vstack((data["x"], data["y"], data["z"])).T
+                    labels = data["class"]
 
                     # Compute projection inds
                     idxs = self.input_trees[i].query(points, return_distance=False)
-                    #dists, idxs = self.input_trees[i_cloud].kneighbors(points)
+                    # dists, idxs = self.input_trees[i_cloud].kneighbors(points)
                     proj_inds = np.squeeze(idxs).astype(np.int32)
 
                     # Save
-                    with open(proj_file, 'wb') as f:
+                    with open(proj_file, "wb") as f:
                         pickle.dump([proj_inds, labels], f)
 
                 self.test_proj += [proj_inds]
                 self.validation_labels += [labels]
-                print('{:s} done in {:.1f}s'.format(cloud_name, time.time() - t0))
+                print("{:s} done in {:.1f}s".format(cloud_name, time.time() - t0))
 
         print()
         return
 
     def load_evaluation_points(self, file_path):
@@ -892,11 +971,11 @@
         Load points (from test or validation split) on which the metrics should be evaluated
         """
 
         # Get original points
         data = read_ply(file_path)
-        return np.vstack((data['x'], data['y'], data['z'])).T
+        return np.vstack((data["x"], data["y"], data["z"])).T
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Utility classes definition
@@ -911,11 +990,11 @@
 
         # Dataset used by the sampler (no copy is made in memory)
         self.dataset = dataset
 
         # Number of step per epoch
-        if dataset.set == 'training':
+        if dataset.set == "training":
             self.N = dataset.config.epoch_steps
         else:
             self.N = dataset.config.validation_size
 
         return
@@ -942,41 +1021,67 @@
             # Choose random points of each class for each cloud
             epoch_indices = np.zeros((2, 0), dtype=np.int64)
             for label_ind, label in enumerate(self.dataset.label_values):
                 if label not in self.dataset.ignored_labels:
 
-                    # Gather indices of the points with this label in all the input clouds 
+                    # Gather indices of the points with this label in all the input clouds
                     all_label_indices = []
                     for cloud_ind, cloud_labels in enumerate(self.dataset.input_labels):
                         label_indices = np.where(np.equal(cloud_labels, label))[0]
-                        all_label_indices.append(np.vstack((np.full(label_indices.shape, cloud_ind, dtype=np.int64), label_indices)))
+                        all_label_indices.append(
+                            np.vstack(
+                                (
+                                    np.full(
+                                        label_indices.shape, cloud_ind, dtype=np.int64
+                                    ),
+                                    label_indices,
+                                )
+                            )
+                        )
 
                     # Stack them: [2, N1+N2+...]
                     all_label_indices = np.hstack(all_label_indices)
 
                     # Select a a random number amongst them
                     N_inds = all_label_indices.shape[1]
                     if N_inds < random_pick_n:
                         chosen_label_inds = np.zeros((2, 0), dtype=np.int64)
                         while chosen_label_inds.shape[1] < random_pick_n:
-                            chosen_label_inds = np.hstack((chosen_label_inds, all_label_indices[:, np.random.permutation(N_inds)]))
-                        warnings.warn('When choosing random epoch indices (use_potentials=False), \
+                            chosen_label_inds = np.hstack(
+                                (
+                                    chosen_label_inds,
+                                    all_label_indices[:, np.random.permutation(N_inds)],
+                                )
+                            )
+                        warnings.warn(
+                            "When choosing random epoch indices (use_potentials=False), \
                                        class {:d}: {:s} only had {:d} available points, while we \
-                                       needed {:d}. Repeating indices in the same epoch'.format(label,
-                                                                                                self.dataset.label_names[label_ind],
-                                                                                                N_inds,
-                                                                                                random_pick_n))
+                                       needed {:d}. Repeating indices in the same epoch".format(
+                                label,
+                                self.dataset.label_names[label_ind],
+                                N_inds,
+                                random_pick_n,
+                            )
+                        )
 
                     elif N_inds < 50 * random_pick_n:
-                        rand_inds = np.random.choice(N_inds, size=random_pick_n, replace=False)
+                        rand_inds = np.random.choice(
+                            N_inds, size=random_pick_n, replace=False
+                        )
                         chosen_label_inds = all_label_indices[:, rand_inds]
 
                     else:
                         chosen_label_inds = np.zeros((2, 0), dtype=np.int64)
                         while chosen_label_inds.shape[1] < random_pick_n:
-                            rand_inds = np.unique(np.random.choice(N_inds, size=2*random_pick_n, replace=True))
-                            chosen_label_inds = np.hstack((chosen_label_inds, all_label_indices[:, rand_inds]))
+                            rand_inds = np.unique(
+                                np.random.choice(
+                                    N_inds, size=2 * random_pick_n, replace=True
+                                )
+                            )
+                            chosen_label_inds = np.hstack(
+                                (chosen_label_inds, all_label_indices[:, rand_inds])
+                            )
                         chosen_label_inds = chosen_label_inds[:, :random_pick_n]
 
                     # Stack for each label
                     all_epoch_inds = np.hstack((all_epoch_inds, chosen_label_inds))
 
@@ -1062,21 +1167,27 @@
                 mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
                 # Console display (only one per second)
                 if (t[-1] - last_display) > 1.0:
                     last_display = t[-1]
-                    message = 'Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d},  //  {:.1f}ms {:.1f}ms'
-                    print(message.format(i,
-                                         estim_b,
-                                         int(self.dataset.batch_limit),
-                                         1000 * mean_dt[0],
-                                         1000 * mean_dt[1]))
+                    message = "Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d},  //  {:.1f}ms {:.1f}ms"
+                    print(
+                        message.format(
+                            i,
+                            estim_b,
+                            int(self.dataset.batch_limit),
+                            1000 * mean_dt[0],
+                            1000 * mean_dt[1],
+                        )
+                    )
 
             if breaking:
                 break
 
-    def calibration(self, dataloader, untouched_ratio=0.9, verbose=False, force_redo=False):
+    def calibration(
+        self, dataloader, untouched_ratio=0.9, verbose=False, force_redo=False
+    ):
         """
         Method performing batch and neighbors calibration.
             Batch calibration: Set "batch_limit" (the maximum number of points allowed in every batch) so that the
                                average batch size (number of stacked pointclouds) is the one asked.
         Neighbors calibration: Set the "neighborhood_limits" (the maximum number of neighbors allowed in convolutions)
@@ -1085,58 +1196,60 @@
 
         ##############################
         # Previously saved calibration
         ##############################
 
-        print('\nStarting Calibration (use verbose=True for more details)')
+        print("\nStarting Calibration (use verbose=True for more details)")
         t0 = time.time()
 
         redo = force_redo
 
         # Batch limit
         # ***********
 
         # Load batch_limit dictionary
-        batch_lim_file = join(self.dataset.path, 'batch_limits.pkl')
+        batch_lim_file = join(self.dataset.path, "batch_limits.pkl")
         if exists(batch_lim_file):
-            with open(batch_lim_file, 'rb') as file:
+            with open(batch_lim_file, "rb") as file:
                 batch_lim_dict = pickle.load(file)
         else:
             batch_lim_dict = {}
 
         # Check if the batch limit associated with current parameters exists
         if self.dataset.use_potentials:
-            sampler_method = 'potentials'
+            sampler_method = "potentials"
         else:
-            sampler_method = 'random'
-        key = '{:s}_{:.3f}_{:.3f}_{:d}'.format(sampler_method,
-                                               self.dataset.config.in_radius,
-                                               self.dataset.config.first_subsampling_dl,
-                                               self.dataset.config.batch_num)
+            sampler_method = "random"
+        key = "{:s}_{:.3f}_{:.3f}_{:d}".format(
+            sampler_method,
+            self.dataset.config.in_radius,
+            self.dataset.config.first_subsampling_dl,
+            self.dataset.config.batch_num,
+        )
         if not redo and key in batch_lim_dict:
             self.dataset.batch_limit[0] = batch_lim_dict[key]
         else:
             redo = True
 
         if verbose:
-            print('\nPrevious calibration found:')
-            print('Check batch limit dictionary')
+            print("\nPrevious calibration found:")
+            print("Check batch limit dictionary")
             if key in batch_lim_dict:
                 color = bcolors.OKGREEN
                 v = str(int(batch_lim_dict[key]))
             else:
                 color = bcolors.FAIL
-                v = '?'
-            print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                v = "?"
+            print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         # Neighbors limit
         # ***************
 
         # Load neighb_limits dictionary
-        neighb_lim_file = join(self.dataset.path, 'neighbors_limits.pkl')
+        neighb_lim_file = join(self.dataset.path, "neighbors_limits.pkl")
         if exists(neighb_lim_file):
-            with open(neighb_lim_file, 'rb') as file:
+            with open(neighb_lim_file, "rb") as file:
                 neighb_lim_dict = pickle.load(file)
         else:
             neighb_lim_dict = {}
 
         # Check if the limit associated with current parameters exists (for each layer)
@@ -1147,62 +1260,66 @@
             if self.dataset.config.deform_layers[layer_ind]:
                 r = dl * self.dataset.config.deform_radius
             else:
                 r = dl * self.dataset.config.conv_radius
 
-            key = '{:.3f}_{:.3f}'.format(dl, r)
+            key = "{:.3f}_{:.3f}".format(dl, r)
             if key in neighb_lim_dict:
                 neighb_limits += [neighb_lim_dict[key]]
 
         if not redo and len(neighb_limits) == self.dataset.config.num_layers:
             self.dataset.neighborhood_limits = neighb_limits
         else:
             redo = True
 
         if verbose:
-            print('Check neighbors limit dictionary')
+            print("Check neighbors limit dictionary")
             for layer_ind in range(self.dataset.config.num_layers):
                 dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
                 if self.dataset.config.deform_layers[layer_ind]:
                     r = dl * self.dataset.config.deform_radius
                 else:
                     r = dl * self.dataset.config.conv_radius
-                key = '{:.3f}_{:.3f}'.format(dl, r)
+                key = "{:.3f}_{:.3f}".format(dl, r)
 
                 if key in neighb_lim_dict:
                     color = bcolors.OKGREEN
                     v = str(neighb_lim_dict[key])
                 else:
                     color = bcolors.FAIL
-                    v = '?'
-                print('{:}\"{:s}\": {:s}{:}'.format(color, key, v, bcolors.ENDC))
+                    v = "?"
+                print('{:}"{:s}": {:s}{:}'.format(color, key, v, bcolors.ENDC))
 
         if redo:
 
             ############################
             # Neighbors calib parameters
             ############################
 
             # From config parameter, compute higher bound of neighbors number in a neighborhood
-            hist_n = int(np.ceil(4 / 3 * np.pi * (self.dataset.config.deform_radius + 1) ** 3))
+            hist_n = int(
+                np.ceil(4 / 3 * np.pi * (self.dataset.config.deform_radius + 1) ** 3)
+            )
 
             # Histogram of neighborhood sizes
-            neighb_hists = np.zeros((self.dataset.config.num_layers, hist_n), dtype=np.int32)
+            neighb_hists = np.zeros(
+                (self.dataset.config.num_layers, hist_n), dtype=np.int32
+            )
 
             ########################
             # Batch calib parameters
             ########################
 
             # Estimated average batch size and target value
             estim_b = 0
             target_b = self.dataset.config.batch_num
-            
+
             # Expected batch size order of magnitude
             expected_N = 100000
 
             # Calibration parameters. Higher means faster but can also become unstable
-            # Reduce Kp and Kd if your GP Uis small as the total number of points per batch will be smaller 
+            # Reduce Kp and Kd if your GP Uis small as the total number of points per batch will be smaller
             low_pass_T = 100
             Kp = expected_N / 200
             Ki = 0.001 * Kp
             Kd = 5 * Kp
             finer = False
@@ -1227,17 +1344,20 @@
 
             #####################
             # Perform calibration
             #####################
 
-            # number of batch per epoch 
+            # number of batch per epoch
             sample_batches = 999
             for epoch in range((sample_batches // self.N) + 1):
                 for batch_i, batch in enumerate(dataloader):
 
                     # Update neighborhood histogram
-                    counts = [np.sum(neighb_mat.numpy() < neighb_mat.shape[0], axis=1) for neighb_mat in batch.neighbors]
+                    counts = [
+                        np.sum(neighb_mat.numpy() < neighb_mat.shape[0], axis=1)
+                        for neighb_mat in batch.neighbors
+                    ]
                     hists = [np.bincount(c, minlength=hist_n)[:hist_n] for c in counts]
                     neighb_hists += np.vstack(hists)
 
                     # batch length
                     b = len(batch.cloud_inds)
@@ -1248,11 +1368,10 @@
                     # Estimate error (noisy)
                     error = target_b - b
                     error_I += error
                     error_D = error - last_error
                     last_error = error
-
 
                     # Save smooth errors for convergene check
                     smooth_errors.append(target_b - estim_b)
                     if len(smooth_errors) > 30:
                         smooth_errors = smooth_errors[1:]
@@ -1281,14 +1400,12 @@
                     t = time.time()
 
                     # Console display (only one per second)
                     if verbose and (t - last_display) > 1.0:
                         last_display = t
-                        message = 'Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d}'
-                        print(message.format(i,
-                                             estim_b,
-                                             int(self.dataset.batch_limit)))
+                        message = "Step {:5d}  estim_b ={:5.2f} batch_limit ={:7d}"
+                        print(message.format(i, estim_b, int(self.dataset.batch_limit)))
 
                     # Debug plots
                     debug_in.append(int(batch.points[0].shape[0]))
                     debug_out.append(int(self.dataset.batch_limit))
                     debug_b.append(b)
@@ -1299,11 +1416,13 @@
 
             # Plot in case we did not reach convergence
             if not breaking:
                 import matplotlib.pyplot as plt
 
-                print("ERROR: It seems that the calibration have not reached convergence. Here are some plot to understand why:")
+                print(
+                    "ERROR: It seems that the calibration have not reached convergence. Here are some plot to understand why:"
+                )
                 print("If you notice unstability, reduce the expected_N value")
                 print("If convergece is too slow, increase the expected_N value")
 
                 plt.figure()
                 plt.plot(debug_in)
@@ -1313,75 +1432,76 @@
                 plt.plot(debug_b)
                 plt.plot(debug_estim_b)
 
                 plt.show()
 
-                a = 1/0
-
+                a = 1 / 0
 
             # Use collected neighbor histogram to get neighbors limit
             cumsum = np.cumsum(neighb_hists.T, axis=0)
-            percentiles = np.sum(cumsum < (untouched_ratio * cumsum[hist_n - 1, :]), axis=0)
+            percentiles = np.sum(
+                cumsum < (untouched_ratio * cumsum[hist_n - 1, :]), axis=0
+            )
             self.dataset.neighborhood_limits = percentiles
-
 
             if verbose:
 
                 # Crop histogram
                 while np.sum(neighb_hists[:, -1]) == 0:
                     neighb_hists = neighb_hists[:, :-1]
                 hist_n = neighb_hists.shape[1]
 
-                print('\n**************************************************\n')
-                line0 = 'neighbors_num '
+                print("\n**************************************************\n")
+                line0 = "neighbors_num "
                 for layer in range(neighb_hists.shape[0]):
-                    line0 += '|  layer {:2d}  '.format(layer)
+                    line0 += "|  layer {:2d}  ".format(layer)
                 print(line0)
                 for neighb_size in range(hist_n):
-                    line0 = '     {:4d}     '.format(neighb_size)
+                    line0 = "     {:4d}     ".format(neighb_size)
                     for layer in range(neighb_hists.shape[0]):
                         if neighb_size > percentiles[layer]:
                             color = bcolors.FAIL
                         else:
                             color = bcolors.OKGREEN
-                        line0 += '|{:}{:10d}{:}  '.format(color,
-                                                         neighb_hists[layer, neighb_size],
-                                                         bcolors.ENDC)
+                        line0 += "|{:}{:10d}{:}  ".format(
+                            color, neighb_hists[layer, neighb_size], bcolors.ENDC
+                        )
 
                     print(line0)
 
-                print('\n**************************************************\n')
-                print('\nchosen neighbors limits: ', percentiles)
+                print("\n**************************************************\n")
+                print("\nchosen neighbors limits: ", percentiles)
                 print()
 
             # Save batch_limit dictionary
             if self.dataset.use_potentials:
-                sampler_method = 'potentials'
+                sampler_method = "potentials"
             else:
-                sampler_method = 'random'
-            key = '{:s}_{:.3f}_{:.3f}_{:d}'.format(sampler_method,
-                                                   self.dataset.config.in_radius,
-                                                   self.dataset.config.first_subsampling_dl,
-                                                   self.dataset.config.batch_num)
+                sampler_method = "random"
+            key = "{:s}_{:.3f}_{:.3f}_{:d}".format(
+                sampler_method,
+                self.dataset.config.in_radius,
+                self.dataset.config.first_subsampling_dl,
+                self.dataset.config.batch_num,
+            )
             batch_lim_dict[key] = float(self.dataset.batch_limit)
-            with open(batch_lim_file, 'wb') as file:
+            with open(batch_lim_file, "wb") as file:
                 pickle.dump(batch_lim_dict, file)
 
             # Save neighb_limit dictionary
             for layer_ind in range(self.dataset.config.num_layers):
-                dl = self.dataset.config.first_subsampling_dl * (2 ** layer_ind)
+                dl = self.dataset.config.first_subsampling_dl * (2**layer_ind)
                 if self.dataset.config.deform_layers[layer_ind]:
                     r = dl * self.dataset.config.deform_radius
                 else:
                     r = dl * self.dataset.config.conv_radius
-                key = '{:.3f}_{:.3f}'.format(dl, r)
+                key = "{:.3f}_{:.3f}".format(dl, r)
                 neighb_lim_dict[key] = self.dataset.neighborhood_limits[layer_ind]
-            with open(neighb_lim_file, 'wb') as file:
+            with open(neighb_lim_file, "wb") as file:
                 pickle.dump(neighb_lim_dict, file)
 
-
-        print('Calibration done in {:.1f}s\n'.format(time.time() - t0))
+        print("Calibration done in {:.1f}s\n".format(time.time() - t0))
         return
 
 
 class S3DISCustomBatch:
     """Custom batch definition with memory pinning for S3DIS"""
@@ -1394,19 +1514,29 @@
         # Number of layers
         L = (len(input_list) - 7) // 5
 
         # Extract input tensors from the list of numpy array
         ind = 0
-        self.points = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.points = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.neighbors = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.neighbors = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.pools = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.pools = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.upsamples = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.upsamples = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
-        self.lengths = [torch.from_numpy(nparray) for nparray in input_list[ind:ind+L]]
+        self.lengths = [
+            torch.from_numpy(nparray) for nparray in input_list[ind : ind + L]
+        ]
         ind += L
         self.features = torch.from_numpy(input_list[ind])
         ind += 1
         self.labels = torch.from_numpy(input_list[ind])
         ind += 1
@@ -1459,54 +1589,54 @@
 
         return self
 
     def unstack_points(self, layer=None):
         """Unstack the points"""
-        return self.unstack_elements('points', layer)
+        return self.unstack_elements("points", layer)
 
     def unstack_neighbors(self, layer=None):
         """Unstack the neighbors indices"""
-        return self.unstack_elements('neighbors', layer)
+        return self.unstack_elements("neighbors", layer)
 
     def unstack_pools(self, layer=None):
         """Unstack the pooling indices"""
-        return self.unstack_elements('pools', layer)
+        return self.unstack_elements("pools", layer)
 
     def unstack_elements(self, element_name, layer=None, to_numpy=True):
         """
         Return a list of the stacked elements in the batch at a certain layer. If no layer is given, then return all
         layers
         """
 
-        if element_name == 'points':
+        if element_name == "points":
             elements = self.points
-        elif element_name == 'neighbors':
+        elif element_name == "neighbors":
             elements = self.neighbors
-        elif element_name == 'pools':
+        elif element_name == "pools":
             elements = self.pools[:-1]
         else:
-            raise ValueError('Unknown element name: {:s}'.format(element_name))
+            raise ValueError("Unknown element name: {:s}".format(element_name))
 
         all_p_list = []
         for layer_i, layer_elems in enumerate(elements):
 
             if layer is None or layer == layer_i:
 
                 i0 = 0
                 p_list = []
-                if element_name == 'pools':
-                    lengths = self.lengths[layer_i+1]
+                if element_name == "pools":
+                    lengths = self.lengths[layer_i + 1]
                 else:
                     lengths = self.lengths[layer_i]
 
                 for b_i, length in enumerate(lengths):
 
-                    elem = layer_elems[i0:i0 + length]
-                    if element_name == 'neighbors':
+                    elem = layer_elems[i0 : i0 + length]
+                    if element_name == "neighbors":
                         elem[elem >= self.points[layer_i].shape[0]] = -1
                         elem[elem >= 0] -= i0
-                    elif element_name == 'pools':
+                    elif element_name == "pools":
                         elem[elem >= self.points[layer_i].shape[0]] = -1
                         elem[elem >= 0] -= torch.sum(self.lengths[layer_i][:b_i])
                     i0 += length
 
                     if to_numpy:
@@ -1533,36 +1663,35 @@
 
 
 def debug_upsampling(dataset, loader):
     """Shows which labels are sampled according to strategy chosen"""
 
-
     for epoch in range(10):
 
         for batch_i, batch in enumerate(loader):
 
             pc1 = batch.points[1].numpy()
             pc2 = batch.points[2].numpy()
             up1 = batch.upsamples[1].numpy()
 
-            print(pc1.shape, '=>', pc2.shape)
+            print(pc1.shape, "=>", pc2.shape)
             print(up1.shape, np.max(up1))
 
             pc2 = np.vstack((pc2, np.zeros_like(pc2[:1, :])))
 
             # Get neighbors distance
             p0 = pc1[10, :]
             neighbs0 = up1[10, :]
             neighbs0 = pc2[neighbs0, :] - p0
-            d2 = np.sum(neighbs0 ** 2, axis=1)
+            d2 = np.sum(neighbs0**2, axis=1)
 
             print(neighbs0.shape)
             print(neighbs0[:5])
             print(d2[:5])
 
-            print('******************')
-        print('*******************************************')
+            print("******************")
+        print("*******************************************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -1596,25 +1725,24 @@
             mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Console display (only one per second)
             if (t[-1] - last_display) > -1.0:
                 last_display = t[-1]
-                message = 'Step {:08d} -> (ms/batch) {:8.2f} {:8.2f} / batch = {:.2f} - {:.0f}'
-                print(message.format(batch_i,
-                                     1000 * mean_dt[0],
-                                     1000 * mean_dt[1],
-                                     estim_b,
-                                     estim_N))
-
-        print('************* Epoch ended *************')
+                message = "Step {:08d} -> (ms/batch) {:8.2f} {:8.2f} / batch = {:.2f} - {:.0f}"
+                print(
+                    message.format(
+                        batch_i, 1000 * mean_dt[0], 1000 * mean_dt[1], estim_b, estim_N
+                    )
+                )
+
+        print("************* Epoch ended *************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
 def debug_show_clouds(dataset, loader):
-
 
     for epoch in range(10):
 
         clouds = []
         cloud_normals = []
@@ -1623,34 +1751,34 @@
         L = dataset.config.num_layers
 
         for batch_i, batch in enumerate(loader):
 
             # Print characteristics of input tensors
-            print('\nPoints tensors')
+            print("\nPoints tensors")
             for i in range(L):
                 print(batch.points[i].dtype, batch.points[i].shape)
-            print('\nNeigbors tensors')
+            print("\nNeigbors tensors")
             for i in range(L):
                 print(batch.neighbors[i].dtype, batch.neighbors[i].shape)
-            print('\nPools tensors')
+            print("\nPools tensors")
             for i in range(L):
                 print(batch.pools[i].dtype, batch.pools[i].shape)
-            print('\nStack lengths')
+            print("\nStack lengths")
             for i in range(L):
                 print(batch.lengths[i].dtype, batch.lengths[i].shape)
-            print('\nFeatures')
+            print("\nFeatures")
             print(batch.features.dtype, batch.features.shape)
-            print('\nLabels')
+            print("\nLabels")
             print(batch.labels.dtype, batch.labels.shape)
-            print('\nAugment Scales')
+            print("\nAugment Scales")
             print(batch.scales.dtype, batch.scales.shape)
-            print('\nAugment Rotations')
+            print("\nAugment Rotations")
             print(batch.rots.dtype, batch.rots.shape)
-            print('\nModel indices')
+            print("\nModel indices")
             print(batch.model_inds.dtype, batch.model_inds.shape)
 
-            print('\nAre input tensors pinned')
+            print("\nAre input tensors pinned")
             print(batch.neighbors[0].is_pinned())
             print(batch.neighbors[-1].is_pinned())
             print(batch.points[0].is_pinned())
             print(batch.points[-1].is_pinned())
             print(batch.labels.is_pinned())
@@ -1658,11 +1786,11 @@
             print(batch.rots.is_pinned())
             print(batch.model_inds.is_pinned())
 
             show_input_batch(batch)
 
-        print('*******************************************')
+        print("*******************************************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
 
 
@@ -1690,14 +1818,12 @@
             mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Console display (only one per second)
             if (t[-1] - last_display) > 1.0:
                 last_display = t[-1]
-                message = 'Step {:08d} -> Average timings (ms/batch) {:8.2f} {:8.2f} '
-                print(message.format(batch_i,
-                                     1000 * mean_dt[0],
-                                     1000 * mean_dt[1]))
-
-        print('************* Epoch ended *************')
+                message = "Step {:08d} -> Average timings (ms/batch) {:8.2f} {:8.2f} "
+                print(message.format(batch_i, 1000 * mean_dt[0], 1000 * mean_dt[1]))
+
+        print("************* Epoch ended *************")
 
     _, counts = np.unique(dataset.input_labels, return_counts=True)
     print(counts)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/metrics.py	2024-06-30 22:34:18.743545+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/metrics.py	2024-07-08 11:53:46.793823+00:00
@@ -29,10 +29,11 @@
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Utilities
 #       \***************/
 #
+
 
 def fast_confusion(true, pred, label_values=None):
     """
     Fast confusion matrix (100x faster than Scikit learn). But only works if labels are la
     :param true:
@@ -43,64 +44,81 @@
 
     # Ensure data is in the right format
     true = np.squeeze(true)
     pred = np.squeeze(pred)
     if len(true.shape) != 1:
-        raise ValueError('Truth values are stored in a {:d}D array instead of 1D array'. format(len(true.shape)))
+        raise ValueError(
+            "Truth values are stored in a {:d}D array instead of 1D array".format(
+                len(true.shape)
+            )
+        )
     if len(pred.shape) != 1:
-        raise ValueError('Prediction values are stored in a {:d}D array instead of 1D array'. format(len(pred.shape)))
+        raise ValueError(
+            "Prediction values are stored in a {:d}D array instead of 1D array".format(
+                len(pred.shape)
+            )
+        )
     if true.dtype not in [np.int32, np.int64]:
-        raise ValueError('Truth values are {:s} instead of int32 or int64'.format(true.dtype))
+        raise ValueError(
+            "Truth values are {:s} instead of int32 or int64".format(true.dtype)
+        )
     if pred.dtype not in [np.int32, np.int64]:
-        raise ValueError('Prediction values are {:s} instead of int32 or int64'.format(pred.dtype))
+        raise ValueError(
+            "Prediction values are {:s} instead of int32 or int64".format(pred.dtype)
+        )
     true = true.astype(np.int32)
     pred = pred.astype(np.int32)
 
     # Get the label values
     if label_values is None:
         # From data if they are not given
         label_values = np.unique(np.hstack((true, pred)))
     else:
         # Ensure they are good if given
         if label_values.dtype not in [np.int32, np.int64]:
-            raise ValueError('label values are {:s} instead of int32 or int64'.format(label_values.dtype))
+            raise ValueError(
+                "label values are {:s} instead of int32 or int64".format(
+                    label_values.dtype
+                )
+            )
         if len(np.unique(label_values)) < len(label_values):
-            raise ValueError('Given labels are not unique')
+            raise ValueError("Given labels are not unique")
 
     # Sort labels
     label_values = np.sort(label_values)
 
     # Get the number of classes
     num_classes = len(label_values)
 
-    #print(num_classes)
-    #print(label_values)
-    #print(np.max(true))
-    #print(np.max(pred))
-    #print(np.max(true * num_classes + pred))
+    # print(num_classes)
+    # print(label_values)
+    # print(np.max(true))
+    # print(np.max(pred))
+    # print(np.max(true * num_classes + pred))
 
     # Start confusion computations
     if label_values[0] == 0 and label_values[-1] == num_classes - 1:
 
         # Vectorized confusion
         vec_conf = np.bincount(true * num_classes + pred)
 
         # Add possible missing values due to classes not being in pred or true
-        #print(vec_conf.shape)
-        if vec_conf.shape[0] < num_classes ** 2:
-            vec_conf = np.pad(vec_conf, (0, num_classes ** 2 - vec_conf.shape[0]), 'constant')
-        #print(vec_conf.shape)
+        # print(vec_conf.shape)
+        if vec_conf.shape[0] < num_classes**2:
+            vec_conf = np.pad(
+                vec_conf, (0, num_classes**2 - vec_conf.shape[0]), "constant"
+            )
+        # print(vec_conf.shape)
 
         # Reshape confusion in a matrix
         return vec_conf.reshape((num_classes, num_classes))
 
-
     else:
 
         # Ensure no negative classes
         if label_values[0] < 0:
-            raise ValueError('Unsupported negative classes')
+            raise ValueError("Unsupported negative classes")
 
         # Get the data in [0,num_classes[
         label_map = np.zeros((label_values[-1] + 1,), dtype=np.int32)
         for k, v in enumerate(label_values):
             label_map[v] = k
@@ -110,15 +128,18 @@
 
         # Vectorized confusion
         vec_conf = np.bincount(true * num_classes + pred)
 
         # Add possible missing values due to classes not being in pred or true
-        if vec_conf.shape[0] < num_classes ** 2:
-            vec_conf = np.pad(vec_conf, (0, num_classes ** 2 - vec_conf.shape[0]), 'constant')
+        if vec_conf.shape[0] < num_classes**2:
+            vec_conf = np.pad(
+                vec_conf, (0, num_classes**2 - vec_conf.shape[0]), "constant"
+            )
 
         # Reshape confusion in a matrix
         return vec_conf.reshape((num_classes, num_classes))
+
 
 def metrics(confusions, ignore_unclassified=False):
     """
     Computes different metrics from confusion matrices.
     :param confusions: ([..., n_c, n_c] np.int32). Can be any dimension, the confusion matrices should be described by
@@ -126,11 +147,11 @@
     :param ignore_unclassified: (bool). True if the the first class should be ignored in the results
     :return: ([..., n_c] np.float32) precision, recall, F1 score, IoU score
     """
 
     # If the first class (often "unclassified") should be ignored, erase it from the confusion.
-    if (ignore_unclassified):
+    if ignore_unclassified:
         confusions[..., 0, :] = 0
         confusions[..., :, 0] = 0
 
     # Compute TP, FP, FN. This assume that the second to last axis counts the truths (like the first axis of a
     # confusion matrix), and that the last axis counts the predictions (like the second axis of a confusion matrix)
@@ -174,11 +195,13 @@
     smoothed_confusions = confusions.copy()
     if confusions.ndim > 2 and smooth_n > 0:
         for epoch in range(confusions.shape[-3]):
             i0 = max(epoch - smooth_n, 0)
             i1 = min(epoch + smooth_n + 1, confusions.shape[-3])
-            smoothed_confusions[..., epoch, :, :] = np.sum(confusions[..., i0:i1, :, :], axis=-3)
+            smoothed_confusions[..., epoch, :, :] = np.sum(
+                confusions[..., i0:i1, :, :], axis=-3
+            )
 
     # Compute TP, FP, FN. This assume that the second to last axis counts the truths (like the first axis of a
     # confusion matrix), and that the last axis counts the predictions (like the second axis of a confusion matrix)
     TP = np.diagonal(smoothed_confusions, axis1=-2, axis2=-1)
     TP_plus_FP = np.sum(smoothed_confusions, axis=-2)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/evaluate_extended_NPM3D.py	2024-06-30 22:34:18.722734+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/evaluate_extended_NPM3D.py	2024-07-08 11:53:46.971839+00:00
@@ -24,18 +24,18 @@
             self.device = torch.device("cpu")
         net.to(self.device)
 
         # Load checkpoint
         checkpoint = torch.load(chkp_path)
-        net.load_state_dict(checkpoint['model_state_dict'])
-        self.epoch = checkpoint['epoch']
+        net.load_state_dict(checkpoint["model_state_dict"])
+        self.epoch = checkpoint["epoch"]
         net.eval()
         print("Model and training state restored.")
 
-
-
-    def cloud_segmentation_test(self, net, test_loader, config, num_votes=100, debug=False):
+    def cloud_segmentation_test(
+        self, net, test_loader, config, num_votes=100, debug=False
+    ):
         test_smooth = 0.95
         test_radius_ratio = 0.7
         softmax = torch.nn.Softmax(1)
         self.cls = 7
         self.act_list = np.arange(0, 22)
@@ -45,23 +45,37 @@
 
         # Number of classes predicted by the model
         nc_model = config.num_classes
 
         # Initiate global prediction on test/validation cloud. Dim: (M, 3) (Remember this is subsampled one so not original cloud)
-        self.test_probs = [np.zeros((l.shape[0], nc_model)) for l in test_loader.dataset.input_labels]
-        self.test_heatmap = [np.zeros((self.act_list.shape[0], l.shape[0],)) for l in test_loader.dataset.input_labels]
+        self.test_probs = [
+            np.zeros((l.shape[0], nc_model)) for l in test_loader.dataset.input_labels
+        ]
+        self.test_heatmap = [
+            np.zeros(
+                (
+                    self.act_list.shape[0],
+                    l.shape[0],
+                )
+            )
+            for l in test_loader.dataset.input_labels
+        ]
 
         self.test_loader = test_loader
 
         # For validation, label proportions. (used as weights in criterion)
-        if test_loader.dataset.set == 'validation':
+        if test_loader.dataset.set == "validation":
             val_proportions = np.zeros(nc_model, dtype=np.float32)
             i = 0
             for label_value in test_loader.dataset.label_values:
                 if label_value not in test_loader.dataset.ignored_labels:
-                    val_proportions[i] = np.sum([np.sum(labels == label_value)
-                                                 for labels in test_loader.dataset.validation_labels])
+                    val_proportions[i] = np.sum(
+                        [
+                            np.sum(labels == label_value)
+                            for labels in test_loader.dataset.validation_labels
+                        ]
+                    )
                     i += 1
         else:
             val_proportions = None
 
         self.val_proportions = val_proportions
@@ -72,11 +86,11 @@
 
         while True:
             print("Initialize workers.")
             for i, batch in enumerate(test_loader):
                 ti = time.time()
-                if 'cuda' in self.device.type:
+                if "cuda" in self.device.type:
                     batch.to(self.device)
 
                 # Forward pass
                 outputs = net(batch, config)
 
@@ -110,23 +124,28 @@
                 # Also update test_probs for each instance.
                 t0 = time.time()
                 i0 = 0
                 for b_i, length in enumerate(lengths):
                     # Get prediction
-                    points = s_points[i0:i0 + length]
-                    probs = stacked_probs[i0:i0 + length]
-                    inds = in_inds[i0:i0 + length]
+                    points = s_points[i0 : i0 + length]
+                    probs = stacked_probs[i0 : i0 + length]
+                    inds = in_inds[i0 : i0 + length]
                     c_i = cloud_inds[b_i]
 
                     if 0 < test_radius_ratio < 1:
-                        mask = np.sum(points ** 2, axis=1) < (test_radius_ratio * config.in_radius) ** 2
+                        mask = (
+                            np.sum(points**2, axis=1)
+                            < (test_radius_ratio * config.in_radius) ** 2
+                        )
                         inds = inds[mask]
                         probs = probs[mask]
 
                     # Update current probs in subsampled cloud
-                    self.test_probs[c_i][inds] = test_smooth * self.test_probs[c_i][inds] + (
-                            1 - test_smooth) * probs
+                    self.test_probs[c_i][inds] = (
+                        test_smooth * self.test_probs[c_i][inds]
+                        + (1 - test_smooth) * probs
+                    )
                     i0 += length
 
                 t1 = time.time()
 
                 for act in self.act_list:
@@ -141,11 +160,13 @@
                     alpha = torch.sum(grads, axis=0, keepdim=True)
 
                     stacked_heatmap = torch.matmul(cur_act, alpha.T).squeeze()
 
                     # Apply ReLU
-                    stacked_heatmap = torch.maximum(stacked_heatmap, torch.zeros_like(stacked_heatmap))
+                    stacked_heatmap = torch.maximum(
+                        stacked_heatmap, torch.zeros_like(stacked_heatmap)
+                    )
 
                     # Normalize
                     max_val = torch.max(stacked_heatmap, dim=-1, keepdim=True)[0]
                     min_val = torch.min(stacked_heatmap, dim=-1, keepdim=True)[0]
                     stacked_heatmap = (stacked_heatmap - min_val) / (max_val - min_val)
@@ -160,37 +181,46 @@
 
                     t7 = time.time()
 
                     i0 = 0
                     for b_i, length in enumerate(lengths):
-                        points = s_points[i0:i0 + length]
-                        heatmap = stacked_heatmap[i0:i0 + length]
+                        points = s_points[i0 : i0 + length]
+                        heatmap = stacked_heatmap[i0 : i0 + length]
                         c_i = cloud_inds[b_i]
-                        inds = in_inds[i0:i0 + length]
+                        inds = in_inds[i0 : i0 + length]
 
                         if 0 < test_radius_ratio < 1:
-                            mask = np.sum(points ** 2, axis=1) < (test_radius_ratio * config.in_radius) ** 2
+                            mask = (
+                                np.sum(points**2, axis=1)
+                                < (test_radius_ratio * config.in_radius) ** 2
+                            )
                             inds = inds[mask]
                             heatmap = heatmap[mask]
 
                         # Update current heatmap in subsampled cloud
-                        self.test_heatmap[c_i][act][inds] = test_smooth * self.test_heatmap[c_i][act][inds] + (
-                                    1 - test_smooth) * heatmap
+                        self.test_heatmap[c_i][act][inds] = (
+                            test_smooth * self.test_heatmap[c_i][act][inds]
+                            + (1 - test_smooth) * heatmap
+                        )
                         i0 += length
 
                     t8 = time.time()
 
                 t9 = time.time()
 
                 if i % 20 == 0:
-                    message = 'e{:03d}-i{:04d}'
+                    message = "e{:03d}-i{:04d}"
                     print(message.format(test_epoch, i))
 
             # Update min potentials
 
             new_min = torch.min(test_loader.dataset.min_potentials)
-            print('Test epoch {:d}, end. Min potential = {:.1f}'.format(test_epoch, new_min))
+            print(
+                "Test epoch {:d}, end. Min potential = {:.1f}".format(
+                    test_epoch, new_min
+                )
+            )
 
             # Compute confusion for subsampled clouds
             if last_min + 1 < new_min:
                 # Update last min
                 last_min += 1
@@ -199,11 +229,10 @@
                 break
 
         # Voting results on subsampled clouds (NOT ORIGINAL CLOUD)
         self.compute_on_sub_cloud(save=True)
         self.compute_on_full_cloud()
-
 
     def compute_on_sub_cloud(self, save=False):
         print("\nConfusion on subsampled clouds...")
         Confs = []
         for i, file_path in enumerate(self.test_loader.dataset.files):
@@ -212,11 +241,13 @@
             for l_ind, label_value in enumerate(self.test_loader.dataset.label_values):
                 if label_value in self.test_loader.dataset.ignored_labels:
                     probs = np.insert(probs, l_ind, 0, axis=1)
 
             # Predicted labels
-            preds = self.test_loader.dataset.label_values[np.argmax(probs, axis=1)].astype(np.int32)
+            preds = self.test_loader.dataset.label_values[
+                np.argmax(probs, axis=1)
+            ].astype(np.int32)
 
             # Targets
             targets = self.test_loader.dataset.input_labels[i]
 
             # Subsampled points
@@ -227,35 +258,42 @@
                 pgscam = self.test_heatmap[i][act, :]
 
                 pgscam = np.nan_to_num(pgscam, nan=0.0)
 
                 if save:
-                    write_ply(f'./pgscam_results/KPConv_NPM3d_cls_{self.cls}_act_{act+1}.ply',
-                              [sub_points, preds, targets, pgscam], ['x', 'y', 'z', 'preds', 'class', 'pgscam'])
+                    write_ply(
+                        f"./pgscam_results/KPConv_NPM3d_cls_{self.cls}_act_{act+1}.ply",
+                        [sub_points, preds, targets, pgscam],
+                        ["x", "y", "z", "preds", "class", "pgscam"],
+                    )
 
             # Confs
-            Confs += [fast_confusion(targets, preds, self.test_loader.dataset.label_values)]
+            Confs += [
+                fast_confusion(targets, preds, self.test_loader.dataset.label_values)
+            ]
 
         # Regroup confusions
         C = np.sum(np.stack(Confs), axis=0).astype(np.float32)
 
         # Remove ignored labels from confusions
-        for l_ind, label_value in reversed(list(enumerate(self.test_loader.dataset.label_values))):
+        for l_ind, label_value in reversed(
+            list(enumerate(self.test_loader.dataset.label_values))
+        ):
             if label_value in self.test_loader.dataset.ignored_labels:
                 C = np.delete(C, l_ind, axis=0)
                 C = np.delete(C, l_ind, axis=1)
 
         # Rescale with the right number of point per class
         C *= np.expand_dims(self.val_proportions / (np.sum(C, axis=1) + 1e-6), 1)
 
         # Compute IoUs
         IoUs = IoU_from_confusions(C)
         mIoU = np.mean(IoUs)
-        s = '{:5.2f} | '.format(100 * mIoU)
+        s = "{:5.2f} | ".format(100 * mIoU)
         for IoU in IoUs:
-            s += '{:5.2f} '.format(100 * IoU)
-        print(s + '\n')
+            s += "{:5.2f} ".format(100 * IoU)
+        print(s + "\n")
 
     def compute_on_full_cloud(self):
         print("Reprojection for full cloud (KNN with 1 neighbor)")
         # REPROJECTION to compute for full cloud (Uses KNN with 1 neighbor for compute for entire cloud from subsampled cloud)
         proj_probs = []
@@ -271,35 +309,39 @@
         # PROJECTION ON FULL CLOUDS
         print("Confusion on full clouds...")
         Confs = []
         for i, file_path in enumerate(self.test_loader.dataset.files):
             # Get the predicted labels
-            preds = self.test_loader.dataset.label_values[np.argmax(proj_probs[i], axis=1)].astype(np.int32)
+            preds = self.test_loader.dataset.label_values[
+                np.argmax(proj_probs[i], axis=1)
+            ].astype(np.int32)
 
             if self.save_labels:
-                print("You have the preds for full cloud. Save label anywhere you want...")
+                print(
+                    "You have the preds for full cloud. Save label anywhere you want..."
+                )
 
             # Confusion
             targets = self.test_loader.dataset.validation_labels[i]
-            Confs += [fast_confusion(targets, preds, self.test_loader.dataset.label_values)]
+            Confs += [
+                fast_confusion(targets, preds, self.test_loader.dataset.label_values)
+            ]
 
         # Regroup confusions
         C = np.sum(np.stack(Confs), axis=0)
 
         # Remove ignored labels from confusions
-        for l_ind, label_value in reversed(list(enumerate(self.test_loader.dataset.label_values))):
+        for l_ind, label_value in reversed(
+            list(enumerate(self.test_loader.dataset.label_values))
+        ):
             if label_value in self.test_loader.dataset.ignored_labels:
                 C = np.delete(C, l_ind, axis=0)
                 C = np.delete(C, l_ind, axis=1)
 
         IoUs = IoU_from_confusions(C)
         mIoU = np.mean(IoUs)
-        s = '{:5.2f} | '.format(100 * mIoU)
+        s = "{:5.2f} | ".format(100 * mIoU)
         for IoU in IoUs:
-            s += '{:5.2f} '.format(100 * IoU)
-        print('-' * len(s))
+            s += "{:5.2f} ".format(100 * IoU)
+        print("-" * len(s))
         print(s)
-        print('-' * len(s) + '\n')
-
-
-
-
+        print("-" * len(s) + "\n")
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/visualize_deformations.py	2024-06-30 22:34:18.765684+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/visualize_deformations.py	2024-07-08 11:53:47.169747+00:00
@@ -42,61 +42,68 @@
 #
 #           Main Call
 #       \***************/
 #
 
+
 def model_choice(chosen_log):
 
     ###########################
     # Call the test initializer
     ###########################
 
     # Automatically retrieve the last trained model
-    if chosen_log in ['last_ModelNet40', 'last_ShapeNetPart', 'last_S3DIS']:
+    if chosen_log in ["last_ModelNet40", "last_ShapeNetPart", "last_S3DIS"]:
 
         # Dataset name
-        test_dataset = '_'.join(chosen_log.split('_')[1:])
+        test_dataset = "_".join(chosen_log.split("_")[1:])
 
         # List all training logs
-        logs = np.sort([os.path.join('results', f) for f in os.listdir('results') if f.startswith('Log')])
+        logs = np.sort(
+            [
+                os.path.join("results", f)
+                for f in os.listdir("results")
+                if f.startswith("Log")
+            ]
+        )
 
         # Find the last log of asked dataset
         for log in logs[::-1]:
             log_config = Config()
             log_config.load(log)
             if log_config.dataset.startswith(test_dataset):
                 chosen_log = log
                 break
 
-        if chosen_log in ['last_ModelNet40', 'last_ShapeNetPart', 'last_S3DIS']:
+        if chosen_log in ["last_ModelNet40", "last_ShapeNetPart", "last_S3DIS"]:
             raise ValueError('No log of the dataset "' + test_dataset + '" found')
 
     # Check if log exists
     if not os.path.exists(chosen_log):
-        raise ValueError('The given log does not exists: ' + chosen_log)
+        raise ValueError("The given log does not exists: " + chosen_log)
 
     return chosen_log
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Main Call
 #       \***************/
 #
 
-if __name__ == '__main__':
+if __name__ == "__main__":
 
     ###############################
     # Choose the model to visualize
     ###############################
 
     #   Here you can choose which model you want to test with the variable test_model. Here are the possible values :
     #
     #       > 'last_XXX': Automatically retrieve the last trained model on dataset XXX
     #       > 'results/Log_YYYY-MM-DD_HH-MM-SS': Directly provide the path of a trained model
 
-    chosen_log = 'results/Log_2020-04-23_19-42-18'
+    chosen_log = "results/Log_2020-04-23_19-42-18"
 
     # Choose the index of the checkpoint to load OR None if you want to load the current checkpoint
     chkp_idx = None
 
     # Eventually you can choose which feature is visualized (index of the deform convolution in the network)
@@ -108,29 +115,29 @@
     ############################
     # Initialize the environment
     ############################
 
     # Set which gpu is going to be used
-    GPU_ID = '0'
+    GPU_ID = "0"
 
     # Set GPU visible device
-    os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID
+    os.environ["CUDA_VISIBLE_DEVICES"] = GPU_ID
 
     ###############
     # Previous chkp
     ###############
 
     # Find all checkpoints in the chosen training folder
-    chkp_path = os.path.join(chosen_log, 'checkpoints')
-    chkps = [f for f in os.listdir(chkp_path) if f[:4] == 'chkp']
+    chkp_path = os.path.join(chosen_log, "checkpoints")
+    chkps = [f for f in os.listdir(chkp_path) if f[:4] == "chkp"]
 
     # Find which snapshot to restore
     if chkp_idx is None:
-        chosen_chkp = 'current_chkp.tar'
+        chosen_chkp = "current_chkp.tar"
     else:
         chosen_chkp = np.sort(chkps)[chkp_idx]
-    chosen_chkp = os.path.join(chosen_log, 'checkpoints', chosen_chkp)
+    chosen_chkp = os.path.join(chosen_log, "checkpoints", chosen_chkp)
 
     # Initialize configuration class
     config = Config()
     config.load(chosen_log)
 
@@ -148,55 +155,56 @@
     ##############
     # Prepare Data
     ##############
 
     print()
-    print('Data Preparation')
-    print('****************')
+    print("Data Preparation")
+    print("****************")
 
     # Initiate dataset
-    if config.dataset.startswith('ModelNet40'):
+    if config.dataset.startswith("ModelNet40"):
         test_dataset = ModelNet40Dataset(config, train=False)
         test_sampler = ModelNet40Sampler(test_dataset)
         collate_fn = ModelNet40Collate
-    elif config.dataset == 'S3DIS':
-        test_dataset = S3DISDataset(config, set='validation', use_potentials=True)
+    elif config.dataset == "S3DIS":
+        test_dataset = S3DISDataset(config, set="validation", use_potentials=True)
         test_sampler = S3DISSampler(test_dataset)
         collate_fn = S3DISCollate
     else:
-        raise ValueError('Unsupported dataset : ' + config.dataset)
+        raise ValueError("Unsupported dataset : " + config.dataset)
 
     # Data loader
-    test_loader = DataLoader(test_dataset,
-                             batch_size=1,
-                             sampler=test_sampler,
-                             collate_fn=collate_fn,
-                             num_workers=config.input_threads,
-                             pin_memory=True)
+    test_loader = DataLoader(
+        test_dataset,
+        batch_size=1,
+        sampler=test_sampler,
+        collate_fn=collate_fn,
+        num_workers=config.input_threads,
+        pin_memory=True,
+    )
 
     # Calibrate samplers
     test_sampler.calibration(test_loader, verbose=True)
 
-    print('\nModel Preparation')
-    print('*****************')
+    print("\nModel Preparation")
+    print("*****************")
 
     # Define network model
     t1 = time.time()
-    if config.dataset_task == 'classification':
+    if config.dataset_task == "classification":
         net = KPCNN(config)
-    elif config.dataset_task in ['cloud_segmentation', 'slam_segmentation']:
+    elif config.dataset_task in ["cloud_segmentation", "slam_segmentation"]:
         net = KPFCNN(config, test_dataset.label_values, test_dataset.ignored_labels)
     else:
-        raise ValueError('Unsupported dataset_task for deformation visu: ' + config.dataset_task)
+        raise ValueError(
+            "Unsupported dataset_task for deformation visu: " + config.dataset_task
+        )
 
     # Define a visualizer class
     visualizer = ModelVisualizer(net, config, chkp_path=chosen_chkp, on_gpu=False)
-    print('Done in {:.1f}s\n'.format(time.time() - t1))
-
-    print('\nStart visualization')
-    print('*******************')
+    print("Done in {:.1f}s\n".format(time.time() - t1))
+
+    print("\nStart visualization")
+    print("*******************")
 
     # Training
     visualizer.show_deformable_kernels(net, test_loader, config, deform_idx)
-
-
-
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/ply.py	2024-06-30 22:34:18.743545+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/ply.py	2024-07-08 11:53:47.168772+00:00
@@ -26,32 +26,33 @@
 import numpy as np
 import sys
 
 
 # Define PLY types
-ply_dtypes = dict([
-    (b'int8', 'i1'),
-    (b'char', 'i1'),
-    (b'uint8', 'u1'),
-    (b'uchar', 'u1'),
-    (b'int16', 'i2'),
-    (b'short', 'i2'),
-    (b'uint16', 'u2'),
-    (b'ushort', 'u2'),
-    (b'int32', 'i4'),
-    (b'int', 'i4'),
-    (b'uint32', 'u4'),
-    (b'uint', 'u4'),
-    (b'float32', 'f4'),
-    (b'float', 'f4'),
-    (b'float64', 'f8'),
-    (b'double', 'f8')
-])
+ply_dtypes = dict(
+    [
+        (b"int8", "i1"),
+        (b"char", "i1"),
+        (b"uint8", "u1"),
+        (b"uchar", "u1"),
+        (b"int16", "i2"),
+        (b"short", "i2"),
+        (b"uint16", "u2"),
+        (b"ushort", "u2"),
+        (b"int32", "i4"),
+        (b"int", "i4"),
+        (b"uint32", "u4"),
+        (b"uint", "u4"),
+        (b"float32", "f4"),
+        (b"float", "f4"),
+        (b"float64", "f8"),
+        (b"double", "f8"),
+    ]
+)
 
 # Numpy reader format
-valid_formats = {'ascii': '', 'binary_big_endian': '>',
-                 'binary_little_endian': '<'}
+valid_formats = {"ascii": "", "binary_big_endian": ">", "binary_little_endian": "<"}
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Functions
@@ -63,18 +64,18 @@
     # Variables
     line = []
     properties = []
     num_points = None
 
-    while b'end_header' not in line and line != b'':
+    while b"end_header" not in line and line != b"":
         line = plyfile.readline()
 
-        if b'element' in line:
+        if b"element" in line:
             line = line.split()
             num_points = int(line[2])
 
-        elif b'property' in line:
+        elif b"property" in line:
             line = line.split()
             properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))
 
     return num_points, properties
 
@@ -85,32 +86,31 @@
     vertex_properties = []
     num_points = None
     num_faces = None
     current_element = None
 
-
-    while b'end_header' not in line and line != b'':
+    while b"end_header" not in line and line != b"":
         line = plyfile.readline()
 
         # Find point element
-        if b'element vertex' in line:
-            current_element = 'vertex'
+        if b"element vertex" in line:
+            current_element = "vertex"
             line = line.split()
             num_points = int(line[2])
 
-        elif b'element face' in line:
-            current_element = 'face'
+        elif b"element face" in line:
+            current_element = "face"
             line = line.split()
             num_faces = int(line[2])
 
-        elif b'property' in line:
-            if current_element == 'vertex':
+        elif b"property" in line:
+            if current_element == "vertex":
                 line = line.split()
                 vertex_properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))
-            elif current_element == 'vertex':
-                if not line.startswith('property list uchar int'):
-                    raise ValueError('Unsupported faces property : ' + line)
+            elif current_element == "vertex":
+                if not line.startswith("property list uchar int"):
+                    raise ValueError("Unsupported faces property : " + line)
 
     return num_points, num_faces, vertex_properties
 
 
 def read_ply(filename, triangular_mesh=False):
@@ -138,31 +138,30 @@
     Read the file
 
     >>> data = read_ply('example.ply')
     >>> values = data['values']
     array([0, 0, 1, 1, 0])
-    
+
     >>> points = np.vstack((data['x'], data['y'], data['z'])).T
     array([[ 0.466  0.595  0.324]
            [ 0.538  0.407  0.654]
            [ 0.850  0.018  0.988]
            [ 0.395  0.394  0.363]
            [ 0.873  0.996  0.092]])
 
     """
 
-    with open(filename, 'rb') as plyfile:
-
+    with open(filename, "rb") as plyfile:
 
         # Check if the file start with ply
-        if b'ply' not in plyfile.readline():
-            raise ValueError('The file does not start whith the word ply')
+        if b"ply" not in plyfile.readline():
+            raise ValueError("The file does not start whith the word ply")
 
         # get binary_little/big or ascii
         fmt = plyfile.readline().split()[1].decode()
         if fmt == "ascii":
-            raise ValueError('The file is not binary')
+            raise ValueError("The file is not binary")
 
         # get extension for building the numpy dtypes
         ext = valid_formats[fmt]
 
         # PointCloud reader vs mesh reader
@@ -173,18 +172,20 @@
 
             # Get point data
             vertex_data = np.fromfile(plyfile, dtype=properties, count=num_points)
 
             # Get face data
-            face_properties = [('k', ext + 'u1'),
-                               ('v1', ext + 'i4'),
-                               ('v2', ext + 'i4'),
-                               ('v3', ext + 'i4')]
+            face_properties = [
+                ("k", ext + "u1"),
+                ("v1", ext + "i4"),
+                ("v2", ext + "i4"),
+                ("v3", ext + "i4"),
+            ]
             faces_data = np.fromfile(plyfile, dtype=face_properties, count=num_faces)
 
             # Return vertex data and concatenated faces
-            faces = np.vstack((faces_data['v1'], faces_data['v2'], faces_data['v3'])).T
+            faces = np.vstack((faces_data["v1"], faces_data["v2"], faces_data["v3"])).T
             data = [vertex_data, faces]
 
         else:
 
             # Parse header
@@ -200,17 +201,17 @@
 
     # List of lines to write
     lines = []
 
     # First line describing element vertex
-    lines.append('element vertex %d' % field_list[0].shape[0])
+    lines.append("element vertex %d" % field_list[0].shape[0])
 
     # Properties lines
     i = 0
     for fields in field_list:
         for field in fields.T:
-            lines.append('property %s %s' % (field.dtype.name, field_names[i]))
+            lines.append("property %s %s" % (field.dtype.name, field_names[i]))
             i += 1
 
     return lines
 
 
@@ -219,20 +220,20 @@
     Write ".ply" files
 
     Parameters
     ----------
     filename : string
-        the name of the file to which the data is saved. A '.ply' extension will be appended to the 
+        the name of the file to which the data is saved. A '.ply' extension will be appended to the
         file name if it does no already have one.
 
     field_list : list, tuple, numpy array
-        the fields to be saved in the ply file. Either a numpy array, a list of numpy arrays or a 
-        tuple of numpy arrays. Each 1D numpy array and each column of 2D numpy arrays are considered 
-        as one field. 
+        the fields to be saved in the ply file. Either a numpy array, a list of numpy arrays or a
+        tuple of numpy arrays. Each 1D numpy array and each column of 2D numpy arrays are considered
+        as one field.
 
     field_names : list
-        the name of each fields as a list of strings. Has to be the same length as the number of 
+        the name of each fields as a list of strings. Has to be the same length as the number of
         fields.
 
     Examples
     --------
     >>> points = np.random.rand(10, 3)
@@ -246,60 +247,64 @@
     >>> write_ply('example3.ply', [points, colors, values], field_names)
 
     """
 
     # Format list input to the right form
-    field_list = list(field_list) if (type(field_list) == list or type(field_list) == tuple) else list((field_list,))
+    field_list = (
+        list(field_list)
+        if (type(field_list) == list or type(field_list) == tuple)
+        else list((field_list,))
+    )
     for i, field in enumerate(field_list):
         if field.ndim < 2:
             field_list[i] = field.reshape(-1, 1)
         if field.ndim > 2:
-            print('fields have more than 2 dimensions')
-            return False    
+            print("fields have more than 2 dimensions")
+            return False
 
     # check all fields have the same number of data
     n_points = [field.shape[0] for field in field_list]
     if not np.all(np.equal(n_points, n_points[0])):
-        print('wrong field dimensions')
-        return False    
+        print("wrong field dimensions")
+        return False
 
     # Check if field_names and field_list have same nb of column
     n_fields = np.sum([field.shape[1] for field in field_list])
-    if (n_fields != len(field_names)):
-        print('wrong number of field names')
+    if n_fields != len(field_names):
+        print("wrong number of field names")
         return False
 
     # Add extension if not there
-    if not filename.endswith('.ply'):
-        filename += '.ply'
+    if not filename.endswith(".ply"):
+        filename += ".ply"
 
     # open in text mode to write the header
-    with open(filename, 'w') as plyfile:
+    with open(filename, "w") as plyfile:
 
         # First magical word
-        header = ['ply']
+        header = ["ply"]
 
         # Encoding format
-        header.append('format binary_' + sys.byteorder + '_endian 1.0')
+        header.append("format binary_" + sys.byteorder + "_endian 1.0")
 
         # Points properties description
         header.extend(header_properties(field_list, field_names))
 
         # Add faces if needded
         if triangular_faces is not None:
-            header.append('element face {:d}'.format(triangular_faces.shape[0]))
-            header.append('property list uchar int vertex_indices')
+            header.append("element face {:d}".format(triangular_faces.shape[0]))
+            header.append("property list uchar int vertex_indices")
 
         # End of header
-        header.append('end_header')
+        header.append("end_header")
 
         # Write all lines
         for line in header:
             plyfile.write("%s\n" % line)
 
     # open in binary/append to use tofile
-    with open(filename, 'ab') as plyfile:
+    with open(filename, "ab") as plyfile:
 
         # Create a structured array
         i = 0
         type_list = []
         for fields in field_list:
@@ -315,41 +320,41 @@
 
         data.tofile(plyfile)
 
         if triangular_faces is not None:
             triangular_faces = triangular_faces.astype(np.int32)
-            type_list = [('k', 'uint8')] + [(str(ind), 'int32') for ind in range(3)]
+            type_list = [("k", "uint8")] + [(str(ind), "int32") for ind in range(3)]
             data = np.empty(triangular_faces.shape[0], dtype=type_list)
-            data['k'] = np.full((triangular_faces.shape[0],), 3, dtype=np.uint8)
-            data['0'] = triangular_faces[:, 0]
-            data['1'] = triangular_faces[:, 1]
-            data['2'] = triangular_faces[:, 2]
+            data["k"] = np.full((triangular_faces.shape[0],), 3, dtype=np.uint8)
+            data["0"] = triangular_faces[:, 0]
+            data["1"] = triangular_faces[:, 1]
+            data["2"] = triangular_faces[:, 2]
             data.tofile(plyfile)
 
     return True
 
 
 def describe_element(name, df):
-    """ Takes the columns of the dataframe and builds a ply-like description
+    """Takes the columns of the dataframe and builds a ply-like description
 
     Parameters
     ----------
     name: str
     df: pandas DataFrame
 
     Returns
     -------
     element: list[str]
     """
-    property_formats = {'f': 'float', 'u': 'uchar', 'i': 'int'}
-    element = ['element ' + name + ' ' + str(len(df))]
-
-    if name == 'face':
+    property_formats = {"f": "float", "u": "uchar", "i": "int"}
+    element = ["element " + name + " " + str(len(df))]
+
+    if name == "face":
         element.append("property list uchar int points_indices")
 
     else:
         for i in range(len(df.columns)):
             # get first letter of dtype to infer format
             f = property_formats[str(df.dtypes[i])[0]]
-            element.append('property ' + f + ' ' + df.columns.values[i])
-
-    return element
\ No newline at end of file
+            element.append("property " + f + " " + df.columns.values[i])
+
+    return element
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/mayavi_visu.py	2024-06-30 22:34:18.738364+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/mayavi_visu.py	2024-07-08 11:53:47.189298+00:00
@@ -45,11 +45,11 @@
     ###########################
     # Interactive visualization
     ###########################
 
     # Create figure for features
-    fig1 = mlab.figure('Models', bgcolor=(1, 1, 1), size=(1000, 800))
+    fig1 = mlab.figure("Models", bgcolor=(1, 1, 1), size=(1000, 800))
     fig1.scene.parallel_projection = False
 
     # Indices
     global file_i
     file_i = 0
@@ -64,44 +64,46 @@
 
         # Rescale points for visu
         points = (points * 1.5 + np.array([1.0, 1.0, 1.0])) * 50.0
 
         # Show point clouds colorized with activations
-        activations = mlab.points3d(points[:, 0],
-                                    points[:, 1],
-                                    points[:, 2],
-                                    points[:, 2],
-                                    scale_factor=3.0,
-                                    scale_mode='none',
-                                    figure=fig1)
+        activations = mlab.points3d(
+            points[:, 0],
+            points[:, 1],
+            points[:, 2],
+            points[:, 2],
+            scale_factor=3.0,
+            scale_mode="none",
+            figure=fig1,
+        )
 
         # New title
         mlab.title(str(file_i), color=(0, 0, 0), size=0.3, height=0.01)
-        text = '<--- (press g for previous)' + 50 * ' ' + '(press h for next) --->'
+        text = "<--- (press g for previous)" + 50 * " " + "(press h for next) --->"
         mlab.text(0.01, 0.01, text, color=(0, 0, 0), width=0.98)
         mlab.orientation_axes()
 
         return
 
     def keyboard_callback(vtk_obj, event):
         global file_i
 
-        if vtk_obj.GetKeyCode() in ['g', 'G']:
+        if vtk_obj.GetKeyCode() in ["g", "G"]:
 
             file_i = (file_i - 1) % len(all_points)
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in ['h', 'H']:
+        elif vtk_obj.GetKeyCode() in ["h", "H"]:
 
             file_i = (file_i + 1) % len(all_points)
             update_scene()
 
         return
 
     # Draw a first plot
     update_scene()
-    fig1.scene.interactor.add_observer('KeyPressEvent', keyboard_callback)
+    fig1.scene.interactor.add_observer("KeyPressEvent", keyboard_callback)
     mlab.show()
 
 
 def show_ModelNet_examples(clouds, cloud_normals=None, cloud_labels=None):
     from mayavi import mlab
@@ -109,11 +111,11 @@
     ###########################
     # Interactive visualization
     ###########################
 
     # Create figure for features
-    fig1 = mlab.figure('Models', bgcolor=(1, 1, 1), size=(1000, 800))
+    fig1 = mlab.figure("Models", bgcolor=(1, 1, 1), size=(1000, 800))
     fig1.scene.parallel_projection = False
 
     if cloud_labels is None:
         cloud_labels = [points[:, 2] for points in clouds]
 
@@ -137,56 +139,60 @@
 
         # Rescale points for visu
         points = (points * 1.5 + np.array([1.0, 1.0, 1.0])) * 50.0
 
         # Show point clouds colorized with activations
-        activations = mlab.points3d(points[:, 0],
-                                    points[:, 1],
-                                    points[:, 2],
-                                    labels,
-                                    scale_factor=3.0,
-                                    scale_mode='none',
-                                    figure=fig1)
+        activations = mlab.points3d(
+            points[:, 0],
+            points[:, 1],
+            points[:, 2],
+            labels,
+            scale_factor=3.0,
+            scale_mode="none",
+            figure=fig1,
+        )
         if normals is not None and show_normals:
-            activations = mlab.quiver3d(points[:, 0],
-                                        points[:, 1],
-                                        points[:, 2],
-                                        normals[:, 0],
-                                        normals[:, 1],
-                                        normals[:, 2],
-                                        scale_factor=10.0,
-                                        scale_mode='none',
-                                        figure=fig1)
+            activations = mlab.quiver3d(
+                points[:, 0],
+                points[:, 1],
+                points[:, 2],
+                normals[:, 0],
+                normals[:, 1],
+                normals[:, 2],
+                scale_factor=10.0,
+                scale_mode="none",
+                figure=fig1,
+            )
 
         # New title
         mlab.title(str(file_i), color=(0, 0, 0), size=0.3, height=0.01)
-        text = '<--- (press g for previous)' + 50 * ' ' + '(press h for next) --->'
+        text = "<--- (press g for previous)" + 50 * " " + "(press h for next) --->"
         mlab.text(0.01, 0.01, text, color=(0, 0, 0), width=0.98)
         mlab.orientation_axes()
 
         return
 
     def keyboard_callback(vtk_obj, event):
         global file_i, show_normals
 
-        if vtk_obj.GetKeyCode() in ['g', 'G']:
+        if vtk_obj.GetKeyCode() in ["g", "G"]:
             file_i = (file_i - 1) % len(clouds)
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in ['h', 'H']:
+        elif vtk_obj.GetKeyCode() in ["h", "H"]:
             file_i = (file_i + 1) % len(clouds)
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in ['n', 'N']:
+        elif vtk_obj.GetKeyCode() in ["n", "N"]:
             show_normals = not show_normals
             update_scene()
 
         return
 
     # Draw a first plot
     update_scene()
-    fig1.scene.interactor.add_observer('KeyPressEvent', keyboard_callback)
+    fig1.scene.interactor.add_observer("KeyPressEvent", keyboard_callback)
     mlab.show()
 
 
 def show_neighbors(query, supports, neighbors):
     from mayavi import mlab
@@ -194,11 +200,11 @@
     ###########################
     # Interactive visualization
     ###########################
 
     # Create figure for features
-    fig1 = mlab.figure('Models', bgcolor=(1, 1, 1), size=(1000, 800))
+    fig1 = mlab.figure("Models", bgcolor=(1, 1, 1), size=(1000, 800))
     fig1.scene.parallel_projection = False
 
     # Indices
     global file_i
     file_i = 0
@@ -210,63 +216,67 @@
 
         # Rescale points for visu
         p1 = (query * 1.5 + np.array([1.0, 1.0, 1.0])) * 50.0
         p2 = (supports * 1.5 + np.array([1.0, 1.0, 1.0])) * 50.0
 
-        l1 = p1[:, 2]*0
+        l1 = p1[:, 2] * 0
         l1[file_i] = 1
 
-        l2 = p2[:, 2]*0 + 2
+        l2 = p2[:, 2] * 0 + 2
         l2[neighbors[file_i]] = 3
 
         # Show point clouds colorized with activations
-        activations = mlab.points3d(p1[:, 0],
-                                    p1[:, 1],
-                                    p1[:, 2],
-                                    l1,
-                                    scale_factor=2.0,
-                                    scale_mode='none',
-                                    vmin=0.0,
-                                    vmax=3.0,
-                                    figure=fig1)
-
-        activations = mlab.points3d(p2[:, 0],
-                                    p2[:, 1],
-                                    p2[:, 2],
-                                    l2,
-                                    scale_factor=3.0,
-                                    scale_mode='none',
-                                    vmin=0.0,
-                                    vmax=3.0,
-                                    figure=fig1)
+        activations = mlab.points3d(
+            p1[:, 0],
+            p1[:, 1],
+            p1[:, 2],
+            l1,
+            scale_factor=2.0,
+            scale_mode="none",
+            vmin=0.0,
+            vmax=3.0,
+            figure=fig1,
+        )
+
+        activations = mlab.points3d(
+            p2[:, 0],
+            p2[:, 1],
+            p2[:, 2],
+            l2,
+            scale_factor=3.0,
+            scale_mode="none",
+            vmin=0.0,
+            vmax=3.0,
+            figure=fig1,
+        )
 
         # New title
         mlab.title(str(file_i), color=(0, 0, 0), size=0.3, height=0.01)
-        text = '<--- (press g for previous)' + 50 * ' ' + '(press h for next) --->'
+        text = "<--- (press g for previous)" + 50 * " " + "(press h for next) --->"
         mlab.text(0.01, 0.01, text, color=(0, 0, 0), width=0.98)
         mlab.orientation_axes()
 
         return
 
     def keyboard_callback(vtk_obj, event):
         global file_i
 
-        if vtk_obj.GetKeyCode() in ['g', 'G']:
+        if vtk_obj.GetKeyCode() in ["g", "G"]:
 
             file_i = (file_i - 1) % len(query)
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in ['h', 'H']:
+        elif vtk_obj.GetKeyCode() in ["h", "H"]:
 
             file_i = (file_i + 1) % len(query)
             update_scene()
 
         return
 
     # Draw a first plot
     update_scene()
-    fig1.scene.interactor.add_observer('KeyPressEvent', keyboard_callback)
+    fig1.scene.interactor.add_observer("KeyPressEvent", keyboard_callback)
     mlab.show()
 
 
 def show_input_batch(batch):
     from mayavi import mlab
@@ -274,11 +284,11 @@
     ###########################
     # Interactive visualization
     ###########################
 
     # Create figure for features
-    fig1 = mlab.figure('Input', bgcolor=(1, 1, 1), size=(1000, 800))
+    fig1 = mlab.figure("Input", bgcolor=(1, 1, 1), size=(1000, 800))
     fig1.scene.parallel_projection = False
 
     # Unstack batch
     all_points = batch.unstack_points()
     all_neighbors = batch.unstack_neighbors()
@@ -296,36 +306,40 @@
         #  clear figure
         mlab.clf(fig1)
 
         # Rescale points for visu
         p = (all_points[l_i][b_i] * 1.5 + np.array([1.0, 1.0, 1.0])) * 50.0
-        labels = p[:, 2]*0
+        labels = p[:, 2] * 0
 
         if show_pools:
-            p2 = (all_points[l_i+1][b_i][neighb_i:neighb_i+1] * 1.5 + np.array([1.0, 1.0, 1.0])) * 50.0
+            p2 = (
+                all_points[l_i + 1][b_i][neighb_i : neighb_i + 1] * 1.5
+                + np.array([1.0, 1.0, 1.0])
+            ) * 50.0
             p = np.vstack((p, p2))
-            labels = np.hstack((labels, np.ones((1,), dtype=np.int32)*3))
+            labels = np.hstack((labels, np.ones((1,), dtype=np.int32) * 3))
             pool_inds = all_pools[l_i][b_i][neighb_i]
             pool_inds = pool_inds[pool_inds >= 0]
             labels[pool_inds] = 2
         else:
             neighb_inds = all_neighbors[l_i][b_i][neighb_i]
             neighb_inds = neighb_inds[neighb_inds >= 0]
             labels[neighb_inds] = 2
             labels[neighb_i] = 3
 
         # Show point clouds colorized with activations
-        mlab.points3d(p[:, 0],
-                      p[:, 1],
-                      p[:, 2],
-                      labels,
-                      scale_factor=2.0,
-                      scale_mode='none',
-                      vmin=0.0,
-                      vmax=3.0,
-                      figure=fig1)
-
+        mlab.points3d(
+            p[:, 0],
+            p[:, 1],
+            p[:, 2],
+            labels,
+            scale_factor=2.0,
+            scale_mode="none",
+            vmin=0.0,
+            vmax=3.0,
+            figure=fig1,
+        )
 
         """
         mlab.points3d(p[-2:, 0],
                       p[-2:, 1],
                       p[-2:, 2],
@@ -348,89 +362,69 @@
                       figure=fig1)
                       
         """
 
         # New title
-        title_str = '<([) b_i={:d} (])>    <(,) l_i={:d} (.)>    <(N) n_i={:d} (M)>'.format(b_i, l_i, neighb_i)
+        title_str = (
+            "<([) b_i={:d} (])>    <(,) l_i={:d} (.)>    <(N) n_i={:d} (M)>".format(
+                b_i, l_i, neighb_i
+            )
+        )
         mlab.title(title_str, color=(0, 0, 0), size=0.3, height=0.90)
         if show_pools:
-            text = 'pools (switch with G)'
+            text = "pools (switch with G)"
         else:
-            text = 'neighbors (switch with G)'
+            text = "neighbors (switch with G)"
         mlab.text(0.01, 0.01, text, color=(0, 0, 0), width=0.3)
         mlab.orientation_axes()
 
         return
 
     def keyboard_callback(vtk_obj, event):
         global b_i, l_i, neighb_i, show_pools
 
-        if vtk_obj.GetKeyCode() in ['[', '{']:
+        if vtk_obj.GetKeyCode() in ["[", "{"]:
             b_i = (b_i - 1) % len(all_points[l_i])
             neighb_i = 0
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in [']', '}']:
+        elif vtk_obj.GetKeyCode() in ["]", "}"]:
             b_i = (b_i + 1) % len(all_points[l_i])
             neighb_i = 0
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in [',', '<']:
+        elif vtk_obj.GetKeyCode() in [",", "<"]:
             if show_pools:
                 l_i = (l_i - 1) % (len(all_points) - 1)
             else:
                 l_i = (l_i - 1) % len(all_points)
             neighb_i = 0
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in ['.', '>']:
+        elif vtk_obj.GetKeyCode() in [".", ">"]:
             if show_pools:
                 l_i = (l_i + 1) % (len(all_points) - 1)
             else:
                 l_i = (l_i + 1) % len(all_points)
             neighb_i = 0
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in ['n', 'N']:
+        elif vtk_obj.GetKeyCode() in ["n", "N"]:
             neighb_i = (neighb_i - 1) % all_points[l_i][b_i].shape[0]
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in ['m', 'M']:
+        elif vtk_obj.GetKeyCode() in ["m", "M"]:
             neighb_i = (neighb_i + 1) % all_points[l_i][b_i].shape[0]
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in ['g', 'G']:
+        elif vtk_obj.GetKeyCode() in ["g", "G"]:
             if l_i < len(all_points) - 1:
                 show_pools = not show_pools
                 neighb_i = 0
             update_scene()
 
         return
 
     # Draw a first plot
     update_scene()
-    fig1.scene.interactor.add_observer('KeyPressEvent', keyboard_callback)
+    fig1.scene.interactor.add_observer("KeyPressEvent", keyboard_callback)
     mlab.show()
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/evaluate_extended_kitti.py	2024-06-30 22:34:18.722734+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/evaluate_extended_kitti.py	2024-07-08 11:53:47.269984+00:00
@@ -24,17 +24,18 @@
             self.device = torch.device("cpu")
         net.to(self.device)
 
         # Load checkpoint
         checkpoint = torch.load(chkp_path)
-        net.load_state_dict(checkpoint['model_state_dict'])
-        self.epoch = checkpoint['epoch']
+        net.load_state_dict(checkpoint["model_state_dict"])
+        self.epoch = checkpoint["epoch"]
         net.eval()
         print("Model and training state restored.")
-        
-        
-    def slam_segmentation_test(self, net, test_loader, config, num_votes=100, debug=True):
+
+    def slam_segmentation_test(
+        self, net, test_loader, config, num_votes=100, debug=True
+    ):
         # Choose validation smoothing parameter (0 for no smothing, 0.99 for big smoothing)
         test_smooth = 0.5
         last_min = -0.5
         softmax = torch.nn.Softmax(1)
         self.cls = 0
@@ -46,61 +47,69 @@
         nc_model = net.C
 
         # Test saving path
         test_path = None
         report_path = None
-        config.saving_path = ''
+        config.saving_path = ""
         config.validation_size = 100
 
-        seq_path = join(test_loader.dataset.path, 'sequences', test_loader.dataset.sequences[0])
-        velo_file = join(seq_path, 'velodyne', test_loader.dataset.frames[0][0] + '.bin')
+        seq_path = join(
+            test_loader.dataset.path, "sequences", test_loader.dataset.sequences[0]
+        )
+        velo_file = join(
+            seq_path, "velodyne", test_loader.dataset.frames[0][0] + ".bin"
+        )
         frame_points = np.fromfile(velo_file, dtype=np.float32)
         frame_points = frame_points.reshape((-1, 4))[:, :3]
         # Get frames
 
-
         if config.saving:
-            test_path = join('test', config.saving_path.split('/')[-1])
+            test_path = join("test", config.saving_path.split("/")[-1])
             if not exists(test_path):
                 makedirs(test_path)
-            report_path = join(test_path, 'reports')
+            report_path = join(test_path, "reports")
             if not exists(report_path):
                 makedirs(report_path)
 
         self.report_path = report_path
 
         # Init validation container
         all_f_preds = []
         all_f_labels = []
         all_f_heatmaps = []
-        if test_loader.dataset.set == 'validation':
+        if test_loader.dataset.set == "validation":
             for i, seq_frames in enumerate(test_loader.dataset.frames):
                 all_f_preds.append([np.zeros((0,), dtype=np.int32) for _ in seq_frames])
-                all_f_labels.append([np.zeros((0,), dtype=np.int32) for _ in seq_frames])
-                all_f_heatmaps.append([[np.zeros((0,), dtype=np.float32) for _ in seq_frames] for _ in self.act_list])
-               
-            
+                all_f_labels.append(
+                    [np.zeros((0,), dtype=np.int32) for _ in seq_frames]
+                )
+                all_f_heatmaps.append(
+                    [
+                        [np.zeros((0,), dtype=np.float32) for _ in seq_frames]
+                        for _ in self.act_list
+                    ]
+                )
+
         #####################
         # Network predictions
         #####################
-                
+
         self.predictions = []
         self.targets = []
         test_epoch = 0
-        
+
         # Start test loop
         while True:
-            print('Initialize workers')
+            print("Initialize workers")
             for i, batch in enumerate(test_loader):
-                if 'cuda' in self.device.type:
+                if "cuda" in self.device.type:
                     batch.to(self.device)
 
                 # Forward pass
                 outputs = net(batch, config)
 
-
-                #pGSCAM core
+                # pGSCAM core
                 stacked_probs = softmax(outputs)
                 logits = stacked_probs[:, self.cls]
                 logits = torch.sum(logits, axis=0)
                 logits = logits.squeeze()
                 logits.backward(retain_graph=True)
@@ -113,30 +122,28 @@
                     pt = pt.cpu().numpy()
                     tree = KDTree(pt, leaf_size=20)
                     idx_ = tree.query(s_points, k=1, return_distance=False)
                     idx_ = idx_.squeeze()
                     reproj_idx[pt.shape[0]] = idx_
-
 
                 # Get probs and labels
                 stk_probs = softmax(outputs).cpu().detach().numpy()
                 lengths = batch.lengths[0].cpu().numpy()
                 f_inds = batch.frame_inds.cpu().numpy()
                 r_inds_list = batch.reproj_inds
                 r_mask_list = batch.reproj_masks
                 labels_list = batch.val_labels
                 torch.cuda.synchronize(self.device)
 
-
                 # Get predictions and labels per instance
                 # ***************************************
 
                 i0 = 0
                 for b_i, length in enumerate(lengths):
 
                     # Get prediction
-                    probs = stk_probs[i0:i0 + length]
+                    probs = stk_probs[i0 : i0 + length]
                     proj_inds = r_inds_list[b_i]
                     proj_mask = r_mask_list[b_i]
                     frame_labels = labels_list[b_i]
                     s_ind = f_inds[b_i, 0]
                     f_ind = f_inds[b_i, 1]
@@ -148,42 +155,54 @@
                     if proj_probs.ndim < 2:
                         proj_probs = np.expand_dims(proj_probs, 0)
 
                     # Save probs in a binary file (uint8 format for lighter weight)
                     seq_name = test_loader.dataset.sequences[s_ind]
-                    if test_loader.dataset.set == 'validation':
-                        folder = 'val_probs'
-                        pred_folder = 'val_predictions'
+                    if test_loader.dataset.set == "validation":
+                        folder = "val_probs"
+                        pred_folder = "val_predictions"
                     else:
-                        folder = 'probs'
-                        pred_folder = 'predictions'
-                    filename = '{:s}_{:07d}.npy'.format(seq_name, f_ind)
+                        folder = "probs"
+                        pred_folder = "predictions"
+                    filename = "{:s}_{:07d}.npy".format(seq_name, f_ind)
                     filepath = join(test_path, folder, filename)
                     if exists(filepath):
                         frame_probs_uint8 = np.load(filepath)
                     else:
-                        frame_probs_uint8 = np.zeros((proj_mask.shape[0], nc_model), dtype=np.uint8)
-                    frame_probs = frame_probs_uint8[proj_mask, :].astype(np.float32) / 255
-                    frame_probs = test_smooth * frame_probs + (1 - test_smooth) * proj_probs
-                    frame_probs_uint8[proj_mask, :] = (frame_probs * 255).astype(np.uint8)
+                        frame_probs_uint8 = np.zeros(
+                            (proj_mask.shape[0], nc_model), dtype=np.uint8
+                        )
+                    frame_probs = (
+                        frame_probs_uint8[proj_mask, :].astype(np.float32) / 255
+                    )
+                    frame_probs = (
+                        test_smooth * frame_probs + (1 - test_smooth) * proj_probs
+                    )
+                    frame_probs_uint8[proj_mask, :] = (frame_probs * 255).astype(
+                        np.uint8
+                    )
                     np.save(filepath, frame_probs_uint8)
-                    
-                    
+
                     # Save some prediction in ply format for visual
-                    if test_loader.dataset.set == 'validation':
+                    if test_loader.dataset.set == "validation":
                         # Insert false columns for ignored labels
                         frame_probs_uint8_bis = frame_probs_uint8.copy()
-                        for l_ind, label_value in enumerate(test_loader.dataset.label_values):
+                        for l_ind, label_value in enumerate(
+                            test_loader.dataset.label_values
+                        ):
                             if label_value in test_loader.dataset.ignored_labels:
-                                frame_probs_uint8_bis = np.insert(frame_probs_uint8_bis, l_ind, 0, axis=1)
+                                frame_probs_uint8_bis = np.insert(
+                                    frame_probs_uint8_bis, l_ind, 0, axis=1
+                                )
                         # Predicted labels
-                        frame_preds = test_loader.dataset.label_values[np.argmax(frame_probs_uint8_bis, axis=1)].astype(np.int32)
-            
+                        frame_preds = test_loader.dataset.label_values[
+                            np.argmax(frame_probs_uint8_bis, axis=1)
+                        ].astype(np.int32)
+
                         # keep frame preds in memory
                         all_f_preds[s_ind][f_ind] = frame_preds
                         all_f_labels[s_ind][f_ind] = frame_labels
-
 
                     # Stack all prediction for this epoch
                     i0 += length
 
                 for act in self.act_list:
@@ -198,11 +217,13 @@
                     alpha = torch.sum(grads, axis=0, keepdim=True)
 
                     stacked_heatmap = torch.matmul(cur_act, alpha.T).squeeze()
 
                     # Apply ReLU
-                    stacked_heatmap = torch.maximum(stacked_heatmap, torch.zeros_like(stacked_heatmap))
+                    stacked_heatmap = torch.maximum(
+                        stacked_heatmap, torch.zeros_like(stacked_heatmap)
+                    )
 
                     # Normalize
                     max_val = torch.max(stacked_heatmap, dim=-1, keepdim=True)[0]
                     min_val = torch.min(stacked_heatmap, dim=-1, keepdim=True)[0]
                     stacked_heatmap = (stacked_heatmap - min_val) / (max_val - min_val)
@@ -217,32 +238,36 @@
 
                     t7 = time.time()
 
                     i0 = 0
                     for b_i, length in enumerate(lengths):
-                        pgscam_hm = stacked_heatmap[i0:i0 + length]
+                        pgscam_hm = stacked_heatmap[i0 : i0 + length]
                         proj_inds = r_inds_list[b_i]
                         proj_mask = r_mask_list[b_i]
                         frame_labels = labels_list[b_i]
                         s_ind = f_inds[b_i, 0]
                         f_ind = f_inds[b_i, 1]
 
                         # Project predictions on the frame points
                         proj_hm = pgscam_hm[proj_inds]
 
-                        if test_loader.dataset.set == 'validation':
-                            folder = 'val_probs'
-                            pred_folder = 'val_predictions'
+                        if test_loader.dataset.set == "validation":
+                            folder = "val_probs"
+                            pred_folder = "val_predictions"
                         else:
-                            folder = 'probs'
-                            pred_folder = 'predictions'
-                        filename = '{:s}_{:d}_{:07d}_hm.npy'.format(seq_name, act, f_ind)
+                            folder = "probs"
+                            pred_folder = "predictions"
+                        filename = "{:s}_{:d}_{:07d}_hm.npy".format(
+                            seq_name, act, f_ind
+                        )
                         filepath = join(test_path, folder, filename)
                         if exists(filepath):
                             frame_hm_ufloat32 = np.load(filepath)
                         else:
-                            frame_hm_ufloat32 = np.zeros((proj_mask.shape[0],), dtype=np.float32)
+                            frame_hm_ufloat32 = np.zeros(
+                                (proj_mask.shape[0],), dtype=np.float32
+                            )
 
                         frame_hm = frame_hm_ufloat32[proj_mask].astype(np.float32)
                         frame_hm = test_smooth * frame_hm + (1 - test_smooth) * proj_hm
                         frame_hm_ufloat32[proj_mask] = frame_hm.astype(np.float32)
                         np.save(filepath, frame_hm_ufloat32)
@@ -253,47 +278,68 @@
 
                     t8 = time.time()
 
                 t9 = time.time()
 
-                if i%10 == 0:
-                    message = f'e{test_epoch}-i{i}'
+                if i % 10 == 0:
+                    message = f"e{test_epoch}-i{i}"
                     print(message)
             # Update minimum od potentials
             new_min = torch.min(test_loader.dataset.potentials)
-            print('Test epoch {:d}, end. Min potential = {:.1f}'.format(test_epoch, new_min))
-            
+            print(
+                "Test epoch {:d}, end. Min potential = {:.1f}".format(
+                    test_epoch, new_min
+                )
+            )
+
             # Compute confusion for subsampled clouds
             if last_min + 1 < new_min:
                 # Update last min
                 last_min += 1
                 print(last_min)
-                self.compute_on_cloud(test_loader, all_f_preds, all_f_labels, all_f_heatmaps, last_min, save=False)
-                
+                self.compute_on_cloud(
+                    test_loader,
+                    all_f_preds,
+                    all_f_labels,
+                    all_f_heatmaps,
+                    last_min,
+                    save=False,
+                )
 
             test_epoch += 1
-            
+
             if last_min > num_votes:
                 break
-                
+
         return
-            
-            
-    def compute_on_cloud(self, test_loader, all_f_preds, all_f_labels, all_f_heatmaps, last_min, save=False):
+
+    def compute_on_cloud(
+        self,
+        test_loader,
+        all_f_preds,
+        all_f_labels,
+        all_f_heatmaps,
+        last_min,
+        save=False,
+    ):
         #####################################
         # Results on the whole validation set
         #####################################
         print("Confusion for whole validations set...")
         # Confusions for our subparts of validation set
-        Confs = np.zeros((len(self.predictions), self.nc_tot, self.nc_tot), dtype=np.int32)
+        Confs = np.zeros(
+            (len(self.predictions), self.nc_tot, self.nc_tot), dtype=np.int32
+        )
         for i, (preds, truth) in enumerate(zip(self.predictions, self.targets)):
 
             # Confusions
-            Confs[i, :, :] = fast_confusion(truth, preds, test_loader.dataset.label_values).astype(np.int32)
+            Confs[i, :, :] = fast_confusion(
+                truth, preds, test_loader.dataset.label_values
+            ).astype(np.int32)
 
         # Show vote results
-        print('\nCompute confusion')
+        print("\nCompute confusion")
 
         val_preds = []
         val_labels = []
         t1 = time.time()
         for i, seq_frames in enumerate(test_loader.dataset.frames):
@@ -302,57 +348,69 @@
         val_preds = np.hstack(val_preds)
         val_labels = np.hstack(val_labels)
         t2 = time.time()
         C_tot = fast_confusion(val_labels, val_preds, test_loader.dataset.label_values)
         t3 = time.time()
-        print(' Stacking time : {:.1f}s'.format(t2 - t1))
-        print('Confusion time : {:.1f}s'.format(t3 - t2))
-
-        s1 = '\n'
+        print(" Stacking time : {:.1f}s".format(t2 - t1))
+        print("Confusion time : {:.1f}s".format(t3 - t2))
+
+        s1 = "\n"
         for cc in C_tot:
             for c in cc:
-                s1 += '{:7.0f} '.format(c)
-            s1 += '\n'
+                s1 += "{:7.0f} ".format(c)
+            s1 += "\n"
 
         # Remove ignored labels from confusions
-        for l_ind, label_value in reversed(list(enumerate(test_loader.dataset.label_values))):
+        for l_ind, label_value in reversed(
+            list(enumerate(test_loader.dataset.label_values))
+        ):
             if label_value in test_loader.dataset.ignored_labels:
                 C_tot = np.delete(C_tot, l_ind, axis=0)
                 C_tot = np.delete(C_tot, l_ind, axis=1)
 
         # Objects IoU
         val_IoUs = IoU_from_confusions(C_tot)
 
         # Compute IoUs
         mIoU = np.mean(val_IoUs)
-        s2 = '{:5.2f} | '.format(100 * mIoU)
+        s2 = "{:5.2f} | ".format(100 * mIoU)
         for IoU in val_IoUs:
-            s2 += '{:5.2f} '.format(100 * IoU)
-        print(s2 + '\n')
+            s2 += "{:5.2f} ".format(100 * IoU)
+        print(s2 + "\n")
 
         # Save a report
-        report_file = join(self.report_path, 'report_{:04d}.txt'.format(int(np.floor(last_min))))
-        str = 'Report of the confusion and metrics\n'
-        str += '***********************************\n\n\n'
-        str += 'Confusion matrix:\n\n'
+        report_file = join(
+            self.report_path, "report_{:04d}.txt".format(int(np.floor(last_min)))
+        )
+        str = "Report of the confusion and metrics\n"
+        str += "***********************************\n\n\n"
+        str += "Confusion matrix:\n\n"
         str += s1
-        str += '\nIoU values:\n\n'
+        str += "\nIoU values:\n\n"
         str += s2
-        str += '\n\n'
-        with open(report_file, 'w') as f:
+        str += "\n\n"
+        with open(report_file, "w") as f:
             f.write(str)
 
         print("Saving pGSCAM results...")
         s_ind = 0
         f_ind = 0
-        seq_path = join(test_loader.dataset.path, 'sequences', test_loader.dataset.sequences[s_ind])
-        velo_file = join(seq_path, 'velodyne', test_loader.dataset.frames[s_ind][f_ind] + '.bin')
+        seq_path = join(
+            test_loader.dataset.path, "sequences", test_loader.dataset.sequences[s_ind]
+        )
+        velo_file = join(
+            seq_path, "velodyne", test_loader.dataset.frames[s_ind][f_ind] + ".bin"
+        )
         frame_points = np.fromfile(velo_file, dtype=np.float32)
 
         frame_points = frame_points.reshape((-1, 4))[:, :3]
         preds = all_f_preds[s_ind][f_ind].astype(np.int32)
         labels = all_f_labels[s_ind][f_ind].astype(np.int32)
 
         for act in self.act_list:
             pgscam = all_f_heatmaps[s_ind][act][f_ind]
             entities = [frame_points, preds, labels, pgscam]
-            write_ply(f'./pgscam_results/KPConv_SemanticKITTI_cls_{self.cls}_act_{act}.ply', entities, ['x', 'y', 'z', 'preds', 'class', 'pgscam'])
\ No newline at end of file
+            write_ply(
+                f"./pgscam_results/KPConv_SemanticKITTI_cls_{self.cls}_act_{act}.ply",
+                entities,
+                ["x", "y", "z", "preds", "class", "pgscam"],
+            )
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/main_SemanticKITTI.py	2024-06-30 22:34:19.201896+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/main_SemanticKITTI.py	2024-07-08 11:53:47.994847+00:00
@@ -11,70 +11,97 @@
 from datetime import datetime
 from pGSCAM import PowerCAM, TSNE_cls, Drop_attack, piecewise_pGSCAM
 from tqdm import tqdm
 
 
-
 parser = argparse.ArgumentParser()
-parser.add_argument('--checkpoint_path', default='output/checkpoint_60.tar', help='Model checkpoint path [default: None]')
-parser.add_argument('--log_dir', default='output', help='Dump dir to save model checkpoint [default: log]')
-parser.add_argument('--max_epoch', type=int, default=400, help='Epoch to run [default: 180]')
-parser.add_argument('--batch_size', type=int, default=1, help='Batch Size during training [default: 8]')
+parser.add_argument(
+    "--checkpoint_path",
+    default="output/checkpoint_60.tar",
+    help="Model checkpoint path [default: None]",
+)
+parser.add_argument(
+    "--log_dir",
+    default="output",
+    help="Dump dir to save model checkpoint [default: log]",
+)
+parser.add_argument(
+    "--max_epoch", type=int, default=400, help="Epoch to run [default: 180]"
+)
+parser.add_argument(
+    "--batch_size", type=int, default=1, help="Batch Size during training [default: 8]"
+)
 FLAGS = parser.parse_args()
 
 #################################################   log   #################################################
 LOG_DIR = FLAGS.log_dir
 if not os.path.exists(LOG_DIR):
     os.mkdir(LOG_DIR)
-LOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'a')
+LOG_FOUT = open(os.path.join(LOG_DIR, "log_train.txt"), "a")
+
 
 def log_string(out_str):
-    LOG_FOUT.write(out_str + '\n')
+    LOG_FOUT.write(out_str + "\n")
     LOG_FOUT.flush()
     print(out_str)
 
 
 #################################################   dataset   #################################################
 # Init datasets and dataloaders
 def my_worker_init_fn(worker_id):
     np.random.seed(np.random.get_state()[1][0] + worker_id)
 
+
 transform_map = {
-          0: "car",
-          1: "bicycle",
-          2: "motorcycle",
-          3: "truck",
-          4: "other-vehicle",
-          5: "person",
-          6: "bicyclist",
-          7: "motorcyclist",
-          8: "road",
-          9: "parking",
-          10: "sidewalk",
-          11: "other-ground",
-          12: "building",
-          13: "fence",
-          14: "vegetation",
-          15: "trunk",
-          16: "terrain",
-          17: "pole",
-          18: "traffic-sign"
-}    
-
-
-eval_class = 0 # car
+    0: "car",
+    1: "bicycle",
+    2: "motorcycle",
+    3: "truck",
+    4: "other-vehicle",
+    5: "person",
+    6: "bicyclist",
+    7: "motorcyclist",
+    8: "road",
+    9: "parking",
+    10: "sidewalk",
+    11: "other-ground",
+    12: "building",
+    13: "fence",
+    14: "vegetation",
+    15: "trunk",
+    16: "terrain",
+    17: "pole",
+    18: "traffic-sign",
+}
+
+
+eval_class = 0  # car
 # EVAL_DATASET = SemanticKITTI('cam_eval', transform_map[eval_class])
 # EVAL_DATALOADER = DataLoader(EVAL_DATASET, batch_size=FLAGS.batch_size, shuffle=True, num_workers=20,
 #                             worker_init_fn=my_worker_init_fn, collate_fn=EVAL_DATASET.collate_fn)
 
 # Create Dataset and Dataloader
-TRAIN_DATASET = SemanticKITTI('training', None)
-TEST_DATASET = SemanticKITTI('validation', None)
+TRAIN_DATASET = SemanticKITTI("training", None)
+TEST_DATASET = SemanticKITTI("validation", None)
 
 print(len(TRAIN_DATASET), len(TEST_DATASET))
-TRAIN_DATALOADER = DataLoader(TRAIN_DATASET, batch_size=FLAGS.batch_size, shuffle=True, num_workers=20, worker_init_fn=my_worker_init_fn, collate_fn=TRAIN_DATASET.collate_fn)
-TEST_DATALOADER = DataLoader(TEST_DATASET, batch_size=FLAGS.batch_size, shuffle=False, num_workers=20, worker_init_fn=my_worker_init_fn, collate_fn=TEST_DATASET.collate_fn)
+TRAIN_DATALOADER = DataLoader(
+    TRAIN_DATASET,
+    batch_size=FLAGS.batch_size,
+    shuffle=True,
+    num_workers=20,
+    worker_init_fn=my_worker_init_fn,
+    collate_fn=TRAIN_DATASET.collate_fn,
+)
+TEST_DATALOADER = DataLoader(
+    TEST_DATASET,
+    batch_size=FLAGS.batch_size,
+    shuffle=False,
+    num_workers=20,
+    worker_init_fn=my_worker_init_fn,
+    collate_fn=TEST_DATASET.collate_fn,
+)
 
 # print(len(TRAIN_DATALOADER), len(TEST_DATALOADER))
 
 
 #################################################   network   #################################################
@@ -87,37 +114,35 @@
 
 # Load the Adam optimizer
 optimizer = optim.Adam(net.parameters(), lr=cfg.learning_rate)
 
 # Load checkpoint if there is any
-it = -1 # for the initialize value of `LambdaLR` and `BNMomentumScheduler`
+it = -1  # for the initialize value of `LambdaLR` and `BNMomentumScheduler`
 start_epoch = 0
 CHECKPOINT_PATH = FLAGS.checkpoint_path
 if CHECKPOINT_PATH is not None and os.path.isfile(CHECKPOINT_PATH):
     checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)
-    net.load_state_dict(checkpoint['model_state_dict'])
-    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
-    start_epoch = checkpoint['epoch']
-    log_string("-> loaded checkpoint %s (epoch: %d)"%(CHECKPOINT_PATH, start_epoch))
+    net.load_state_dict(checkpoint["model_state_dict"])
+    optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
+    start_epoch = checkpoint["epoch"]
+    log_string("-> loaded checkpoint %s (epoch: %d)" % (CHECKPOINT_PATH, start_epoch))
 
 
 if torch.cuda.device_count() > 1:
     log_string("Let's use %d GPUs!" % (torch.cuda.device_count()))
     # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs
     net = nn.DataParallel(net)
 
 
-
-
 #################################################   training functions   ###########################################
 
 
 def adjust_learning_rate(optimizer, epoch):
-    lr = optimizer.param_groups[0]['lr']
+    lr = optimizer.param_groups[0]["lr"]
     lr = lr * cfg.lr_decays[epoch]
     for param_group in optimizer.param_groups:
-        param_group['lr'] = lr
+        param_group["lr"] = lr
 
 
 def train_one_epoch():
     stat_dict = {}  # collect statistics
     adjust_learning_rate(optimizer, EPOCH_CNT)
@@ -142,33 +167,34 @@
         acc, end_points = compute_acc(end_points)
         iou_calc.add_data(end_points)
 
         # Accumulate statistics and print out
         for key in end_points:
-            if 'loss' in key or 'acc' in key or 'iou' in key:
-                if key not in stat_dict: stat_dict[key] = 0
+            if "loss" in key or "acc" in key or "iou" in key:
+                if key not in stat_dict:
+                    stat_dict[key] = 0
                 stat_dict[key] += end_points[key].item()
 
         batch_interval = 10
         if (batch_idx + 1) % batch_interval == 0:
-            log_string(' ---- batch: %03d ----' % (batch_idx + 1))
+            log_string(" ---- batch: %03d ----" % (batch_idx + 1))
             # TRAIN_VISUALIZER.log_scalars({key:stat_dict[key]/batch_interval for key in stat_dict},
             #     (EPOCH_CNT*len(TRAIN_DATALOADER)+batch_idx)*BATCH_SIZE)
             for key in sorted(stat_dict.keys()):
-                log_string('mean %s: %f' % (key, stat_dict[key] / batch_interval))
+                log_string("mean %s: %f" % (key, stat_dict[key] / batch_interval))
                 stat_dict[key] = 0
     mean_iou, iou_list = iou_calc.compute_iou()
-    log_string('mean IoU:{:.1f}'.format(mean_iou * 100))
-    s = 'IoU:'
+    log_string("mean IoU:{:.1f}".format(mean_iou * 100))
+    s = "IoU:"
     for iou_tmp in iou_list:
-        s += '{:5.2f} '.format(100 * iou_tmp)
+        s += "{:5.2f} ".format(100 * iou_tmp)
     log_string(s)
 
 
 def evaluate_one_epoch():
-    stat_dict = {} # collect statistics
-    net.eval() # set model to eval mode (for bn and dp)
+    stat_dict = {}  # collect statistics
+    net.eval()  # set model to eval mode (for bn and dp)
     iou_calc = IoUCalculator(cfg)
     for batch_idx, batch_data in enumerate(TEST_DATALOADER):
         for key in batch_data:
             if type(batch_data[key]) is list:
                 for i in range(len(batch_data[key])):
@@ -186,118 +212,122 @@
         acc, end_points = compute_acc(end_points)
         iou_calc.add_data(end_points)
 
         # Accumulate statistics and print out
         for key in end_points:
-            if 'loss' in key or 'acc' in key or 'iou' in key:
-                if key not in stat_dict: stat_dict[key] = 0
+            if "loss" in key or "acc" in key or "iou" in key:
+                if key not in stat_dict:
+                    stat_dict[key] = 0
                 stat_dict[key] += end_points[key].item()
 
         batch_interval = 10
         if (batch_idx + 1) % batch_interval == 0:
-            log_string(' ---- batch: %03d ----' % (batch_idx + 1))
+            log_string(" ---- batch: %03d ----" % (batch_idx + 1))
 
     for key in sorted(stat_dict.keys()):
-        log_string('eval mean %s: %f'%(key, stat_dict[key]/(float(batch_idx+1))))
+        log_string("eval mean %s: %f" % (key, stat_dict[key] / (float(batch_idx + 1))))
     mean_iou, iou_list = iou_calc.compute_iou()
-    log_string('mean IoU:{:.1f}'.format(mean_iou * 100))
-    s = 'IoU:'
+    log_string("mean IoU:{:.1f}".format(mean_iou * 100))
+    s = "IoU:"
     for iou_tmp in iou_list:
-        s += '{:5.2f} '.format(100 * iou_tmp)
+        s += "{:5.2f} ".format(100 * iou_tmp)
     log_string(s)
 
 
 def train(start_epoch):
     global EPOCH_CNT
     loss = 0
     for epoch in range(start_epoch, FLAGS.max_epoch):
         EPOCH_CNT = epoch
-        log_string('**** EPOCH %03d ****' % (epoch))
+        log_string("**** EPOCH %03d ****" % (epoch))
 
         log_string(str(datetime.now()))
 
         np.random.seed()
         train_one_epoch()
 
-        if EPOCH_CNT == 0 or EPOCH_CNT % 10 == 9: # Eval every 10 epochs
-            log_string('**** EVAL EPOCH %03d START****' % (epoch))
+        if EPOCH_CNT == 0 or EPOCH_CNT % 10 == 9:  # Eval every 10 epochs
+            log_string("**** EVAL EPOCH %03d START****" % (epoch))
             evaluate_one_epoch()
-            log_string('**** EVAL EPOCH %03d END****' % (epoch))
+            log_string("**** EVAL EPOCH %03d END****" % (epoch))
         # Save checkpoint
-        save_dict = {'epoch': epoch+1, # after training one epoch, the start_epoch should be epoch+1
-                    'optimizer_state_dict': optimizer.state_dict(),
-                    'loss': loss,
-                    }
-        try: # with nn.DataParallel() the net is added as a submodule of DataParallel
-            save_dict['model_state_dict'] = net.module.state_dict()
+        save_dict = {
+            "epoch": epoch
+            + 1,  # after training one epoch, the start_epoch should be epoch+1
+            "optimizer_state_dict": optimizer.state_dict(),
+            "loss": loss,
+        }
+        try:  # with nn.DataParallel() the net is added as a submodule of DataParallel
+            save_dict["model_state_dict"] = net.module.state_dict()
         except:
-            save_dict['model_state_dict'] = net.state_dict()
-        torch.save(save_dict, os.path.join(LOG_DIR, 'checkpoint.tar'))
+            save_dict["model_state_dict"] = net.state_dict()
+        torch.save(save_dict, os.path.join(LOG_DIR, "checkpoint.tar"))
 
 
 # For testing pGS-CAM
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     # mean_IoU = np.array([0])
     # counter = 0
     print(len(TEST_DATALOADER))
     # MIOU_HIGH = []
     # CIOU_HIGH = []
     # MIOU_LOW = []
     # CIOU_LOW = []
-    
+
     for num_batch, batch_data in enumerate(tqdm(TEST_DATALOADER)):
-#         for key in batch_data:
-#             if type(batch_data[key]) is list:
-#                 for i in range(len(batch_data[key])):
-#                     batch_data[key][i] = batch_data[key][i].cuda()
-#             else:
-#                 batch_data[key] = batch_data[key].cuda()
-        
-# #         print("Points shape: ", batch_data['xyz'][0].shape)
-        
-#         attack = Drop_attack()
-#         miou_high_collect, ciou_high_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='high')
-#         miou_low_collect, ciou_low_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='low')
-#         MIOU_HIGH.append(miou_high_collect)
-#         CIOU_HIGH.append(ciou_high_collect)
-#         MIOU_LOW.append(miou_low_collect)
-    #     CIOU_LOW.append(ciou_low_collect)
-        
-    #     if num_batch > 100:
-    #         break
-        
-    # MIOU_HIGH = np.array(MIOU_HIGH)
-    # CIOU_HIGH = np.array(CIOU_HIGH)
-    # MIOU_LOW = np.array(MIOU_LOW)
-    # CIOU_LOW = np.array(CIOU_LOW)
-    
-    # MIOU_HIGH_AVERAGE = np.sum(MIOU_HIGH, axis=0) / (MIOU_HIGH.shape[0])
-    # CIOU_HIGH_AVERAGE = np.sum(CIOU_HIGH, axis=0) / (CIOU_HIGH.shape[0])
-    # MIOU_LOW_AVERAGE = np.sum(MIOU_LOW, axis=0) / (MIOU_LOW.shape[0])
-    # CIOU_LOW_AVERAGE = np.sum(CIOU_LOW, axis=0) / (CIOU_LOW.shape[0])
-    # print("MIOU_HIGH_AVERAGE: ", MIOU_HIGH_AVERAGE)
-    # print("Class HIGH IOU AVERAGE: ", CIOU_HIGH_AVERAGE)
-    # print("MIOU_LOW_AVERAGE: ", MIOU_LOW_AVERAGE)
-    # print("Class LOW IOU AVERAGE: ", CIOU_LOW_AVERAGE)
-    
-        
-        
-        
-        
+        #         for key in batch_data:
+        #             if type(batch_data[key]) is list:
+        #                 for i in range(len(batch_data[key])):
+        #                     batch_data[key][i] = batch_data[key][i].cuda()
+        #             else:
+        #                 batch_data[key] = batch_data[key].cuda()
+
+        # #         print("Points shape: ", batch_data['xyz'][0].shape)
+
+        #         attack = Drop_attack()
+        #         miou_high_collect, ciou_high_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='high')
+        #         miou_low_collect, ciou_low_collect = attack.drop(net, batch_data, cfg, cls=eval_class, drop_type='low')
+        #         MIOU_HIGH.append(miou_high_collect)
+        #         CIOU_HIGH.append(ciou_high_collect)
+        #         MIOU_LOW.append(miou_low_collect)
+        #     CIOU_LOW.append(ciou_low_collect)
+
+        #     if num_batch > 100:
+        #         break
+
+        # MIOU_HIGH = np.array(MIOU_HIGH)
+        # CIOU_HIGH = np.array(CIOU_HIGH)
+        # MIOU_LOW = np.array(MIOU_LOW)
+        # CIOU_LOW = np.array(CIOU_LOW)
+
+        # MIOU_HIGH_AVERAGE = np.sum(MIOU_HIGH, axis=0) / (MIOU_HIGH.shape[0])
+        # CIOU_HIGH_AVERAGE = np.sum(CIOU_HIGH, axis=0) / (CIOU_HIGH.shape[0])
+        # MIOU_LOW_AVERAGE = np.sum(MIOU_LOW, axis=0) / (MIOU_LOW.shape[0])
+        # CIOU_LOW_AVERAGE = np.sum(CIOU_LOW, axis=0) / (CIOU_LOW.shape[0])
+        # print("MIOU_HIGH_AVERAGE: ", MIOU_HIGH_AVERAGE)
+        # print("Class HIGH IOU AVERAGE: ", CIOU_HIGH_AVERAGE)
+        # print("MIOU_LOW_AVERAGE: ", MIOU_LOW_AVERAGE)
+        # print("Class LOW IOU AVERAGE: ", CIOU_LOW_AVERAGE)
+
         if num_points > 1000:
             break
         else:
             continue
-        
-        
-        cam = PowerCAM(net, batch_data, cfg, norm=True, cls=8, mode='counterfactual', mask_type='none')
+
+        cam = PowerCAM(
+            net,
+            batch_data,
+            cfg,
+            norm=True,
+            cls=8,
+            mode="counterfactual",
+            mask_type="none",
+        )
         num_points = cam.runCAM()
         print(num_points)
 
 
-    
-
 # Training Loop
 
 # if __name__ == "__main__":
 #     train(0)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/visualizer.py	2024-06-30 22:34:18.759179+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/visualizer.py	2024-07-08 11:53:48.008133+00:00
@@ -79,17 +79,17 @@
         ##########################
 
         checkpoint = torch.load(chkp_path)
 
         new_dict = {}
-        for k, v in checkpoint['model_state_dict'].items():
-            if 'blocs' in k:
-                k = k.replace('blocs', 'blocks')
+        for k, v in checkpoint["model_state_dict"].items():
+            if "blocs" in k:
+                k = k.replace("blocs", "blocks")
             new_dict[k] = v
 
         net.load_state_dict(new_dict)
-        self.epoch = checkpoint['epoch']
+        self.epoch = checkpoint["epoch"]
         net.eval()
         print("\nModel state restored from {:s}.".format(chkp_path))
 
         return
 
@@ -103,27 +103,38 @@
 
         ##########################################
         # First choose the visualized deformations
         ##########################################
 
-        print('\nList of the deformable convolution available (chosen one highlighted in green)')
-        fmt_str = '  {:}{:2d} > KPConv(r={:.3f}, Din={:d}, Dout={:d}){:}'
+        print(
+            "\nList of the deformable convolution available (chosen one highlighted in green)"
+        )
+        fmt_str = "  {:}{:2d} > KPConv(r={:.3f}, Din={:d}, Dout={:d}){:}"
         deform_convs = []
         for m in net.modules():
             if isinstance(m, KPConv) and m.deformable:
                 if len(deform_convs) == deform_idx:
                     color = bcolors.OKGREEN
                 else:
                     color = bcolors.FAIL
-                print(fmt_str.format(color, len(deform_convs), m.radius, m.in_channels, m.out_channels, bcolors.ENDC))
+                print(
+                    fmt_str.format(
+                        color,
+                        len(deform_convs),
+                        m.radius,
+                        m.in_channels,
+                        m.out_channels,
+                        bcolors.ENDC,
+                    )
+                )
                 deform_convs.append(m)
 
         ################
         # Initialization
         ################
 
-        print('\n****************************************************\n')
+        print("\n****************************************************\n")
 
         # Loop variables
         t0 = time.time()
         t = [time.time()]
         last_display = time.time()
@@ -141,20 +152,24 @@
 
                 # New time
                 t = t[-1:]
                 t += [time.time()]
 
-                if 'cuda' in self.device.type:
+                if "cuda" in self.device.type:
                     batch.to(self.device)
 
                 # Forward pass
                 outputs = net(batch, config)
-                original_KP = deform_convs[deform_idx].kernel_points.cpu().detach().numpy()
-                stacked_deformed_KP = deform_convs[deform_idx].deformed_KP.cpu().detach().numpy()
+                original_KP = (
+                    deform_convs[deform_idx].kernel_points.cpu().detach().numpy()
+                )
+                stacked_deformed_KP = (
+                    deform_convs[deform_idx].deformed_KP.cpu().detach().numpy()
+                )
                 count += batch.lengths[0].shape[0]
 
-                if 'cuda' in self.device.type:
+                if "cuda" in self.device.type:
                     torch.cuda.synchronize(self.device)
 
                 # Find layer
                 l = None
                 for i, p in enumerate(batch.points):
@@ -169,30 +184,38 @@
                 deformed_KP = []
                 points = []
                 lookuptrees = []
                 i0 = 0
                 for b_i, length in enumerate(batch.lengths[0]):
-                    in_points.append(batch.points[0][i0:i0 + length].cpu().detach().numpy())
+                    in_points.append(
+                        batch.points[0][i0 : i0 + length].cpu().detach().numpy()
+                    )
                     if batch.features.shape[1] == 4:
-                        in_colors.append(batch.features[i0:i0 + length, 1:].cpu().detach().numpy())
+                        in_colors.append(
+                            batch.features[i0 : i0 + length, 1:].cpu().detach().numpy()
+                        )
                     else:
                         in_colors.append(None)
                     i0 += length
 
                 i0 = 0
                 for b_i, length in enumerate(batch.lengths[l]):
-                    points.append(batch.points[l][i0:i0 + length].cpu().detach().numpy())
-                    deformed_KP.append(stacked_deformed_KP[i0:i0 + length])
+                    points.append(
+                        batch.points[l][i0 : i0 + length].cpu().detach().numpy()
+                    )
+                    deformed_KP.append(stacked_deformed_KP[i0 : i0 + length])
                     lookuptrees.append(KDTree(points[-1]))
                     i0 += length
 
                 ###########################
                 # Interactive visualization
                 ###########################
 
                 # Create figure for features
-                fig1 = mlab.figure('Deformations', bgcolor=(1.0, 1.0, 1.0), size=(1280, 920))
+                fig1 = mlab.figure(
+                    "Deformations", bgcolor=(1.0, 1.0, 1.0), size=(1280, 920)
+                )
                 fig1.scene.parallel_projection = False
 
                 # Indices
                 global obj_i, point_i, plots, offsets, p_scale, show_in_p, aim_point
                 p_scale = 0.03
@@ -202,30 +225,45 @@
                 offsets = False
                 show_in_p = 2
                 aim_point = np.zeros((1, 3))
 
                 def picker_callback(picker):
-                    """ Picker callback: this get called when on pick events.
-                    """
+                    """Picker callback: this get called when on pick events."""
                     global plots, aim_point
 
-                    if 'in_points' in plots:
-                        if plots['in_points'].actor.actor._vtk_obj in [o._vtk_obj for o in picker.actors]:
-                            point_rez = plots['in_points'].glyph.glyph_source.glyph_source.output.points.to_array().shape[0]
+                    if "in_points" in plots:
+                        if plots["in_points"].actor.actor._vtk_obj in [
+                            o._vtk_obj for o in picker.actors
+                        ]:
+                            point_rez = (
+                                plots["in_points"]
+                                .glyph.glyph_source.glyph_source.output.points.to_array()
+                                .shape[0]
+                            )
                             new_point_i = int(np.floor(picker.point_id / point_rez))
-                            if new_point_i < len(plots['in_points'].mlab_source.points):
+                            if new_point_i < len(plots["in_points"].mlab_source.points):
                                 # Get closest point in the layer we are interested in
-                                aim_point = plots['in_points'].mlab_source.points[new_point_i:new_point_i + 1]
+                                aim_point = plots["in_points"].mlab_source.points[
+                                    new_point_i : new_point_i + 1
+                                ]
                                 update_scene()
 
-                    if 'points' in plots:
-                        if plots['points'].actor.actor._vtk_obj in [o._vtk_obj for o in picker.actors]:
-                            point_rez = plots['points'].glyph.glyph_source.glyph_source.output.points.to_array().shape[0]
+                    if "points" in plots:
+                        if plots["points"].actor.actor._vtk_obj in [
+                            o._vtk_obj for o in picker.actors
+                        ]:
+                            point_rez = (
+                                plots["points"]
+                                .glyph.glyph_source.glyph_source.output.points.to_array()
+                                .shape[0]
+                            )
                             new_point_i = int(np.floor(picker.point_id / point_rez))
-                            if new_point_i < len(plots['points'].mlab_source.points):
+                            if new_point_i < len(plots["points"].mlab_source.points):
                                 # Get closest point in the layer we are interested in
-                                aim_point = plots['points'].mlab_source.points[new_point_i:new_point_i + 1]
+                                aim_point = plots["points"].mlab_source.points[
+                                    new_point_i : new_point_i + 1
+                                ]
                                 update_scene()
 
                 def update_scene():
                     global plots, offsets, p_scale, show_in_p, aim_point, point_i
 
@@ -241,101 +279,122 @@
 
                     # Plot new data feature
                     p = points[obj_i]
 
                     # Rescale points for visu
-                    p = (p * 1.5 / config.in_radius)
-
+                    p = p * 1.5 / config.in_radius
 
                     # Show point cloud
                     if show_in_p <= 1:
-                        plots['points'] = mlab.points3d(p[:, 0],
-                                                        p[:, 1],
-                                                        p[:, 2],
-                                                        resolution=8,
-                                                        scale_factor=p_scale,
-                                                        scale_mode='none',
-                                                        color=(0, 1, 1),
-                                                        figure=fig1)
+                        plots["points"] = mlab.points3d(
+                            p[:, 0],
+                            p[:, 1],
+                            p[:, 2],
+                            resolution=8,
+                            scale_factor=p_scale,
+                            scale_mode="none",
+                            color=(0, 1, 1),
+                            figure=fig1,
+                        )
 
                     if show_in_p >= 1:
 
                         # Get points and colors
                         in_p = in_points[obj_i]
-                        in_p = (in_p * 1.5 / config.in_radius)
+                        in_p = in_p * 1.5 / config.in_radius
 
                         # Color point cloud if possible
                         in_c = in_colors[obj_i]
                         if in_c is not None:
 
                             # Primitives
-                            scalars = np.arange(len(in_p))  # Key point: set an integer for each point
+                            scalars = np.arange(
+                                len(in_p)
+                            )  # Key point: set an integer for each point
 
                             # Define color table (including alpha), which must be uint8 and [0,255]
                             colors = np.hstack((in_c, np.ones_like(in_c[:, :1])))
                             colors = (colors * 255).astype(np.uint8)
 
-                            plots['in_points'] = mlab.points3d(in_p[:, 0],
-                                                               in_p[:, 1],
-                                                               in_p[:, 2],
-                                                               scalars,
-                                                               resolution=8,
-                                                               scale_factor=p_scale*0.8,
-                                                               scale_mode='none',
-                                                               figure=fig1)
-                            plots['in_points'].module_manager.scalar_lut_manager.lut.table = colors
+                            plots["in_points"] = mlab.points3d(
+                                in_p[:, 0],
+                                in_p[:, 1],
+                                in_p[:, 2],
+                                scalars,
+                                resolution=8,
+                                scale_factor=p_scale * 0.8,
+                                scale_mode="none",
+                                figure=fig1,
+                            )
+                            plots[
+                                "in_points"
+                            ].module_manager.scalar_lut_manager.lut.table = colors
 
                         else:
 
-                            plots['in_points'] = mlab.points3d(in_p[:, 0],
-                                                               in_p[:, 1],
-                                                               in_p[:, 2],
-                                                               resolution=8,
-                                                               scale_factor=p_scale*0.8,
-                                                               scale_mode='none',
-                                                               figure=fig1)
-
+                            plots["in_points"] = mlab.points3d(
+                                in_p[:, 0],
+                                in_p[:, 1],
+                                in_p[:, 2],
+                                resolution=8,
+                                scale_factor=p_scale * 0.8,
+                                scale_mode="none",
+                                figure=fig1,
+                            )
 
                     # Get KP locations
                     rescaled_aim_point = aim_point * config.in_radius / 1.5
-                    point_i = lookuptrees[obj_i].query(rescaled_aim_point, return_distance=False)[0][0]
+                    point_i = lookuptrees[obj_i].query(
+                        rescaled_aim_point, return_distance=False
+                    )[0][0]
                     if offsets:
                         KP = points[obj_i][point_i] + deformed_KP[obj_i][point_i]
                         scals = np.ones_like(KP[:, 0])
                     else:
                         KP = points[obj_i][point_i] + original_KP
                         scals = np.zeros_like(KP[:, 0])
 
-                    KP = (KP * 1.5 / config.in_radius)
-
-                    plots['KP'] = mlab.points3d(KP[:, 0],
-                                                KP[:, 1],
-                                                KP[:, 2],
-                                                scals,
-                                                colormap='autumn',
-                                                resolution=8,
-                                                scale_factor=1.2*p_scale,
-                                                scale_mode='none',
-                                                vmin=0,
-                                                vmax=1,
-                                                figure=fig1)
-
+                    KP = KP * 1.5 / config.in_radius
+
+                    plots["KP"] = mlab.points3d(
+                        KP[:, 0],
+                        KP[:, 1],
+                        KP[:, 2],
+                        scals,
+                        colormap="autumn",
+                        resolution=8,
+                        scale_factor=1.2 * p_scale,
+                        scale_mode="none",
+                        vmin=0,
+                        vmax=1,
+                        figure=fig1,
+                    )
 
                     if True:
-                        plots['center'] = mlab.points3d(p[point_i, 0],
-                                                        p[point_i, 1],
-                                                        p[point_i, 2],
-                                                        scale_factor=1.1*p_scale,
-                                                        scale_mode='none',
-                                                        color=(0, 1, 0),
-                                                        figure=fig1)
+                        plots["center"] = mlab.points3d(
+                            p[point_i, 0],
+                            p[point_i, 1],
+                            p[point_i, 2],
+                            scale_factor=1.1 * p_scale,
+                            scale_mode="none",
+                            color=(0, 1, 0),
+                            figure=fig1,
+                        )
 
                         # New title
-                        plots['title'] = mlab.title(str(obj_i), color=(0, 0, 0), size=0.3, height=0.01)
-                        text = '<--- (press g for previous)' + 50 * ' ' + '(press h for next) --->'
-                        plots['text'] = mlab.text(0.01, 0.01, text, color=(0, 0, 0), width=0.98)
-                        plots['orient'] = mlab.orientation_axes()
+                        plots["title"] = mlab.title(
+                            str(obj_i), color=(0, 0, 0), size=0.3, height=0.01
+                        )
+                        text = (
+                            "<--- (press g for previous)"
+                            + 50 * " "
+                            + "(press h for next) --->"
+                        )
+                        plots["text"] = mlab.text(
+                            0.01, 0.01, text, color=(0, 0, 0), width=0.98
+                        )
+                        plots["orient"] = mlab.orientation_axes()
 
                     # Set the saved view
                     mlab.view(*v)
                     mlab.roll(roll)
 
@@ -345,99 +404,107 @@
                     global plots, offsets, p_scale, show_in_p
 
                     # Get KP locations
 
                     KP_def = points[obj_i][point_i] + deformed_KP[obj_i][point_i]
-                    KP_def = (KP_def * 1.5 / config.in_radius)
+                    KP_def = KP_def * 1.5 / config.in_radius
                     KP_def_color = (1, 0, 0)
 
                     KP_rigid = points[obj_i][point_i] + original_KP
-                    KP_rigid = (KP_rigid * 1.5 / config.in_radius)
+                    KP_rigid = KP_rigid * 1.5 / config.in_radius
                     KP_rigid_color = (1, 0.7, 0)
 
                     if offsets:
                         t_list = np.linspace(0, 1, 150, dtype=np.float32)
                     else:
                         t_list = np.linspace(1, 0, 150, dtype=np.float32)
 
                     @mlab.animate(delay=10)
                     def anim():
                         for t in t_list:
-                            plots['KP'].mlab_source.set(x=t * KP_def[:, 0] + (1 - t) * KP_rigid[:, 0],
-                                                        y=t * KP_def[:, 1] + (1 - t) * KP_rigid[:, 1],
-                                                        z=t * KP_def[:, 2] + (1 - t) * KP_rigid[:, 2],
-                                                        scalars=t * np.ones_like(KP_def[:, 0]))
+                            plots["KP"].mlab_source.set(
+                                x=t * KP_def[:, 0] + (1 - t) * KP_rigid[:, 0],
+                                y=t * KP_def[:, 1] + (1 - t) * KP_rigid[:, 1],
+                                z=t * KP_def[:, 2] + (1 - t) * KP_rigid[:, 2],
+                                scalars=t * np.ones_like(KP_def[:, 0]),
+                            )
 
                             yield
 
                     anim()
 
                     return
 
                 def keyboard_callback(vtk_obj, event):
                     global obj_i, point_i, offsets, p_scale, show_in_p
 
-                    if vtk_obj.GetKeyCode() in ['b', 'B']:
+                    if vtk_obj.GetKeyCode() in ["b", "B"]:
                         p_scale /= 1.5
                         update_scene()
 
-                    elif vtk_obj.GetKeyCode() in ['n', 'N']:
+                    elif vtk_obj.GetKeyCode() in ["n", "N"]:
                         p_scale *= 1.5
                         update_scene()
 
-                    if vtk_obj.GetKeyCode() in ['g', 'G']:
+                    if vtk_obj.GetKeyCode() in ["g", "G"]:
                         obj_i = (obj_i - 1) % len(deformed_KP)
                         point_i = 0
                         update_scene()
 
-                    elif vtk_obj.GetKeyCode() in ['h', 'H']:
+                    elif vtk_obj.GetKeyCode() in ["h", "H"]:
                         obj_i = (obj_i + 1) % len(deformed_KP)
                         point_i = 0
                         update_scene()
 
-                    elif vtk_obj.GetKeyCode() in ['k', 'K']:
+                    elif vtk_obj.GetKeyCode() in ["k", "K"]:
                         offsets = not offsets
                         animate_kernel()
 
-                    elif vtk_obj.GetKeyCode() in ['z', 'Z']:
+                    elif vtk_obj.GetKeyCode() in ["z", "Z"]:
                         show_in_p = (show_in_p + 1) % 3
                         update_scene()
 
-                    elif vtk_obj.GetKeyCode() in ['0']:
-
-                        print('Saving')
+                    elif vtk_obj.GetKeyCode() in ["0"]:
+
+                        print("Saving")
 
                         # Find a new name
                         file_i = 0
-                        file_name = 'KP_{:03d}.ply'.format(file_i)
-                        files = [f for f in listdir('KP_clouds') if f.endswith('.ply')]
+                        file_name = "KP_{:03d}.ply".format(file_i)
+                        files = [f for f in listdir("KP_clouds") if f.endswith(".ply")]
                         while file_name in files:
                             file_i += 1
-                            file_name = 'KP_{:03d}.ply'.format(file_i)
+                            file_name = "KP_{:03d}.ply".format(file_i)
 
                         KP_deform = points[obj_i][point_i] + deformed_KP[obj_i][point_i]
                         KP_normal = points[obj_i][point_i] + original_KP
 
                         # Save
-                        write_ply(join('KP_clouds', file_name),
-                                  [in_points[obj_i], in_colors[obj_i]],
-                                  ['x', 'y', 'z', 'red', 'green', 'blue'])
-                        write_ply(join('KP_clouds', 'KP_{:03d}_deform.ply'.format(file_i)),
-                                  [KP_deform],
-                                  ['x', 'y', 'z'])
-                        write_ply(join('KP_clouds', 'KP_{:03d}_normal.ply'.format(file_i)),
-                                  [KP_normal],
-                                  ['x', 'y', 'z'])
-                        print('OK')
+                        write_ply(
+                            join("KP_clouds", file_name),
+                            [in_points[obj_i], in_colors[obj_i]],
+                            ["x", "y", "z", "red", "green", "blue"],
+                        )
+                        write_ply(
+                            join("KP_clouds", "KP_{:03d}_deform.ply".format(file_i)),
+                            [KP_deform],
+                            ["x", "y", "z"],
+                        )
+                        write_ply(
+                            join("KP_clouds", "KP_{:03d}_normal.ply".format(file_i)),
+                            [KP_normal],
+                            ["x", "y", "z"],
+                        )
+                        print("OK")
 
                     return
 
                 # Draw a first plot
                 pick_func = fig1.on_mouse_pick(picker_callback)
                 pick_func.tolerance = 0.01
                 update_scene()
-                fig1.scene.interactor.add_observer('KeyPressEvent', keyboard_callback)
+                fig1.scene.interactor.add_observer("KeyPressEvent", keyboard_callback)
                 mlab.show()
 
         return
 
     # Utilities
@@ -449,11 +516,11 @@
     ###########################
     # Interactive visualization
     ###########################
 
     # Create figure for features
-    fig1 = mlab.figure('Models', bgcolor=(1, 1, 1), size=(1000, 800))
+    fig1 = mlab.figure("Models", bgcolor=(1, 1, 1), size=(1000, 800))
     fig1.scene.parallel_projection = False
 
     # Indices
     global file_i
     file_i = 0
@@ -468,64 +535,42 @@
 
         # Rescale points for visu
         points = (points * 1.5 + np.array([1.0, 1.0, 1.0])) * 50.0
 
         # Show point clouds colorized with activations
-        activations = mlab.points3d(points[:, 0],
-                                    points[:, 1],
-                                    points[:, 2],
-                                    points[:, 2],
-                                    scale_factor=3.0,
-                                    scale_mode='none',
-                                    figure=fig1)
+        activations = mlab.points3d(
+            points[:, 0],
+            points[:, 1],
+            points[:, 2],
+            points[:, 2],
+            scale_factor=3.0,
+            scale_mode="none",
+            figure=fig1,
+        )
 
         # New title
         mlab.title(str(file_i), color=(0, 0, 0), size=0.3, height=0.01)
-        text = '<--- (press g for previous)' + 50 * ' ' + '(press h for next) --->'
+        text = "<--- (press g for previous)" + 50 * " " + "(press h for next) --->"
         mlab.text(0.01, 0.01, text, color=(0, 0, 0), width=0.98)
         mlab.orientation_axes()
 
         return
 
     def keyboard_callback(vtk_obj, event):
         global file_i
 
-        if vtk_obj.GetKeyCode() in ['g', 'G']:
+        if vtk_obj.GetKeyCode() in ["g", "G"]:
 
             file_i = (file_i - 1) % len(all_points)
             update_scene()
 
-        elif vtk_obj.GetKeyCode() in ['h', 'H']:
+        elif vtk_obj.GetKeyCode() in ["h", "H"]:
 
             file_i = (file_i + 1) % len(all_points)
             update_scene()
 
         return
 
     # Draw a first plot
     update_scene()
-    fig1.scene.interactor.add_observer('KeyPressEvent', keyboard_callback)
+    fig1.scene.interactor.add_observer("KeyPressEvent", keyboard_callback)
     mlab.show()
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/RandLANet.py	2024-06-30 22:34:18.826910+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/RandLANet.py	2024-07-08 11:53:48.154312+00:00
@@ -10,11 +10,11 @@
 class Network(nn.Module):
 
     def __init__(self, config):
         super().__init__()
         self.config = config
-        self.class_weights = DP.get_class_weights('SemanticKITTI')
+        self.class_weights = DP.get_class_weights("SemanticKITTI")
 
         self.fc0 = pt_utils.Conv1d(3, 8, kernel_size=1, bn=True)
 
         self.dilated_res_blocks = nn.ModuleList()
         d_in = 8
@@ -22,56 +22,62 @@
             d_out = self.config.d_out[i]
             self.dilated_res_blocks.append(Dilated_res_block(d_in, d_out))
             d_in = 2 * d_out
 
         d_out = d_in
-        self.decoder_0 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
+        self.decoder_0 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
 
         self.decoder_blocks = nn.ModuleList()
         for j in range(self.config.num_layers):
             if j < 3:
-                d_in = d_out + 2 * self.config.d_out[-j-2]
-                d_out = 2 * self.config.d_out[-j-2]
+                d_in = d_out + 2 * self.config.d_out[-j - 2]
+                d_out = 2 * self.config.d_out[-j - 2]
             else:
                 d_in = 4 * self.config.d_out[-4]
                 d_out = 2 * self.config.d_out[-4]
-            self.decoder_blocks.append(pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True))
-
-        self.fc1 = pt_utils.Conv2d(d_out, 64, kernel_size=(1,1), bn=True)
-        self.fc2 = pt_utils.Conv2d(64, 32, kernel_size=(1,1), bn=True)
+            self.decoder_blocks.append(
+                pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+            )
+
+        self.fc1 = pt_utils.Conv2d(d_out, 64, kernel_size=(1, 1), bn=True)
+        self.fc2 = pt_utils.Conv2d(64, 32, kernel_size=(1, 1), bn=True)
         self.dropout = nn.Dropout(0.5)
-        self.fc3 = pt_utils.Conv2d(32, self.config.num_classes, kernel_size=(1,1), bn=False, activation=None)
-        
+        self.fc3 = pt_utils.Conv2d(
+            32, self.config.num_classes, kernel_size=(1, 1), bn=False, activation=None
+        )
+
     def activations_hook(self, grad):
         self.gradients = grad
-        
+
     def logits_hook(self, grad):
         self.logits_gradients = grad
 
     def forward(self, end_points):
         self.activation_maps = []
-        features = end_points['features']  # Batch*channel*npoints
+        features = end_points["features"]  # Batch*channel*npoints
         features = self.fc0(features)
 
         features = features.unsqueeze(dim=3)  # Batch*channel*npoints*1
 
         # ###########################Encoder############################
         f_encoder_list = []
         for i in range(self.config.num_layers):
-            f_encoder_i = self.dilated_res_blocks[i](features, end_points['xyz'][i], end_points['neigh_idx'][i])
-            f_sampled_i = self.random_sample(f_encoder_i, end_points['sub_idx'][i])
+            f_encoder_i = self.dilated_res_blocks[i](
+                features, end_points["xyz"][i], end_points["neigh_idx"][i]
+            )
+            f_sampled_i = self.random_sample(f_encoder_i, end_points["sub_idx"][i])
             features = f_sampled_i
             if i == 0:
-#                 activations = f_encoder_i
-#                 act_hook = f_encoder_i.register_hook(self.activations_hook)
-#                 f_encoder_i.retain_grad()
-#                 print("Activations grad shape: ", self.activations.grad.shape)
+                #                 activations = f_encoder_i
+                #                 act_hook = f_encoder_i.register_hook(self.activations_hook)
+                #                 f_encoder_i.retain_grad()
+                #                 print("Activations grad shape: ", self.activations.grad.shape)
                 act_hook = f_encoder_i.register_hook(self.activations_hook)
                 f_encoder_i.retain_grad()
                 self.activation_maps.append(f_encoder_i)
                 f_encoder_list.append(f_encoder_i)
-            
+
             if i != self.config.num_layers - 1:
                 act_hook = f_sampled_i.register_hook(self.activations_hook)
                 f_sampled_i.retain_grad()
                 self.activation_maps.append(f_sampled_i)
             f_encoder_list.append(f_sampled_i)
@@ -80,47 +86,47 @@
         features = self.decoder_0(f_encoder_list[-1])
 
         # ###########################Decoder############################
         f_decoder_list = []
         for j in range(self.config.num_layers):
-            f_interp_i = self.nearest_interpolation(features, end_points['interp_idx'][-j - 1])
-            f_decoder_i = self.decoder_blocks[j](torch.cat([f_encoder_list[-j - 2], f_interp_i], dim=1))
+            f_interp_i = self.nearest_interpolation(
+                features, end_points["interp_idx"][-j - 1]
+            )
+            f_decoder_i = self.decoder_blocks[j](
+                torch.cat([f_encoder_list[-j - 2], f_interp_i], dim=1)
+            )
 
             features = f_decoder_i
             act_hook = f_decoder_i.register_hook(self.activations_hook)
             f_decoder_i.retain_grad()
             self.activation_maps.append(f_decoder_i)
             f_decoder_list.append(f_decoder_i)
         # ###########################Decoder############################
-        
-
 
         features = self.fc1(features)
         act_hook = features.register_hook(self.activations_hook)
         features.retain_grad()
         self.activation_maps.append(features)
-        
+
         features = self.fc2(features)
         act_hook = features.register_hook(self.activations_hook)
         features.retain_grad()
         self.activation_maps.append(features)
-        
+
         features = self.dropout(features)
 
         features = self.fc3(features)
         act_hook = features.register_hook(self.activations_hook)
         features.retain_grad()
         self.activation_maps.append(features)
 
-
         f_out = features.squeeze(3)
-        
-        
-#         self.logits = f_out
-#         self.activations = activations
-        end_points['activations'] = self.activation_maps
-        end_points['logits'] = f_out
+
+        #         self.logits = f_out
+        #         self.activations = activations
+        end_points["activations"] = self.activation_maps
+        end_points["logits"] = f_out
 
         return end_points
 
     @staticmethod
     def random_sample(feature, pool_idx):
@@ -132,13 +138,17 @@
         feature = feature.squeeze(dim=3)  # batch*channel*npoints
         num_neigh = pool_idx.shape[-1]
         d = feature.shape[1]
         batch_size = pool_idx.shape[0]
         pool_idx = pool_idx.reshape(batch_size, -1)  # batch*(npoints,nsamples)
-        pool_features = torch.gather(feature, 2, pool_idx.unsqueeze(1).repeat(1, feature.shape[1], 1))
+        pool_features = torch.gather(
+            feature, 2, pool_idx.unsqueeze(1).repeat(1, feature.shape[1], 1)
+        )
         pool_features = pool_features.reshape(batch_size, d, -1, num_neigh)
-        pool_features = pool_features.max(dim=3, keepdim=True)[0]  # batch*channel*npoints*1
+        pool_features = pool_features.max(dim=3, keepdim=True)[
+            0
+        ]  # batch*channel*npoints*1
         return pool_features
 
     @staticmethod
     def nearest_interpolation(feature, interp_idx):
         """
@@ -148,23 +158,26 @@
         """
         feature = feature.squeeze(dim=3)  # batch*channel*npoints
         batch_size = interp_idx.shape[0]
         up_num_points = interp_idx.shape[1]
         interp_idx = interp_idx.reshape(batch_size, up_num_points)
-        interpolated_features = torch.gather(feature, 2, interp_idx.unsqueeze(1).repeat(1,feature.shape[1],1))
-        interpolated_features = interpolated_features.unsqueeze(3)  # batch*channel*npoints*1
+        interpolated_features = torch.gather(
+            feature, 2, interp_idx.unsqueeze(1).repeat(1, feature.shape[1], 1)
+        )
+        interpolated_features = interpolated_features.unsqueeze(
+            3
+        )  # batch*channel*npoints*1
         return interpolated_features
 
 
-
 def compute_acc(end_points):
 
-    logits = end_points['valid_logits']
-    labels = end_points['valid_labels']
+    logits = end_points["valid_logits"]
+    labels = end_points["valid_labels"]
     logits = logits.max(dim=1)[1]
     acc = (logits == labels).sum().float() / float(labels.shape[0])
-    end_points['acc'] = acc
+    end_points["acc"] = acc
     return acc, end_points
 
 
 class IoUCalculator:
     def __init__(self, cfg):
@@ -172,12 +185,12 @@
         self.positive_classes = [0 for _ in range(cfg.num_classes)]
         self.true_positive_classes = [0 for _ in range(cfg.num_classes)]
         self.cfg = cfg
 
     def add_data(self, end_points):
-        logits = end_points['valid_logits']
-        labels = end_points['valid_labels']
+        logits = end_points["valid_logits"]
+        labels = end_points["valid_labels"]
         pred = logits.max(dim=1)[1]
         pred_valid = pred.detach().cpu().numpy()
         labels_valid = labels.detach().cpu().numpy()
 
         val_total_correct = 0
@@ -185,96 +198,130 @@
 
         correct = np.sum(pred_valid == labels_valid)
         val_total_correct += correct
         val_total_seen += len(labels_valid)
 
-        conf_matrix = confusion_matrix(labels_valid, pred_valid, labels=np.arange(0, self.cfg.num_classes, 1))
+        conf_matrix = confusion_matrix(
+            labels_valid, pred_valid, labels=np.arange(0, self.cfg.num_classes, 1)
+        )
         self.gt_classes += np.sum(conf_matrix, axis=1)
         self.positive_classes += np.sum(conf_matrix, axis=0)
         self.true_positive_classes += np.diagonal(conf_matrix)
 
     def compute_iou(self):
         iou_list = []
         for n in range(0, self.cfg.num_classes, 1):
-            if float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n]) != 0:
-                iou = self.true_positive_classes[n] / float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n])
+            if (
+                float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
+                != 0
+            ):
+                iou = self.true_positive_classes[n] / float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
                 iou_list.append(iou)
             else:
                 iou_list.append(0.0)
         mean_iou = sum(iou_list) / float(self.cfg.num_classes)
         return mean_iou, iou_list
 
 
-
 class Dilated_res_block(nn.Module):
     def __init__(self, d_in, d_out):
         super().__init__()
 
-        self.mlp1 = pt_utils.Conv2d(d_in, d_out//2, kernel_size=(1,1), bn=True)
+        self.mlp1 = pt_utils.Conv2d(d_in, d_out // 2, kernel_size=(1, 1), bn=True)
         self.lfa = Building_block(d_out)
-        self.mlp2 = pt_utils.Conv2d(d_out, d_out*2, kernel_size=(1, 1), bn=True, activation=None)
-        self.shortcut = pt_utils.Conv2d(d_in, d_out*2, kernel_size=(1,1), bn=True, activation=None)
+        self.mlp2 = pt_utils.Conv2d(
+            d_out, d_out * 2, kernel_size=(1, 1), bn=True, activation=None
+        )
+        self.shortcut = pt_utils.Conv2d(
+            d_in, d_out * 2, kernel_size=(1, 1), bn=True, activation=None
+        )
 
     def forward(self, feature, xyz, neigh_idx):
         f_pc = self.mlp1(feature)  # Batch*channel*npoints*1
         f_pc = self.lfa(xyz, f_pc, neigh_idx)  # Batch*d_out*npoints*1
         f_pc = self.mlp2(f_pc)
         shortcut = self.shortcut(feature)
-        return F.leaky_relu(f_pc+shortcut, negative_slope=0.2)
+        return F.leaky_relu(f_pc + shortcut, negative_slope=0.2)
 
 
 class Building_block(nn.Module):
     def __init__(self, d_out):  #  d_in = d_out//2
         super().__init__()
-        self.mlp1 = pt_utils.Conv2d(10, d_out//2, kernel_size=(1,1), bn=True)
-        self.att_pooling_1 = Att_pooling(d_out, d_out//2)
-
-        self.mlp2 = pt_utils.Conv2d(d_out//2, d_out//2, kernel_size=(1, 1), bn=True)
+        self.mlp1 = pt_utils.Conv2d(10, d_out // 2, kernel_size=(1, 1), bn=True)
+        self.att_pooling_1 = Att_pooling(d_out, d_out // 2)
+
+        self.mlp2 = pt_utils.Conv2d(d_out // 2, d_out // 2, kernel_size=(1, 1), bn=True)
         self.att_pooling_2 = Att_pooling(d_out, d_out)
 
     def forward(self, xyz, feature, neigh_idx):  # feature: Batch*channel*npoints*1
         f_xyz = self.relative_pos_encoding(xyz, neigh_idx)  # batch*npoint*nsamples*10
         f_xyz = f_xyz.permute((0, 3, 1, 2))  # batch*10*npoint*nsamples
         f_xyz = self.mlp1(f_xyz)
-        f_neighbours = self.gather_neighbour(feature.squeeze(-1).permute((0, 2, 1)), neigh_idx)  # batch*npoint*nsamples*channel
-        f_neighbours = f_neighbours.permute((0, 3, 1, 2))  # batch*channel*npoint*nsamples
+        f_neighbours = self.gather_neighbour(
+            feature.squeeze(-1).permute((0, 2, 1)), neigh_idx
+        )  # batch*npoint*nsamples*channel
+        f_neighbours = f_neighbours.permute(
+            (0, 3, 1, 2)
+        )  # batch*channel*npoint*nsamples
         f_concat = torch.cat([f_neighbours, f_xyz], dim=1)
         f_pc_agg = self.att_pooling_1(f_concat)  # Batch*channel*npoints*1
 
         f_xyz = self.mlp2(f_xyz)
-        f_neighbours = self.gather_neighbour(f_pc_agg.squeeze(-1).permute((0, 2, 1)), neigh_idx)  # batch*npoint*nsamples*channel
-        f_neighbours = f_neighbours.permute((0, 3, 1, 2))  # batch*channel*npoint*nsamples
+        f_neighbours = self.gather_neighbour(
+            f_pc_agg.squeeze(-1).permute((0, 2, 1)), neigh_idx
+        )  # batch*npoint*nsamples*channel
+        f_neighbours = f_neighbours.permute(
+            (0, 3, 1, 2)
+        )  # batch*channel*npoint*nsamples
         f_concat = torch.cat([f_neighbours, f_xyz], dim=1)
         f_pc_agg = self.att_pooling_2(f_concat)
         return f_pc_agg
 
     def relative_pos_encoding(self, xyz, neigh_idx):
         neighbor_xyz = self.gather_neighbour(xyz, neigh_idx)  # batch*npoint*nsamples*3
 
-        xyz_tile = xyz.unsqueeze(2).repeat(1, 1, neigh_idx.shape[-1], 1)  # batch*npoint*nsamples*3
+        xyz_tile = xyz.unsqueeze(2).repeat(
+            1, 1, neigh_idx.shape[-1], 1
+        )  # batch*npoint*nsamples*3
         relative_xyz = xyz_tile - neighbor_xyz  # batch*npoint*nsamples*3
-        relative_dis = torch.sqrt(torch.sum(torch.pow(relative_xyz, 2), dim=-1, keepdim=True))  # batch*npoint*nsamples*1
-        relative_feature = torch.cat([relative_dis, relative_xyz, xyz_tile, neighbor_xyz], dim=-1)  # batch*npoint*nsamples*10
+        relative_dis = torch.sqrt(
+            torch.sum(torch.pow(relative_xyz, 2), dim=-1, keepdim=True)
+        )  # batch*npoint*nsamples*1
+        relative_feature = torch.cat(
+            [relative_dis, relative_xyz, xyz_tile, neighbor_xyz], dim=-1
+        )  # batch*npoint*nsamples*10
         return relative_feature
 
     @staticmethod
     def gather_neighbour(pc, neighbor_idx):  # pc: batch*npoint*channel
         # gather the coordinates or features of neighboring points
         batch_size = pc.shape[0]
         num_points = pc.shape[1]
         d = pc.shape[2]
         index_input = neighbor_idx.reshape(batch_size, -1)
-        features = torch.gather(pc, 1, index_input.unsqueeze(-1).repeat(1, 1, pc.shape[2]))
-        features = features.reshape(batch_size, num_points, neighbor_idx.shape[-1], d)  # batch*npoint*nsamples*channel
+        features = torch.gather(
+            pc, 1, index_input.unsqueeze(-1).repeat(1, 1, pc.shape[2])
+        )
+        features = features.reshape(
+            batch_size, num_points, neighbor_idx.shape[-1], d
+        )  # batch*npoint*nsamples*channel
         return features
 
 
 class Att_pooling(nn.Module):
     def __init__(self, d_in, d_out):
         super().__init__()
         self.fc = nn.Conv2d(d_in, d_in, (1, 1), bias=False)
-        self.mlp = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
+        self.mlp = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
 
     def forward(self, feature_set):
 
         att_activation = self.fc(feature_set)
         att_scores = F.softmax(att_activation, dim=3)
@@ -284,12 +331,12 @@
         return f_agg
 
 
 def compute_loss(end_points, cfg):
 
-    logits = end_points['logits']
-    labels = end_points['labels']
+    logits = end_points["logits"]
+    labels = end_points["labels"]
 
     logits = logits.transpose(1, 2).reshape(-1, cfg.num_classes)
     labels = labels.reshape(-1)
 
     # Boolean mask of points that should be ignored
@@ -304,22 +351,24 @@
 
     # Reduce label values in the range of logit shape
     reducing_list = torch.arange(0, cfg.num_classes).long().cuda()
     inserted_value = torch.zeros((1,)).long().cuda()
     for ign_label in cfg.ignored_label_inds:
-        reducing_list = torch.cat([reducing_list[:ign_label], inserted_value, reducing_list[ign_label:]], 0)
+        reducing_list = torch.cat(
+            [reducing_list[:ign_label], inserted_value, reducing_list[ign_label:]], 0
+        )
     valid_labels = torch.gather(reducing_list, 0, valid_labels_init)
     loss = get_loss(valid_logits, valid_labels, cfg.class_weights)
-    end_points['valid_logits'], end_points['valid_labels'] = valid_logits, valid_labels
-    end_points['loss'] = loss
+    end_points["valid_logits"], end_points["valid_labels"] = valid_logits, valid_labels
+    end_points["loss"] = loss
     return loss, end_points
 
 
 def get_loss(logits, labels, pre_cal_weights):
     # calculate the weighted cross entropy according to the inverse frequency
     class_weights = torch.from_numpy(pre_cal_weights).float().cuda()
     # one_hot_labels = F.one_hot(labels, self.config.num_classes)
 
-    criterion = nn.CrossEntropyLoss(weight=class_weights, reduction='none')
+    criterion = nn.CrossEntropyLoss(weight=class_weights, reduction="none")
     output_loss = criterion(logits, labels)
     output_loss = output_loss.mean()
     return output_loss
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/helper_tool.py	2024-06-30 22:34:19.196927+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/helper_tool.py	2024-07-08 11:53:48.256573+00:00
@@ -2,44 +2,49 @@
 from os.path import join
 import numpy as np
 import colorsys, random, os, sys
 import pandas as pd
 
-os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
+os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
 
 BASE_DIR = os.path.dirname(os.path.abspath(__file__))
 
 sys.path.append(BASE_DIR)
-sys.path.append(os.path.join(BASE_DIR, 'utils'))
+sys.path.append(os.path.join(BASE_DIR, "utils"))
 
 import utils.cpp_wrappers.cpp_subsampling.grid_subsampling as cpp_subsampling
 import utils.nearest_neighbors.lib.python.nearest_neighbors as nearest_neighbors
 
 
 class ConfigSemanticKITTI:
     k_n = 16  # KNN
     num_layers = 4  # Number of layers
     num_points = 4096 * 11  # Number of input points
-#     num_points = 40000
+    #     num_points = 40000
     num_classes = 19  # Number of valid classes
     sub_grid_size = 0.06  # preprocess_parameter
 
     batch_size = 6  # batch_size during training
     val_batch_size = 20  # batch_size during validation and test
     train_steps = 500  # Number of steps per epochs
     val_steps = 100  # Number of validation steps per epoch
 
     sub_sampling_ratio = [4, 4, 4, 4]  # sampling ratio of random sampling at each layer
     d_out = [16, 64, 128, 256]  # feature dimension
-    num_sub_points = [num_points // 4, num_points // 16, num_points // 64, num_points // 256]
+    num_sub_points = [
+        num_points // 4,
+        num_points // 16,
+        num_points // 64,
+        num_points // 256,
+    ]
 
     noise_init = 3.5  # noise initial parameter
     max_epoch = 100  # maximum epoch during training
     learning_rate = 1e-2  # initial learning rate
     lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate
 
-    train_sum_dir = 'train_log'
+    train_sum_dir = "train_log"
     saving = True
     saving_path = None
 
 
 class ConfigS3DIS:
@@ -52,19 +57,25 @@
     batch_size = 6  # batch_size during training
     val_batch_size = 20  # batch_size during validation and test
     train_steps = 500  # Number of steps per epochs
     val_steps = 100  # Number of validation steps per epoch
 
-    sub_sampling_ratio = [4, 4, 4, 4, 2]  # sampling ratio of random sampling at each layer
+    sub_sampling_ratio = [
+        4,
+        4,
+        4,
+        4,
+        2,
+    ]  # sampling ratio of random sampling at each layer
     d_out = [16, 64, 128, 256, 512]  # feature dimension
 
     noise_init = 3.5  # noise initial parameter
     max_epoch = 100  # maximum epoch during training
     learning_rate = 1e-2  # initial learning rate
     lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate
 
-    train_sum_dir = 'train_log'
+    train_sum_dir = "train_log"
     saving = True
     saving_path = None
 
 
 class ConfigSemantic3D:
@@ -77,42 +88,52 @@
     batch_size = 4  # batch_size during training
     val_batch_size = 16  # batch_size during validation and test
     train_steps = 500  # Number of steps per epochs
     val_steps = 100  # Number of validation steps per epoch
 
-    sub_sampling_ratio = [4, 4, 4, 4, 2]  # sampling ratio of random sampling at each layer
+    sub_sampling_ratio = [
+        4,
+        4,
+        4,
+        4,
+        2,
+    ]  # sampling ratio of random sampling at each layer
     d_out = [16, 64, 128, 256, 512]  # feature dimension
 
     noise_init = 3.5  # noise initial parameter
     max_epoch = 100  # maximum epoch during training
     learning_rate = 1e-2  # initial learning rate
     lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate
 
-    train_sum_dir = 'train_log'
+    train_sum_dir = "train_log"
     saving = True
     saving_path = None
 
     augment_scale_anisotropic = True
     augment_symmetries = [True, False, False]
-    augment_rotation = 'vertical'
+    augment_rotation = "vertical"
     augment_scale_min = 0.8
     augment_scale_max = 1.2
     augment_noise = 0.001
-    augment_occlusion = 'none'
+    augment_occlusion = "none"
     augment_color = 0.8
 
 
 class DataProcessing:
     @staticmethod
     def load_pc_semantic3d(filename):
-        pc_pd = pd.read_csv(filename, header=None, delim_whitespace=True, dtype=np.float16)
+        pc_pd = pd.read_csv(
+            filename, header=None, delim_whitespace=True, dtype=np.float16
+        )
         pc = pc_pd.values
         return pc
 
     @staticmethod
     def load_label_semantic3d(filename):
-        label_pd = pd.read_csv(filename, header=None, delim_whitespace=True, dtype=np.uint8)
+        label_pd = pd.read_csv(
+            filename, header=None, delim_whitespace=True, dtype=np.uint8
+        )
         cloud_labels = label_pd.values
         return cloud_labels
 
     @staticmethod
     def load_pc_kitti(pc_path):
@@ -125,11 +146,11 @@
     def load_label_kitti(label_path, remap_lut):
         label = np.fromfile(label_path, dtype=np.uint32)
         label = label.reshape((-1))
         sem_label = label & 0xFFFF  # semantic label in lower half
         inst_label = label >> 16  # instance id in upper half
-        assert ((sem_label + (inst_label << 16) == label).all())
+        assert (sem_label + (inst_label << 16) == label).all()
         sem_label = remap_lut[sem_label]
         return sem_label.astype(np.int32)
 
     @staticmethod
     def get_file_list(dataset_path, test_scan_num):
@@ -138,23 +159,31 @@
         train_file_list = []
         test_file_list = []
         val_file_list = []
         for seq_id in seq_list:
             seq_path = join(dataset_path, seq_id)
-            pc_path = join(seq_path, 'velodyne')
-            if seq_id == '08':
-                val_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])
+            pc_path = join(seq_path, "velodyne")
+            if seq_id == "08":
+                val_file_list.append(
+                    [join(pc_path, f) for f in np.sort(os.listdir(pc_path))]
+                )
                 if seq_id == test_scan_num:
-                    test_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])
+                    test_file_list.append(
+                        [join(pc_path, f) for f in np.sort(os.listdir(pc_path))]
+                    )
             elif int(seq_id) >= 11 and seq_id == test_scan_num:
-                test_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])
-            elif seq_id in ['00', '01', '02', '03', '04', '05', '06', '07', '09', '10']:
-                train_file_list.append([join(pc_path, f) for f in np.sort(os.listdir(pc_path))])
+                test_file_list.append(
+                    [join(pc_path, f) for f in np.sort(os.listdir(pc_path))]
+                )
+            elif seq_id in ["00", "01", "02", "03", "04", "05", "06", "07", "09", "10"]:
+                train_file_list.append(
+                    [join(pc_path, f) for f in np.sort(os.listdir(pc_path))]
+                )
 
         train_file_list = np.concatenate(train_file_list, axis=0)
         val_file_list = np.concatenate(val_file_list, axis=0)
-        if test_scan_num != 'None':
+        if test_scan_num != "None":
             test_file_list = np.concatenate(test_file_list, axis=0)
         else:
             test_file_list = None
         return train_file_list, val_file_list, test_file_list
 
@@ -210,16 +239,25 @@
         """
 
         if (features is None) and (labels is None):
             return cpp_subsampling.compute(points, sampleDl=grid_size, verbose=verbose)
         elif labels is None:
-            return cpp_subsampling.compute(points, features=features, sampleDl=grid_size, verbose=verbose)
+            return cpp_subsampling.compute(
+                points, features=features, sampleDl=grid_size, verbose=verbose
+            )
         elif features is None:
-            return cpp_subsampling.compute(points, classes=labels, sampleDl=grid_size, verbose=verbose)
+            return cpp_subsampling.compute(
+                points, classes=labels, sampleDl=grid_size, verbose=verbose
+            )
         else:
-            return cpp_subsampling.compute(points, features=features, classes=labels, sampleDl=grid_size,
-                                           verbose=verbose)
+            return cpp_subsampling.compute(
+                points,
+                features=features,
+                classes=labels,
+                sampleDl=grid_size,
+                verbose=verbose,
+            )
 
     @staticmethod
     def IoU_from_confusions(confusions):
         """
         Computes IoU from confusion matrices.
@@ -248,23 +286,63 @@
 
     @staticmethod
     def get_class_weights(dataset_name):
         # pre-calculate the number of points in each category
         num_per_class = []
-        if dataset_name is 'S3DIS':
-            num_per_class = np.array([3370714, 2856755, 4919229, 318158, 375640, 478001, 974733,
-                                      650464, 791496, 88727, 1284130, 229758, 2272837], dtype=np.int32)
-        elif dataset_name is 'Semantic3D':
-            num_per_class = np.array([5181602, 5012952, 6830086, 1311528, 10476365, 946982, 334860, 269353],
-                                     dtype=np.int32)
-        elif dataset_name is 'SemanticKITTI':
-            num_per_class = np.array([55437630, 320797, 541736, 2578735, 3274484, 552662, 184064, 78858,
-                                      240942562, 17294618, 170599734, 6369672, 230413074, 101130274, 476491114,
-                                      9833174, 129609852, 4506626, 1168181])
+        if dataset_name is "S3DIS":
+            num_per_class = np.array(
+                [
+                    3370714,
+                    2856755,
+                    4919229,
+                    318158,
+                    375640,
+                    478001,
+                    974733,
+                    650464,
+                    791496,
+                    88727,
+                    1284130,
+                    229758,
+                    2272837,
+                ],
+                dtype=np.int32,
+            )
+        elif dataset_name is "Semantic3D":
+            num_per_class = np.array(
+                [5181602, 5012952, 6830086, 1311528, 10476365, 946982, 334860, 269353],
+                dtype=np.int32,
+            )
+        elif dataset_name is "SemanticKITTI":
+            num_per_class = np.array(
+                [
+                    55437630,
+                    320797,
+                    541736,
+                    2578735,
+                    3274484,
+                    552662,
+                    184064,
+                    78858,
+                    240942562,
+                    17294618,
+                    170599734,
+                    6369672,
+                    230413074,
+                    101130274,
+                    476491114,
+                    9833174,
+                    129609852,
+                    4506626,
+                    1168181,
+                ]
+            )
         weight = num_per_class / float(sum(num_per_class))
         ce_label_weight = 1 / (weight + 0.02)
         return ce_label_weight
+
+
 #         return np.expand_dims(ce_label_weight, axis=0)
 
 
 class Plot:
     @staticmethod
@@ -319,17 +397,22 @@
             Y_colors[valid_ind] = tp
 
             ### bbox
             valid_xyz = pc_xyz[valid_ind]
 
-            xmin = np.min(valid_xyz[:, 0]);
+            xmin = np.min(valid_xyz[:, 0])
             xmax = np.max(valid_xyz[:, 0])
-            ymin = np.min(valid_xyz[:, 1]);
+            ymin = np.min(valid_xyz[:, 1])
             ymax = np.max(valid_xyz[:, 1])
-            zmin = np.min(valid_xyz[:, 2]);
+            zmin = np.min(valid_xyz[:, 2])
             zmax = np.max(valid_xyz[:, 2])
             sem_ins_bbox.append(
-                [[xmin, ymin, zmin], [xmax, ymax, zmax], [min(tp[0], 1.), min(tp[1], 1.), min(tp[2], 1.)]])
+                [
+                    [xmin, ymin, zmin],
+                    [xmax, ymax, zmax],
+                    [min(tp[0], 1.0), min(tp[1], 1.0), min(tp[2], 1.0)],
+                ]
+            )
 
         Y_semins = np.concatenate([pc_xyz[:, 0:3], Y_colors], axis=-1)
         Plot.draw_pc(Y_semins)
         return Y_semins
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/cpp_wrappers/cpp_subsampling/setup.py	2024-06-30 22:34:20.889281+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/cpp_wrappers/cpp_subsampling/setup.py	2024-07-08 11:53:48.315896+00:00
@@ -7,23 +7,21 @@
 # Adding sources of the project
 # *****************************
 
 m_name = "grid_subsampling"
 
-SOURCES = ["../cpp_utils/cloud/cloud.cpp",
-           "grid_subsampling/grid_subsampling.cpp",
-           "wrapper.cpp"]
+SOURCES = [
+    "../cpp_utils/cloud/cloud.cpp",
+    "grid_subsampling/grid_subsampling.cpp",
+    "wrapper.cpp",
+]
 
-module = Extension(m_name,
-                   sources=SOURCES,
-                   extra_compile_args=['-std=c++11',
-                                       '-D_GLIBCXX_USE_CXX11_ABI=0'])
+module = Extension(
+    m_name,
+    sources=SOURCES,
+    extra_compile_args=["-std=c++11", "-D_GLIBCXX_USE_CXX11_ABI=0"],
+)
 
-setup(ext_modules=[module], include_dirs=numpy.distutils.misc_util.get_numpy_include_dirs())
-
-
-
-
-
-
-
-
+setup(
+    ext_modules=[module],
+    include_dirs=numpy.distutils.misc_util.get_numpy_include_dirs(),
+)
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/6_fold_cv.py	2024-06-30 22:34:20.472685+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/6_fold_cv.py	2024-07-08 11:53:48.416453+00:00
@@ -5,14 +5,14 @@
 ROOT_DIR = os.path.dirname(BASE_DIR)
 sys.path.append(ROOT_DIR)
 from helper_ply import read_ply
 from helper_tool import Plot
 
-if __name__ == '__main__':
-    base_dir = '/data/S3DIS/results'
-    original_data_dir = '/data/S3DIS/original_ply'
-    data_path = glob.glob(os.path.join(base_dir, '*.ply'))
+if __name__ == "__main__":
+    base_dir = "/data/S3DIS/results"
+    original_data_dir = "/data/S3DIS/original_ply"
+    data_path = glob.glob(os.path.join(base_dir, "*.ply"))
     data_path = np.sort(data_path)
 
     test_total_correct = 0
     test_total_seen = 0
     gt_classes = [0 for _ in range(13)]
@@ -20,27 +20,37 @@
     true_positive_classes = [0 for _ in range(13)]
     visualization = False
 
     for file_name in data_path:
         pred_data = read_ply(file_name)
-        pred = pred_data['pred']
-        original_data = read_ply(os.path.join(original_data_dir, file_name.split('/')[-1][:-4] + '.ply'))
-        labels = original_data['class']
-        points = np.vstack((original_data['x'], original_data['y'], original_data['z'])).T
+        pred = pred_data["pred"]
+        original_data = read_ply(
+            os.path.join(original_data_dir, file_name.split("/")[-1][:-4] + ".ply")
+        )
+        labels = original_data["class"]
+        points = np.vstack(
+            (original_data["x"], original_data["y"], original_data["z"])
+        ).T
 
         ##################
         # Visualize data #
         ##################
         if visualization:
-            colors = np.vstack((original_data['red'], original_data['green'], original_data['blue'])).T
+            colors = np.vstack(
+                (original_data["red"], original_data["green"], original_data["blue"])
+            ).T
             xyzrgb = np.concatenate([points, colors], axis=-1)
             Plot.draw_pc(xyzrgb)  # visualize raw point clouds
             Plot.draw_pc_sem_ins(points, labels)  # visualize ground-truth
             Plot.draw_pc_sem_ins(points, pred)  # visualize prediction
 
         correct = np.sum(pred == labels)
-        print(str(file_name.split('/')[-1][:-4]) + '_acc:' + str(correct / float(len(labels))))
+        print(
+            str(file_name.split("/")[-1][:-4])
+            + "_acc:"
+            + str(correct / float(len(labels)))
+        )
         test_total_correct += correct
         test_total_seen += len(labels)
 
         for j in range(len(labels)):
             gt_l = int(labels[j])
@@ -49,18 +59,20 @@
             positive_classes[pred_l] += 1
             true_positive_classes[gt_l] += int(gt_l == pred_l)
 
     iou_list = []
     for n in range(13):
-        iou = true_positive_classes[n] / float(gt_classes[n] + positive_classes[n] - true_positive_classes[n])
+        iou = true_positive_classes[n] / float(
+            gt_classes[n] + positive_classes[n] - true_positive_classes[n]
+        )
         iou_list.append(iou)
     mean_iou = sum(iou_list) / 13.0
-    print('eval accuracy: {}'.format(test_total_correct / float(test_total_seen)))
-    print('mean IOU:{}'.format(mean_iou))
+    print("eval accuracy: {}".format(test_total_correct / float(test_total_seen)))
+    print("mean IOU:{}".format(mean_iou))
     print(iou_list)
 
     acc_list = []
     for n in range(13):
         acc = true_positive_classes[n] / float(gt_classes[n])
         acc_list.append(acc)
     mean_acc = sum(acc_list) / 13.0
-    print('mAcc value is :{}'.format(mean_acc))
+    print("mAcc value is :{}".format(mean_acc))
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/RandLANet_expand.py	2024-06-30 22:34:18.842571+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/RandLANet_expand.py	2024-07-08 11:53:48.487048+00:00
@@ -8,11 +8,11 @@
 
 
 class Network(nn.Module):
     def __init__(self, config):
         super().__init__()
-        '''
+        """
         Config settings:-
         
         k_n = 16  # KNN
         num_layers = 4  # Number of layers
         num_points = 4096 * 11  # Number of input points
@@ -35,141 +35,146 @@
 
         train_sum_dir = 'train_log'
         saving = True
         saving_path = None
         
-        '''
+        """
         self.config = config
-        self.class_weights = DP.get_class_weights('SemanticKITTI')
-        
+        self.class_weights = DP.get_class_weights("SemanticKITTI")
+
         self.fc0 = pt_utils.Conv1d(3, 8, kernel_size=1, bn=True)
-        
+
         self.dilated_res_blocks = nn.ModuleList()
-        
+
         d_in = 8
-        d_out = self.config.d_out[0] # 16
-        
+        d_out = self.config.d_out[0]  # 16
+
         self.e0 = Dilated_res_block(d_in, d_out)
-        
+
         d_in = 2 * d_out
-        d_out = self.config.d_out[1] # 64
-        
+        d_out = self.config.d_out[1]  # 64
+
         self.e1 = Dilated_res_block(d_in, d_out)
-        
+
         d_in = 2 * d_out
         d_out = self.config.d_out[2]
-        
-        self.e2 = Dilated_res_block(d_in, d_out) #128
-        
+
+        self.e2 = Dilated_res_block(d_in, d_out)  # 128
+
         d_in = 2 * d_out
-        d_out = self.config.d_out[3]  #256
-        
+        d_out = self.config.d_out[3]  # 256
+
         self.e3 = Dilated_res_block(d_in, d_out)
-        
+
         d_in = 2 * d_out
         d_out = d_in
-        
-        self.d0 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
-        
-        d_in = d_out + 2 * self.config.d_out[-0-2]
-        d_out = 2 * self.config.d_out[-0-2]
-        
-        self.d1 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
-        
-        d_in = d_out + 2 * self.config.d_out[-1-2]
-        d_out = 2 * self.config.d_out[-1-2]
-        
-        self.d2 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
-        
-        d_in = d_out + 2 * self.config.d_out[-2-2]
-        d_out = 2 * self.config.d_out[-2-2]
-        
-        self.d3 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
-        
+
+        self.d0 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+
+        d_in = d_out + 2 * self.config.d_out[-0 - 2]
+        d_out = 2 * self.config.d_out[-0 - 2]
+
+        self.d1 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+
+        d_in = d_out + 2 * self.config.d_out[-1 - 2]
+        d_out = 2 * self.config.d_out[-1 - 2]
+
+        self.d2 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+
+        d_in = d_out + 2 * self.config.d_out[-2 - 2]
+        d_out = 2 * self.config.d_out[-2 - 2]
+
+        self.d3 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+
         d_in = 4 * self.config.d_out[-4]
         d_out = 2 * self.config.d_out[-4]
-        
-        self.d4 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
-        
-        self.fc1 = pt_utils.Conv2d(d_out, 64, kernel_size=(1,1), bn=True)
-        self.fc2 = pt_utils.Conv2d(64, 32, kernel_size=(1,1), bn=True)
+
+        self.d4 = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
+
+        self.fc1 = pt_utils.Conv2d(d_out, 64, kernel_size=(1, 1), bn=True)
+        self.fc2 = pt_utils.Conv2d(64, 32, kernel_size=(1, 1), bn=True)
         self.dropout = nn.Dropout(0.5)
-        self.fc3 = pt_utils.Conv2d(32, self.config.num_classes, kernel_size=(1,1), bn=False, activation=None)
-        
+        self.fc3 = pt_utils.Conv2d(
+            32, self.config.num_classes, kernel_size=(1, 1), bn=False, activation=None
+        )
+
     def forward(self, end_points):
         f_encoder_list = []
-        
-        features = end_points['features']
+
+        features = end_points["features"]
         features = self.fc0(features)
-        
-        features = features.unsqueeze(dim=3) 
-        
-        f_e0 = self.e0(features, end_points['xyz'][0], end_points['neigh_idx'][0])
-        f_s0 = self.random_sample(f_e0, end_points['sub_idx'][0])
+
+        features = features.unsqueeze(dim=3)
+
+        f_e0 = self.e0(features, end_points["xyz"][0], end_points["neigh_idx"][0])
+        f_s0 = self.random_sample(f_e0, end_points["sub_idx"][0])
         features = f_s0
         f_encoder_list.append(f_e0)
-        
-        
-        f_e1 = self.e1(features, end_points['xyz'][1], end_points['neigh_idx'][1])
-        f_s1 = self.random_sample(f_e1, end_points['sub_idx'][1])
+
+        f_e1 = self.e1(features, end_points["xyz"][1], end_points["neigh_idx"][1])
+        f_s1 = self.random_sample(f_e1, end_points["sub_idx"][1])
         features = f_s1
         f_encoder_list.append(f_s1)
-        
-        f_e2 = self.e2(features, end_points['xyz'][2], end_points['neigh_idx'][2])
-        f_s2 = self.random_sample(f_e2, end_points['sub_idx'][2])
+
+        f_e2 = self.e2(features, end_points["xyz"][2], end_points["neigh_idx"][2])
+        f_s2 = self.random_sample(f_e2, end_points["sub_idx"][2])
         features = f_s2
         f_encoder_list.append(f_s2)
-        
-        
-        f_e3 = self.e3(features, end_points['xyz'][3], end_points['neigh_idx'][3])
-        f_s3 = self.random_sample(f_e3, end_points['sub_idx'][3])
+
+        f_e3 = self.e3(features, end_points["xyz"][3], end_points["neigh_idx"][3])
+        f_s3 = self.random_sample(f_e3, end_points["sub_idx"][3])
         features = f_s3
         f_encoder_list.append(f_s3)
-        
-        
-#         print(features.shape)
-#         print(f_encoder_list[-1].shape)
-        
+
+        #         print(features.shape)
+        #         print(f_encoder_list[-1].shape)
+
         features = self.d0(f_encoder_list[-1])
-        
-        
+
         f_decoder_list = []
-        
-        f_interp_1 = self.nearest_interpolation(features, end_points['interp_idx'][-0 - 1])
+
+        f_interp_1 = self.nearest_interpolation(
+            features, end_points["interp_idx"][-0 - 1]
+        )
         f_d1 = self.d1(torch.cat([f_encoder_list[-0 - 2], f_interp_1], dim=1))
         features = f_d1
         f_decoder_list.append(f_d1)
-        
-        f_interp_2 = self.nearest_interpolation(features, end_points['interp_idx'][-1 - 1])
+
+        f_interp_2 = self.nearest_interpolation(
+            features, end_points["interp_idx"][-1 - 1]
+        )
         print(f_interp_2.shape)
         print(f_encoder_list[-1 - 1].shape)
         f_d2 = self.d2(torch.cat([f_encoder_list[-1 - 2], f_interp_2], dim=1))
         features = f_d2
         f_decoder_list.append(f_d2)
-        
-        f_interp_3 = self.nearest_interpolation(features, end_points['interp_idx'][-2 - 1])
+
+        f_interp_3 = self.nearest_interpolation(
+            features, end_points["interp_idx"][-2 - 1]
+        )
         print(f_interp_3.shape)
         print(f_encoder_list[-2 - 2].shape)
         f_d3 = self.d3(torch.cat([f_encoder_list[-2 - 2], f_interp_3], dim=1))
         features = f_d3
         f_decoder_list.append(f_d3)
-        
-        f_interp_4 = self.nearest_interpolation(features, end_points['interp_idx'][-3 - 1])
+
+        f_interp_4 = self.nearest_interpolation(
+            features, end_points["interp_idx"][-3 - 1]
+        )
         f_d4 = self.d4(torch.cat([f_encoder_list[-3 - 2], f_interp_4], dim=1))
         features = f_d4
         f_decoder_list.append(f_d4)
-        
+
         features = self.fc1(features)
         features = self.fc2(features)
         features = self.dropout(features)
         features = self.fc3(features)
         f_out = features.squeeze(3)
-        
-        end_points['logits'] = f_out
+
+        end_points["logits"] = f_out
         return end_points
-    
-    
+
     @staticmethod
     def random_sample(feature, pool_idx):
         """
         :param feature: [B, N, d] input features matrix
         :param pool_idx: [B, N', max_num] N' < N, N' is the selected position after pooling
@@ -178,13 +183,17 @@
         feature = feature.squeeze(dim=3)  # batch*channel*npoints
         num_neigh = pool_idx.shape[-1]
         d = feature.shape[1]
         batch_size = pool_idx.shape[0]
         pool_idx = pool_idx.reshape(batch_size, -1)  # batch*(npoints,nsamples)
-        pool_features = torch.gather(feature, 2, pool_idx.unsqueeze(1).repeat(1, feature.shape[1], 1))
+        pool_features = torch.gather(
+            feature, 2, pool_idx.unsqueeze(1).repeat(1, feature.shape[1], 1)
+        )
         pool_features = pool_features.reshape(batch_size, d, -1, num_neigh)
-        pool_features = pool_features.max(dim=3, keepdim=True)[0]  # batch*channel*npoints*1
+        pool_features = pool_features.max(dim=3, keepdim=True)[
+            0
+        ]  # batch*channel*npoints*1
         return pool_features
 
     @staticmethod
     def nearest_interpolation(feature, interp_idx):
         """
@@ -194,23 +203,26 @@
         """
         feature = feature.squeeze(dim=3)  # batch*channel*npoints
         batch_size = interp_idx.shape[0]
         up_num_points = interp_idx.shape[1]
         interp_idx = interp_idx.reshape(batch_size, up_num_points)
-        interpolated_features = torch.gather(feature, 2, interp_idx.unsqueeze(1).repeat(1,feature.shape[1],1))
-        interpolated_features = interpolated_features.unsqueeze(3)  # batch*channel*npoints*1
+        interpolated_features = torch.gather(
+            feature, 2, interp_idx.unsqueeze(1).repeat(1, feature.shape[1], 1)
+        )
+        interpolated_features = interpolated_features.unsqueeze(
+            3
+        )  # batch*channel*npoints*1
         return interpolated_features
 
 
-
 def compute_acc(end_points):
 
-    logits = end_points['valid_logits']
-    labels = end_points['valid_labels']
+    logits = end_points["valid_logits"]
+    labels = end_points["valid_labels"]
     logits = logits.max(dim=1)[1]
     acc = (logits == labels).sum().float() / float(labels.shape[0])
-    end_points['acc'] = acc
+    end_points["acc"] = acc
     return acc, end_points
 
 
 class IoUCalculator:
     def __init__(self, cfg):
@@ -218,12 +230,12 @@
         self.positive_classes = [0 for _ in range(cfg.num_classes)]
         self.true_positive_classes = [0 for _ in range(cfg.num_classes)]
         self.cfg = cfg
 
     def add_data(self, end_points):
-        logits = end_points['valid_logits']
-        labels = end_points['valid_labels']
+        logits = end_points["valid_logits"]
+        labels = end_points["valid_labels"]
         pred = logits.max(dim=1)[1]
         pred_valid = pred.detach().cpu().numpy()
         labels_valid = labels.detach().cpu().numpy()
 
         val_total_correct = 0
@@ -231,96 +243,130 @@
 
         correct = np.sum(pred_valid == labels_valid)
         val_total_correct += correct
         val_total_seen += len(labels_valid)
 
-        conf_matrix = confusion_matrix(labels_valid, pred_valid, np.arange(0, self.cfg.num_classes, 1))
+        conf_matrix = confusion_matrix(
+            labels_valid, pred_valid, np.arange(0, self.cfg.num_classes, 1)
+        )
         self.gt_classes += np.sum(conf_matrix, axis=1)
         self.positive_classes += np.sum(conf_matrix, axis=0)
         self.true_positive_classes += np.diagonal(conf_matrix)
 
     def compute_iou(self):
         iou_list = []
         for n in range(0, self.cfg.num_classes, 1):
-            if float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n]) != 0:
-                iou = self.true_positive_classes[n] / float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n])
+            if (
+                float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
+                != 0
+            ):
+                iou = self.true_positive_classes[n] / float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
                 iou_list.append(iou)
             else:
                 iou_list.append(0.0)
         mean_iou = sum(iou_list) / float(self.cfg.num_classes)
         return mean_iou, iou_list
 
 
-
 class Dilated_res_block(nn.Module):
     def __init__(self, d_in, d_out):
         super().__init__()
 
-        self.mlp1 = pt_utils.Conv2d(d_in, d_out//2, kernel_size=(1,1), bn=True)
+        self.mlp1 = pt_utils.Conv2d(d_in, d_out // 2, kernel_size=(1, 1), bn=True)
         self.lfa = Building_block(d_out)
-        self.mlp2 = pt_utils.Conv2d(d_out, d_out*2, kernel_size=(1, 1), bn=True, activation=None)
-        self.shortcut = pt_utils.Conv2d(d_in, d_out*2, kernel_size=(1,1), bn=True, activation=None)
+        self.mlp2 = pt_utils.Conv2d(
+            d_out, d_out * 2, kernel_size=(1, 1), bn=True, activation=None
+        )
+        self.shortcut = pt_utils.Conv2d(
+            d_in, d_out * 2, kernel_size=(1, 1), bn=True, activation=None
+        )
 
     def forward(self, feature, xyz, neigh_idx):
         f_pc = self.mlp1(feature)  # Batch*channel*npoints*1
         f_pc = self.lfa(xyz, f_pc, neigh_idx)  # Batch*d_out*npoints*1
         f_pc = self.mlp2(f_pc)
         shortcut = self.shortcut(feature)
-        return F.leaky_relu(f_pc+shortcut, negative_slope=0.2)
+        return F.leaky_relu(f_pc + shortcut, negative_slope=0.2)
 
 
 class Building_block(nn.Module):
     def __init__(self, d_out):  #  d_in = d_out//2
         super().__init__()
-        self.mlp1 = pt_utils.Conv2d(10, d_out//2, kernel_size=(1,1), bn=True)
-        self.att_pooling_1 = Att_pooling(d_out, d_out//2)
-
-        self.mlp2 = pt_utils.Conv2d(d_out//2, d_out//2, kernel_size=(1, 1), bn=True)
+        self.mlp1 = pt_utils.Conv2d(10, d_out // 2, kernel_size=(1, 1), bn=True)
+        self.att_pooling_1 = Att_pooling(d_out, d_out // 2)
+
+        self.mlp2 = pt_utils.Conv2d(d_out // 2, d_out // 2, kernel_size=(1, 1), bn=True)
         self.att_pooling_2 = Att_pooling(d_out, d_out)
 
     def forward(self, xyz, feature, neigh_idx):  # feature: Batch*channel*npoints*1
         f_xyz = self.relative_pos_encoding(xyz, neigh_idx)  # batch*npoint*nsamples*10
         f_xyz = f_xyz.permute((0, 3, 1, 2))  # batch*10*npoint*nsamples
         f_xyz = self.mlp1(f_xyz)
-        f_neighbours = self.gather_neighbour(feature.squeeze(-1).permute((0, 2, 1)), neigh_idx)  # batch*npoint*nsamples*channel
-        f_neighbours = f_neighbours.permute((0, 3, 1, 2))  # batch*channel*npoint*nsamples
+        f_neighbours = self.gather_neighbour(
+            feature.squeeze(-1).permute((0, 2, 1)), neigh_idx
+        )  # batch*npoint*nsamples*channel
+        f_neighbours = f_neighbours.permute(
+            (0, 3, 1, 2)
+        )  # batch*channel*npoint*nsamples
         f_concat = torch.cat([f_neighbours, f_xyz], dim=1)
         f_pc_agg = self.att_pooling_1(f_concat)  # Batch*channel*npoints*1
 
         f_xyz = self.mlp2(f_xyz)
-        f_neighbours = self.gather_neighbour(f_pc_agg.squeeze(-1).permute((0, 2, 1)), neigh_idx)  # batch*npoint*nsamples*channel
-        f_neighbours = f_neighbours.permute((0, 3, 1, 2))  # batch*channel*npoint*nsamples
+        f_neighbours = self.gather_neighbour(
+            f_pc_agg.squeeze(-1).permute((0, 2, 1)), neigh_idx
+        )  # batch*npoint*nsamples*channel
+        f_neighbours = f_neighbours.permute(
+            (0, 3, 1, 2)
+        )  # batch*channel*npoint*nsamples
         f_concat = torch.cat([f_neighbours, f_xyz], dim=1)
         f_pc_agg = self.att_pooling_2(f_concat)
         return f_pc_agg
 
     def relative_pos_encoding(self, xyz, neigh_idx):
         neighbor_xyz = self.gather_neighbour(xyz, neigh_idx)  # batch*npoint*nsamples*3
 
-        xyz_tile = xyz.unsqueeze(2).repeat(1, 1, neigh_idx.shape[-1], 1)  # batch*npoint*nsamples*3
+        xyz_tile = xyz.unsqueeze(2).repeat(
+            1, 1, neigh_idx.shape[-1], 1
+        )  # batch*npoint*nsamples*3
         relative_xyz = xyz_tile - neighbor_xyz  # batch*npoint*nsamples*3
-        relative_dis = torch.sqrt(torch.sum(torch.pow(relative_xyz, 2), dim=-1, keepdim=True))  # batch*npoint*nsamples*1
-        relative_feature = torch.cat([relative_dis, relative_xyz, xyz_tile, neighbor_xyz], dim=-1)  # batch*npoint*nsamples*10
+        relative_dis = torch.sqrt(
+            torch.sum(torch.pow(relative_xyz, 2), dim=-1, keepdim=True)
+        )  # batch*npoint*nsamples*1
+        relative_feature = torch.cat(
+            [relative_dis, relative_xyz, xyz_tile, neighbor_xyz], dim=-1
+        )  # batch*npoint*nsamples*10
         return relative_feature
 
     @staticmethod
     def gather_neighbour(pc, neighbor_idx):  # pc: batch*npoint*channel
         # gather the coordinates or features of neighboring points
         batch_size = pc.shape[0]
         num_points = pc.shape[1]
         d = pc.shape[2]
         index_input = neighbor_idx.reshape(batch_size, -1)
-        features = torch.gather(pc, 1, index_input.unsqueeze(-1).repeat(1, 1, pc.shape[2]))
-        features = features.reshape(batch_size, num_points, neighbor_idx.shape[-1], d)  # batch*npoint*nsamples*channel
+        features = torch.gather(
+            pc, 1, index_input.unsqueeze(-1).repeat(1, 1, pc.shape[2])
+        )
+        features = features.reshape(
+            batch_size, num_points, neighbor_idx.shape[-1], d
+        )  # batch*npoint*nsamples*channel
         return features
 
 
 class Att_pooling(nn.Module):
     def __init__(self, d_in, d_out):
         super().__init__()
         self.fc = nn.Conv2d(d_in, d_in, (1, 1), bias=False)
-        self.mlp = pt_utils.Conv2d(d_in, d_out, kernel_size=(1,1), bn=True)
+        self.mlp = pt_utils.Conv2d(d_in, d_out, kernel_size=(1, 1), bn=True)
 
     def forward(self, feature_set):
 
         att_activation = self.fc(feature_set)
         att_scores = F.softmax(att_activation, dim=3)
@@ -330,12 +376,12 @@
         return f_agg
 
 
 def compute_loss(end_points, cfg):
 
-    logits = end_points['logits']
-    labels = end_points['labels']
+    logits = end_points["logits"]
+    labels = end_points["labels"]
 
     logits = logits.transpose(1, 2).reshape(-1, cfg.num_classes)
     labels = labels.reshape(-1)
 
     # Boolean mask of points that should be ignored
@@ -350,27 +396,24 @@
 
     # Reduce label values in the range of logit shape
     reducing_list = torch.range(0, cfg.num_classes).long().cuda()
     inserted_value = torch.zeros((1,)).long().cuda()
     for ign_label in cfg.ignored_label_inds:
-        reducing_list = torch.cat([reducing_list[:ign_label], inserted_value, reducing_list[ign_label:]], 0)
+        reducing_list = torch.cat(
+            [reducing_list[:ign_label], inserted_value, reducing_list[ign_label:]], 0
+        )
     valid_labels = torch.gather(reducing_list, 0, valid_labels_init)
     loss = get_loss(valid_logits, valid_labels, cfg.class_weights)
-    end_points['valid_logits'], end_points['valid_labels'] = valid_logits, valid_labels
-    end_points['loss'] = loss
+    end_points["valid_logits"], end_points["valid_labels"] = valid_logits, valid_labels
+    end_points["loss"] = loss
     return loss, end_points
 
 
 def get_loss(logits, labels, pre_cal_weights):
     # calculate the weighted cross entropy according to the inverse frequency
     class_weights = torch.from_numpy(pre_cal_weights).float().cuda()
     # one_hot_labels = F.one_hot(labels, self.config.num_classes)
 
-    criterion = nn.CrossEntropyLoss(weight=class_weights, reduction='none')
+    criterion = nn.CrossEntropyLoss(weight=class_weights, reduction="none")
     output_loss = criterion(logits, labels)
     output_loss = output_loss.mean()
     return output_loss
-        
-            
-                            
-                            
-        
\ No newline at end of file
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/pytorch_utils.py	2024-06-30 22:34:19.826779+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/pytorch_utils.py	2024-07-08 11:53:48.601125+00:00
@@ -3,67 +3,68 @@
 
 
 class SharedMLP(nn.Sequential):
 
     def __init__(
-            self,
-            args: List[int],
-            *,
-            bn: bool = False,
-            activation=nn.ReLU(inplace=True),
-            preact: bool = False,
-            first: bool = False,
-            name: str = "",
-            instance_norm: bool = False
+        self,
+        args: List[int],
+        *,
+        bn: bool = False,
+        activation=nn.ReLU(inplace=True),
+        preact: bool = False,
+        first: bool = False,
+        name: str = "",
+        instance_norm: bool = False
     ):
         super().__init__()
 
         for i in range(len(args) - 1):
             self.add_module(
-                name + 'layer{}'.format(i),
+                name + "layer{}".format(i),
                 Conv2d(
                     args[i],
                     args[i + 1],
                     bn=(not first or not preact or (i != 0)) and bn,
-                    activation=activation
-                    if (not first or not preact or (i != 0)) else None,
+                    activation=(
+                        activation if (not first or not preact or (i != 0)) else None
+                    ),
                     preact=preact,
-                    instance_norm=instance_norm
-                )
+                    instance_norm=instance_norm,
+                ),
             )
 
 
 class _ConvBase(nn.Sequential):
 
     def __init__(
-            self,
-            in_size,
-            out_size,
-            kernel_size,
-            stride,
-            padding,
-            activation,
-            bn,
-            init,
-            conv=None,
-            batch_norm=None,
-            bias=True,
-            preact=False,
-            name="",
-            instance_norm=False,
-            instance_norm_func=None
+        self,
+        in_size,
+        out_size,
+        kernel_size,
+        stride,
+        padding,
+        activation,
+        bn,
+        init,
+        conv=None,
+        batch_norm=None,
+        bias=True,
+        preact=False,
+        name="",
+        instance_norm=False,
+        instance_norm_func=None,
     ):
         super().__init__()
 
         bias = bias and (not bn)
         conv_unit = conv(
             in_size,
             out_size,
             kernel_size=kernel_size,
             stride=stride,
             padding=padding,
-            bias=bias
+            bias=bias,
         )
         init(conv_unit.weight)
         if bias:
             nn.init.constant_(conv_unit.bias, 0)
 
@@ -72,35 +73,39 @@
                 bn_unit = batch_norm(out_size)
             else:
                 bn_unit = batch_norm(in_size)
         if instance_norm:
             if not preact:
-                in_unit = instance_norm_func(out_size, affine=False, track_running_stats=False)
+                in_unit = instance_norm_func(
+                    out_size, affine=False, track_running_stats=False
+                )
             else:
-                in_unit = instance_norm_func(in_size, affine=False, track_running_stats=False)
+                in_unit = instance_norm_func(
+                    in_size, affine=False, track_running_stats=False
+                )
 
         if preact:
             if bn:
-                self.add_module(name + 'bn', bn_unit)
-
-            if activation is not None:
-                self.add_module(name + 'activation', activation)
+                self.add_module(name + "bn", bn_unit)
+
+            if activation is not None:
+                self.add_module(name + "activation", activation)
 
             if not bn and instance_norm:
-                self.add_module(name + 'in', in_unit)
-
-        self.add_module(name + 'conv', conv_unit)
+                self.add_module(name + "in", in_unit)
+
+        self.add_module(name + "conv", conv_unit)
 
         if not preact:
             if bn:
-                self.add_module(name + 'bn', bn_unit)
-
-            if activation is not None:
-                self.add_module(name + 'activation', activation)
+                self.add_module(name + "bn", bn_unit)
+
+            if activation is not None:
+                self.add_module(name + "activation", activation)
 
             if not bn and instance_norm:
-                self.add_module(name + 'in', in_unit)
+                self.add_module(name + "in", in_unit)
 
 
 class _BNBase(nn.Sequential):
 
     def __init__(self, in_size, batch_norm=None, name=""):
@@ -124,24 +129,24 @@
 
 
 class Conv1d(_ConvBase):
 
     def __init__(
-            self,
-            in_size: int,
-            out_size: int,
-            *,
-            kernel_size: int = 1,
-            stride: int = 1,
-            padding: int = 0,
-            activation=nn.LeakyReLU(negative_slope=0.2, inplace=True),
-            bn: bool = False,
-            init=nn.init.kaiming_normal_,
-            bias: bool = True,
-            preact: bool = False,
-            name: str = "",
-            instance_norm=False
+        self,
+        in_size: int,
+        out_size: int,
+        *,
+        kernel_size: int = 1,
+        stride: int = 1,
+        padding: int = 0,
+        activation=nn.LeakyReLU(negative_slope=0.2, inplace=True),
+        bn: bool = False,
+        init=nn.init.kaiming_normal_,
+        bias: bool = True,
+        preact: bool = False,
+        name: str = "",
+        instance_norm=False
     ):
         super().__init__(
             in_size,
             out_size,
             kernel_size,
@@ -154,31 +159,31 @@
             batch_norm=BatchNorm1d,
             bias=bias,
             preact=preact,
             name=name,
             instance_norm=instance_norm,
-            instance_norm_func=nn.InstanceNorm1d
+            instance_norm_func=nn.InstanceNorm1d,
         )
 
 
 class Conv2d(_ConvBase):
 
     def __init__(
-            self,
-            in_size: int,
-            out_size: int,
-            *,
-            kernel_size: Tuple[int, int] = (1, 1),
-            stride: Tuple[int, int] = (1, 1),
-            padding: Tuple[int, int] = (0, 0),
-            activation=nn.LeakyReLU(negative_slope=0.2, inplace=True),
-            bn: bool = False,
-            init=nn.init.kaiming_normal_,
-            bias: bool = True,
-            preact: bool = False,
-            name: str = "",
-            instance_norm=False
+        self,
+        in_size: int,
+        out_size: int,
+        *,
+        kernel_size: Tuple[int, int] = (1, 1),
+        stride: Tuple[int, int] = (1, 1),
+        padding: Tuple[int, int] = (0, 0),
+        activation=nn.LeakyReLU(negative_slope=0.2, inplace=True),
+        bn: bool = False,
+        init=nn.init.kaiming_normal_,
+        bias: bool = True,
+        preact: bool = False,
+        name: str = "",
+        instance_norm=False
     ):
         super().__init__(
             in_size,
             out_size,
             kernel_size,
@@ -191,26 +196,26 @@
             batch_norm=BatchNorm2d,
             bias=bias,
             preact=preact,
             name=name,
             instance_norm=instance_norm,
-            instance_norm_func=nn.InstanceNorm2d
+            instance_norm_func=nn.InstanceNorm2d,
         )
 
 
 class FC(nn.Sequential):
 
     def __init__(
-            self,
-            in_size: int,
-            out_size: int,
-            *,
-            activation=nn.ReLU(inplace=True),
-            bn: bool = False,
-            init=None,
-            preact: bool = False,
-            name: str = ""
+        self,
+        in_size: int,
+        out_size: int,
+        *,
+        activation=nn.ReLU(inplace=True),
+        bn: bool = False,
+        init=None,
+        preact: bool = False,
+        name: str = ""
     ):
         super().__init__()
 
         fc = nn.Linear(in_size, out_size, bias=not bn)
         if init is not None:
@@ -218,23 +223,23 @@
         if not bn:
             nn.init.constant(fc.bias, 0)
 
         if preact:
             if bn:
-                self.add_module(name + 'bn', BatchNorm1d(in_size))
-
-            if activation is not None:
-                self.add_module(name + 'activation', activation)
-
-        self.add_module(name + 'fc', fc)
+                self.add_module(name + "bn", BatchNorm1d(in_size))
+
+            if activation is not None:
+                self.add_module(name + "activation", activation)
+
+        self.add_module(name + "fc", fc)
 
         if not preact:
             if bn:
-                self.add_module(name + 'bn', BatchNorm1d(out_size))
-
-            if activation is not None:
-                self.add_module(name + 'activation', activation)
+                self.add_module(name + "bn", BatchNorm1d(out_size))
+
+            if activation is not None:
+                self.add_module(name + "activation", activation)
 
 
 def set_bn_momentum_default(bn_momentum):
 
     def fn(m):
@@ -244,19 +249,14 @@
     return fn
 
 
 class BNMomentumScheduler(object):
 
-    def __init__(
-            self, model, bn_lambda, last_epoch=-1,
-            setter=set_bn_momentum_default
-    ):
+    def __init__(self, model, bn_lambda, last_epoch=-1, setter=set_bn_momentum_default):
         if not isinstance(model, nn.Module):
             raise RuntimeError(
-                "Class '{}' is not a PyTorch nn Module".format(
-                    type(model).__name__
-                )
+                "Class '{}' is not a PyTorch nn Module".format(type(model).__name__)
             )
 
         self.model = model
         self.setter = setter
         self.lmbd = bn_lambda
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/data_prepare_gender.py	2024-06-30 22:34:20.930953+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/data_prepare_gender.py	2024-07-08 11:53:48.649225+00:00
@@ -7,70 +7,74 @@
 ROOT_DIR = dirname(BASE_DIR)
 sys.path.append(BASE_DIR)
 sys.path.append(ROOT_DIR)
 from helper_tool import DataProcessing as DP
 
-data_config = os.path.join(BASE_DIR, 'gender.yaml')
-DATA = yaml.safe_load(open(data_config, 'r'))
+data_config = os.path.join(BASE_DIR, "gender.yaml")
+DATA = yaml.safe_load(open(data_config, "r"))
 remap_dict = DATA["learning_map"]
 max_key = max(remap_dict.keys())
 remap_lut = np.zeros((max_key + 100), dtype=np.int32)
 remap_lut[list(remap_dict.keys())] = list(remap_dict.values())
 
 
 grid_size = 0.06
-dataset_path = '/DATA1/Scene_scans/sequences'
-output_path = '/DATA1/Scene_scans/sequences' + '_' + str(grid_size)
+dataset_path = "/DATA1/Scene_scans/sequences"
+output_path = "/DATA1/Scene_scans/sequences" + "_" + str(grid_size)
 seq_list = np.sort(os.listdir(dataset_path))
 for seq_id in seq_list:
-    print('sequence' + seq_id + ' start')
+    print("sequence" + seq_id + " start")
     seq_path = join(dataset_path, seq_id)
     seq_path_out = join(output_path, seq_id)
-    pc_path = join(seq_path, 'velodyne')
-    pc_path_out = join(seq_path_out, 'velodyne')
-    KDTree_path_out = join(seq_path_out, 'KDTree')
+    pc_path = join(seq_path, "velodyne")
+    pc_path_out = join(seq_path_out, "velodyne")
+    KDTree_path_out = join(seq_path_out, "KDTree")
     os.makedirs(seq_path_out) if not exists(seq_path_out) else None
     os.makedirs(pc_path_out) if not exists(pc_path_out) else None
     os.makedirs(KDTree_path_out) if not exists(KDTree_path_out) else None
 
     if int(seq_id) < 11:
-        label_path = join(seq_path, 'labels')
-        label_path_out = join(seq_path_out, 'labels')
+        label_path = join(seq_path, "labels")
+        label_path_out = join(seq_path_out, "labels")
         os.makedirs(label_path_out) if not exists(label_path_out) else None
         scan_list = np.sort(os.listdir(pc_path))
         for scan_id in scan_list:
             print(scan_id)
             points = DP.load_pc_gender(join(pc_path, scan_id))
-            labels = DP.load_label_gender(join(label_path, str(scan_id[:-4]) + '.label'), remap_lut)
-            sub_points, sub_labels = DP.grid_sub_sampling(points, labels=labels, grid_size=grid_size)
+            labels = DP.load_label_gender(
+                join(label_path, str(scan_id[:-4]) + ".label"), remap_lut
+            )
+            sub_points, sub_labels = DP.grid_sub_sampling(
+                points, labels=labels, grid_size=grid_size
+            )
             search_tree = KDTree(sub_points)
-            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + '.pkl')
+            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + ".pkl")
             np.save(join(pc_path_out, scan_id)[:-4], sub_points)
             np.save(join(label_path_out, scan_id)[:-4], sub_labels)
-            with open(KDTree_save, 'wb') as f:
+            with open(KDTree_save, "wb") as f:
                 pickle.dump(search_tree, f)
-            if seq_id == '10':
-                proj_path = join(seq_path_out, 'proj')
+            if seq_id == "10":
+                proj_path = join(seq_path_out, "proj")
                 os.makedirs(proj_path) if not exists(proj_path) else None
                 proj_inds = np.squeeze(search_tree.query(points, return_distance=False))
                 proj_inds = proj_inds.astype(np.int32)
-                proj_save = join(proj_path, str(scan_id[:-4]) + '_proj.pkl')
-                with open(proj_save, 'wb') as f:
+                proj_save = join(proj_path, str(scan_id[:-4]) + "_proj.pkl")
+                with open(proj_save, "wb") as f:
                     pickle.dump([proj_inds], f)
     else:
-        proj_path = join(seq_path_out, 'proj')
+        proj_path = join(seq_path_out, "proj")
         os.makedirs(proj_path) if not exists(proj_path) else None
         scan_list = np.sort(os.listdir(pc_path))
         for scan_id in scan_list:
             print(scan_id)
             points = DP.load_pc_gender(join(pc_path, scan_id))
             sub_points = DP.grid_sub_sampling(points, grid_size=0.06)
             search_tree = KDTree(sub_points)
             proj_inds = np.squeeze(search_tree.query(points, return_distance=False))
             proj_inds = proj_inds.astype(np.int32)
-            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + '.pkl')
-            proj_save = join(proj_path, str(scan_id[:-4]) + '_proj.pkl')
+            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + ".pkl")
+            proj_save = join(proj_path, str(scan_id[:-4]) + "_proj.pkl")
             np.save(join(pc_path_out, scan_id)[:-4], sub_points)
-            with open(KDTree_save, 'wb') as f:
+            with open(KDTree_save, "wb") as f:
                 pickle.dump(search_tree, f)
-            with open(proj_save, 'wb') as f:
+            with open(proj_save, "wb") as f:
                 pickle.dump([proj_inds], f)
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/nearest_neighbors/lib/python/KNN_NanoFLANN-0.0.0-py3.7-linux-x86_64.egg/nearest_neighbors.py	2024-06-30 22:34:21.535224+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/nearest_neighbors/lib/python/KNN_NanoFLANN-0.0.0-py3.7-linux-x86_64.egg/nearest_neighbors.py	2024-07-08 11:53:48.704973+00:00
@@ -1,9 +1,15 @@
 def __bootstrap__():
     global __bootstrap__, __loader__, __file__
     import sys, pkg_resources, importlib.util
-    __file__ = pkg_resources.resource_filename(__name__, 'nearest_neighbors.cpython-37m-x86_64-linux-gnu.so')
-    __loader__ = None; del __bootstrap__, __loader__
-    spec = importlib.util.spec_from_file_location(__name__,__file__)
+
+    __file__ = pkg_resources.resource_filename(
+        __name__, "nearest_neighbors.cpython-37m-x86_64-linux-gnu.so"
+    )
+    __loader__ = None
+    del __bootstrap__, __loader__
+    spec = importlib.util.spec_from_file_location(__name__, __file__)
     mod = importlib.util.module_from_spec(spec)
     spec.loader.exec_module(mod)
+
+
 __bootstrap__()
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/data_prepare_s3dis.py	2024-06-30 22:34:20.930953+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/data_prepare_s3dis.py	2024-07-08 11:53:48.747227+00:00
@@ -9,23 +9,23 @@
 sys.path.append(BASE_DIR)
 sys.path.append(ROOT_DIR)
 from helper_ply import write_ply
 from helper_tool import DataProcessing as DP
 
-dataset_path = '/data/S3DIS/Stanford3dDataset_v1.2_Aligned_Version'
-anno_paths = [line.rstrip() for line in open(join(BASE_DIR, 'meta/anno_paths.txt'))]
+dataset_path = "/data/S3DIS/Stanford3dDataset_v1.2_Aligned_Version"
+anno_paths = [line.rstrip() for line in open(join(BASE_DIR, "meta/anno_paths.txt"))]
 anno_paths = [join(dataset_path, p) for p in anno_paths]
 
-gt_class = [x.rstrip() for x in open(join(BASE_DIR, 'meta/class_names.txt'))]
+gt_class = [x.rstrip() for x in open(join(BASE_DIR, "meta/class_names.txt"))]
 gt_class2label = {cls: i for i, cls in enumerate(gt_class)}
 
 sub_grid_size = 0.04
-original_pc_folder = join(dirname(dataset_path), 'original_ply')
-sub_pc_folder = join(dirname(dataset_path), 'input_{:.3f}'.format(sub_grid_size))
+original_pc_folder = join(dirname(dataset_path), "original_ply")
+sub_pc_folder = join(dirname(dataset_path), "input_{:.3f}".format(sub_grid_size))
 os.mkdir(original_pc_folder) if not exists(original_pc_folder) else None
 os.mkdir(sub_pc_folder) if not exists(sub_pc_folder) else None
-out_format = '.ply'
+out_format = ".ply"
 
 
 def convert_pc2ply(anno_path, save_path):
     """
     Convert original dataset files to ply file (each line is XYZRGBL).
@@ -34,14 +34,14 @@
     :param save_path: path to save original point clouds (each line is XYZRGBL)
     :return: None
     """
     data_list = []
 
-    for f in glob.glob(join(anno_path, '*.txt')):
-        class_name = os.path.basename(f).split('_')[0]
+    for f in glob.glob(join(anno_path, "*.txt")):
+        class_name = os.path.basename(f).split("_")[0]
         if class_name not in gt_class:  # note: in some room there is 'staris' class..
-            class_name = 'clutter'
+            class_name = "clutter"
         pc = pd.read_csv(f, header=None, delim_whitespace=True).values
         labels = np.ones((pc.shape[0], 1)) * gt_class2label[class_name]
         data_list.append(np.concatenate([pc, labels], 1))  # Nx7
 
     pc_label = np.concatenate(data_list, 0)
@@ -49,32 +49,44 @@
     pc_label[:, 0:3] -= xyz_min
 
     xyz = pc_label[:, :3].astype(np.float32)
     colors = pc_label[:, 3:6].astype(np.uint8)
     labels = pc_label[:, 6].astype(np.uint8)
-    write_ply(save_path, (xyz, colors, labels), ['x', 'y', 'z', 'red', 'green', 'blue', 'class'])
+    write_ply(
+        save_path,
+        (xyz, colors, labels),
+        ["x", "y", "z", "red", "green", "blue", "class"],
+    )
 
     # save sub_cloud and KDTree file
-    sub_xyz, sub_colors, sub_labels = DP.grid_sub_sampling(xyz, colors, labels, sub_grid_size)
+    sub_xyz, sub_colors, sub_labels = DP.grid_sub_sampling(
+        xyz, colors, labels, sub_grid_size
+    )
     sub_colors = sub_colors / 255.0
-    sub_ply_file = join(sub_pc_folder, save_path.split('/')[-1][:-4] + '.ply')
-    write_ply(sub_ply_file, [sub_xyz, sub_colors, sub_labels], ['x', 'y', 'z', 'red', 'green', 'blue', 'class'])
+    sub_ply_file = join(sub_pc_folder, save_path.split("/")[-1][:-4] + ".ply")
+    write_ply(
+        sub_ply_file,
+        [sub_xyz, sub_colors, sub_labels],
+        ["x", "y", "z", "red", "green", "blue", "class"],
+    )
 
     search_tree = KDTree(sub_xyz)
-    kd_tree_file = join(sub_pc_folder, str(save_path.split('/')[-1][:-4]) + '_KDTree.pkl')
-    with open(kd_tree_file, 'wb') as f:
+    kd_tree_file = join(
+        sub_pc_folder, str(save_path.split("/")[-1][:-4]) + "_KDTree.pkl"
+    )
+    with open(kd_tree_file, "wb") as f:
         pickle.dump(search_tree, f)
 
     proj_idx = np.squeeze(search_tree.query(xyz, return_distance=False))
     proj_idx = proj_idx.astype(np.int32)
-    proj_save = join(sub_pc_folder, str(save_path.split('/')[-1][:-4]) + '_proj.pkl')
-    with open(proj_save, 'wb') as f:
+    proj_save = join(sub_pc_folder, str(save_path.split("/")[-1][:-4]) + "_proj.pkl")
+    with open(proj_save, "wb") as f:
         pickle.dump([proj_idx, labels], f)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     # Note: there is an extra character in the v1.2 data in Area_5/hallway_6. It's fixed manually.
     for annotation_path in anno_paths:
         print(annotation_path)
-        elements = str(annotation_path).split('/')
-        out_file_name = elements[-3] + '_' + elements[-2] + out_format
+        elements = str(annotation_path).split("/")
+        out_file_name = elements[-3] + "_" + elements[-2] + out_format
         convert_pc2ply(annotation_path, join(original_pc_folder, out_file_name))
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/semantic_kitti_dataset.py	2024-06-30 22:34:19.847934+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/semantic_kitti_dataset.py	2024-07-08 11:53:48.783838+00:00
@@ -6,152 +6,163 @@
 import torch.utils.data as torch_data
 import torch
 import glob
 
 
-
 class SemanticKITTI(torch_data.Dataset):
     def __init__(self, mode, cls=None, test_id=None):
-        self.name = 'SemanticKITTI'
-        self.dataset_path = '../../SemanticKitti/unzipped/dataset/sequences_0.06'
-        self.label_to_names = {0: 'unlabeled',
-                               1: 'car',
-                               2: 'bicycle',
-                               3: 'motorcycle',
-                               4: 'truck',
-                               5: 'other-vehicle',
-                               6: 'person',
-                               7: 'bicyclist',
-                               8: 'motorcyclist',
-                               9: 'road',
-                               10: 'parking',
-                               11: 'sidewalk',
-                               12: 'other-ground',
-                               13: 'building',
-                               14: 'fence',
-                               15: 'vegetation',
-                               16: 'trunk',
-                               17: 'terrain',
-                               18: 'pole',
-                               19: 'traffic-sign'}
+        self.name = "SemanticKITTI"
+        self.dataset_path = "../../SemanticKitti/unzipped/dataset/sequences_0.06"
+        self.label_to_names = {
+            0: "unlabeled",
+            1: "car",
+            2: "bicycle",
+            3: "motorcycle",
+            4: "truck",
+            5: "other-vehicle",
+            6: "person",
+            7: "bicyclist",
+            8: "motorcyclist",
+            9: "road",
+            10: "parking",
+            11: "sidewalk",
+            12: "other-ground",
+            13: "building",
+            14: "fence",
+            15: "vegetation",
+            16: "trunk",
+            17: "terrain",
+            18: "pole",
+            19: "traffic-sign",
+        }
         self.num_classes = len(self.label_to_names)
         self.label_values = np.sort([k for k, v in self.label_to_names.items()])
         self.label_to_idx = {l: i for i, l in enumerate(self.label_values)}
         self.ignored_labels = np.sort([0])
         self.cls = cls
 
         self.seq_list = np.sort(os.listdir(self.dataset_path))
 
-        if mode == 'test':
+        if mode == "test":
             self.test_scan_number = str(test_id)
 
         self.mode = mode
-        
-        if mode == 'cam_eval':
-            eval_path = self.dataset_path + f'/{self.cls}/velodyne/*'
+
+        if mode == "cam_eval":
+            eval_path = self.dataset_path + f"/{self.cls}/velodyne/*"
             self.data_list = np.array(glob.glob(eval_path))
-            
-            
+
         else:
-            train_list, val_list, test_list = DP.get_file_list(self.dataset_path, str(test_id))
-
-            if mode == 'training':
+            train_list, val_list, test_list = DP.get_file_list(
+                self.dataset_path, str(test_id)
+            )
+
+            if mode == "training":
                 self.data_list = train_list
-            elif mode == 'validation':
+            elif mode == "validation":
                 self.data_list = val_list
-            elif mode == 'test':
+            elif mode == "test":
                 self.data_list = test_list
-        
+
             # self.data_list = self.data_list[0:1]
             self.data_list = DP.shuffle_list(self.data_list)
 
-
         self.possibility = []
         self.min_possibility = []
-        if mode == 'test':
+        if mode == "test":
             path_list = self.data_list
             for test_file_name in path_list:
                 points = np.load(test_file_name)
                 self.possibility += [np.random.rand(points.shape[0]) * 1e-3]
                 self.min_possibility += [float(np.min(self.possibility[-1]))]
 
-        cfg.ignored_label_inds = [self.label_to_idx[ign_label] for ign_label in self.ignored_labels]
-        cfg.class_weights = DP.get_class_weights('SemanticKITTI')
-
-
+        cfg.ignored_label_inds = [
+            self.label_to_idx[ign_label] for ign_label in self.ignored_labels
+        ]
+        cfg.class_weights = DP.get_class_weights("SemanticKITTI")
 
     def __len__(self):
         return len(self.data_list)
 
-
     def __getitem__(self, item):
 
-        selected_pc, selected_labels, selected_idx, cloud_ind = self.spatially_regular_gen(item)
+        selected_pc, selected_labels, selected_idx, cloud_ind = (
+            self.spatially_regular_gen(item)
+        )
         return selected_pc, selected_labels, selected_idx, cloud_ind
-
-
 
     def spatially_regular_gen(self, item):
         # Generator loop
-        if self.mode == 'cam_eval':
+        if self.mode == "cam_eval":
             cloud_ind = item
             pc_path = self.data_list[cloud_ind]
-            
+
             pc, tree, labels = self.get_data_eval(pc_path)
             pick_idx = np.random.choice(len(pc), 1)
             # We bypass crop_pc in cam_eval
-            selected_pc, selected_labels, selected_idx = self.crop_pc(pc, labels, tree, pick_idx)
-            
-            
-        elif self.mode != 'test':
+            selected_pc, selected_labels, selected_idx = self.crop_pc(
+                pc, labels, tree, pick_idx
+            )
+
+        elif self.mode != "test":
             cloud_ind = item
             pc_path = self.data_list[cloud_ind]
             pc, tree, labels = self.get_data(pc_path)
             # crop a small point cloud
             pick_idx = np.random.choice(len(pc), 1)
-            selected_pc, selected_labels, selected_idx = self.crop_pc(pc, labels, tree, pick_idx)
+            selected_pc, selected_labels, selected_idx = self.crop_pc(
+                pc, labels, tree, pick_idx
+            )
         else:
             cloud_ind = int(np.argmin(self.min_possibility))
             pick_idx = np.argmin(self.possibility[cloud_ind])
             pc_path = path_list[cloud_ind]
             pc, tree, labels = self.get_data(pc_path)
-            selected_pc, selected_labels, selected_idx = self.crop_pc(pc, labels, tree, pick_idx)
+            selected_pc, selected_labels, selected_idx = self.crop_pc(
+                pc, labels, tree, pick_idx
+            )
 
             # update the possibility of the selected pc
-            dists = np.sum(np.square((selected_pc - pc[pick_idx]).astype(np.float32)), axis=1)
+            dists = np.sum(
+                np.square((selected_pc - pc[pick_idx]).astype(np.float32)), axis=1
+            )
             delta = np.square(1 - dists / np.max(dists))
             self.possibility[cloud_ind][selected_idx] += delta
             self.min_possibility[cloud_ind] = np.min(self.possibility[cloud_ind])
 
-        return selected_pc.astype(np.float32), selected_labels.astype(np.int32), selected_idx.astype(np.int32), np.array([cloud_ind], dtype=np.int32)
-    
-    
+        return (
+            selected_pc.astype(np.float32),
+            selected_labels.astype(np.int32),
+            selected_idx.astype(np.int32),
+            np.array([cloud_ind], dtype=np.int32),
+        )
+
     def get_data_eval(self, file_path):
-        frame_id = file_path.split('/')[-1][:-4]
-        kd_tree_path = join(self.dataset_path, self.cls, 'KDTree', frame_id + '.pkl')
-        with open(kd_tree_path, 'rb') as f:
+        frame_id = file_path.split("/")[-1][:-4]
+        kd_tree_path = join(self.dataset_path, self.cls, "KDTree", frame_id + ".pkl")
+        with open(kd_tree_path, "rb") as f:
             search_tree = pickle.load(f)
         points = np.array(search_tree.data, copy=False)
-        
-        label_path = join(self.dataset_path, self.cls, 'labels', frame_id + '.npy')
+
+        label_path = join(self.dataset_path, self.cls, "labels", frame_id + ".npy")
         labels = np.squeeze(np.load(label_path))
-        
+
         return points, search_tree, labels
 
     def get_data(self, file_path):
-        seq_id = file_path.split('/')[-3]
-        frame_id = file_path.split('/')[-1][:-4]
-        kd_tree_path = join(self.dataset_path, seq_id, 'KDTree', frame_id + '.pkl')
+        seq_id = file_path.split("/")[-3]
+        frame_id = file_path.split("/")[-1][:-4]
+        kd_tree_path = join(self.dataset_path, seq_id, "KDTree", frame_id + ".pkl")
         # Read pkl with search tree
-        with open(kd_tree_path, 'rb') as f:
+        with open(kd_tree_path, "rb") as f:
             search_tree = pickle.load(f)
         points = np.array(search_tree.data, copy=False)
         # Load labels
         if int(seq_id) >= 11:
             labels = np.zeros(np.shape(points)[0], dtype=np.uint8)
         else:
-            label_path = join(self.dataset_path, seq_id, 'labels', frame_id + '.npy')
+            label_path = join(self.dataset_path, seq_id, "labels", frame_id + ".npy")
             labels = np.squeeze(np.load(label_path))
         return points, search_tree, labels
 
     @staticmethod
     def crop_pc(points, labels, search_tree, pick_idx):
@@ -170,12 +181,16 @@
         input_pools = []
         input_up_samples = []
 
         for i in range(cfg.num_layers):
             neighbour_idx = DP.knn_search(batch_pc, batch_pc, cfg.k_n)
-            sub_points = batch_pc[:, :batch_pc.shape[1] // cfg.sub_sampling_ratio[i], :]
-            pool_i = neighbour_idx[:, :batch_pc.shape[1] // cfg.sub_sampling_ratio[i], :]
+            sub_points = batch_pc[
+                :, : batch_pc.shape[1] // cfg.sub_sampling_ratio[i], :
+            ]
+            pool_i = neighbour_idx[
+                :, : batch_pc.shape[1] // cfg.sub_sampling_ratio[i], :
+            ]
             up_i = DP.knn_search(sub_points, batch_pc, 1)
             input_points.append(batch_pc)
             input_neighbors.append(neighbour_idx)
             input_pools.append(pool_i)
             input_up_samples.append(up_i)
@@ -184,13 +199,13 @@
         input_list = input_points + input_neighbors + input_pools + input_up_samples
         input_list += [features, batch_label, batch_pc_idx, batch_cloud_idx]
 
         return input_list
 
-    def collate_fn(self,batch):
-
-        selected_pc, selected_labels, selected_idx, cloud_ind = [],[],[],[]
+    def collate_fn(self, batch):
+
+        selected_pc, selected_labels, selected_idx, cloud_ind = [], [], [], []
         for i in range(len(batch)):
             selected_pc.append(batch[i][0])
             selected_labels.append(batch[i][1])
             selected_idx.append(batch[i][2])
             cloud_ind.append(batch[i][3])
@@ -202,25 +217,25 @@
 
         flat_inputs = self.tf_map(selected_pc, selected_labels, selected_idx, cloud_ind)
 
         num_layers = cfg.num_layers
         inputs = {}
-        inputs['xyz'] = []
+        inputs["xyz"] = []
         for tmp in flat_inputs[:num_layers]:
-            inputs['xyz'].append(torch.from_numpy(tmp).float())
-        inputs['neigh_idx'] = []
-        for tmp in flat_inputs[num_layers: 2 * num_layers]:
-            inputs['neigh_idx'].append(torch.from_numpy(tmp).long())
-        inputs['sub_idx'] = []
-        for tmp in flat_inputs[2 * num_layers:3 * num_layers]:
-            inputs['sub_idx'].append(torch.from_numpy(tmp).long())
-        inputs['interp_idx'] = []
-        for tmp in flat_inputs[3 * num_layers:4 * num_layers]:
-            inputs['interp_idx'].append(torch.from_numpy(tmp).long())
-        inputs['features'] = torch.from_numpy(flat_inputs[4 * num_layers]).transpose(1,2).float()
-        inputs['labels'] = torch.from_numpy(flat_inputs[4 * num_layers + 1]).long()
-        inputs['input_inds'] = torch.from_numpy(flat_inputs[4 * num_layers + 2]).long()
-        inputs['cloud_inds'] = torch.from_numpy(flat_inputs[4 * num_layers + 3]).long()
+            inputs["xyz"].append(torch.from_numpy(tmp).float())
+        inputs["neigh_idx"] = []
+        for tmp in flat_inputs[num_layers : 2 * num_layers]:
+            inputs["neigh_idx"].append(torch.from_numpy(tmp).long())
+        inputs["sub_idx"] = []
+        for tmp in flat_inputs[2 * num_layers : 3 * num_layers]:
+            inputs["sub_idx"].append(torch.from_numpy(tmp).long())
+        inputs["interp_idx"] = []
+        for tmp in flat_inputs[3 * num_layers : 4 * num_layers]:
+            inputs["interp_idx"].append(torch.from_numpy(tmp).long())
+        inputs["features"] = (
+            torch.from_numpy(flat_inputs[4 * num_layers]).transpose(1, 2).float()
+        )
+        inputs["labels"] = torch.from_numpy(flat_inputs[4 * num_layers + 1]).long()
+        inputs["input_inds"] = torch.from_numpy(flat_inputs[4 * num_layers + 2]).long()
+        inputs["cloud_inds"] = torch.from_numpy(flat_inputs[4 * num_layers + 3]).long()
 
         return inputs
-    
-    
\ No newline at end of file
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/nearest_neighbors/test.py	2024-06-30 22:34:21.618443+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/nearest_neighbors/test.py	2024-07-08 11:53:48.792968+00:00
@@ -9,7 +9,5 @@
 
 # nearest neighbours
 start = time.time()
 neigh_idx = nearest_neighbors.knn_batch(pc, pc, K, omp=True)
 print(time.time() - start)
-
-
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/nearest_neighbors/setup.py	2024-06-30 22:34:21.613259+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/nearest_neighbors/setup.py	2024-07-08 11:53:48.794938+00:00
@@ -2,20 +2,27 @@
 from distutils.extension import Extension
 from Cython.Distutils import build_ext
 import numpy
 
 
-
-ext_modules = [Extension(
-       "nearest_neighbors",
-       sources=["knn.pyx", "knn_.cxx",],  # source file(s)
-       include_dirs=["./", numpy.get_include()],
-       language="c++",            
-       extra_compile_args = [ "-std=c++11", "-fopenmp",],
-       extra_link_args=["-std=c++11", '-fopenmp'],
-  )]
+ext_modules = [
+    Extension(
+        "nearest_neighbors",
+        sources=[
+            "knn.pyx",
+            "knn_.cxx",
+        ],  # source file(s)
+        include_dirs=["./", numpy.get_include()],
+        language="c++",
+        extra_compile_args=[
+            "-std=c++11",
+            "-fopenmp",
+        ],
+        extra_link_args=["-std=c++11", "-fopenmp"],
+    )
+]
 
 setup(
-    name = "KNN NanoFLANN",
-    ext_modules = ext_modules,
-    cmdclass = {'build_ext': build_ext},
+    name="KNN NanoFLANN",
+    ext_modules=ext_modules,
+    cmdclass={"build_ext": build_ext},
 )
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/tester.py	2024-06-30 22:34:18.743545+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/tester.py	2024-07-08 11:53:48.794794+00:00
@@ -37,11 +37,11 @@
 
 # Metrics
 from utils.metrics import IoU_from_confusions, fast_confusion
 from sklearn.metrics import confusion_matrix
 
-#from utils.visualizer import show_ModelNet_models
+# from utils.visualizer import show_ModelNet_models
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Tester Class
 #       \******************/
@@ -69,12 +69,12 @@
         ##########################
         # Load previous checkpoint
         ##########################
 
         checkpoint = torch.load(chkp_path)
-        net.load_state_dict(checkpoint['model_state_dict'])
-        self.epoch = checkpoint['epoch']
+        net.load_state_dict(checkpoint["model_state_dict"])
+        self.epoch = checkpoint["epoch"]
         net.eval()
         print("Model and training state restored.")
 
         return
 
@@ -118,64 +118,74 @@
 
                 # New time
                 t = t[-1:]
                 t += [time.time()]
 
-                if 'cuda' in self.device.type:
+                if "cuda" in self.device.type:
                     batch.to(self.device)
 
                 # Forward pass
                 outputs = net(batch, config)
 
                 # Get probs and labels
                 probs += [softmax(outputs).cpu().detach().numpy()]
                 targets += [batch.labels.cpu().numpy()]
                 obj_inds += [batch.model_inds.cpu().numpy()]
 
-                if 'cuda' in self.device.type:
+                if "cuda" in self.device.type:
                     torch.cuda.synchronize(self.device)
 
                 # Average timing
                 t += [time.time()]
                 mean_dt = 0.95 * mean_dt + 0.05 * (np.array(t[1:]) - np.array(t[:-1]))
 
                 # Display
                 if (t[-1] - last_display) > 1.0:
                     last_display = t[-1]
-                    message = 'Test vote {:.0f} : {:.1f}% (timings : {:4.2f} {:4.2f})'
-                    print(message.format(np.min(self.test_counts),
-                                         100 * len(obj_inds) / config.validation_size,
-                                         1000 * (mean_dt[0]),
-                                         1000 * (mean_dt[1])))
+                    message = "Test vote {:.0f} : {:.1f}% (timings : {:4.2f} {:4.2f})"
+                    print(
+                        message.format(
+                            np.min(self.test_counts),
+                            100 * len(obj_inds) / config.validation_size,
+                            1000 * (mean_dt[0]),
+                            1000 * (mean_dt[1]),
+                        )
+                    )
             # Stack all validation predictions
             probs = np.vstack(probs)
             targets = np.hstack(targets)
             obj_inds = np.hstack(obj_inds)
 
             if np.any(test_loader.dataset.input_labels[obj_inds] != targets):
-                raise ValueError('wrong object indices')
+                raise ValueError("wrong object indices")
 
             # Compute incremental average (predictions are always ordered)
             self.test_counts[obj_inds] += 1
-            self.test_probs[obj_inds] += (probs - self.test_probs[obj_inds]) / (self.test_counts[obj_inds])
+            self.test_probs[obj_inds] += (probs - self.test_probs[obj_inds]) / (
+                self.test_counts[obj_inds]
+            )
 
             # Save/Display temporary results
             # ******************************
 
             test_labels = np.array(test_loader.dataset.label_values)
 
             # Compute classification results
-            C1 = fast_confusion(test_loader.dataset.input_labels,
-                                np.argmax(self.test_probs, axis=1),
-                                test_labels)
+            C1 = fast_confusion(
+                test_loader.dataset.input_labels,
+                np.argmax(self.test_probs, axis=1),
+                test_labels,
+            )
 
             ACC = 100 * np.sum(np.diag(C1)) / (np.sum(C1) + 1e-6)
-            print('Test Accuracy = {:.1f}%'.format(ACC))
+            print("Test Accuracy = {:.1f}%".format(ACC))
 
         return
 
-    def cloud_segmentation_test(self, net, test_loader, config, num_votes=100, debug=False):
+    def cloud_segmentation_test(
+        self, net, test_loader, config, num_votes=100, debug=False
+    ):
         """
         Test method for cloud segmentation models
         """
 
         ############
@@ -192,34 +202,40 @@
 
         # Number of classes predicted by the model
         nc_model = config.num_classes
 
         # Initiate global prediction over test clouds
-        self.test_probs = [np.zeros((l.shape[0], nc_model)) for l in test_loader.dataset.input_labels]
+        self.test_probs = [
+            np.zeros((l.shape[0], nc_model)) for l in test_loader.dataset.input_labels
+        ]
 
         # Test saving path
         if config.saving:
-            test_path = join('test', config.saving_path.split('/')[-1])
+            test_path = join("test", config.saving_path.split("/")[-1])
             if not exists(test_path):
                 makedirs(test_path)
-            if not exists(join(test_path, 'predictions')):
-                makedirs(join(test_path, 'predictions'))
-            if not exists(join(test_path, 'probs')):
-                makedirs(join(test_path, 'probs'))
-            if not exists(join(test_path, 'potentials')):
-                makedirs(join(test_path, 'potentials'))
+            if not exists(join(test_path, "predictions")):
+                makedirs(join(test_path, "predictions"))
+            if not exists(join(test_path, "probs")):
+                makedirs(join(test_path, "probs"))
+            if not exists(join(test_path, "potentials")):
+                makedirs(join(test_path, "potentials"))
         else:
             test_path = None
 
         # If on validation directly compute score
-        if test_loader.dataset.set == 'validation':
+        if test_loader.dataset.set == "validation":
             val_proportions = np.zeros(nc_model, dtype=np.float32)
             i = 0
             for label_value in test_loader.dataset.label_values:
                 if label_value not in test_loader.dataset.ignored_labels:
-                    val_proportions[i] = np.sum([np.sum(labels == label_value)
-                                                 for labels in test_loader.dataset.validation_labels])
+                    val_proportions[i] = np.sum(
+                        [
+                            np.sum(labels == label_value)
+                            for labels in test_loader.dataset.validation_labels
+                        ]
+                    )
                     i += 1
         else:
             val_proportions = None
 
         #####################
@@ -233,21 +249,21 @@
         last_display = time.time()
         mean_dt = np.zeros(1)
 
         # Start test loop
         while True:
-            print('Initialize workers')
+            print("Initialize workers")
             for i, batch in enumerate(test_loader):
 
                 # New time
                 t = t[-1:]
                 t += [time.time()]
 
                 if i == 0:
-                    print('Done in {:.1f}s'.format(t[1] - t[0]))
-
-                if 'cuda' in self.device.type:
+                    print("Done in {:.1f}s".format(t[1] - t[0]))
+
+                if "cuda" in self.device.type:
                     batch.to(self.device)
 
                 # Forward pass
                 outputs = net(batch, config)
 
@@ -266,22 +282,28 @@
 
                 i0 = 0
                 for b_i, length in enumerate(lengths):
 
                     # Get prediction
-                    points = s_points[i0:i0 + length]
-                    probs = stacked_probs[i0:i0 + length]
-                    inds = in_inds[i0:i0 + length]
+                    points = s_points[i0 : i0 + length]
+                    probs = stacked_probs[i0 : i0 + length]
+                    inds = in_inds[i0 : i0 + length]
                     c_i = cloud_inds[b_i]
 
                     if 0 < test_radius_ratio < 1:
-                        mask = np.sum(points ** 2, axis=1) < (test_radius_ratio * config.in_radius) ** 2
+                        mask = (
+                            np.sum(points**2, axis=1)
+                            < (test_radius_ratio * config.in_radius) ** 2
+                        )
                         inds = inds[mask]
                         probs = probs[mask]
 
                     # Update current probs in whole cloud
-                    self.test_probs[c_i][inds] = test_smooth * self.test_probs[c_i][inds] + (1 - test_smooth) * probs
+                    self.test_probs[c_i][inds] = (
+                        test_smooth * self.test_probs[c_i][inds]
+                        + (1 - test_smooth) * probs
+                    )
                     i0 += length
 
                 # Average timing
                 t += [time.time()]
                 if i < 2:
@@ -290,74 +312,95 @@
                     mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
                 # Display
                 if (t[-1] - last_display) > 1.0:
                     last_display = t[-1]
-                    message = 'e{:03d}-i{:04d} => {:.1f}% (timings : {:4.2f} {:4.2f} {:4.2f})'
-                    print(message.format(test_epoch, i,
-                                         100 * i / config.validation_size,
-                                         1000 * (mean_dt[0]),
-                                         1000 * (mean_dt[1]),
-                                         1000 * (mean_dt[2])))
+                    message = (
+                        "e{:03d}-i{:04d} => {:.1f}% (timings : {:4.2f} {:4.2f} {:4.2f})"
+                    )
+                    print(
+                        message.format(
+                            test_epoch,
+                            i,
+                            100 * i / config.validation_size,
+                            1000 * (mean_dt[0]),
+                            1000 * (mean_dt[1]),
+                            1000 * (mean_dt[2]),
+                        )
+                    )
 
             # Update minimum od potentials
             new_min = torch.min(test_loader.dataset.min_potentials)
-            print('Test epoch {:d}, end. Min potential = {:.1f}'.format(test_epoch, new_min))
-            #print([np.mean(pots) for pots in test_loader.dataset.potentials])
+            print(
+                "Test epoch {:d}, end. Min potential = {:.1f}".format(
+                    test_epoch, new_min
+                )
+            )
+            # print([np.mean(pots) for pots in test_loader.dataset.potentials])
 
             # Save predicted cloud
             if last_min + 1 < new_min:
 
                 # Update last_min
                 last_min += 1
 
                 # Show vote results (On subcloud so it is not the good values here)
-                if test_loader.dataset.set == 'validation':
-                    print('\nConfusion on sub clouds')
+                if test_loader.dataset.set == "validation":
+                    print("\nConfusion on sub clouds")
                     Confs = []
                     for i, file_path in enumerate(test_loader.dataset.files):
 
                         # Insert false columns for ignored labels
                         probs = np.array(self.test_probs[i], copy=True)
-                        for l_ind, label_value in enumerate(test_loader.dataset.label_values):
+                        for l_ind, label_value in enumerate(
+                            test_loader.dataset.label_values
+                        ):
                             if label_value in test_loader.dataset.ignored_labels:
                                 probs = np.insert(probs, l_ind, 0, axis=1)
 
                         # Predicted labels
-                        preds = test_loader.dataset.label_values[np.argmax(probs, axis=1)].astype(np.int32)
+                        preds = test_loader.dataset.label_values[
+                            np.argmax(probs, axis=1)
+                        ].astype(np.int32)
 
                         # Targets
                         targets = test_loader.dataset.input_labels[i]
 
                         # Confs
-                        Confs += [fast_confusion(targets, preds, test_loader.dataset.label_values)]
+                        Confs += [
+                            fast_confusion(
+                                targets, preds, test_loader.dataset.label_values
+                            )
+                        ]
 
                     # Regroup confusions
                     C = np.sum(np.stack(Confs), axis=0).astype(np.float32)
 
                     # Remove ignored labels from confusions
-                    for l_ind, label_value in reversed(list(enumerate(test_loader.dataset.label_values))):
+                    for l_ind, label_value in reversed(
+                        list(enumerate(test_loader.dataset.label_values))
+                    ):
                         if label_value in test_loader.dataset.ignored_labels:
                             C = np.delete(C, l_ind, axis=0)
                             C = np.delete(C, l_ind, axis=1)
 
                     # Rescale with the right number of point per class
                     C *= np.expand_dims(val_proportions / (np.sum(C, axis=1) + 1e-6), 1)
 
                     # Compute IoUs
                     IoUs = IoU_from_confusions(C)
                     mIoU = np.mean(IoUs)
-                    s = '{:5.2f} | '.format(100 * mIoU)
+                    s = "{:5.2f} | ".format(100 * mIoU)
                     for IoU in IoUs:
-                        s += '{:5.2f} '.format(100 * IoU)
-                    print(s + '\n')
+                        s += "{:5.2f} ".format(100 * IoU)
+                    print(s + "\n")
 
                 # Save real IoU once in a while
                 # if int(np.ceil(new_min)) % 10 == 0:
                 if new_min:
                     # Project predictions
-                    print('\nReproject Vote #{:d}'.format(int(np.floor(new_min))))
+                    print("\nReproject Vote #{:d}".format(int(np.floor(new_min))))
                     t1 = time.time()
                     proj_probs = []
                     for i, file_path in enumerate(test_loader.dataset.files):
 
                         # print(i, file_path, test_loader.dataset.test_proj[i].shape, self.test_probs[i].shape)
@@ -368,104 +411,134 @@
                         # Reproject probs on the evaluations points
                         probs = self.test_probs[i][test_loader.dataset.test_proj[i], :]
                         proj_probs += [probs]
 
                         # Insert false columns for ignored labels
-                        for l_ind, label_value in enumerate(test_loader.dataset.label_values):
+                        for l_ind, label_value in enumerate(
+                            test_loader.dataset.label_values
+                        ):
                             if label_value in test_loader.dataset.ignored_labels:
-                                proj_probs[i] = np.insert(proj_probs[i], l_ind, 0, axis=1)
+                                proj_probs[i] = np.insert(
+                                    proj_probs[i], l_ind, 0, axis=1
+                                )
 
                     t2 = time.time()
-                    print('Done in {:.1f} s\n'.format(t2 - t1))
+                    print("Done in {:.1f} s\n".format(t2 - t1))
 
                     # Show vote results
-                    if test_loader.dataset.set == 'validation':
-                        print('Confusion on full clouds')
+                    if test_loader.dataset.set == "validation":
+                        print("Confusion on full clouds")
                         t1 = time.time()
                         Confs = []
                         for i, file_path in enumerate(test_loader.dataset.files):
 
                             # Get the predicted labels
-                            preds = test_loader.dataset.label_values[np.argmax(proj_probs[i], axis=1)].astype(np.int32)
+                            preds = test_loader.dataset.label_values[
+                                np.argmax(proj_probs[i], axis=1)
+                            ].astype(np.int32)
 
                             # Confusion
                             targets = test_loader.dataset.validation_labels[i]
-                            Confs += [fast_confusion(targets, preds, test_loader.dataset.label_values)]
+                            Confs += [
+                                fast_confusion(
+                                    targets, preds, test_loader.dataset.label_values
+                                )
+                            ]
 
                         t2 = time.time()
-                        print('Done in {:.1f} s\n'.format(t2 - t1))
+                        print("Done in {:.1f} s\n".format(t2 - t1))
 
                         # Regroup confusions
                         C = np.sum(np.stack(Confs), axis=0)
 
                         # Remove ignored labels from confusions
-                        for l_ind, label_value in reversed(list(enumerate(test_loader.dataset.label_values))):
+                        for l_ind, label_value in reversed(
+                            list(enumerate(test_loader.dataset.label_values))
+                        ):
                             if label_value in test_loader.dataset.ignored_labels:
                                 C = np.delete(C, l_ind, axis=0)
                                 C = np.delete(C, l_ind, axis=1)
 
                         IoUs = IoU_from_confusions(C)
                         mIoU = np.mean(IoUs)
-                        s = '{:5.2f} | '.format(100 * mIoU)
+                        s = "{:5.2f} | ".format(100 * mIoU)
                         for IoU in IoUs:
-                            s += '{:5.2f} '.format(100 * IoU)
-                        print('-' * len(s))
+                            s += "{:5.2f} ".format(100 * IoU)
+                        print("-" * len(s))
                         print(s)
-                        print('-' * len(s) + '\n')
+                        print("-" * len(s) + "\n")
 
                     # Save predictions
-                    print('Saving clouds')
+                    print("Saving clouds")
                     t1 = time.time()
                     for i, file_path in enumerate(test_loader.dataset.files):
 
                         # Get file
                         points = test_loader.dataset.load_evaluation_points(file_path)
 
                         # Get the predicted labels
-                        preds = test_loader.dataset.label_values[np.argmax(proj_probs[i], axis=1)].astype(np.int32)
+                        preds = test_loader.dataset.label_values[
+                            np.argmax(proj_probs[i], axis=1)
+                        ].astype(np.int32)
 
                         # Save plys
-                        cloud_name = file_path.split('/')[-1]
-                        test_name = join(test_path, 'predictions', cloud_name)
-                        write_ply(test_name,
-                                  [points, preds],
-                                  ['x', 'y', 'z', 'preds'])
-                        test_name2 = join(test_path, 'probs', cloud_name)
-                        prob_names = ['_'.join(test_loader.dataset.label_to_names[label].split())
-                                      for label in test_loader.dataset.label_values]
-                        write_ply(test_name2,
-                                  [points, proj_probs[i]],
-                                  ['x', 'y', 'z'] + prob_names)
+                        cloud_name = file_path.split("/")[-1]
+                        test_name = join(test_path, "predictions", cloud_name)
+                        write_ply(test_name, [points, preds], ["x", "y", "z", "preds"])
+                        test_name2 = join(test_path, "probs", cloud_name)
+                        prob_names = [
+                            "_".join(test_loader.dataset.label_to_names[label].split())
+                            for label in test_loader.dataset.label_values
+                        ]
+                        write_ply(
+                            test_name2,
+                            [points, proj_probs[i]],
+                            ["x", "y", "z"] + prob_names,
+                        )
 
                         # Save potentials
-                        pot_points = np.array(test_loader.dataset.pot_trees[i].data, copy=False)
-                        pot_name = join(test_path, 'potentials', cloud_name)
-                        pots = test_loader.dataset.potentials[i].numpy().astype(np.float32)
-                        write_ply(pot_name,
-                                  [pot_points.astype(np.float32), pots],
-                                  ['x', 'y', 'z', 'pots'])
+                        pot_points = np.array(
+                            test_loader.dataset.pot_trees[i].data, copy=False
+                        )
+                        pot_name = join(test_path, "potentials", cloud_name)
+                        pots = (
+                            test_loader.dataset.potentials[i].numpy().astype(np.float32)
+                        )
+                        write_ply(
+                            pot_name,
+                            [pot_points.astype(np.float32), pots],
+                            ["x", "y", "z", "pots"],
+                        )
 
                         # Save ascii preds
-                        if test_loader.dataset.set == 'test':
-                            if test_loader.dataset.name.startswith('Semantic3D'):
-                                ascii_name = join(test_path, 'predictions', test_loader.dataset.ascii_files[cloud_name])
+                        if test_loader.dataset.set == "test":
+                            if test_loader.dataset.name.startswith("Semantic3D"):
+                                ascii_name = join(
+                                    test_path,
+                                    "predictions",
+                                    test_loader.dataset.ascii_files[cloud_name],
+                                )
                             else:
-                                ascii_name = join(test_path, 'predictions', cloud_name[:-4] + '.txt')
-                            np.savetxt(ascii_name, preds, fmt='%d')
+                                ascii_name = join(
+                                    test_path, "predictions", cloud_name[:-4] + ".txt"
+                                )
+                            np.savetxt(ascii_name, preds, fmt="%d")
 
                     t2 = time.time()
-                    print('Done in {:.1f} s\n'.format(t2 - t1))
+                    print("Done in {:.1f} s\n".format(t2 - t1))
 
             test_epoch += 1
 
             # Break when reaching number of desired votes
             if last_min > num_votes:
                 break
 
         return
 
-    def slam_segmentation_test(self, net, test_loader, config, num_votes=100, debug=True):
+    def slam_segmentation_test(
+        self, net, test_loader, config, num_votes=100, debug=True
+    ):
         """
         Test method for slam segmentation models
         """
 
         ############
@@ -483,33 +556,35 @@
 
         # Test saving path
         test_path = None
         report_path = None
         if config.saving:
-            test_path = join('test', config.saving_path.split('/')[-1])
+            test_path = join("test", config.saving_path.split("/")[-1])
             if not exists(test_path):
                 makedirs(test_path)
-            report_path = join(test_path, 'reports')
+            report_path = join(test_path, "reports")
             if not exists(report_path):
                 makedirs(report_path)
 
-        if test_loader.dataset.set == 'validation':
-            for folder in ['val_predictions', 'val_probs']:
+        if test_loader.dataset.set == "validation":
+            for folder in ["val_predictions", "val_probs"]:
                 if not exists(join(test_path, folder)):
                     makedirs(join(test_path, folder))
         else:
-            for folder in ['predictions', 'probs']:
+            for folder in ["predictions", "probs"]:
                 if not exists(join(test_path, folder)):
                     makedirs(join(test_path, folder))
 
         # Init validation container
         all_f_preds = []
         all_f_labels = []
-        if test_loader.dataset.set == 'validation':
+        if test_loader.dataset.set == "validation":
             for i, seq_frames in enumerate(test_loader.dataset.frames):
                 all_f_preds.append([np.zeros((0,), dtype=np.int32) for _ in seq_frames])
-                all_f_labels.append([np.zeros((0,), dtype=np.int32) for _ in seq_frames])
+                all_f_labels.append(
+                    [np.zeros((0,), dtype=np.int32) for _ in seq_frames]
+                )
 
         #####################
         # Network predictions
         #####################
 
@@ -521,21 +596,21 @@
         last_display = time.time()
         mean_dt = np.zeros(1)
 
         # Start test loop
         while True:
-            print('Initialize workers')
+            print("Initialize workers")
             for i, batch in enumerate(test_loader):
 
                 # New time
                 t = t[-1:]
                 t += [time.time()]
 
                 if i == 0:
-                    print('Done in {:.1f}s'.format(t[1] - t[0]))
-
-                if 'cuda' in self.device.type:
+                    print("Done in {:.1f}s".format(t[1] - t[0]))
+
+                if "cuda" in self.device.type:
                     batch.to(self.device)
 
                 # Forward pass
                 outputs = net(batch, config)
 
@@ -555,11 +630,11 @@
 
                 i0 = 0
                 for b_i, length in enumerate(lengths):
 
                     # Get prediction
-                    probs = stk_probs[i0:i0 + length]
+                    probs = stk_probs[i0 : i0 + length]
                     proj_inds = r_inds_list[b_i]
                     proj_mask = r_mask_list[b_i]
                     frame_labels = labels_list[b_i]
                     s_ind = f_inds[b_i, 0]
                     f_ind = f_inds[b_i, 1]
@@ -571,66 +646,104 @@
                     if proj_probs.ndim < 2:
                         proj_probs = np.expand_dims(proj_probs, 0)
 
                     # Save probs in a binary file (uint8 format for lighter weight)
                     seq_name = test_loader.dataset.sequences[s_ind]
-                    if test_loader.dataset.set == 'validation':
-                        folder = 'val_probs'
-                        pred_folder = 'val_predictions'
+                    if test_loader.dataset.set == "validation":
+                        folder = "val_probs"
+                        pred_folder = "val_predictions"
                     else:
-                        folder = 'probs'
-                        pred_folder = 'predictions'
-                    filename = '{:s}_{:07d}.npy'.format(seq_name, f_ind)
+                        folder = "probs"
+                        pred_folder = "predictions"
+                    filename = "{:s}_{:07d}.npy".format(seq_name, f_ind)
                     filepath = join(test_path, folder, filename)
                     if exists(filepath):
                         frame_probs_uint8 = np.load(filepath)
                     else:
-                        frame_probs_uint8 = np.zeros((proj_mask.shape[0], nc_model), dtype=np.uint8)
-                    frame_probs = frame_probs_uint8[proj_mask, :].astype(np.float32) / 255
-                    frame_probs = test_smooth * frame_probs + (1 - test_smooth) * proj_probs
-                    frame_probs_uint8[proj_mask, :] = (frame_probs * 255).astype(np.uint8)
+                        frame_probs_uint8 = np.zeros(
+                            (proj_mask.shape[0], nc_model), dtype=np.uint8
+                        )
+                    frame_probs = (
+                        frame_probs_uint8[proj_mask, :].astype(np.float32) / 255
+                    )
+                    frame_probs = (
+                        test_smooth * frame_probs + (1 - test_smooth) * proj_probs
+                    )
+                    frame_probs_uint8[proj_mask, :] = (frame_probs * 255).astype(
+                        np.uint8
+                    )
                     np.save(filepath, frame_probs_uint8)
 
                     # Save some prediction in ply format for visual
-                    if test_loader.dataset.set == 'validation':
+                    if test_loader.dataset.set == "validation":
 
                         # Insert false columns for ignored labels
                         frame_probs_uint8_bis = frame_probs_uint8.copy()
-                        for l_ind, label_value in enumerate(test_loader.dataset.label_values):
+                        for l_ind, label_value in enumerate(
+                            test_loader.dataset.label_values
+                        ):
                             if label_value in test_loader.dataset.ignored_labels:
-                                frame_probs_uint8_bis = np.insert(frame_probs_uint8_bis, l_ind, 0, axis=1)
+                                frame_probs_uint8_bis = np.insert(
+                                    frame_probs_uint8_bis, l_ind, 0, axis=1
+                                )
 
                         # Predicted labels
-                        frame_preds = test_loader.dataset.label_values[np.argmax(frame_probs_uint8_bis,
-                                                                                 axis=1)].astype(np.int32)
+                        frame_preds = test_loader.dataset.label_values[
+                            np.argmax(frame_probs_uint8_bis, axis=1)
+                        ].astype(np.int32)
 
                         # Save some of the frame pots
                         if f_ind % 20 == 0:
-                            seq_path = join(test_loader.dataset.path, 'sequences', test_loader.dataset.sequences[s_ind])
-                            velo_file = join(seq_path, 'velodyne', test_loader.dataset.frames[s_ind][f_ind] + '.bin')
+                            seq_path = join(
+                                test_loader.dataset.path,
+                                "sequences",
+                                test_loader.dataset.sequences[s_ind],
+                            )
+                            velo_file = join(
+                                seq_path,
+                                "velodyne",
+                                test_loader.dataset.frames[s_ind][f_ind] + ".bin",
+                            )
                             frame_points = np.fromfile(velo_file, dtype=np.float32)
                             frame_points = frame_points.reshape((-1, 4))
-                            predpath = join(test_path, pred_folder, filename[:-4] + '.ply')
-                            #pots = test_loader.dataset.f_potentials[s_ind][f_ind]
+                            predpath = join(
+                                test_path, pred_folder, filename[:-4] + ".ply"
+                            )
+                            # pots = test_loader.dataset.f_potentials[s_ind][f_ind]
                             pots = np.zeros((0,))
                             if pots.shape[0] > 0:
-                                write_ply(predpath,
-                                          [frame_points[:, :3], frame_labels, frame_preds, pots],
-                                          ['x', 'y', 'z', 'gt', 'pre', 'pots'])
+                                write_ply(
+                                    predpath,
+                                    [
+                                        frame_points[:, :3],
+                                        frame_labels,
+                                        frame_preds,
+                                        pots,
+                                    ],
+                                    ["x", "y", "z", "gt", "pre", "pots"],
+                                )
                             else:
-                                write_ply(predpath,
-                                          [frame_points[:, :3], frame_labels, frame_preds],
-                                          ['x', 'y', 'z', 'gt', 'pre'])
+                                write_ply(
+                                    predpath,
+                                    [frame_points[:, :3], frame_labels, frame_preds],
+                                    ["x", "y", "z", "gt", "pre"],
+                                )
 
                             # Also Save lbl probabilities
-                            probpath = join(test_path, folder, filename[:-4] + '_probs.ply')
-                            lbl_names = [test_loader.dataset.label_to_names[l]
-                                         for l in test_loader.dataset.label_values
-                                         if l not in test_loader.dataset.ignored_labels]
-                            write_ply(probpath,
-                                      [frame_points[:, :3], frame_probs_uint8],
-                                      ['x', 'y', 'z'] + lbl_names)
+                            probpath = join(
+                                test_path, folder, filename[:-4] + "_probs.ply"
+                            )
+                            lbl_names = [
+                                test_loader.dataset.label_to_names[l]
+                                for l in test_loader.dataset.label_values
+                                if l not in test_loader.dataset.ignored_labels
+                            ]
+                            write_ply(
+                                probpath,
+                                [frame_points[:, :3], frame_probs_uint8],
+                                ["x", "y", "z"] + lbl_names,
+                            )
 
                         # keep frame preds in memory
                         all_f_preds[s_ind][f_ind] = frame_preds
                         all_f_labels[s_ind][f_ind] = frame_labels
 
@@ -638,34 +751,53 @@
 
                         # Save some of the frame preds
                         if f_inds[b_i, 1] % 100 == 0:
 
                             # Insert false columns for ignored labels
-                            for l_ind, label_value in enumerate(test_loader.dataset.label_values):
+                            for l_ind, label_value in enumerate(
+                                test_loader.dataset.label_values
+                            ):
                                 if label_value in test_loader.dataset.ignored_labels:
-                                    frame_probs_uint8 = np.insert(frame_probs_uint8, l_ind, 0, axis=1)
+                                    frame_probs_uint8 = np.insert(
+                                        frame_probs_uint8, l_ind, 0, axis=1
+                                    )
 
                             # Predicted labels
-                            frame_preds = test_loader.dataset.label_values[np.argmax(frame_probs_uint8,
-                                                                                     axis=1)].astype(np.int32)
+                            frame_preds = test_loader.dataset.label_values[
+                                np.argmax(frame_probs_uint8, axis=1)
+                            ].astype(np.int32)
 
                             # Load points
-                            seq_path = join(test_loader.dataset.path, 'sequences', test_loader.dataset.sequences[s_ind])
-                            velo_file = join(seq_path, 'velodyne', test_loader.dataset.frames[s_ind][f_ind] + '.bin')
+                            seq_path = join(
+                                test_loader.dataset.path,
+                                "sequences",
+                                test_loader.dataset.sequences[s_ind],
+                            )
+                            velo_file = join(
+                                seq_path,
+                                "velodyne",
+                                test_loader.dataset.frames[s_ind][f_ind] + ".bin",
+                            )
                             frame_points = np.fromfile(velo_file, dtype=np.float32)
                             frame_points = frame_points.reshape((-1, 4))
-                            predpath = join(test_path, pred_folder, filename[:-4] + '.ply')
-                            #pots = test_loader.dataset.f_potentials[s_ind][f_ind]
+                            predpath = join(
+                                test_path, pred_folder, filename[:-4] + ".ply"
+                            )
+                            # pots = test_loader.dataset.f_potentials[s_ind][f_ind]
                             pots = np.zeros((0,))
                             if pots.shape[0] > 0:
-                                write_ply(predpath,
-                                          [frame_points[:, :3], frame_preds, pots],
-                                          ['x', 'y', 'z', 'pre', 'pots'])
+                                write_ply(
+                                    predpath,
+                                    [frame_points[:, :3], frame_preds, pots],
+                                    ["x", "y", "z", "pre", "pots"],
+                                )
                             else:
-                                write_ply(predpath,
-                                          [frame_points[:, :3], frame_preds],
-                                          ['x', 'y', 'z', 'pre'])
+                                write_ply(
+                                    predpath,
+                                    [frame_points[:, :3], frame_preds],
+                                    ["x", "y", "z", "pre"],
+                                )
 
                     # Stack all prediction for this epoch
                     i0 += length
 
                 # Average timing
@@ -673,126 +805,125 @@
                 mean_dt = 0.95 * mean_dt + 0.05 * (np.array(t[1:]) - np.array(t[:-1]))
 
                 # Display
                 if (t[-1] - last_display) > 1.0:
                     last_display = t[-1]
-                    message = 'e{:03d}-i{:04d} => {:.1f}% (timings : {:4.2f} {:4.2f} {:4.2f}) / pots {:d} => {:.1f}%'
-                    min_pot = int(torch.floor(torch.min(test_loader.dataset.potentials)))
-                    pot_num = torch.sum(test_loader.dataset.potentials > min_pot + 0.5).type(torch.int32).item()
-                    current_num = pot_num + (i + 1 - config.validation_size) * config.val_batch_num
-                    print(message.format(test_epoch, i,
-                                         100 * i / config.validation_size,
-                                         1000 * (mean_dt[0]),
-                                         1000 * (mean_dt[1]),
-                                         1000 * (mean_dt[2]),
-                                         min_pot,
-                                         100.0 * current_num / len(test_loader.dataset.potentials)))
-
+                    message = "e{:03d}-i{:04d} => {:.1f}% (timings : {:4.2f} {:4.2f} {:4.2f}) / pots {:d} => {:.1f}%"
+                    min_pot = int(
+                        torch.floor(torch.min(test_loader.dataset.potentials))
+                    )
+                    pot_num = (
+                        torch.sum(test_loader.dataset.potentials > min_pot + 0.5)
+                        .type(torch.int32)
+                        .item()
+                    )
+                    current_num = (
+                        pot_num
+                        + (i + 1 - config.validation_size) * config.val_batch_num
+                    )
+                    print(
+                        message.format(
+                            test_epoch,
+                            i,
+                            100 * i / config.validation_size,
+                            1000 * (mean_dt[0]),
+                            1000 * (mean_dt[1]),
+                            1000 * (mean_dt[2]),
+                            min_pot,
+                            100.0 * current_num / len(test_loader.dataset.potentials),
+                        )
+                    )
 
             # Update minimum od potentials
             new_min = torch.min(test_loader.dataset.potentials)
-            print('Test epoch {:d}, end. Min potential = {:.1f}'.format(test_epoch, new_min))
+            print(
+                "Test epoch {:d}, end. Min potential = {:.1f}".format(
+                    test_epoch, new_min
+                )
+            )
 
             if last_min + 1 < new_min:
 
                 # Update last_min
                 last_min += 1
 
-                if test_loader.dataset.set == 'validation' and last_min % 1 == 0:
+                if test_loader.dataset.set == "validation" and last_min % 1 == 0:
 
                     #####################################
                     # Results on the whole validation set
                     #####################################
 
                     # Confusions for our subparts of validation set
                     Confs = np.zeros((len(predictions), nc_tot, nc_tot), dtype=np.int32)
                     for i, (preds, truth) in enumerate(zip(predictions, targets)):
 
                         # Confusions
-                        Confs[i, :, :] = fast_confusion(truth, preds, test_loader.dataset.label_values).astype(np.int32)
-
+                        Confs[i, :, :] = fast_confusion(
+                            truth, preds, test_loader.dataset.label_values
+                        ).astype(np.int32)
 
                     # Show vote results
-                    print('\nCompute confusion')
+                    print("\nCompute confusion")
 
                     val_preds = []
                     val_labels = []
                     t1 = time.time()
                     for i, seq_frames in enumerate(test_loader.dataset.frames):
                         val_preds += [np.hstack(all_f_preds[i])]
                         val_labels += [np.hstack(all_f_labels[i])]
                     val_preds = np.hstack(val_preds)
                     val_labels = np.hstack(val_labels)
                     t2 = time.time()
-                    C_tot = fast_confusion(val_labels, val_preds, test_loader.dataset.label_values)
+                    C_tot = fast_confusion(
+                        val_labels, val_preds, test_loader.dataset.label_values
+                    )
                     t3 = time.time()
-                    print(' Stacking time : {:.1f}s'.format(t2 - t1))
-                    print('Confusion time : {:.1f}s'.format(t3 - t2))
-
-                    s1 = '\n'
+                    print(" Stacking time : {:.1f}s".format(t2 - t1))
+                    print("Confusion time : {:.1f}s".format(t3 - t2))
+
+                    s1 = "\n"
                     for cc in C_tot:
                         for c in cc:
-                            s1 += '{:7.0f} '.format(c)
-                        s1 += '\n'
+                            s1 += "{:7.0f} ".format(c)
+                        s1 += "\n"
                     if debug:
                         print(s1)
 
                     # Remove ignored labels from confusions
-                    for l_ind, label_value in reversed(list(enumerate(test_loader.dataset.label_values))):
+                    for l_ind, label_value in reversed(
+                        list(enumerate(test_loader.dataset.label_values))
+                    ):
                         if label_value in test_loader.dataset.ignored_labels:
                             C_tot = np.delete(C_tot, l_ind, axis=0)
                             C_tot = np.delete(C_tot, l_ind, axis=1)
 
                     # Objects IoU
                     val_IoUs = IoU_from_confusions(C_tot)
 
                     # Compute IoUs
                     mIoU = np.mean(val_IoUs)
-                    s2 = '{:5.2f} | '.format(100 * mIoU)
+                    s2 = "{:5.2f} | ".format(100 * mIoU)
                     for IoU in val_IoUs:
-                        s2 += '{:5.2f} '.format(100 * IoU)
-                    print(s2 + '\n')
+                        s2 += "{:5.2f} ".format(100 * IoU)
+                    print(s2 + "\n")
 
                     # Save a report
-                    report_file = join(report_path, 'report_{:04d}.txt'.format(int(np.floor(last_min))))
-                    str = 'Report of the confusion and metrics\n'
-                    str += '***********************************\n\n\n'
-                    str += 'Confusion matrix:\n\n'
+                    report_file = join(
+                        report_path, "report_{:04d}.txt".format(int(np.floor(last_min)))
+                    )
+                    str = "Report of the confusion and metrics\n"
+                    str += "***********************************\n\n\n"
+                    str += "Confusion matrix:\n\n"
                     str += s1
-                    str += '\nIoU values:\n\n'
+                    str += "\nIoU values:\n\n"
                     str += s2
-                    str += '\n\n'
-                    with open(report_file, 'w') as f:
+                    str += "\n\n"
+                    with open(report_file, "w") as f:
                         f.write(str)
 
             test_epoch += 1
 
             # Break when reaching number of desired votes
             if last_min > num_votes:
                 break
 
         return
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/data_prepare_semantic3d.py	2024-06-30 22:34:20.946582+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/data_prepare_semantic3d.py	2024-07-08 11:53:48.847401+00:00
@@ -10,74 +10,95 @@
 sys.path.append(ROOT_DIR)
 from helper_ply import write_ply
 from helper_tool import DataProcessing as DP
 
 grid_size = 0.06
-dataset_path = '/data/semantic3d/original_data'
-original_pc_folder = join(dirname(dataset_path), 'original_ply')
-sub_pc_folder = join(dirname(dataset_path), 'input_{:.3f}'.format(grid_size))
+dataset_path = "/data/semantic3d/original_data"
+original_pc_folder = join(dirname(dataset_path), "original_ply")
+sub_pc_folder = join(dirname(dataset_path), "input_{:.3f}".format(grid_size))
 os.mkdir(original_pc_folder) if not exists(original_pc_folder) else None
 os.mkdir(sub_pc_folder) if not exists(sub_pc_folder) else None
 
-for pc_path in glob.glob(join(dataset_path, '*.txt')):
+for pc_path in glob.glob(join(dataset_path, "*.txt")):
     print(pc_path)
-    file_name = pc_path.split('/')[-1][:-4]
+    file_name = pc_path.split("/")[-1][:-4]
 
     # check if it has already calculated
-    if exists(join(sub_pc_folder, file_name + '_KDTree.pkl')):
+    if exists(join(sub_pc_folder, file_name + "_KDTree.pkl")):
         continue
 
     pc = DP.load_pc_semantic3d(pc_path)
     # check if label exists
-    label_path = pc_path[:-4] + '.labels'
+    label_path = pc_path[:-4] + ".labels"
     if exists(label_path):
         labels = DP.load_label_semantic3d(label_path)
-        full_ply_path = join(original_pc_folder, file_name + '.ply')
+        full_ply_path = join(original_pc_folder, file_name + ".ply")
 
         # Subsample to save space
-        sub_points, sub_colors, sub_labels = DP.grid_sub_sampling(pc[:, :3].astype(np.float32),
-                                                                  pc[:, 4:7].astype(np.uint8), labels, 0.01)
+        sub_points, sub_colors, sub_labels = DP.grid_sub_sampling(
+            pc[:, :3].astype(np.float32), pc[:, 4:7].astype(np.uint8), labels, 0.01
+        )
         sub_labels = np.squeeze(sub_labels)
 
-        write_ply(full_ply_path, (sub_points, sub_colors, sub_labels), ['x', 'y', 'z', 'red', 'green', 'blue', 'class'])
+        write_ply(
+            full_ply_path,
+            (sub_points, sub_colors, sub_labels),
+            ["x", "y", "z", "red", "green", "blue", "class"],
+        )
 
         # save sub_cloud and KDTree file
-        sub_xyz, sub_colors, sub_labels = DP.grid_sub_sampling(sub_points, sub_colors, sub_labels, grid_size)
+        sub_xyz, sub_colors, sub_labels = DP.grid_sub_sampling(
+            sub_points, sub_colors, sub_labels, grid_size
+        )
         sub_colors = sub_colors / 255.0
         sub_labels = np.squeeze(sub_labels)
-        sub_ply_file = join(sub_pc_folder, file_name + '.ply')
-        write_ply(sub_ply_file, [sub_xyz, sub_colors, sub_labels], ['x', 'y', 'z', 'red', 'green', 'blue', 'class'])
+        sub_ply_file = join(sub_pc_folder, file_name + ".ply")
+        write_ply(
+            sub_ply_file,
+            [sub_xyz, sub_colors, sub_labels],
+            ["x", "y", "z", "red", "green", "blue", "class"],
+        )
 
         search_tree = KDTree(sub_xyz, leaf_size=50)
-        kd_tree_file = join(sub_pc_folder, file_name + '_KDTree.pkl')
-        with open(kd_tree_file, 'wb') as f:
+        kd_tree_file = join(sub_pc_folder, file_name + "_KDTree.pkl")
+        with open(kd_tree_file, "wb") as f:
             pickle.dump(search_tree, f)
 
         proj_idx = np.squeeze(search_tree.query(sub_points, return_distance=False))
         proj_idx = proj_idx.astype(np.int32)
-        proj_save = join(sub_pc_folder, file_name + '_proj.pkl')
-        with open(proj_save, 'wb') as f:
+        proj_save = join(sub_pc_folder, file_name + "_proj.pkl")
+        with open(proj_save, "wb") as f:
             pickle.dump([proj_idx, labels], f)
 
     else:
-        full_ply_path = join(original_pc_folder, file_name + '.ply')
-        write_ply(full_ply_path, (pc[:, :3].astype(np.float32), pc[:, 4:7].astype(np.uint8)),
-                  ['x', 'y', 'z', 'red', 'green', 'blue'])
+        full_ply_path = join(original_pc_folder, file_name + ".ply")
+        write_ply(
+            full_ply_path,
+            (pc[:, :3].astype(np.float32), pc[:, 4:7].astype(np.uint8)),
+            ["x", "y", "z", "red", "green", "blue"],
+        )
 
         # save sub_cloud and KDTree file
-        sub_xyz, sub_colors = DP.grid_sub_sampling(pc[:, :3].astype(np.float32), pc[:, 4:7].astype(np.uint8),
-                                                   grid_size=grid_size)
+        sub_xyz, sub_colors = DP.grid_sub_sampling(
+            pc[:, :3].astype(np.float32),
+            pc[:, 4:7].astype(np.uint8),
+            grid_size=grid_size,
+        )
         sub_colors = sub_colors / 255.0
-        sub_ply_file = join(sub_pc_folder, file_name + '.ply')
-        write_ply(sub_ply_file, [sub_xyz, sub_colors], ['x', 'y', 'z', 'red', 'green', 'blue'])
+        sub_ply_file = join(sub_pc_folder, file_name + ".ply")
+        write_ply(
+            sub_ply_file, [sub_xyz, sub_colors], ["x", "y", "z", "red", "green", "blue"]
+        )
         labels = np.zeros(pc.shape[0], dtype=np.uint8)
 
         search_tree = KDTree(sub_xyz, leaf_size=50)
-        kd_tree_file = join(sub_pc_folder, file_name + '_KDTree.pkl')
-        with open(kd_tree_file, 'wb') as f:
+        kd_tree_file = join(sub_pc_folder, file_name + "_KDTree.pkl")
+        with open(kd_tree_file, "wb") as f:
             pickle.dump(search_tree, f)
 
-        proj_idx = np.squeeze(search_tree.query(pc[:, :3].astype(np.float32), return_distance=False))
+        proj_idx = np.squeeze(
+            search_tree.query(pc[:, :3].astype(np.float32), return_distance=False)
+        )
         proj_idx = proj_idx.astype(np.int32)
-        proj_save = join(sub_pc_folder, file_name + '_proj.pkl')
-        with open(proj_save, 'wb') as f:
+        proj_save = join(sub_pc_folder, file_name + "_proj.pkl")
+        with open(proj_save, "wb") as f:
             pickle.dump([proj_idx, labels], f)
--- /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/trainer.py	2024-06-30 22:34:18.759179+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/KPConv/utils/trainer.py	2024-07-08 11:53:48.880068+00:00
@@ -73,18 +73,19 @@
         # Epoch index
         self.epoch = 0
         self.step = 0
 
         # Optimizer with specific learning rate for deformable KPConv
-        deform_params = [v for k, v in net.named_parameters() if 'offset' in k]
-        other_params = [v for k, v in net.named_parameters() if 'offset' not in k]
+        deform_params = [v for k, v in net.named_parameters() if "offset" in k]
+        other_params = [v for k, v in net.named_parameters() if "offset" not in k]
         deform_lr = config.learning_rate * config.deform_lr_factor
-        self.optimizer = torch.optim.SGD([{'params': other_params},
-                                          {'params': deform_params, 'lr': deform_lr}],
-                                         lr=config.learning_rate,
-                                         momentum=config.momentum,
-                                         weight_decay=config.weight_decay)
+        self.optimizer = torch.optim.SGD(
+            [{"params": other_params}, {"params": deform_params, "lr": deform_lr}],
+            lr=config.learning_rate,
+            momentum=config.momentum,
+            weight_decay=config.weight_decay,
+        )
 
         # Choose to train on CPU or GPU
         if on_gpu and torch.cuda.is_available():
             self.device = torch.device("cuda:0")
         else:
@@ -93,28 +94,30 @@
 
         ##########################
         # Load previous checkpoint
         ##########################
 
-        if (chkp_path is not None):
+        if chkp_path is not None:
             if finetune:
                 checkpoint = torch.load(chkp_path)
-                net.load_state_dict(checkpoint['model_state_dict'])
+                net.load_state_dict(checkpoint["model_state_dict"])
                 net.train()
                 print("Model restored and ready for finetuning.")
             else:
                 checkpoint = torch.load(chkp_path)
-                net.load_state_dict(checkpoint['model_state_dict'])
-                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
-                self.epoch = checkpoint['epoch']
+                net.load_state_dict(checkpoint["model_state_dict"])
+                self.optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
+                self.epoch = checkpoint["epoch"]
                 net.train()
                 print("Model and training state restored.")
 
         # Path of the result folder
         if config.saving:
             if config.saving_path is None:
-                config.saving_path = time.strftime('results/Log_%Y-%m-%d_%H-%M-%S', time.gmtime())
+                config.saving_path = time.strftime(
+                    "results/Log_%Y-%m-%d_%H-%M-%S", time.gmtime()
+                )
             if not exists(config.saving_path):
                 makedirs(config.saving_path)
             config.save()
 
         return
@@ -131,21 +134,21 @@
         # Initialization
         ################
 
         if config.saving:
             # Training log file
-            with open(join(config.saving_path, 'training.txt'), "w") as file:
-                file.write('epochs steps out_loss offset_loss train_accuracy time\n')
+            with open(join(config.saving_path, "training.txt"), "w") as file:
+                file.write("epochs steps out_loss offset_loss train_accuracy time\n")
 
             # Killing file (simply delete this file when you want to stop the training)
-            PID_file = join(config.saving_path, 'running_PID.txt')
+            PID_file = join(config.saving_path, "running_PID.txt")
             if not exists(PID_file):
                 with open(PID_file, "w") as file:
-                    file.write('Launched with PyCharm')
+                    file.write("Launched with PyCharm")
 
             # Checkpoints directory
-            checkpoint_directory = join(config.saving_path, 'checkpoints')
+            checkpoint_directory = join(config.saving_path, "checkpoints")
             if not exists(checkpoint_directory):
                 makedirs(checkpoint_directory)
         else:
             checkpoint_directory = None
             PID_file = None
@@ -176,11 +179,11 @@
 
                 # New time
                 t = t[-1:]
                 t += [time.time()]
 
-                if 'cuda' in self.device.type:
+                if "cuda" in self.device.type:
                     batch.to(self.device)
 
                 # zero the parameter gradients
                 self.optimizer.zero_grad()
 
@@ -193,15 +196,16 @@
 
                 # Backward + optimize
                 loss.backward()
 
                 if config.grad_clip_norm > 0:
-                    #torch.nn.utils.clip_grad_norm_(net.parameters(), config.grad_clip_norm)
-                    torch.nn.utils.clip_grad_value_(net.parameters(), config.grad_clip_norm)
+                    # torch.nn.utils.clip_grad_norm_(net.parameters(), config.grad_clip_norm)
+                    torch.nn.utils.clip_grad_value_(
+                        net.parameters(), config.grad_clip_norm
+                    )
                 self.optimizer.step()
 
-                
                 torch.cuda.empty_cache()
                 torch.cuda.synchronize(self.device)
 
                 t += [time.time()]
 
@@ -212,29 +216,37 @@
                     mean_dt = 0.9 * mean_dt + 0.1 * (np.array(t[1:]) - np.array(t[:-1]))
 
                 # Console display (only one per second)
                 if (t[-1] - last_display) > 1.0:
                     last_display = t[-1]
-                    message = 'e{:03d}-i{:04d} => L={:.3f} acc={:3.0f}% / t(ms): {:5.1f} {:5.1f} {:5.1f})'
-                    print(message.format(self.epoch, self.step,
-                                         loss.item(),
-                                         100*acc,
-                                         1000 * mean_dt[0],
-                                         1000 * mean_dt[1],
-                                         1000 * mean_dt[2]))
+                    message = "e{:03d}-i{:04d} => L={:.3f} acc={:3.0f}% / t(ms): {:5.1f} {:5.1f} {:5.1f})"
+                    print(
+                        message.format(
+                            self.epoch,
+                            self.step,
+                            loss.item(),
+                            100 * acc,
+                            1000 * mean_dt[0],
+                            1000 * mean_dt[1],
+                            1000 * mean_dt[2],
+                        )
+                    )
 
                 # Log file
                 if config.saving:
-                    with open(join(config.saving_path, 'training.txt'), "a") as file:
-                        message = '{:d} {:d} {:.3f} {:.3f} {:.3f} {:.3f}\n'
-                        file.write(message.format(self.epoch,
-                                                  self.step,
-                                                  net.output_loss,
-                                                  net.reg_loss,
-                                                  acc,
-                                                  t[-1] - t0))
-
+                    with open(join(config.saving_path, "training.txt"), "a") as file:
+                        message = "{:d} {:d} {:.3f} {:.3f} {:.3f} {:.3f}\n"
+                        file.write(
+                            message.format(
+                                self.epoch,
+                                self.step,
+                                net.output_loss,
+                                net.reg_loss,
+                                acc,
+                                t[-1] - t0,
+                            )
+                        )
 
                 self.step += 1
 
             ##############
             # End of epoch
@@ -245,55 +257,59 @@
                 break
 
             # Update learning rate
             if self.epoch in config.lr_decays:
                 for param_group in self.optimizer.param_groups:
-                    param_group['lr'] *= config.lr_decays[self.epoch]
+                    param_group["lr"] *= config.lr_decays[self.epoch]
 
             # Update epoch
             self.epoch += 1
 
             # Saving
             if config.saving:
                 # Get current state dict
-                save_dict = {'epoch': self.epoch,
-                             'model_state_dict': net.state_dict(),
-                             'optimizer_state_dict': self.optimizer.state_dict(),
-                             'saving_path': config.saving_path}
+                save_dict = {
+                    "epoch": self.epoch,
+                    "model_state_dict": net.state_dict(),
+                    "optimizer_state_dict": self.optimizer.state_dict(),
+                    "saving_path": config.saving_path,
+                }
 
                 # Save current state of the network (for restoring purposes)
-                checkpoint_path = join(checkpoint_directory, 'current_chkp.tar')
+                checkpoint_path = join(checkpoint_directory, "current_chkp.tar")
                 torch.save(save_dict, checkpoint_path)
 
                 # Save checkpoints occasionally
                 if (self.epoch + 1) % config.checkpoint_gap == 0:
-                    checkpoint_path = join(checkpoint_directory, 'chkp_{:04d}.tar'.format(self.epoch + 1))
+                    checkpoint_path = join(
+                        checkpoint_directory, "chkp_{:04d}.tar".format(self.epoch + 1)
+                    )
                     torch.save(save_dict, checkpoint_path)
 
             # Validation
             net.eval()
             self.validation(net, val_loader, config)
             net.train()
 
-        print('Finished Training')
+        print("Finished Training")
         return
 
     # Validation methods
     # ------------------------------------------------------------------------------------------------------------------
 
     def validation(self, net, val_loader, config: Config):
 
-        if config.dataset_task == 'classification':
+        if config.dataset_task == "classification":
             self.object_classification_validation(net, val_loader, config)
-        elif config.dataset_task == 'segmentation':
+        elif config.dataset_task == "segmentation":
             self.object_segmentation_validation(net, val_loader, config)
-        elif config.dataset_task == 'cloud_segmentation':
+        elif config.dataset_task == "cloud_segmentation":
             self.cloud_segmentation_validation(net, val_loader, config)
-        elif config.dataset_task == 'slam_segmentation':
+        elif config.dataset_task == "slam_segmentation":
             self.slam_segmentation_validation(net, val_loader, config)
         else:
-            raise ValueError('No validation method implemented for this network type')
+            raise ValueError("No validation method implemented for this network type")
 
     def object_classification_validation(self, net, val_loader, config):
         """
         Perform a round of validation and show/save results
         :param net: network object
@@ -311,11 +327,11 @@
         # Number of classes predicted by the model
         nc_model = config.num_classes
         softmax = torch.nn.Softmax(1)
 
         # Initialize global prediction over all models
-        if not hasattr(self, 'val_probs'):
+        if not hasattr(self, "val_probs"):
             self.val_probs = np.zeros((val_loader.dataset.num_models, nc_model))
 
         #####################
         # Network predictions
         #####################
@@ -333,11 +349,11 @@
 
             # New time
             t = t[-1:]
             t += [time.time()]
 
-            if 'cuda' in self.device.type:
+            if "cuda" in self.device.type:
                 batch.to(self.device)
 
             # Forward pass
             outputs = net(batch, config)
 
@@ -352,66 +368,71 @@
             mean_dt = 0.95 * mean_dt + 0.05 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Display
             if (t[-1] - last_display) > 1.0:
                 last_display = t[-1]
-                message = 'Validation : {:.1f}% (timings : {:4.2f} {:4.2f})'
-                print(message.format(100 * len(obj_inds) / config.validation_size,
-                                     1000 * (mean_dt[0]),
-                                     1000 * (mean_dt[1])))
+                message = "Validation : {:.1f}% (timings : {:4.2f} {:4.2f})"
+                print(
+                    message.format(
+                        100 * len(obj_inds) / config.validation_size,
+                        1000 * (mean_dt[0]),
+                        1000 * (mean_dt[1]),
+                    )
+                )
 
         # Stack all validation predictions
         probs = np.vstack(probs)
         targets = np.hstack(targets)
         obj_inds = np.hstack(obj_inds)
 
         ###################
         # Voting validation
         ###################
 
-        self.val_probs[obj_inds] = val_smooth * self.val_probs[obj_inds] + (1-val_smooth) * probs
+        self.val_probs[obj_inds] = (
+            val_smooth * self.val_probs[obj_inds] + (1 - val_smooth) * probs
+        )
 
         ############
         # Confusions
         ############
 
         validation_labels = np.array(val_loader.dataset.label_values)
 
         # Compute classification results
-        C1 = fast_confusion(targets,
-                            np.argmax(probs, axis=1),
-                            validation_labels)
+        C1 = fast_confusion(targets, np.argmax(probs, axis=1), validation_labels)
 
         # Compute votes confusion
-        C2 = fast_confusion(val_loader.dataset.input_labels,
-                            np.argmax(self.val_probs, axis=1),
-                            validation_labels)
-
+        C2 = fast_confusion(
+            val_loader.dataset.input_labels,
+            np.argmax(self.val_probs, axis=1),
+            validation_labels,
+        )
 
         # Saving (optionnal)
         if config.saving:
             print("Save confusions")
             conf_list = [C1, C2]
-            file_list = ['val_confs.txt', 'vote_confs.txt']
+            file_list = ["val_confs.txt", "vote_confs.txt"]
             for conf, conf_file in zip(conf_list, file_list):
                 test_file = join(config.saving_path, conf_file)
                 if exists(test_file):
                     with open(test_file, "a") as text_file:
                         for line in conf:
                             for value in line:
-                                text_file.write('%d ' % value)
-                        text_file.write('\n')
+                                text_file.write("%d " % value)
+                        text_file.write("\n")
                 else:
                     with open(test_file, "w") as text_file:
                         for line in conf:
                             for value in line:
-                                text_file.write('%d ' % value)
-                        text_file.write('\n')
+                                text_file.write("%d " % value)
+                        text_file.write("\n")
 
         val_ACC = 100 * np.sum(np.diag(C1)) / (np.sum(C1) + 1e-6)
         vote_ACC = 100 * np.sum(np.diag(C2)) / (np.sum(C2) + 1e-6)
-        print('Accuracies : val = {:.1f}% / vote = {:.1f}%'.format(val_ACC, vote_ACC))
+        print("Accuracies : val = {:.1f}% / vote = {:.1f}%".format(val_ACC, vote_ACC))
 
         return C1
 
     def cloud_segmentation_validation(self, net, val_loader, config, debug=False):
         """
@@ -436,23 +457,29 @@
         nc_tot = val_loader.dataset.num_classes
 
         # Number of classes predicted by the model
         nc_model = config.num_classes
 
-        #print(nc_tot)
-        #print(nc_model)
+        # print(nc_tot)
+        # print(nc_model)
 
         # Initiate global prediction over validation clouds
-        if not hasattr(self, 'validation_probs'):
-            self.validation_probs = [np.zeros((l.shape[0], nc_model))
-                                     for l in val_loader.dataset.input_labels]
+        if not hasattr(self, "validation_probs"):
+            self.validation_probs = [
+                np.zeros((l.shape[0], nc_model))
+                for l in val_loader.dataset.input_labels
+            ]
             self.val_proportions = np.zeros(nc_model, dtype=np.float32)
             i = 0
             for label_value in val_loader.dataset.label_values:
                 if label_value not in val_loader.dataset.ignored_labels:
-                    self.val_proportions[i] = np.sum([np.sum(labels == label_value)
-                                                      for labels in val_loader.dataset.validation_labels])
+                    self.val_proportions[i] = np.sum(
+                        [
+                            np.sum(labels == label_value)
+                            for labels in val_loader.dataset.validation_labels
+                        ]
+                    )
                     i += 1
 
         #####################
         # Network predictions
         #####################
@@ -462,21 +489,20 @@
 
         t = [time.time()]
         last_display = time.time()
         mean_dt = np.zeros(1)
 
-
         t1 = time.time()
 
         # Start validation loop
         for i, batch in enumerate(val_loader):
 
             # New time
             t = t[-1:]
             t += [time.time()]
 
-            if 'cuda' in self.device.type:
+            if "cuda" in self.device.type:
                 batch.to(self.device)
 
             # Forward pass
             outputs = net(batch, config)
 
@@ -493,18 +519,20 @@
 
             i0 = 0
             for b_i, length in enumerate(lengths):
 
                 # Get prediction
-                target = labels[i0:i0 + length]
-                probs = stacked_probs[i0:i0 + length]
-                inds = in_inds[i0:i0 + length]
+                target = labels[i0 : i0 + length]
+                probs = stacked_probs[i0 : i0 + length]
+                inds = in_inds[i0 : i0 + length]
                 c_i = cloud_inds[b_i]
 
                 # Update current probs in whole cloud
-                self.validation_probs[c_i][inds] = val_smooth * self.validation_probs[c_i][inds] \
-                                                   + (1 - val_smooth) * probs
+                self.validation_probs[c_i][inds] = (
+                    val_smooth * self.validation_probs[c_i][inds]
+                    + (1 - val_smooth) * probs
+                )
 
                 # Stack all prediction for this epoch
                 predictions.append(probs)
                 targets.append(target)
                 i0 += length
@@ -514,14 +542,18 @@
             mean_dt = 0.95 * mean_dt + 0.05 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Display
             if (t[-1] - last_display) > 1.0:
                 last_display = t[-1]
-                message = 'Validation : {:.1f}% (timings : {:4.2f} {:4.2f})'
-                print(message.format(100 * i / config.validation_size,
-                                     1000 * (mean_dt[0]),
-                                     1000 * (mean_dt[1])))
+                message = "Validation : {:.1f}% (timings : {:4.2f} {:4.2f})"
+                print(
+                    message.format(
+                        100 * i / config.validation_size,
+                        1000 * (mean_dt[0]),
+                        1000 * (mean_dt[1]),
+                    )
+                )
 
         t2 = time.time()
 
         # Confusions for our subparts of validation set
         Confs = np.zeros((len(predictions), nc_tot, nc_tot), dtype=np.int32)
@@ -534,28 +566,30 @@
 
             # Predicted labels
             preds = val_loader.dataset.label_values[np.argmax(probs, axis=1)]
 
             # Confusions
-            Confs[i, :, :] = fast_confusion(truth, preds, val_loader.dataset.label_values).astype(np.int32)
-
+            Confs[i, :, :] = fast_confusion(
+                truth, preds, val_loader.dataset.label_values
+            ).astype(np.int32)
 
         t3 = time.time()
 
         # Sum all confusions
         C = np.sum(Confs, axis=0).astype(np.float32)
 
         # Remove ignored labels from confusions
-        for l_ind, label_value in reversed(list(enumerate(val_loader.dataset.label_values))):
+        for l_ind, label_value in reversed(
+            list(enumerate(val_loader.dataset.label_values))
+        ):
             if label_value in val_loader.dataset.ignored_labels:
                 C = np.delete(C, l_ind, axis=0)
                 C = np.delete(C, l_ind, axis=1)
 
         # Balance with real validation proportions
         C *= np.expand_dims(self.val_proportions / (np.sum(C, axis=1) + 1e-6), 1)
 
-
         t4 = time.time()
 
         # Objects IoU
         IoUs = IoU_from_confusions(C)
 
@@ -563,17 +597,17 @@
 
         # Saving (optionnal)
         if config.saving:
 
             # Name of saving file
-            test_file = join(config.saving_path, 'val_IoUs.txt')
+            test_file = join(config.saving_path, "val_IoUs.txt")
 
             # Line to write:
-            line = ''
+            line = ""
             for IoU in IoUs:
-                line += '{:.3f} '.format(IoU)
-            line = line + '\n'
+                line += "{:.3f} ".format(IoU)
+            line = line + "\n"
 
             # Write in file
             if exists(test_file):
                 with open(test_file, "a") as text_file:
                     text_file.write(line)
@@ -581,32 +615,36 @@
                 with open(test_file, "w") as text_file:
                     text_file.write(line)
 
             # Save potentials
             if val_loader.dataset.use_potentials:
-                pot_path = join(config.saving_path, 'potentials')
+                pot_path = join(config.saving_path, "potentials")
                 if not exists(pot_path):
                     makedirs(pot_path)
                 files = val_loader.dataset.files
                 for i, file_path in enumerate(files):
-                    pot_points = np.array(val_loader.dataset.pot_trees[i].data, copy=False)
-                    cloud_name = file_path.split('/')[-1]
+                    pot_points = np.array(
+                        val_loader.dataset.pot_trees[i].data, copy=False
+                    )
+                    cloud_name = file_path.split("/")[-1]
                     pot_name = join(pot_path, cloud_name)
                     pots = val_loader.dataset.potentials[i].numpy().astype(np.float32)
-                    write_ply(pot_name,
-                            [pot_points.astype(np.float32), pots],
-                            ['x', 'y', 'z', 'pots'])
+                    write_ply(
+                        pot_name,
+                        [pot_points.astype(np.float32), pots],
+                        ["x", "y", "z", "pots"],
+                    )
 
         t6 = time.time()
 
         # Print instance mean
         mIoU = 100 * np.mean(IoUs)
-        print('{:s} mean IoU = {:.1f}%'.format(config.dataset, mIoU))
+        print("{:s} mean IoU = {:.1f}%".format(config.dataset, mIoU))
 
         # Save predicted cloud occasionally
         if config.saving and (self.epoch + 1) % config.checkpoint_gap == 0:
-            val_path = join(config.saving_path, 'val_preds_{:d}'.format(self.epoch + 1))
+            val_path = join(config.saving_path, "val_preds_{:d}".format(self.epoch + 1))
             if not exists(val_path):
                 makedirs(val_path)
             files = val_loader.dataset.files
             for i, file_path in enumerate(files):
 
@@ -620,38 +658,40 @@
                 for l_ind, label_value in enumerate(val_loader.dataset.label_values):
                     if label_value in val_loader.dataset.ignored_labels:
                         sub_probs = np.insert(sub_probs, l_ind, 0, axis=1)
 
                 # Get the predicted labels
-                sub_preds = val_loader.dataset.label_values[np.argmax(sub_probs, axis=1).astype(np.int32)]
+                sub_preds = val_loader.dataset.label_values[
+                    np.argmax(sub_probs, axis=1).astype(np.int32)
+                ]
 
                 # Reproject preds on the evaluations points
                 preds = (sub_preds[val_loader.dataset.test_proj[i]]).astype(np.int32)
 
                 # Path of saved validation file
-                cloud_name = file_path.split('/')[-1]
+                cloud_name = file_path.split("/")[-1]
                 val_name = join(val_path, cloud_name)
 
                 # Save file
                 labels = val_loader.dataset.validation_labels[i].astype(np.int32)
-                write_ply(val_name,
-                          [points, preds, labels],
-                          ['x', 'y', 'z', 'preds', 'class'])
+                write_ply(
+                    val_name, [points, preds, labels], ["x", "y", "z", "preds", "class"]
+                )
 
         # Display timings
         t7 = time.time()
         if debug:
-            print('\n************************\n')
-            print('Validation timings:')
-            print('Init ...... {:.1f}s'.format(t1 - t0))
-            print('Loop ...... {:.1f}s'.format(t2 - t1))
-            print('Confs ..... {:.1f}s'.format(t3 - t2))
-            print('Confs bis . {:.1f}s'.format(t4 - t3))
-            print('IoU ....... {:.1f}s'.format(t5 - t4))
-            print('Save1 ..... {:.1f}s'.format(t6 - t5))
-            print('Save2 ..... {:.1f}s'.format(t7 - t6))
-            print('\n************************\n')
+            print("\n************************\n")
+            print("Validation timings:")
+            print("Init ...... {:.1f}s".format(t1 - t0))
+            print("Loop ...... {:.1f}s".format(t2 - t1))
+            print("Confs ..... {:.1f}s".format(t3 - t2))
+            print("Confs bis . {:.1f}s".format(t4 - t3))
+            print("IoU ....... {:.1f}s".format(t5 - t4))
+            print("Save1 ..... {:.1f}s".format(t6 - t5))
+            print("Save2 ..... {:.1f}s".format(t7 - t6))
+            print("\n************************\n")
 
         return
 
     def slam_segmentation_validation(self, net, val_loader, config, debug=True):
         """
@@ -671,12 +711,12 @@
         # Choose validation smoothing parameter (0 for no smothing, 0.99 for big smoothing)
         val_smooth = 0.95
         softmax = torch.nn.Softmax(1)
 
         # Create folder for validation predictions
-        if not exists (join(config.saving_path, 'val_preds')):
-            makedirs(join(config.saving_path, 'val_preds'))
+        if not exists(join(config.saving_path, "val_preds")):
+            makedirs(join(config.saving_path, "val_preds"))
 
         # initiate the dataset validation containers
         val_loader.dataset.val_points = []
         val_loader.dataset.val_labels = []
 
@@ -694,21 +734,20 @@
 
         t = [time.time()]
         last_display = time.time()
         mean_dt = np.zeros(1)
 
-
         t1 = time.time()
 
         # Start validation loop
         for i, batch in enumerate(val_loader):
 
             # New time
             t = t[-1:]
             t += [time.time()]
 
-            if 'cuda' in self.device.type:
+            if "cuda" in self.device.type:
                 batch.to(self.device)
 
             # Forward pass
             outputs = net(batch, config)
 
@@ -726,11 +765,11 @@
 
             i0 = 0
             for b_i, length in enumerate(lengths):
 
                 # Get prediction
-                probs = stk_probs[i0:i0 + length]
+                probs = stk_probs[i0 : i0 + length]
                 proj_inds = r_inds_list[b_i]
                 proj_mask = r_mask_list[b_i]
                 frame_labels = labels_list[b_i]
                 s_ind = f_inds[b_i, 0]
                 f_ind = f_inds[b_i, 1]
@@ -749,33 +788,47 @@
 
                 # Predicted labels
                 preds = val_loader.dataset.label_values[np.argmax(proj_probs, axis=1)]
 
                 # Save predictions in a binary file
-                filename = '{:s}_{:07d}.npy'.format(val_loader.dataset.sequences[s_ind], f_ind)
-                filepath = join(config.saving_path, 'val_preds', filename)
+                filename = "{:s}_{:07d}.npy".format(
+                    val_loader.dataset.sequences[s_ind], f_ind
+                )
+                filepath = join(config.saving_path, "val_preds", filename)
                 if exists(filepath):
                     frame_preds = np.load(filepath)
                 else:
                     frame_preds = np.zeros(frame_labels.shape, dtype=np.uint8)
                 frame_preds[proj_mask] = preds.astype(np.uint8)
                 np.save(filepath, frame_preds)
 
                 # Save some of the frame pots
                 if f_ind % 20 == 0:
-                    seq_path = join(val_loader.dataset.path, 'sequences', val_loader.dataset.sequences[s_ind])
-                    velo_file = join(seq_path, 'velodyne', val_loader.dataset.frames[s_ind][f_ind] + '.bin')
+                    seq_path = join(
+                        val_loader.dataset.path,
+                        "sequences",
+                        val_loader.dataset.sequences[s_ind],
+                    )
+                    velo_file = join(
+                        seq_path,
+                        "velodyne",
+                        val_loader.dataset.frames[s_ind][f_ind] + ".bin",
+                    )
                     frame_points = np.fromfile(velo_file, dtype=np.float32)
                     frame_points = frame_points.reshape((-1, 4))
-                    write_ply(filepath[:-4] + '_pots.ply',
-                              [frame_points[:, :3], frame_labels, frame_preds],
-                              ['x', 'y', 'z', 'gt', 'pre'])
+                    write_ply(
+                        filepath[:-4] + "_pots.ply",
+                        [frame_points[:, :3], frame_labels, frame_preds],
+                        ["x", "y", "z", "gt", "pre"],
+                    )
 
                 # Update validation confusions
-                frame_C = fast_confusion(frame_labels,
-                                         frame_preds.astype(np.int32),
-                                         val_loader.dataset.label_values)
+                frame_C = fast_confusion(
+                    frame_labels,
+                    frame_preds.astype(np.int32),
+                    val_loader.dataset.label_values,
+                )
                 val_loader.dataset.val_confs[s_ind][f_ind, :, :] = frame_C
 
                 # Stack all prediction for this epoch
                 predictions += [preds]
                 targets += [frame_labels[proj_mask]]
@@ -788,23 +841,29 @@
             mean_dt = 0.95 * mean_dt + 0.05 * (np.array(t[1:]) - np.array(t[:-1]))
 
             # Display
             if (t[-1] - last_display) > 1.0:
                 last_display = t[-1]
-                message = 'Validation : {:.1f}% (timings : {:4.2f} {:4.2f})'
-                print(message.format(100 * i / config.validation_size,
-                                     1000 * (mean_dt[0]),
-                                     1000 * (mean_dt[1])))
+                message = "Validation : {:.1f}% (timings : {:4.2f} {:4.2f})"
+                print(
+                    message.format(
+                        100 * i / config.validation_size,
+                        1000 * (mean_dt[0]),
+                        1000 * (mean_dt[1]),
+                    )
+                )
 
         t2 = time.time()
 
         # Confusions for our subparts of validation set
         Confs = np.zeros((len(predictions), nc_tot, nc_tot), dtype=np.int32)
         for i, (preds, truth) in enumerate(zip(predictions, targets)):
 
             # Confusions
-            Confs[i, :, :] = fast_confusion(truth, preds, val_loader.dataset.label_values).astype(np.int32)
+            Confs[i, :, :] = fast_confusion(
+                truth, preds, val_loader.dataset.label_values
+            ).astype(np.int32)
 
         t3 = time.time()
 
         #######################################
         # Results on this subpart of validation
@@ -812,14 +871,18 @@
 
         # Sum all confusions
         C = np.sum(Confs, axis=0).astype(np.float32)
 
         # Balance with real validation proportions
-        C *= np.expand_dims(val_loader.dataset.class_proportions / (np.sum(C, axis=1) + 1e-6), 1)
+        C *= np.expand_dims(
+            val_loader.dataset.class_proportions / (np.sum(C, axis=1) + 1e-6), 1
+        )
 
         # Remove ignored labels from confusions
-        for l_ind, label_value in reversed(list(enumerate(val_loader.dataset.label_values))):
+        for l_ind, label_value in reversed(
+            list(enumerate(val_loader.dataset.label_values))
+        ):
             if label_value in val_loader.dataset.ignored_labels:
                 C = np.delete(C, l_ind, axis=0)
                 C = np.delete(C, l_ind, axis=1)
 
         # Objects IoU
@@ -830,23 +893,29 @@
         #####################################
 
         t4 = time.time()
 
         # Sum all validation confusions
-        C_tot = [np.sum(seq_C, axis=0) for seq_C in val_loader.dataset.val_confs if len(seq_C) > 0]
+        C_tot = [
+            np.sum(seq_C, axis=0)
+            for seq_C in val_loader.dataset.val_confs
+            if len(seq_C) > 0
+        ]
         C_tot = np.sum(np.stack(C_tot, axis=0), axis=0)
 
         if debug:
-            s = '\n'
+            s = "\n"
             for cc in C_tot:
                 for c in cc:
-                    s += '{:8.1f} '.format(c)
-                s += '\n'
+                    s += "{:8.1f} ".format(c)
+                s += "\n"
             print(s)
 
         # Remove ignored labels from confusions
-        for l_ind, label_value in reversed(list(enumerate(val_loader.dataset.label_values))):
+        for l_ind, label_value in reversed(
+            list(enumerate(val_loader.dataset.label_values))
+        ):
             if label_value in val_loader.dataset.ignored_labels:
                 C_tot = np.delete(C_tot, l_ind, axis=0)
                 C_tot = np.delete(C_tot, l_ind, axis=1)
 
         # Objects IoU
@@ -856,21 +925,21 @@
 
         # Saving (optionnal)
         if config.saving:
 
             IoU_list = [IoUs, val_IoUs]
-            file_list = ['subpart_IoUs.txt', 'val_IoUs.txt']
+            file_list = ["subpart_IoUs.txt", "val_IoUs.txt"]
             for IoUs_to_save, IoU_file in zip(IoU_list, file_list):
 
                 # Name of saving file
                 test_file = join(config.saving_path, IoU_file)
 
                 # Line to write:
-                line = ''
+                line = ""
                 for IoU in IoUs_to_save:
-                    line += '{:.3f} '.format(IoU)
-                line = line + '\n'
+                    line += "{:.3f} ".format(IoU)
+                line = line + "\n"
 
                 # Write in file
                 if exists(test_file):
                     with open(test_file, "a") as text_file:
                         text_file.write(line)
@@ -878,59 +947,24 @@
                     with open(test_file, "w") as text_file:
                         text_file.write(line)
 
         # Print instance mean
         mIoU = 100 * np.mean(IoUs)
-        print('{:s} : subpart mIoU = {:.1f} %'.format(config.dataset, mIoU))
+        print("{:s} : subpart mIoU = {:.1f} %".format(config.dataset, mIoU))
         mIoU = 100 * np.mean(val_IoUs)
-        print('{:s} :     val mIoU = {:.1f} %'.format(config.dataset, mIoU))
+        print("{:s} :     val mIoU = {:.1f} %".format(config.dataset, mIoU))
 
         t6 = time.time()
 
         # Display timings
         if debug:
-            print('\n************************\n')
-            print('Validation timings:')
-            print('Init ...... {:.1f}s'.format(t1 - t0))
-            print('Loop ...... {:.1f}s'.format(t2 - t1))
-            print('Confs ..... {:.1f}s'.format(t3 - t2))
-            print('IoU1 ...... {:.1f}s'.format(t4 - t3))
-            print('IoU2 ...... {:.1f}s'.format(t5 - t4))
-            print('Save ...... {:.1f}s'.format(t6 - t5))
-            print('\n************************\n')
+            print("\n************************\n")
+            print("Validation timings:")
+            print("Init ...... {:.1f}s".format(t1 - t0))
+            print("Loop ...... {:.1f}s".format(t2 - t1))
+            print("Confs ..... {:.1f}s".format(t3 - t2))
+            print("IoU1 ...... {:.1f}s".format(t4 - t3))
+            print("IoU2 ...... {:.1f}s".format(t5 - t4))
+            print("Save ...... {:.1f}s".format(t6 - t5))
+            print("\n************************\n")
 
         return
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/data_prepare_semantickitti.py	2024-06-30 22:34:20.951973+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/data_prepare_semantickitti.py	2024-07-08 11:53:48.917395+00:00
@@ -7,70 +7,76 @@
 ROOT_DIR = dirname(BASE_DIR)
 sys.path.append(BASE_DIR)
 sys.path.append(ROOT_DIR)
 from helper_tool import DataProcessing as DP
 
-data_config = os.path.join(BASE_DIR, 'semantic-kitti.yaml')
-DATA = yaml.safe_load(open(data_config, 'r'))
+data_config = os.path.join(BASE_DIR, "semantic-kitti.yaml")
+DATA = yaml.safe_load(open(data_config, "r"))
 remap_dict = DATA["learning_map"]
 max_key = max(remap_dict.keys())
 remap_lut = np.zeros((max_key + 100), dtype=np.int32)
 remap_lut[list(remap_dict.keys())] = list(remap_dict.values())
 
 grid_size = 0.06
-dataset_path = '/DATA/abhishek/SemanticKitti/unzipped/dataset/sequences'
-output_path = '/DATA/abhishek/SemanticKitti/unzipped/dataset/sequences' + '_' + str(grid_size)
+dataset_path = "/DATA/abhishek/SemanticKitti/unzipped/dataset/sequences"
+output_path = (
+    "/DATA/abhishek/SemanticKitti/unzipped/dataset/sequences" + "_" + str(grid_size)
+)
 seq_list = np.sort(os.listdir(dataset_path))[1:]
 
 for seq_id in seq_list:
-    print('sequence' + seq_id + ' start')
+    print("sequence" + seq_id + " start")
     seq_path = join(dataset_path, seq_id)
     seq_path_out = join(output_path, seq_id)
-    pc_path = join(seq_path, 'velodyne')
-    pc_path_out = join(seq_path_out, 'velodyne')
-    KDTree_path_out = join(seq_path_out, 'KDTree')
+    pc_path = join(seq_path, "velodyne")
+    pc_path_out = join(seq_path_out, "velodyne")
+    KDTree_path_out = join(seq_path_out, "KDTree")
     os.makedirs(seq_path_out) if not exists(seq_path_out) else None
     os.makedirs(pc_path_out) if not exists(pc_path_out) else None
     os.makedirs(KDTree_path_out) if not exists(KDTree_path_out) else None
 
-    if int(seq_id) < 11 or int(seq_id)==22:
-        label_path = join(seq_path, 'labels')
-        label_path_out = join(seq_path_out, 'labels')
+    if int(seq_id) < 11 or int(seq_id) == 22:
+        label_path = join(seq_path, "labels")
+        label_path_out = join(seq_path_out, "labels")
         os.makedirs(label_path_out) if not exists(label_path_out) else None
         scan_list = np.sort(os.listdir(pc_path))
         for scan_id in scan_list:
             print(scan_id)
             points = DP.load_pc_kitti(join(pc_path, scan_id))
-            labels = DP.load_label_kitti(join(label_path, str(scan_id[:-4]) + '.label'), remap_lut)
-            sub_points, sub_labels = DP.grid_sub_sampling(points, labels=labels, grid_size=grid_size)
+            labels = DP.load_label_kitti(
+                join(label_path, str(scan_id[:-4]) + ".label"), remap_lut
+            )
+            sub_points, sub_labels = DP.grid_sub_sampling(
+                points, labels=labels, grid_size=grid_size
+            )
             search_tree = KDTree(sub_points)
-            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + '.pkl')
+            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + ".pkl")
             np.save(join(pc_path_out, scan_id)[:-4], sub_points)
             np.save(join(label_path_out, scan_id)[:-4], sub_labels)
-            with open(KDTree_save, 'wb') as f:
+            with open(KDTree_save, "wb") as f:
                 pickle.dump(search_tree, f)
-            if seq_id == '08':
-                proj_path = join(seq_path_out, 'proj')
+            if seq_id == "08":
+                proj_path = join(seq_path_out, "proj")
                 os.makedirs(proj_path) if not exists(proj_path) else None
                 proj_inds = np.squeeze(search_tree.query(points, return_distance=False))
                 proj_inds = proj_inds.astype(np.int32)
-                proj_save = join(proj_path, str(scan_id[:-4]) + '_proj.pkl')
-                with open(proj_save, 'wb') as f:
+                proj_save = join(proj_path, str(scan_id[:-4]) + "_proj.pkl")
+                with open(proj_save, "wb") as f:
                     pickle.dump([proj_inds], f)
     else:
-        proj_path = join(seq_path_out, 'proj')
+        proj_path = join(seq_path_out, "proj")
         os.makedirs(proj_path) if not exists(proj_path) else None
         scan_list = np.sort(os.listdir(pc_path))
         for scan_id in scan_list:
             print(scan_id)
             points = DP.load_pc_kitti(join(pc_path, scan_id))
             sub_points = DP.grid_sub_sampling(points, grid_size=0.06)
             search_tree = KDTree(sub_points)
             proj_inds = np.squeeze(search_tree.query(points, return_distance=False))
             proj_inds = proj_inds.astype(np.int32)
-            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + '.pkl')
-            proj_save = join(proj_path, str(scan_id[:-4]) + '_proj.pkl')
+            KDTree_save = join(KDTree_path_out, str(scan_id[:-4]) + ".pkl")
+            proj_save = join(proj_path, str(scan_id[:-4]) + "_proj.pkl")
             np.save(join(pc_path_out, scan_id)[:-4], sub_points)
-            with open(KDTree_save, 'wb') as f:
+            with open(KDTree_save, "wb") as f:
                 pickle.dump(search_tree, f)
-            with open(proj_save, 'wb') as f:
+            with open(proj_save, "wb") as f:
                 pickle.dump([proj_inds], f)
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/pGSCAM.py	2024-06-30 22:34:19.800754+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/pGSCAM.py	2024-07-08 11:53:49.108158+00:00
@@ -1,6 +1,6 @@
-import numpy as np 
+import numpy as np
 import torch
 from utils.ply import read_ply, write_ply
 from torch.autograd import grad
 from sklearn.metrics import confusion_matrix
 from sklearn.neighbors import KDTree
@@ -12,423 +12,457 @@
 from drop_dataset import SemanticKITTI
 from torch.utils.data import DataLoader
 from sklearn.cluster import DBSCAN
 import umap
 
-        
-        
+
 class PowerCAM:
     """
-    Vanilla gradient class activation mapping 
+    Vanilla gradient class activation mapping
     """
-    
-    def __init__(self, input_model, batch, config, mask_type="none", mode="normal", norm=False, cls=-1):
+
+    def __init__(
+        self,
+        input_model,
+        batch,
+        config,
+        mask_type="none",
+        mode="normal",
+        norm=False,
+        cls=-1,
+    ):
         # mode: [normal, counterfactual]
         # mask_type: [none, single, subset]:- none(no mask), single(only single point), subset(collection of points)
-        
+
         self.input_model = input_model
         self.batch = batch
         self.cls = cls
         self.config = config
         self.norm = norm
         self.is_masked = True
         self.threshold = [0.1, 0.3, 0.3]
         self.mode = mode
         self.mask_type = mask_type
-        
+
         # actuall labels starts from unlabelled but we are ignoring it
         self.transform_map = {
-          0: "car",
-          1: "bicycle",
-          2: "motorcycle",
-          3: "truck",
-          4: "other-vehicle",
-          5: "person",
-          6: "bicyclist",
-          7: "motorcyclist",
-          8: "road",
-          9: "parking",
-          10: "sidewalk",
-          11: "other-ground",
-          12: "building",
-          13: "fence",
-          14: "vegetation",
-          15: "trunk",
-          16: "terrain",
-          17: "pole",
-          18: "traffic-sign"
-      }
-        
+            0: "car",
+            1: "bicycle",
+            2: "motorcycle",
+            3: "truck",
+            4: "other-vehicle",
+            5: "person",
+            6: "bicyclist",
+            7: "motorcyclist",
+            8: "road",
+            9: "parking",
+            10: "sidewalk",
+            11: "other-ground",
+            12: "building",
+            13: "fence",
+            14: "vegetation",
+            15: "trunk",
+            16: "terrain",
+            17: "pole",
+            18: "traffic-sign",
+        }
+
     def create_mask(self):
         # logits: [1, d, N]
         # points: [1, N, 3]
         # preds: [1, N]
-        logits = self.end_points['logits']
+        logits = self.end_points["logits"]
         softmax = torch.nn.Softmax(1)
         preds = softmax(logits).argmax(dim=1)
-        point_0 = self.end_points['xyz'][0]
-        if self.mask_type == 'none':
+        point_0 = self.end_points["xyz"][0]
+        if self.mask_type == "none":
             logits_mask = torch.ones_like(logits)
-            
-        elif self.mask_type == 'subset':
+
+        elif self.mask_type == "subset":
             # Create Mask
             pred_mask = (preds == self.cls).int()
             inds_mask = torch.argwhere(pred_mask.squeeze()).squeeze()
             masked_point = point_0[:, inds_mask, :].detach().cpu().numpy()
-            
+
             # Perform DBSCAN clustering to seperate entities of class self.cls
-            clustering = DBSCAN(eps=0.5, min_samples=5, metric='euclidean', algorithm='auto').fit(masked_point.squeeze())
-            
+            clustering = DBSCAN(
+                eps=0.5, min_samples=5, metric="euclidean", algorithm="auto"
+            ).fit(masked_point.squeeze())
+
             cluster_labels = clustering.labels_
-            
+
             # Let's extract cluster 0
             inds_clust = np.argwhere((cluster_labels == 0).astype(int)).squeeze()
-            clust_point = point_0[:, inds_mask[inds_clust], :]            
+            clust_point = point_0[:, inds_mask[inds_clust], :]
             logits_mask = torch.zeros_like(logits)
             logits_mask[:, :, inds_mask[inds_clust]] = 1
-            
-            preds_mask  = -torch.ones_like(preds)
+
+            preds_mask = -torch.ones_like(preds)
             preds_mask[:, inds_mask[inds_clust]] = 1
-            
-            entities = [point_0[0].detach().cpu().numpy(), preds_mask[0].cpu().numpy().astype(np.int32)]
-            
-            write_ply('vis_cluster.ply', entities, ['x', 'y', 'z', 'preds'])
-
-        elif self.mask_type == 'single':
+
+            entities = [
+                point_0[0].detach().cpu().numpy(),
+                preds_mask[0].cpu().numpy().astype(np.int32),
+            ]
+
+            write_ply("vis_cluster.ply", entities, ["x", "y", "z", "preds"])
+
+        elif self.mask_type == "single":
             # Create Mask
             pred_mask = (preds == self.cls).int()
             inds_mask = torch.argwhere(pred_mask.squeeze()).squeeze()
-            
+
             # First element of inds mask as ROI
             logits_mask = torch.zeros_like(logits)
-            
-            # Logits 
+
+            # Logits
             logits_mask[:, :, inds_mask[0]] = 1
-            
-            
-        
+
         return logits_mask
-#         return inds_mask[inds_clust]
-        
+
+    #         return inds_mask[inds_clust]
+
     def getGradients(self):
-#         print(f"Current class: {self.transform_map[self.cls]}")
+        #         print(f"Current class: {self.transform_map[self.cls]}")
         self.input_model.eval()
         self.end_points = self.input_model(self.batch)
-        logits = self.end_points['logits']
-                
-#         logits = self.create_mask()*logits
+        logits = self.end_points["logits"]
+
+        #         logits = self.create_mask()*logits
         softmax = torch.nn.Softmax(1)
         preds = softmax(logits).argmax(dim=1)
-                
-#         logits = logits[:, :, self.create_mask()]
-        logits = self.create_mask()*logits
-        
+
+        #         logits = logits[:, :, self.create_mask()]
+        logits = self.create_mask() * logits
+
         logits = softmax(logits)
         mask = ((preds.squeeze(0) == self.cls).unsqueeze(0)).unsqueeze(1)
-#         print(f"Number of points for class {self.transform_map[self.cls]}: ", torch.sum(mask.squeeze()).item())
+        #         print(f"Number of points for class {self.transform_map[self.cls]}: ", torch.sum(mask.squeeze()).item())
 
         logits = logits[:, self.cls, :]
         logits = torch.sum(logits, axis=-1)
-        
+
         logits = logits.squeeze()
-        
+
         self.logits = logits
 
         self.logits.backward(retain_graph=True)
-                
-        self.activations = self.end_points['activations']
-        
+
+        self.activations = self.end_points["activations"]
+
         return torch.sum(mask.squeeze()).item()
-    
-    
+
     def heatmap(self):
-#         self.logits.backward(retain_graph=True)
-#         self.logits.backward()
-        
+        #         self.logits.backward(retain_graph=True)
+        #         self.logits.backward()
+
         heatmaps_III = []
         heatmaps_III_kdtree = []
-        point_0 = self.end_points['xyz'][0].cpu().numpy().squeeze()
-#         tree = KDTree(point_0.cpu().numpy().squeeze())
-#         print(point_0.shape)
-        
+        point_0 = self.end_points["xyz"][0].cpu().numpy().squeeze()
+        #         tree = KDTree(point_0.cpu().numpy().squeeze())
+        #         print(point_0.shape)
+
         for i, act in enumerate(self.activations):
             grads = act.grad
-            if self.mode == 'normal':
-                alpha = torch.sum(grads, axis=(2,3))
-            elif self.mode == 'counterfactual':
-                alpha = -torch.sum(grads, axis=(2,3))
+            if self.mode == "normal":
+                alpha = torch.sum(grads, axis=(2, 3))
+            elif self.mode == "counterfactual":
+                alpha = -torch.sum(grads, axis=(2, 3))
             activation = act.squeeze()
             heatmap = torch.matmul(alpha, activation)
-            
+
             # Apply ReLU
             heatmap = torch.maximum(heatmap, torch.zeros_like(heatmap))
-            
+
             # Normalize
             max_val = torch.max(heatmap, dim=-1, keepdim=True)[0]
             min_val = torch.min(heatmap, dim=-1, keepdim=True)[0]
             heatmap = (heatmap - min_val) / (max_val - min_val)
             heatmap = heatmap.cpu().detach().numpy()
-            
+
             # Fill NaN values
             heatmap = np.nan_to_num(heatmap)
-            
+
             heatmaps_III.append(heatmap)
-            
+
             heatmap = heatmap.squeeze()
-            
-
-            
+
             if act.shape[2] != point_0.shape[1]:
-                for pt in self.end_points['xyz']:
+                for pt in self.end_points["xyz"]:
                     if pt.shape[1] == act.shape[2]:
                         tree = KDTree(pt.cpu().numpy().squeeze(), leaf_size=40)
                         idx = tree.query(point_0, return_distance=False).squeeze()
                         heatmaps_III_kdtree.append(np.expand_dims(heatmap[idx], 0))
             else:
-                heatmaps_III_kdtree.append(np.expand_dims(heatmap[idx],0))
-#             print(act.shape, heatmap.shape)
-         
+                heatmaps_III_kdtree.append(np.expand_dims(heatmap[idx], 0))
+        #             print(act.shape, heatmap.shape)
+
         self.heatmaps_III = heatmaps_III
         self.heatmaps_III_kdtree = heatmaps_III_kdtree
-        
-        
-        
+
     def refinement(self):
         hm = self.heatmaps_III_kdtree[-1].squeeze()
-        logits = self.end_points['logits']
-#         logits = self.create_mask()*logits
+        logits = self.end_points["logits"]
+        #         logits = self.create_mask()*logits
         softmax = torch.nn.Softmax(1)
         preds = softmax(logits).argmax(dim=1).squeeze().detach().cpu().numpy()
-        
+
         preds_mask = (preds == self.cls).astype(np.int32)
-        
+
         hm_mask = (hm > 0.5).astype(np.int32)
-        
+
         pred_final = hm_mask * preds_mask
-        
+
         print(pred_final.shape, np.unique(hm_mask), np.unique(preds_mask))
 
-        
     def visCAM(self):
         print("Saving visuals...")
-        points = self.end_points['xyz']
-        labels = self.end_points['labels'].cpu().numpy().astype(np.int32)
-        preds = self.end_points['logits'].cpu()
-        
+        points = self.end_points["xyz"]
+        labels = self.end_points["labels"].cpu().numpy().astype(np.int32)
+        preds = self.end_points["logits"].cpu()
+
         for hm_i, hm in enumerate(self.heatmaps_III):
             for p_i, p in enumerate(points):
                 if hm.shape[1] == p.shape[1]:
                     entities = [p[0].detach().cpu().numpy(), hm[0]]
                     break
-            
-            write_ply(f'./visuals/{self.mask_type}_{self.mode}_{self.transform_map[self.cls]}_{hm_i}_pgscam.ply', entities, ['x', 'y', 'z', 'heatmap'])
-            
-        
+
+            write_ply(
+                f"./visuals/{self.mask_type}_{self.mode}_{self.transform_map[self.cls]}_{hm_i}_pgscam.ply",
+                entities,
+                ["x", "y", "z", "heatmap"],
+            )
+
         for hm_i, hm in enumerate(self.heatmaps_III_kdtree):
             for p_i, p in enumerate(points):
                 if hm.shape[1] == p.shape[1]:
                     entities = [p[0].detach().cpu().numpy(), hm[0]]
                     break
-                    
-            write_ply(f'./visuals/{self.mask_type}_{self.mode}_{self.transform_map[self.cls]}_{hm_i}_pgscam_kdtree.ply', entities, ['x', 'y', 'z', 'heatmap'])       
-        
-#     def visCAM(self):
-#         print("Saving visuals...")
-#         points = self.end_points['xyz']  # list
-#         labels = self.end_points['labels'].cpu().numpy().astype(np.int32)  # [1, N]
-#         preds = self.end_points['logits'].cpu()
-#         softmax = torch.nn.Softmax(1)
-#         preds = softmax(preds).argmax(dim=1).detach().numpy().astype(np.int32) # [1, N]
-            
-#         for hm_i, hm in enumerate(self.heatmaps_I_II_III):
-#             for p_i, p in enumerate(points):
-#                 if hm.shape[1] == p.shape[1]:
-#                     entities = [p[0].detach().cpu().numpy(), hm[0].detach().cpu().numpy()]
-#             if hm.shape[1] == points[0].shape[1]:
-#                 entities += [labels[0], preds[0]]    
-#                 write_ply(f'./visuals/{self.transform_map[self.cls]}_{hm_i}_vanillaCam.ply', entities, ['x', 'y', 'z', 'heatmap', 'labels', 'preds'])
-#                 continue
-#             write_ply(f'./visuals/{self.transform_map[self.cls]}_{hm_i}_vanillaCam.ply', entities, ['x', 'y', 'z', 'heatmap'])
-
-    
-    
+
+            write_ply(
+                f"./visuals/{self.mask_type}_{self.mode}_{self.transform_map[self.cls]}_{hm_i}_pgscam_kdtree.ply",
+                entities,
+                ["x", "y", "z", "heatmap"],
+            )
+
+    #     def visCAM(self):
+    #         print("Saving visuals...")
+    #         points = self.end_points['xyz']  # list
+    #         labels = self.end_points['labels'].cpu().numpy().astype(np.int32)  # [1, N]
+    #         preds = self.end_points['logits'].cpu()
+    #         softmax = torch.nn.Softmax(1)
+    #         preds = softmax(preds).argmax(dim=1).detach().numpy().astype(np.int32) # [1, N]
+
+    #         for hm_i, hm in enumerate(self.heatmaps_I_II_III):
+    #             for p_i, p in enumerate(points):
+    #                 if hm.shape[1] == p.shape[1]:
+    #                     entities = [p[0].detach().cpu().numpy(), hm[0].detach().cpu().numpy()]
+    #             if hm.shape[1] == points[0].shape[1]:
+    #                 entities += [labels[0], preds[0]]
+    #                 write_ply(f'./visuals/{self.transform_map[self.cls]}_{hm_i}_vanillaCam.ply', entities, ['x', 'y', 'z', 'heatmap', 'labels', 'preds'])
+    #                 continue
+    #             write_ply(f'./visuals/{self.transform_map[self.cls]}_{hm_i}_vanillaCam.ply', entities, ['x', 'y', 'z', 'heatmap'])
+
     def runCAM(self):
         num_points = self.getGradients()
         self.heatmap()
-#         self.refinement()
-#         self.visCAM()
+        #         self.refinement()
+        #         self.visCAM()
         return num_points
-    
-class Drop_attack():
+
+
+class Drop_attack:
     def __init__(self):
         self.transform_map = {
-          0: "car",
-          1: "bicycle",
-          2: "motorcycle",
-          3: "truck",
-          4: "other-vehicle",
-          5: "person",
-          6: "bicyclist",
-          7: "motorcyclist",
-          8: "road",
-          9: "parking",
-          10: "sidewalk",
-          11: "other-ground",
-          12: "building",
-          13: "fence",
-          14: "vegetation",
-          15: "trunk",
-          16: "terrain",
-          17: "pole",
-          18: "traffic-sign"
-      }
-        
+            0: "car",
+            1: "bicycle",
+            2: "motorcycle",
+            3: "truck",
+            4: "other-vehicle",
+            5: "person",
+            6: "bicyclist",
+            7: "motorcyclist",
+            8: "road",
+            9: "parking",
+            10: "sidewalk",
+            11: "other-ground",
+            12: "building",
+            13: "fence",
+            14: "vegetation",
+            15: "trunk",
+            16: "terrain",
+            17: "pole",
+            18: "traffic-sign",
+        }
+
     @staticmethod
     def my_worker_init_fn(worker_id):
-#         np.random.seed(np.random.get_state()[1][0] + worker_id)
+        #         np.random.seed(np.random.get_state()[1][0] + worker_id)
         np.random.seed(0)
-    
-    def drop(self, input_model, batch, config, n_drop=[0, 1000, 2000, 3000, 4000, 5000], cls=-1, drop_type='high'):
+
+    def drop(
+        self,
+        input_model,
+        batch,
+        config,
+        n_drop=[0, 1000, 2000, 3000, 4000, 5000],
+        cls=-1,
+        drop_type="high",
+    ):
         self.cls = cls
         cam = PowerCAM(input_model, batch, config, norm=False, cls=cls)
         _ = cam.runCAM()
         heatmaps = cam.heatmaps_III
         end_points = cam.end_points
-        
+
         hm = heatmaps[-1]
-        point_0 = batch['xyz'][0].detach().cpu().numpy()
-        label_0 = batch['labels'].detach().cpu().numpy()
-        preds = batch['logits'].detach().cpu().numpy()
-        
+        point_0 = batch["xyz"][0].detach().cpu().numpy()
+        label_0 = batch["labels"].detach().cpu().numpy()
+        preds = batch["logits"].detach().cpu().numpy()
+
         point_collect = []
         miou_collect = []
         ciou_collect = []
-        
+
         for drop_ in n_drop:
             # Sorts in descending order
-#             print(f"Drop: {drop_}")
-            if drop_type == 'high':
+            #             print(f"Drop: {drop_}")
+            if drop_type == "high":
                 ind = np.argsort(hm.squeeze())[::-1]
             else:
                 ind = np.argsort(hm.squeeze())
-                
+
             point_sort = point_0[:, ind, :]
             label_sort = label_0[:, ind]
             hm_sort = hm[:, ind]
-            
+
             drop_points = point_sort[:, :drop_, :].squeeze()
             drop_labels = label_sort[:, :drop_].squeeze()
             drop_hm = hm_sort[:, :drop_].squeeze()
-            
+
             point_collect.append((drop_points, drop_labels, drop_hm))
-            
-            ent_ = [drop_points.squeeze(), drop_labels.squeeze().astype(np.int32), drop_hm.squeeze()]
-#             write_ply(f'drop_{drop_}', ent_, ['x', 'y', 'z', 'cls', 'hm'])
-            
+
+            ent_ = [
+                drop_points.squeeze(),
+                drop_labels.squeeze().astype(np.int32),
+                drop_hm.squeeze(),
+            ]
+            #             write_ply(f'drop_{drop_}', ent_, ['x', 'y', 'z', 'cls', 'hm'])
+
             rem_points = point_sort[:, drop_:, :].squeeze()
             rem_labels = label_sort[:, drop_:].squeeze()
-            
+
             DATASET = SemanticKITTI(rem_points, rem_labels)
-    
-            DATALOADER = DataLoader(DATASET, batch_size=1, shuffle=True, num_workers=20, worker_init_fn=self.my_worker_init_fn, collate_fn=DATASET.collate_fn)
-    
+
+            DATALOADER = DataLoader(
+                DATASET,
+                batch_size=1,
+                shuffle=True,
+                num_workers=20,
+                worker_init_fn=self.my_worker_init_fn,
+                collate_fn=DATASET.collate_fn,
+            )
+
             for batch_ in DATALOADER:
                 for key in batch_:
                     if type(batch_[key]) is list:
                         for i in range(len(batch_[key])):
                             batch_[key][i] = batch_[key][i].cuda()
                     else:
                         batch_[key] = batch_[key].cuda()
                 continue
-                
+
             end_points_ = input_model(batch_)
             mean_iou_, iou_list_, loss_ = self.compute_iou_(end_points_, config)
-            miou_100, ciou_100 = self.display_iou(mean_iou_, iou_list_, end_points_['xyz'][0].squeeze())
-            
+            miou_100, ciou_100 = self.display_iou(
+                mean_iou_, iou_list_, end_points_["xyz"][0].squeeze()
+            )
+
             miou_collect.append(miou_100)
             ciou_collect.append(ciou_100)
-            
-            
-            
+
             cam_ = PowerCAM(input_model, batch_, config, norm=False, cls=cls)
             _ = cam_.runCAM()
             heatmaps_ = cam_.heatmaps_III_kdtree
-            
+
             point_0 = np.expand_dims(rem_points, axis=0)
             label_0 = np.expand_dims(rem_labels, axis=0)
             hm = heatmaps_[-1]
-            
-#             entities = [batch_['xyz'][0].squeeze().detach().cpu().numpy(), batch_['labels'].squeeze().cpu().numpy().astype(np.int32), hm.squeeze()]
-            
-#             write_ply(f'./accumulated_piecewise/{self.transform_map[self.cls]}_SemanticKITTI_drop_{drop_}', entities, ['x', 'y', 'z', 'cls', 'hm'])
-            
-            
-#         pt_full = np.empty(shape=(0,3))
-#         hm_full = np.empty(shape=(0,))
-#         label_full = np.empty(shape=(0,))
-#         for entity in point_collect:
-#             pt_, lb_, hm_ = entity
-#             pt_full = np.concatenate((pt_full, pt_.squeeze()), axis=0)
-#             hm_full = np.concatenate((hm_full, hm_.squeeze()), axis=0)
-#             label_full = np.concatenate((label_full, lb_.squeeze()), axis=0)
-        
-#         pt_full = np.concatenate((pt_full, point_0.squeeze()), axis=0)
-#         hm_full = np.concatenate((hm_full, hm.squeeze()), axis=0)
-#         label_full = np.concatenate((label_full, label_0.squeeze()), axis=0)
-        
-#         ent_ = [pt_full, label_full.astype(np.int32), hm_full]
-#         write_ply(f'./accumulated_piecewise/pt_full.ply', ent_, ['x', 'y', 'z', 'label', 'pgscam'])
-#         print(pt_full.shape, hm_full.shape, label_full.shape)
-            
-            
-            
-            
-#             end_points_ = input_model(batch_)
-            
-#             mean_iou_, iou_list_, loss_ = self.compute_iou_(end_points_, config)
-#             self.display_iou(mean_iou_, iou_list_, end_points_['xyz'][0].squeeze())
-            
-#             logits = end_points_['logits']
-        
-#             softmax = torch.nn.Softmax(1)
-#             preds = softmax(logits).argmax(dim=1).squeeze().detach().cpu().numpy().astype(np.int32)
-            
-#             entities = [end_points_['xyz'][0].squeeze().detach().cpu().numpy(), end_points_['labels'].squeeze().detach().cpu().numpy().astype(np.int32), preds]
-            
-#             write_ply(f'./drop_vis/{self.transform_map[self.cls]}_SemanticKITTI_drop_{drop_}', entities, ['x', 'y', 'z', 'cls', 'preds'])
+
+        #             entities = [batch_['xyz'][0].squeeze().detach().cpu().numpy(), batch_['labels'].squeeze().cpu().numpy().astype(np.int32), hm.squeeze()]
+
+        #             write_ply(f'./accumulated_piecewise/{self.transform_map[self.cls]}_SemanticKITTI_drop_{drop_}', entities, ['x', 'y', 'z', 'cls', 'hm'])
+
+        #         pt_full = np.empty(shape=(0,3))
+        #         hm_full = np.empty(shape=(0,))
+        #         label_full = np.empty(shape=(0,))
+        #         for entity in point_collect:
+        #             pt_, lb_, hm_ = entity
+        #             pt_full = np.concatenate((pt_full, pt_.squeeze()), axis=0)
+        #             hm_full = np.concatenate((hm_full, hm_.squeeze()), axis=0)
+        #             label_full = np.concatenate((label_full, lb_.squeeze()), axis=0)
+
+        #         pt_full = np.concatenate((pt_full, point_0.squeeze()), axis=0)
+        #         hm_full = np.concatenate((hm_full, hm.squeeze()), axis=0)
+        #         label_full = np.concatenate((label_full, label_0.squeeze()), axis=0)
+
+        #         ent_ = [pt_full, label_full.astype(np.int32), hm_full]
+        #         write_ply(f'./accumulated_piecewise/pt_full.ply', ent_, ['x', 'y', 'z', 'label', 'pgscam'])
+        #         print(pt_full.shape, hm_full.shape, label_full.shape)
+
+        #             end_points_ = input_model(batch_)
+
+        #             mean_iou_, iou_list_, loss_ = self.compute_iou_(end_points_, config)
+        #             self.display_iou(mean_iou_, iou_list_, end_points_['xyz'][0].squeeze())
+
+        #             logits = end_points_['logits']
+
+        #             softmax = torch.nn.Softmax(1)
+        #             preds = softmax(logits).argmax(dim=1).squeeze().detach().cpu().numpy().astype(np.int32)
+
+        #             entities = [end_points_['xyz'][0].squeeze().detach().cpu().numpy(), end_points_['labels'].squeeze().detach().cpu().numpy().astype(np.int32), preds]
+
+        #             write_ply(f'./drop_vis/{self.transform_map[self.cls]}_SemanticKITTI_drop_{drop_}', entities, ['x', 'y', 'z', 'cls', 'preds'])
         return miou_collect, ciou_collect
-        
-        
+
     def compute_iou_(self, end_points, config):
         loss, end_points = compute_loss(end_points, config)
         acc, end_points = compute_acc(end_points)
-        
+
         iou_calc = IoUCalculator(config)
         iou_calc.add_data(end_points)
         mean_iou, iou_list = iou_calc.compute_iou()
-        
+
         return mean_iou, iou_list, loss
-        
+
     def display_iou(self, mean_iou, iou_list, points):
-#         print(f"Points shape: {points.shape}\n")
-#         print("Class Wise IoU: \n")
-#         for i in range(len(iou_list)):
-#             print(f'{self.transform_map[i]}: {iou_list[i]*100}')
-            
-#         print(f"\nMean IoU: {mean_iou * 100}\n")
-        
-#         print(f"Class IoU: {iou_list[self.cls]*100}\n")
-        
-        return (mean_iou * 100, iou_list[self.cls]*100)
-        
- 
-
-class piecewise_pGSCAM():
-    def __init__(self, input_model, batch, config, mask_type="subset", mode="normal", norm=False, cls=-1):
+        #         print(f"Points shape: {points.shape}\n")
+        #         print("Class Wise IoU: \n")
+        #         for i in range(len(iou_list)):
+        #             print(f'{self.transform_map[i]}: {iou_list[i]*100}')
+
+        #         print(f"\nMean IoU: {mean_iou * 100}\n")
+
+        #         print(f"Class IoU: {iou_list[self.cls]*100}\n")
+
+        return (mean_iou * 100, iou_list[self.cls] * 100)
+
+
+class piecewise_pGSCAM:
+    def __init__(
+        self,
+        input_model,
+        batch,
+        config,
+        mask_type="subset",
+        mode="normal",
+        norm=False,
+        cls=-1,
+    ):
         # mode: [normal, counterfactual]
         # mask_type: [none, single, subset]:- none(no mask), single(only single point), subset(collection of points)
-        
+
         self.input_model = input_model
         self.batch = batch
         self.cls = cls
         self.config = config
         self.norm = norm
@@ -437,134 +471,135 @@
         self.mode = mode
         self.mask_type = mask_type
         self.partial_heatmaps = []
         # actuall labels starts from unlabelled but we are ignoring it
         self.transform_map = {
-          0: "car",
-          1: "bicycle",
-          2: "motorcycle",
-          3: "truck",
-          4: "other-vehicle",
-          5: "person",
-          6: "bicyclist",
-          7: "motorcyclist",
-          8: "road",
-          9: "parking",
-          10: "sidewalk",
-          11: "other-ground",
-          12: "building",
-          13: "fence",
-          14: "vegetation",
-          15: "trunk",
-          16: "terrain",
-          17: "pole",
-          18: "traffic-sign"
-      }
-        
+            0: "car",
+            1: "bicycle",
+            2: "motorcycle",
+            3: "truck",
+            4: "other-vehicle",
+            5: "person",
+            6: "bicyclist",
+            7: "motorcyclist",
+            8: "road",
+            9: "parking",
+            10: "sidewalk",
+            11: "other-ground",
+            12: "building",
+            13: "fence",
+            14: "vegetation",
+            15: "trunk",
+            16: "terrain",
+            17: "pole",
+            18: "traffic-sign",
+        }
+
     @staticmethod
     def my_worker_init_fn(worker_id):
-#         np.random.seed(np.random.get_state()[1][0] + worker_id)
+        #         np.random.seed(np.random.get_state()[1][0] + worker_id)
         np.random.seed(0)
-        
+
     def runCAM(self):
         net = self.input_model
         net.eval()
         batch = self.batch
         config = self.config
-        
-#         while True:
+
+        #         while True:
         cam = PowerCAM(net, batch, config, norm=False, cls=self.cls)
         _ = cam.runCAM()
         vanilla_heatmaps = cam.heatmaps_III_kdtree
         activations = cam.activations
 
         # I am interested in act -1
         act = activations[-1]
         hm_orig = vanilla_heatmaps[-1]
-        point_orig = self.batch['xyz'][0].detach().cpu().numpy()
-        label_orig = self.batch['labels'].cpu().numpy()
-        
+        point_orig = self.batch["xyz"][0].detach().cpu().numpy()
+        label_orig = self.batch["labels"].cpu().numpy()
+
         point = point_orig
         label = label_orig
-        hm  = hm_orig
+        hm = hm_orig
         point_temp = []
-#         partial_ind_delete = ['dummy']
+        #         partial_ind_delete = ['dummy']
         itr = 5
-        
+
         while itr:
-                partial_ind_delete = np.argwhere(hm.squeeze() >= 0.8).squeeze()
-                partial_ind_accept = np.argwhere(hm.squeeze() <= 0.8).squeeze()
-                point_ = point[:, partial_ind_delete, :]
-                label_ = label[:, partial_ind_delete]
-                hm_ = hm[:, partial_ind_delete]
-                point_temp.append((point_, label_, hm_))
-                
-                point = point[:, partial_ind_accept, :]
-                label = label[:, partial_ind_accept]
-                
-                print(point.shape, label.shape, partial_ind_delete)
-
-                DATASET = SemanticKITTI(point.squeeze(), label.squeeze())
-
-                DATALOADER = DataLoader(DATASET, batch_size=1, shuffle=True, num_workers=20, worker_init_fn=self.my_worker_init_fn, collate_fn=DATASET.collate_fn)
-
-                for batch_ in DATALOADER:
-                    for key in batch_:
-                        if type(batch_[key]) is list:
-                            for i in range(len(batch_[key])):
-                                batch_[key][i] = batch_[key][i].cuda()
-                        else:
-                            batch_[key] = batch_[key].cuda()
-                    continue
-
-
-                cam_ = PowerCAM(net, batch_, config, norm=False, cls=self.cls)
-                _ = cam_.runCAM()
-                heatmaps_ = cam_.heatmaps_III_kdtree
-                hm = heatmaps_[-1]
-                
-                ent_ = [point.squeeze(), label.squeeze().astype(np.int32), hm.squeeze()]
-                write_ply(f'./accumulated_piecewise/{point.shape[1]}.ply', ent_, ['x', 'y', 'z', 'label', 'pgscam'])
-                itr = itr - 1
-                
-#             except:
-#                 break
-            
-        pt_full = np.empty(shape=(0,3))
+            partial_ind_delete = np.argwhere(hm.squeeze() >= 0.8).squeeze()
+            partial_ind_accept = np.argwhere(hm.squeeze() <= 0.8).squeeze()
+            point_ = point[:, partial_ind_delete, :]
+            label_ = label[:, partial_ind_delete]
+            hm_ = hm[:, partial_ind_delete]
+            point_temp.append((point_, label_, hm_))
+
+            point = point[:, partial_ind_accept, :]
+            label = label[:, partial_ind_accept]
+
+            print(point.shape, label.shape, partial_ind_delete)
+
+            DATASET = SemanticKITTI(point.squeeze(), label.squeeze())
+
+            DATALOADER = DataLoader(
+                DATASET,
+                batch_size=1,
+                shuffle=True,
+                num_workers=20,
+                worker_init_fn=self.my_worker_init_fn,
+                collate_fn=DATASET.collate_fn,
+            )
+
+            for batch_ in DATALOADER:
+                for key in batch_:
+                    if type(batch_[key]) is list:
+                        for i in range(len(batch_[key])):
+                            batch_[key][i] = batch_[key][i].cuda()
+                    else:
+                        batch_[key] = batch_[key].cuda()
+                continue
+
+            cam_ = PowerCAM(net, batch_, config, norm=False, cls=self.cls)
+            _ = cam_.runCAM()
+            heatmaps_ = cam_.heatmaps_III_kdtree
+            hm = heatmaps_[-1]
+
+            ent_ = [point.squeeze(), label.squeeze().astype(np.int32), hm.squeeze()]
+            write_ply(
+                f"./accumulated_piecewise/{point.shape[1]}.ply",
+                ent_,
+                ["x", "y", "z", "label", "pgscam"],
+            )
+            itr = itr - 1
+
+        #             except:
+        #                 break
+
+        pt_full = np.empty(shape=(0, 3))
         hm_full = np.empty(shape=(0,))
         label_full = np.empty(shape=(0,))
         for entity in point_temp:
             pt_, lb_, hm_ = entity
             pt_full = np.concatenate((pt_full, pt_.squeeze()), axis=0)
             hm_full = np.concatenate((hm_full, hm_.squeeze()), axis=0)
             label_full = np.concatenate((label_full, lb_.squeeze()), axis=0)
-        
+
         pt_full = np.concatenate((pt_full, point.squeeze()), axis=0)
         hm_full = np.concatenate((hm_full, hm.squeeze()), axis=0)
         label_full = np.concatenate((label_full, label.squeeze()), axis=0)
-        
+
         ent_ = [pt_full, label_full.astype(np.int32), hm_full]
-        write_ply(f'./accumulated_piecewise/pt_full.ply', ent_, ['x', 'y', 'z', 'label', 'pgscam'])
+        write_ply(
+            f"./accumulated_piecewise/pt_full.ply",
+            ent_,
+            ["x", "y", "z", "label", "pgscam"],
+        )
         print(pt_full.shape, hm_full.shape, label_full.shape)
-        
-            
-            
-            
+
 
 #         print(point_.shape)
-            
-            
-        
-        
-        
-        
-        
-        
-        
-        
-        
-        
+
+
 #     def getmIoU(self):
 # #         num_points = self.getGradients()
 #         hm_IoU = []
 #         hm_1_list, hm_2_list, hm_3_list = self.heatmaps_I, self.heatmaps_I_II, self.heatmaps_I_II_III
 # #         hm_1_list, hm_2_list, hm_3_list = self.heatmap()
@@ -574,137 +609,143 @@
 # #         print(hm_1.shape, hm_2.shape, hm_3.shape)
 #         logits = self.end_points['logits']
 #         softmax = torch.nn.Softmax(1)
 #         preds = softmax(logits).argmax(dim=1).squeeze()
 
-        
+
 #         pred_mask = (preds == self.cls).type(torch.int32)
 #         hm_1 = (hm_1 > self.threshold[0]).type(torch.int32)
 #         hm_2 = (hm_2 > self.threshold[1]).type(torch.int32)
 #         hm_3 = (hm_3 > self.threshold[2]).type(torch.int32)
 #         iou_metric = IoUCalculator()
 #         iou_metric.add_data(hm_1, pred_mask)
 #         mean_iou, iou_list = iou_metric.compute_iou()
 #         cls_iou = iou_list[1]*100
 #         hm_IoU.append(cls_iou)
-        
+
 # #         iou_metric = IoUCalculator()
 #         iou_metric.add_data(hm_2, pred_mask)
 #         mean_iou, iou_list = iou_metric.compute_iou()
 #         cls_iou = iou_list[1]*100
 #         hm_IoU.append(cls_iou)
-        
-        
+
+
 # #         iou_metric = IoUCalculator()
 #         iou_metric.add_data(hm_3, pred_mask)
 #         mean_iou, iou_list = iou_metric.compute_iou()
 #         cls_iou = iou_list[1]*100
 #         hm_IoU.append(cls_iou)
 
 #         return hm_IoU
 #         self.visCAM()
 
 
-class TSNE_cls():
+class TSNE_cls:
     def __init__(self, input_model, batch, config, norm=False, cls=-1):
         self.input_model = input_model
         self.batch = batch
         self.cls = cls
         self.config = config
         self.norm = norm
         self.is_masked = True
         self.threshold = [0.1, 0.3, 0.3]
-        
+
         # actuall labels starts from unlabelled but we are ignoring it
         self.transform_map = {
-          0: "car",
-          1: "bicycle",
-          2: "motorcycle",
-          3: "truck",
-          4: "other-vehicle",
-          5: "person",
-          6: "bicyclist",
-          7: "motorcyclist",
-          8: "road",
-          9: "parking",
-          10: "sidewalk",
-          11: "other-ground",
-          12: "building",
-          13: "fence",
-          14: "vegetation",
-          15: "trunk",
-          16: "terrain",
-          17: "pole",
-          18: "traffic-sign"
-      }
-        
+            0: "car",
+            1: "bicycle",
+            2: "motorcycle",
+            3: "truck",
+            4: "other-vehicle",
+            5: "person",
+            6: "bicyclist",
+            7: "motorcyclist",
+            8: "road",
+            9: "parking",
+            10: "sidewalk",
+            11: "other-ground",
+            12: "building",
+            13: "fence",
+            14: "vegetation",
+            15: "trunk",
+            16: "terrain",
+            17: "pole",
+            18: "traffic-sign",
+        }
+
     def getActivations(self):
         print(f"Current class: {self.transform_map[self.cls]}")
         self.input_model.eval()
         self.end_points = self.input_model(self.batch)
-        logits = self.end_points['logits']
-        
+        logits = self.end_points["logits"]
+
         softmax = torch.nn.Softmax(1)
         preds = softmax(logits).argmax(dim=1)
-        
+
         logits = softmax(logits)
         mask = ((preds.squeeze(0) == self.cls).unsqueeze(0)).unsqueeze(1)
-        print(f"Number of points for class {self.transform_map[self.cls]}: ", torch.sum(mask.squeeze()).item())
-        
-        self.activations = self.end_points['activations']
-        
+        print(
+            f"Number of points for class {self.transform_map[self.cls]}: ",
+            torch.sum(mask.squeeze()).item(),
+        )
+
+        self.activations = self.end_points["activations"]
+
         print(len(self.activations))
-        
+
         return torch.sum(mask.squeeze()).item()
-    
-    
+
     def t_sne(self, i_act):
         act = self.activations[i_act]
-        
-        labels = self.end_points['labels'].cpu().numpy().astype(np.int32).squeeze()
-        logits = self.end_points['logits']
+
+        labels = self.end_points["labels"].cpu().numpy().astype(np.int32).squeeze()
+        logits = self.end_points["logits"]
         softmax = torch.nn.Softmax(1)
         preds = softmax(logits).argmax(dim=1).squeeze().cpu().numpy().astype(np.int32)
-        
+
         act = act.squeeze().T
-#         tsne = TSNE()
+        #         tsne = TSNE()
         reducer = PCA(n_components=2)
         act_reduce = reducer.fit_transform(act.detach().cpu().numpy())
-        np.save(f'./tsne_vis/pca_act_{i_act}', act_reduce)
-        
+        np.save(f"./tsne_vis/pca_act_{i_act}", act_reduce)
+
         print("Computing umap:")
         reducer = TSNE()
         act_reduce = reducer.fit_transform(act.detach().cpu().numpy())
-        np.save(f'./tsne_vis/tsne_act_{i_act}', act_reduce)
-        
-        np.save(f'./tsne_vis/preds', preds)
-        np.save(f'./tsne_vis/labels', labels)
-        palette = sns.color_palette('bright', 10)
-#         sns.scatterplot(act_reduce[:, 0], act_reduce[:, 1], hue=labels, legend='full', palette=palette)
-
-        
-        
+        np.save(f"./tsne_vis/tsne_act_{i_act}", act_reduce)
+
+        np.save(f"./tsne_vis/preds", preds)
+        np.save(f"./tsne_vis/labels", labels)
+        palette = sns.color_palette("bright", 10)
+
+    #         sns.scatterplot(act_reduce[:, 0], act_reduce[:, 1], hue=labels, legend='full', palette=palette)
+
     def runCAM(self):
-        cam = PowerCAM(self.input_model, self.batch, self.config, norm=True, cls=self.cls, mode='normal', mask_type='none')
+        cam = PowerCAM(
+            self.input_model,
+            self.batch,
+            self.config,
+            norm=True,
+            cls=self.cls,
+            mode="normal",
+            mask_type="none",
+        )
         num_points = cam.runCAM()
         print(num_points)
-        
+
         num_points = self.getActivations()
         for act_i in [0, 7, 8, 9, 10]:
             self.t_sne(act_i)
         return num_points
-        
-    
 
 
 class IoUCalculator_heatmaps:
     def __init__(self):
         self.num_classes = 2
         self.gt_classes = [0 for _ in range(self.num_classes)]
         self.positive_classes = [0 for _ in range(self.num_classes)]
         self.true_positive_classes = [0 for _ in range(self.num_classes)]
-       
 
     def add_data(self, hm, pred_mask):
         hm_valid = hm.detach().cpu().numpy()
         pred_mask_valid = pred_mask.detach().cpu().numpy()
 
@@ -713,20 +754,33 @@
 
         correct = np.sum(hm_valid == pred_mask_valid)
         val_total_correct += correct
         val_total_seen += len(pred_mask_valid)
 
-        conf_matrix = confusion_matrix(pred_mask_valid, hm_valid, labels=np.arange(0, self.num_classes, 1))
+        conf_matrix = confusion_matrix(
+            pred_mask_valid, hm_valid, labels=np.arange(0, self.num_classes, 1)
+        )
         self.gt_classes += np.sum(conf_matrix, axis=1)
         self.positive_classes += np.sum(conf_matrix, axis=0)
         self.true_positive_classes += np.diagonal(conf_matrix)
 
     def compute_iou(self):
         iou_list = []
         for n in range(0, self.num_classes, 1):
-            if float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n]) != 0:
-                iou = self.true_positive_classes[n] / float(self.gt_classes[n] + self.positive_classes[n] - self.true_positive_classes[n])
+            if (
+                float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
+                != 0
+            ):
+                iou = self.true_positive_classes[n] / float(
+                    self.gt_classes[n]
+                    + self.positive_classes[n]
+                    - self.true_positive_classes[n]
+                )
                 iou_list.append(iou)
             else:
                 iou_list.append(0.0)
         mean_iou = sum(iou_list) / float(self.num_classes)
         return mean_iou, iou_list
--- /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/ply.py	2024-06-30 22:34:21.618443+00:00
+++ /mnt/c/faps/XAI/pGS-CAM/RandLANet/utils/ply.py	2024-07-08 11:53:49.203140+00:00
@@ -26,32 +26,33 @@
 import numpy as np
 import sys
 
 
 # Define PLY types
-ply_dtypes = dict([
-    (b'int8', 'i1'),
-    (b'char', 'i1'),
-    (b'uint8', 'u1'),
-    (b'uchar', 'u1'),
-    (b'int16', 'i2'),
-    (b'short', 'i2'),
-    (b'uint16', 'u2'),
-    (b'ushort', 'u2'),
-    (b'int32', 'i4'),
-    (b'int', 'i4'),
-    (b'uint32', 'u4'),
-    (b'uint', 'u4'),
-    (b'float32', 'f4'),
-    (b'float', 'f4'),
-    (b'float64', 'f8'),
-    (b'double', 'f8')
-])
+ply_dtypes = dict(
+    [
+        (b"int8", "i1"),
+        (b"char", "i1"),
+        (b"uint8", "u1"),
+        (b"uchar", "u1"),
+        (b"int16", "i2"),
+        (b"short", "i2"),
+        (b"uint16", "u2"),
+        (b"ushort", "u2"),
+        (b"int32", "i4"),
+        (b"int", "i4"),
+        (b"uint32", "u4"),
+        (b"uint", "u4"),
+        (b"float32", "f4"),
+        (b"float", "f4"),
+        (b"float64", "f8"),
+        (b"double", "f8"),
+    ]
+)
 
 # Numpy reader format
-valid_formats = {'ascii': '', 'binary_big_endian': '>',
-                 'binary_little_endian': '<'}
+valid_formats = {"ascii": "", "binary_big_endian": ">", "binary_little_endian": "<"}
 
 
 # ----------------------------------------------------------------------------------------------------------------------
 #
 #           Functions
@@ -63,18 +64,18 @@
     # Variables
     line = []
     properties = []
     num_points = None
 
-    while b'end_header' not in line and line != b'':
+    while b"end_header" not in line and line != b"":
         line = plyfile.readline()
 
-        if b'element' in line:
+        if b"element" in line:
             line = line.split()
             num_points = int(line[2])
 
-        elif b'property' in line:
+        elif b"property" in line:
             line = line.split()
             properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))
 
     return num_points, properties
 
@@ -85,32 +86,31 @@
     vertex_properties = []
     num_points = None
     num_faces = None
     current_element = None
 
-
-    while b'end_header' not in line and line != b'':
+    while b"end_header" not in line and line != b"":
         line = plyfile.readline()
 
         # Find point element
-        if b'element vertex' in line:
-            current_element = 'vertex'
+        if b"element vertex" in line:
+            current_element = "vertex"
             line = line.split()
             num_points = int(line[2])
 
-        elif b'element face' in line:
-            current_element = 'face'
+        elif b"element face" in line:
+            current_element = "face"
             line = line.split()
             num_faces = int(line[2])
 
-        elif b'property' in line:
-            if current_element == 'vertex':
+        elif b"property" in line:
+            if current_element == "vertex":
                 line = line.split()
                 vertex_properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))
-            elif current_element == 'vertex':
-                if not line.startswith('property list uchar int'):
-                    raise ValueError('Unsupported faces property : ' + line)
+            elif current_element == "vertex":
+                if not line.startswith("property list uchar int"):
+                    raise ValueError("Unsupported faces property : " + line)
 
     return num_points, num_faces, vertex_properties
 
 
 def read_ply(filename, triangular_mesh=False):
@@ -138,31 +138,30 @@
     Read the file
 
     >>> data = read_ply('example.ply')
     >>> values = data['values']
     array([0, 0, 1, 1, 0])
-    
+
     >>> points = np.vstack((data['x'], data['y'], data['z'])).T
     array([[ 0.466  0.595  0.324]
            [ 0.538  0.407  0.654]
            [ 0.850  0.018  0.988]
            [ 0.395  0.394  0.363]
            [ 0.873  0.996  0.092]])
 
     """
 
-    with open(filename, 'rb') as plyfile:
-
+    with open(filename, "rb") as plyfile:
 
         # Check if the file start with ply
-        if b'ply' not in plyfile.readline():
-            raise ValueError('The file does not start whith the word ply')
+        if b"ply" not in plyfile.readline():
+            raise ValueError("The file does not start whith the word ply")
 
         # get binary_little/big or ascii
         fmt = plyfile.readline().split()[1].decode()
         if fmt == "ascii":
-            raise ValueError('The file is not binary')
+            raise ValueError("The file is not binary")
 
         # get extension for building the numpy dtypes
         ext = valid_formats[fmt]
 
         # PointCloud reader vs mesh reader
@@ -173,18 +172,20 @@
 
             # Get point data
             vertex_data = np.fromfile(plyfile, dtype=properties, count=num_points)
 
             # Get face data
-            face_properties = [('k', ext + 'u1'),
-                               ('v1', ext + 'i4'),
-                               ('v2', ext + 'i4'),
-                               ('v3', ext + 'i4')]
+            face_properties = [
+                ("k", ext + "u1"),
+                ("v1", ext + "i4"),
+                ("v2", ext + "i4"),
+                ("v3", ext + "i4"),
+            ]
             faces_data = np.fromfile(plyfile, dtype=face_properties, count=num_faces)
 
             # Return vertex data and concatenated faces
-            faces = np.vstack((faces_data['v1'], faces_data['v2'], faces_data['v3'])).T
+            faces = np.vstack((faces_data["v1"], faces_data["v2"], faces_data["v3"])).T
             data = [vertex_data, faces]
 
         else:
 
             # Parse header
@@ -200,17 +201,17 @@
 
     # List of lines to write
     lines = []
 
     # First line describing element vertex
-    lines.append('element vertex %d' % field_list[0].shape[0])
+    lines.append("element vertex %d" % field_list[0].shape[0])
 
     # Properties lines
     i = 0
     for fields in field_list:
         for field in fields.T:
-            lines.append('property %s %s' % (field.dtype.name, field_names[i]))
+            lines.append("property %s %s" % (field.dtype.name, field_names[i]))
             i += 1
 
     return lines
 
 
@@ -219,20 +220,20 @@
     Write ".ply" files
 
     Parameters
     ----------
     filename : string
-        the name of the file to which the data is saved. A '.ply' extension will be appended to the 
+        the name of the file to which the data is saved. A '.ply' extension will be appended to the
         file name if it does no already have one.
 
     field_list : list, tuple, numpy array
-        the fields to be saved in the ply file. Either a numpy array, a list of numpy arrays or a 
-        tuple of numpy arrays. Each 1D numpy array and each column of 2D numpy arrays are considered 
-        as one field. 
+        the fields to be saved in the ply file. Either a numpy array, a list of numpy arrays or a
+        tuple of numpy arrays. Each 1D numpy array and each column of 2D numpy arrays are considered
+        as one field.
 
     field_names : list
-        the name of each fields as a list of strings. Has to be the same length as the number of 
+        the name of each fields as a list of strings. Has to be the same length as the number of
         fields.
 
     Examples
     --------
     >>> points = np.random.rand(10, 3)
@@ -246,60 +247,64 @@
     >>> write_ply('example3.ply', [points, colors, values], field_names)
 
     """
 
     # Format list input to the right form
-    field_list = list(field_list) if (type(field_list) == list or type(field_list) == tuple) else list((field_list,))
+    field_list = (
+        list(field_list)
+        if (type(field_list) == list or type(field_list) == tuple)
+        else list((field_list,))
+    )
     for i, field in enumerate(field_list):
         if field.ndim < 2:
             field_list[i] = field.reshape(-1, 1)
         if field.ndim > 2:
-            print('fields have more than 2 dimensions')
-            return False    
+            print("fields have more than 2 dimensions")
+            return False
 
     # check all fields have the same number of data
     n_points = [field.shape[0] for field in field_list]
     if not np.all(np.equal(n_points, n_points[0])):
-        print('wrong field dimensions')
-        return False    
+        print("wrong field dimensions")
+        return False
 
     # Check if field_names and field_list have same nb of column
     n_fields = np.sum([field.shape[1] for field in field_list])
-    if (n_fields != len(field_names)):
-        print('wrong number of field names')
+    if n_fields != len(field_names):
+        print("wrong number of field names")
         return False
 
     # Add extension if not there
-    if not filename.endswith('.ply'):
-        filename += '.ply'
+    if not filename.endswith(".ply"):
+        filename += ".ply"
 
     # open in text mode to write the header
-    with open(filename, 'w') as plyfile:
+    with open(filename, "w") as plyfile:
 
         # First magical word
-        header = ['ply']
+        header = ["ply"]
 
         # Encoding format
-        header.append('format binary_' + sys.byteorder + '_endian 1.0')
+        header.append("format binary_" + sys.byteorder + "_endian 1.0")
 
         # Points properties description
         header.extend(header_properties(field_list, field_names))
 
         # Add faces if needded
         if triangular_faces is not None:
-            header.append('element face {:d}'.format(triangular_faces.shape[0]))
-            header.append('property list uchar int vertex_indices')
+            header.append("element face {:d}".format(triangular_faces.shape[0]))
+            header.append("property list uchar int vertex_indices")
 
         # End of header
-        header.append('end_header')
+        header.append("end_header")
 
         # Write all lines
         for line in header:
             plyfile.write("%s\n" % line)
 
     # open in binary/append to use tofile
-    with open(filename, 'ab') as plyfile:
+    with open(filename, "ab") as plyfile:
 
         # Create a structured array
         i = 0
         type_list = []
         for fields in field_list:
@@ -315,41 +320,41 @@
 
         data.tofile(plyfile)
 
         if triangular_faces is not None:
             triangular_faces = triangular_faces.astype(np.int32)
-            type_list = [('k', 'uint8')] + [(str(ind), 'int32') for ind in range(3)]
+            type_list = [("k", "uint8")] + [(str(ind), "int32") for ind in range(3)]
             data = np.empty(triangular_faces.shape[0], dtype=type_list)
-            data['k'] = np.full((triangular_faces.shape[0],), 3, dtype=np.uint8)
-            data['0'] = triangular_faces[:, 0]
-            data['1'] = triangular_faces[:, 1]
-            data['2'] = triangular_faces[:, 2]
+            data["k"] = np.full((triangular_faces.shape[0],), 3, dtype=np.uint8)
+            data["0"] = triangular_faces[:, 0]
+            data["1"] = triangular_faces[:, 1]
+            data["2"] = triangular_faces[:, 2]
             data.tofile(plyfile)
 
     return True
 
 
 def describe_element(name, df):
-    """ Takes the columns of the dataframe and builds a ply-like description
+    """Takes the columns of the dataframe and builds a ply-like description
 
     Parameters
     ----------
     name: str
     df: pandas DataFrame
 
     Returns
     -------
     element: list[str]
     """
-    property_formats = {'f': 'float', 'u': 'uchar', 'i': 'int'}
-    element = ['element ' + name + ' ' + str(len(df))]
-
-    if name == 'face':
+    property_formats = {"f": "float", "u": "uchar", "i": "int"}
+    element = ["element " + name + " " + str(len(df))]
+
+    if name == "face":
         element.append("property list uchar int points_indices")
 
     else:
         for i in range(len(df.columns)):
             # get first letter of dtype to infer format
             f = property_formats[str(df.dtypes[i])[0]]
-            element.append('property ' + f + ' ' + df.columns.values[i])
-
-    return element
\ No newline at end of file
+            element.append("property " + f + " " + df.columns.values[i])
+
+    return element
